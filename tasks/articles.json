[
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Nuxt.js`,\n  description: `How to deploy a Nuxt site to Amplify Console Hosting`,\n};\n\nimport js0 from \"/src/fragments/guides/hosting/nuxt.mdx\";\n\n<Fragments fragments={{js: js0}} />\n",
    "meta": {
      "title": "Nuxt.js - JavaScript",
      "description": "How to deploy a Nuxt site to Amplify Console Hosting - JavaScript",
      "subcategory": "Hosting",
      "category": "Guides"
    },
    "filename": "/guides/hosting/nuxt/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Gridsome`,\n  description: `How to deploy a Gridsome site to Amplify Console Hosting`,\n};\n\nimport js0 from \"/src/fragments/guides/hosting/gridsome.mdx\";\n\n<Fragments fragments={{js: js0}} />\n",
    "meta": {
      "title": "Gridsome - JavaScript",
      "description": "How to deploy a Gridsome site to Amplify Console Hosting - JavaScript",
      "subcategory": "Hosting",
      "category": "Guides"
    },
    "filename": "/guides/hosting/gridsome/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Next.js`,\n  description: `How to deploy a Next.js Site to Amplify Hosting`,\n};\n\nimport js0 from \"/src/fragments/guides/hosting/nextjs.mdx\";\n\n<Fragments fragments={{js: js0}} />\n",
    "meta": {
      "title": "Next.js - JavaScript",
      "description": "How to deploy a Next.js Site to Amplify Hosting - JavaScript",
      "subcategory": "Hosting",
      "category": "Guides"
    },
    "filename": "/guides/hosting/nextjs/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Gatsby`,\n  description: `How to deploy a Gatsby site to Amplify Console Hosting`,\n};\n\nimport js0 from \"/src/fragments/guides/hosting/gatsby.mdx\";\n\n<Fragments fragments={{js: js0}} />\n",
    "meta": {
      "title": "Gatsby - JavaScript",
      "description": "How to deploy a Gatsby site to Amplify Console Hosting - JavaScript",
      "subcategory": "Hosting",
      "category": "Guides"
    },
    "filename": "/guides/hosting/gatsby/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Pull-request previews`,\n  description: `How to enable pull-request previews with Amplify hosting`,\n};\n\nimport js0 from \"/src/fragments/guides/hosting/pull-request-previews.mdx\";\n\n<Fragments fragments={{js: js0}} />",
    "meta": {
      "title": "Pull-request previews - JavaScript",
      "description": "How to enable pull-request previews with Amplify hosting - JavaScript",
      "subcategory": "Hosting",
      "category": "Guides"
    },
    "filename": "/guides/hosting/pull-request-previews/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Password protected deployments`,\n  description: `How to enable password-protection for your Amplify web deployments`,\n};\n\nimport js0 from \"/src/fragments/guides/hosting/password-protected-deployments.mdx\";\n\n<Fragments fragments={{js: js0}} />\n",
    "meta": {
      "title": "Password protected deployments - JavaScript",
      "description": "How to enable password-protection for your Amplify web deployments - JavaScript",
      "subcategory": "Hosting",
      "category": "Guides"
    },
    "filename": "/guides/hosting/password-protected-deployments/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Custom Domains`,\n  description: `How to enable a custom domain name using Amplify hosting`,\n};\n\nimport js0 from \"/src/fragments/guides/hosting/custom-domains.mdx\";\n\n<Fragments fragments={{js: js0}} />",
    "meta": {
      "title": "Custom Domains - JavaScript",
      "description": "How to enable a custom domain name using Amplify hosting - JavaScript",
      "subcategory": "Hosting",
      "category": "Guides"
    },
    "filename": "/guides/hosting/custom-domains/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Local deployments`,\n  description: `How to deploy a static site to Amplify hosting using a local project`,\n};\n\nimport js0 from \"/src/fragments/guides/hosting/local-deployments.mdx\";\n\n<Fragments fragments={{js: js0}} />\n",
    "meta": {
      "title": "Local deployments - JavaScript",
      "description": "How to deploy a static site to Amplify hosting using a local project - JavaScript",
      "subcategory": "Hosting",
      "category": "Guides"
    },
    "filename": "/guides/hosting/local-deployments/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Git-based deployments`,\n  description: `How to deploy a static site to Amplify hosting using a Git repo`,\n};\n\nimport js0 from \"/src/fragments/guides/hosting/git-based-deployments.mdx\";\n\n<Fragments fragments={{js: js0}} />",
    "meta": {
      "title": "Git-based deployments - JavaScript",
      "description": "How to deploy a static site to Amplify hosting using a Git repo - JavaScript",
      "subcategory": "Hosting",
      "category": "Guides"
    },
    "filename": "/guides/hosting/git-based-deployments/q/platform/js"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "You may want to override the Amplify CLI default configurations for your Lambda function or configure changes not available within the amplify add function workflow."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Example: When creating a Node.js function, the CLI will automatically configure a runtime version, a default memory size, and more. There are a few things you may want to override or configure:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Runtime"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Memory size"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Environment variables"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Let's look at how to update all of these things."
      },
      {
        "heading": "Updating the Runtime",
        "depth": 2,
        "text": "You may want to tweak the runtime version to be either a newer or older version than the Amplify-generated default."
      },
      {
        "heading": "Updating the Runtime",
        "depth": 2,
        "text": "Let's say we've deployed a Lambda function using a Node.js runtime and we want to modify the version of the runtime to be 14.x."
      },
      {
        "heading": "Updating the Runtime",
        "depth": 2,
        "text": "To do so, open amplify/backend/function/function-name/function-name-cloudformation-template.json and set the Runtime property in the LambdaFunction resource to:"
      },
      {
        "heading": "Updating the Runtime",
        "depth": 2,
        "text": "Next, deploy the updates using the Amplify CLI:"
      },
      {
        "heading": "Updating the default memory size",
        "depth": 2,
        "text": "When you deploy a function with Amplify, the default memory size will be set to a low setting (128MB). Often you will want to increase the default memory size in order to improve performance. A popular memory setting in Lambda is 1024MB as it speeds the function noticeably while usually keeping the cost the same or close to it."
      },
      {
        "heading": "Updating the default memory size",
        "depth": 2,
        "text": "To update the memory size, open amplify/backend/function/function-name/function-name-cloudformation-template.json and set the MemorySize property in the LambdaFunction resource:"
      },
      {
        "heading": "Updating the default memory size",
        "depth": 2,
        "text": "Next, deploy the updates using the Amplify CLI:"
      },
      {
        "heading": "Updating the default memory size",
        "depth": 2,
        "text": "To learn more about optimizing resources allocation for Lambda functions, check out this blog post."
      },
      {
        "heading": "Setting an environment variable",
        "depth": 2,
        "text": "A very common scenario is the need to set and use an environment variable in your Lambda function."
      },
      {
        "heading": "Setting an environment variable",
        "depth": 2,
        "text": "There are generally two types of environment variables:"
      },
      {
        "heading": "Setting an environment variable",
        "depth": 2,
        "text": "Secret values (example: access keys, API keys etc.)"
      },
      {
        "heading": "Setting an environment variable",
        "depth": 2,
        "text": "Non-secret values (example: endpoint information, locale information etc.)"
      },
      {
        "heading": "Setting an environment variable",
        "depth": 2,
        "text": "To view all configuration options available in AWS Lambda, check out the documentation here"
      },
      {
        "heading": "Setting an environment variable",
        "depth": 2,
        "text": "To learn more about extending the Amplify CLI with custom resources, check out the documentation here"
      }
    ],
    "source": "export const meta = {\n  title: `Configuring Lambda function settings`,\n  description: `How to configure custom settings for your Lambda function`,\n};\n\nYou may want to override the Amplify CLI default configurations for your Lambda function or configure changes not available within the `amplify add function` workflow.\n\n*Example*: When creating a `Node.js` function, the CLI will automatically configure a runtime version, a default memory size, and more. There are a few things you may want to override or configure:\n\n1. Runtime\n2. Memory size\n3. Environment variables\n\nLet's look at how to update all of these things.\n\n## Updating the Runtime\n\nYou may want to tweak the runtime version to be either a newer or older version than the Amplify-generated default.\n\nLet's say we've deployed a Lambda function using a Node.js runtime and we want to modify the version of the runtime to be `14.x`.\n\nTo do so, open __amplify/backend/function/function-name/function-name-cloudformation-template.json__ and set the `Runtime` property in the `LambdaFunction` resource to:\n\n```json\n\"Resources\": {\n  \"LambdaFunction\": {\n      ...\n      \"Properties\": {\n        \"Runtime\": \"nodejs14.x\", // Runtime now set to 14.x\n        \"Layers\": [],\n      }\n      ...\n    }\n  },\n}\n```\n\nNext, deploy the updates using the Amplify CLI:\n\n```sh\namplify push\n```\n\n## Updating the default memory size\n\nWhen you deploy a function with Amplify, the default memory size will be set to a low setting (128MB). Often you will want to increase the default memory size in order to improve performance. A popular memory setting in Lambda is 1024MB as it speeds the function noticeably while usually keeping the cost the same or close to it.\n\nTo update the memory size, open __amplify/backend/function/function-name/function-name-cloudformation-template.json__ and set the `MemorySize` property in the `LambdaFunction` resource:\n\n```json\n\"Resources\": {\n  \"LambdaFunction\": {\n      ...\n      \"Properties\": {\n        \"Runtime\": \"nodejs14.x\",\n        \"MemorySize\": 1024, // Memory size now set to 1024 MB\n        \"Layers\": [],\n      }\n      ...\n    }\n  },\n}\n```\n\nNext, deploy the updates using the Amplify CLI:\n\n```sh\namplify push\n```\n\n_To learn more about optimizing resources allocation for Lambda functions, check out [this](https://dev.to/aws/deep-dive-finding-the-optimal-resources-allocation-for-your-lambda-functions-35a6) blog post._\n\n## Setting an environment variable\n\nA very common scenario is the need to set and use an environment variable in your Lambda function.\n\nThere are generally two types of environment variables:\n- [Secret values (example: access keys, API keys etc.)](/cli/function/secrets)\n- [Non-secret values (example: endpoint information, locale information etc.)](/cli/function/env-vars)\n\n<Callout>\n\nTo view all configuration options available in AWS Lambda, check out the documentation [here](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-lambda-function-environment.html)\n\nTo learn more about extending the Amplify CLI with custom resources, check out the documentation [here](/cli/usage/customcf)\n\n</Callout>\n",
    "meta": {
      "title": "Configuring Lambda function settings - iOS",
      "description": "How to configure custom settings for your Lambda function - iOS",
      "subcategory": "Functions",
      "category": "Guides"
    },
    "filename": "/guides/functions/configuring-lambda/q/platform/ios"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "You may want to override the Amplify CLI default configurations for your Lambda function or configure changes not available within the amplify add function workflow."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Example: When creating a Node.js function, the CLI will automatically configure a runtime version, a default memory size, and more. There are a few things you may want to override or configure:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Runtime"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Memory size"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Environment variables"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Let's look at how to update all of these things."
      },
      {
        "heading": "Updating the Runtime",
        "depth": 2,
        "text": "You may want to tweak the runtime version to be either a newer or older version than the Amplify-generated default."
      },
      {
        "heading": "Updating the Runtime",
        "depth": 2,
        "text": "Let's say we've deployed a Lambda function using a Node.js runtime and we want to modify the version of the runtime to be 14.x."
      },
      {
        "heading": "Updating the Runtime",
        "depth": 2,
        "text": "To do so, open amplify/backend/function/function-name/function-name-cloudformation-template.json and set the Runtime property in the LambdaFunction resource to:"
      },
      {
        "heading": "Updating the Runtime",
        "depth": 2,
        "text": "Next, deploy the updates using the Amplify CLI:"
      },
      {
        "heading": "Updating the default memory size",
        "depth": 2,
        "text": "When you deploy a function with Amplify, the default memory size will be set to a low setting (128MB). Often you will want to increase the default memory size in order to improve performance. A popular memory setting in Lambda is 1024MB as it speeds the function noticeably while usually keeping the cost the same or close to it."
      },
      {
        "heading": "Updating the default memory size",
        "depth": 2,
        "text": "To update the memory size, open amplify/backend/function/function-name/function-name-cloudformation-template.json and set the MemorySize property in the LambdaFunction resource:"
      },
      {
        "heading": "Updating the default memory size",
        "depth": 2,
        "text": "Next, deploy the updates using the Amplify CLI:"
      },
      {
        "heading": "Updating the default memory size",
        "depth": 2,
        "text": "To learn more about optimizing resources allocation for Lambda functions, check out this blog post."
      },
      {
        "heading": "Setting an environment variable",
        "depth": 2,
        "text": "A very common scenario is the need to set and use an environment variable in your Lambda function."
      },
      {
        "heading": "Setting an environment variable",
        "depth": 2,
        "text": "There are generally two types of environment variables:"
      },
      {
        "heading": "Setting an environment variable",
        "depth": 2,
        "text": "Secret values (example: access keys, API keys etc.)"
      },
      {
        "heading": "Setting an environment variable",
        "depth": 2,
        "text": "Non-secret values (example: endpoint information, locale information etc.)"
      },
      {
        "heading": "Setting an environment variable",
        "depth": 2,
        "text": "To view all configuration options available in AWS Lambda, check out the documentation here"
      },
      {
        "heading": "Setting an environment variable",
        "depth": 2,
        "text": "To learn more about extending the Amplify CLI with custom resources, check out the documentation here"
      }
    ],
    "source": "export const meta = {\n  title: `Configuring Lambda function settings`,\n  description: `How to configure custom settings for your Lambda function`,\n};\n\nYou may want to override the Amplify CLI default configurations for your Lambda function or configure changes not available within the `amplify add function` workflow.\n\n*Example*: When creating a `Node.js` function, the CLI will automatically configure a runtime version, a default memory size, and more. There are a few things you may want to override or configure:\n\n1. Runtime\n2. Memory size\n3. Environment variables\n\nLet's look at how to update all of these things.\n\n## Updating the Runtime\n\nYou may want to tweak the runtime version to be either a newer or older version than the Amplify-generated default.\n\nLet's say we've deployed a Lambda function using a Node.js runtime and we want to modify the version of the runtime to be `14.x`.\n\nTo do so, open __amplify/backend/function/function-name/function-name-cloudformation-template.json__ and set the `Runtime` property in the `LambdaFunction` resource to:\n\n```json\n\"Resources\": {\n  \"LambdaFunction\": {\n      ...\n      \"Properties\": {\n        \"Runtime\": \"nodejs14.x\", // Runtime now set to 14.x\n        \"Layers\": [],\n      }\n      ...\n    }\n  },\n}\n```\n\nNext, deploy the updates using the Amplify CLI:\n\n```sh\namplify push\n```\n\n## Updating the default memory size\n\nWhen you deploy a function with Amplify, the default memory size will be set to a low setting (128MB). Often you will want to increase the default memory size in order to improve performance. A popular memory setting in Lambda is 1024MB as it speeds the function noticeably while usually keeping the cost the same or close to it.\n\nTo update the memory size, open __amplify/backend/function/function-name/function-name-cloudformation-template.json__ and set the `MemorySize` property in the `LambdaFunction` resource:\n\n```json\n\"Resources\": {\n  \"LambdaFunction\": {\n      ...\n      \"Properties\": {\n        \"Runtime\": \"nodejs14.x\",\n        \"MemorySize\": 1024, // Memory size now set to 1024 MB\n        \"Layers\": [],\n      }\n      ...\n    }\n  },\n}\n```\n\nNext, deploy the updates using the Amplify CLI:\n\n```sh\namplify push\n```\n\n_To learn more about optimizing resources allocation for Lambda functions, check out [this](https://dev.to/aws/deep-dive-finding-the-optimal-resources-allocation-for-your-lambda-functions-35a6) blog post._\n\n## Setting an environment variable\n\nA very common scenario is the need to set and use an environment variable in your Lambda function.\n\nThere are generally two types of environment variables:\n- [Secret values (example: access keys, API keys etc.)](/cli/function/secrets)\n- [Non-secret values (example: endpoint information, locale information etc.)](/cli/function/env-vars)\n\n<Callout>\n\nTo view all configuration options available in AWS Lambda, check out the documentation [here](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-lambda-function-environment.html)\n\nTo learn more about extending the Amplify CLI with custom resources, check out the documentation [here](/cli/usage/customcf)\n\n</Callout>\n",
    "meta": {
      "title": "Configuring Lambda function settings - Android",
      "description": "How to configure custom settings for your Lambda function - Android",
      "subcategory": "Functions",
      "category": "Guides"
    },
    "filename": "/guides/functions/configuring-lambda/q/platform/android"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "You may want to override the Amplify CLI default configurations for your Lambda function or configure changes not available within the amplify add function workflow."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Example: When creating a Node.js function, the CLI will automatically configure a runtime version, a default memory size, and more. There are a few things you may want to override or configure:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Runtime"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Memory size"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Environment variables"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Let's look at how to update all of these things."
      },
      {
        "heading": "Updating the Runtime",
        "depth": 2,
        "text": "You may want to tweak the runtime version to be either a newer or older version than the Amplify-generated default."
      },
      {
        "heading": "Updating the Runtime",
        "depth": 2,
        "text": "Let's say we've deployed a Lambda function using a Node.js runtime and we want to modify the version of the runtime to be 14.x."
      },
      {
        "heading": "Updating the Runtime",
        "depth": 2,
        "text": "To do so, open amplify/backend/function/function-name/function-name-cloudformation-template.json and set the Runtime property in the LambdaFunction resource to:"
      },
      {
        "heading": "Updating the Runtime",
        "depth": 2,
        "text": "Next, deploy the updates using the Amplify CLI:"
      },
      {
        "heading": "Updating the default memory size",
        "depth": 2,
        "text": "When you deploy a function with Amplify, the default memory size will be set to a low setting (128MB). Often you will want to increase the default memory size in order to improve performance. A popular memory setting in Lambda is 1024MB as it speeds the function noticeably while usually keeping the cost the same or close to it."
      },
      {
        "heading": "Updating the default memory size",
        "depth": 2,
        "text": "To update the memory size, open amplify/backend/function/function-name/function-name-cloudformation-template.json and set the MemorySize property in the LambdaFunction resource:"
      },
      {
        "heading": "Updating the default memory size",
        "depth": 2,
        "text": "Next, deploy the updates using the Amplify CLI:"
      },
      {
        "heading": "Updating the default memory size",
        "depth": 2,
        "text": "To learn more about optimizing resources allocation for Lambda functions, check out this blog post."
      },
      {
        "heading": "Setting an environment variable",
        "depth": 2,
        "text": "A very common scenario is the need to set and use an environment variable in your Lambda function."
      },
      {
        "heading": "Setting an environment variable",
        "depth": 2,
        "text": "There are generally two types of environment variables:"
      },
      {
        "heading": "Setting an environment variable",
        "depth": 2,
        "text": "Secret values (example: access keys, API keys etc.)"
      },
      {
        "heading": "Setting an environment variable",
        "depth": 2,
        "text": "Non-secret values (example: endpoint information, locale information etc.)"
      },
      {
        "heading": "Setting an environment variable",
        "depth": 2,
        "text": "To view all configuration options available in AWS Lambda, check out the documentation here"
      },
      {
        "heading": "Setting an environment variable",
        "depth": 2,
        "text": "To learn more about extending the Amplify CLI with custom resources, check out the documentation here"
      }
    ],
    "source": "export const meta = {\n  title: `Configuring Lambda function settings`,\n  description: `How to configure custom settings for your Lambda function`,\n};\n\nYou may want to override the Amplify CLI default configurations for your Lambda function or configure changes not available within the `amplify add function` workflow.\n\n*Example*: When creating a `Node.js` function, the CLI will automatically configure a runtime version, a default memory size, and more. There are a few things you may want to override or configure:\n\n1. Runtime\n2. Memory size\n3. Environment variables\n\nLet's look at how to update all of these things.\n\n## Updating the Runtime\n\nYou may want to tweak the runtime version to be either a newer or older version than the Amplify-generated default.\n\nLet's say we've deployed a Lambda function using a Node.js runtime and we want to modify the version of the runtime to be `14.x`.\n\nTo do so, open __amplify/backend/function/function-name/function-name-cloudformation-template.json__ and set the `Runtime` property in the `LambdaFunction` resource to:\n\n```json\n\"Resources\": {\n  \"LambdaFunction\": {\n      ...\n      \"Properties\": {\n        \"Runtime\": \"nodejs14.x\", // Runtime now set to 14.x\n        \"Layers\": [],\n      }\n      ...\n    }\n  },\n}\n```\n\nNext, deploy the updates using the Amplify CLI:\n\n```sh\namplify push\n```\n\n## Updating the default memory size\n\nWhen you deploy a function with Amplify, the default memory size will be set to a low setting (128MB). Often you will want to increase the default memory size in order to improve performance. A popular memory setting in Lambda is 1024MB as it speeds the function noticeably while usually keeping the cost the same or close to it.\n\nTo update the memory size, open __amplify/backend/function/function-name/function-name-cloudformation-template.json__ and set the `MemorySize` property in the `LambdaFunction` resource:\n\n```json\n\"Resources\": {\n  \"LambdaFunction\": {\n      ...\n      \"Properties\": {\n        \"Runtime\": \"nodejs14.x\",\n        \"MemorySize\": 1024, // Memory size now set to 1024 MB\n        \"Layers\": [],\n      }\n      ...\n    }\n  },\n}\n```\n\nNext, deploy the updates using the Amplify CLI:\n\n```sh\namplify push\n```\n\n_To learn more about optimizing resources allocation for Lambda functions, check out [this](https://dev.to/aws/deep-dive-finding-the-optimal-resources-allocation-for-your-lambda-functions-35a6) blog post._\n\n## Setting an environment variable\n\nA very common scenario is the need to set and use an environment variable in your Lambda function.\n\nThere are generally two types of environment variables:\n- [Secret values (example: access keys, API keys etc.)](/cli/function/secrets)\n- [Non-secret values (example: endpoint information, locale information etc.)](/cli/function/env-vars)\n\n<Callout>\n\nTo view all configuration options available in AWS Lambda, check out the documentation [here](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-lambda-function-environment.html)\n\nTo learn more about extending the Amplify CLI with custom resources, check out the documentation [here](/cli/usage/customcf)\n\n</Callout>\n",
    "meta": {
      "title": "Configuring Lambda function settings - JavaScript",
      "description": "How to configure custom settings for your Lambda function - JavaScript",
      "subcategory": "Functions",
      "category": "Guides"
    },
    "filename": "/guides/functions/configuring-lambda/q/platform/js"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "If you are using AWS Cognito to handle authentication in your application you can use triggers to handle authentication\nevents. For example, send a welcome email after the user signs up. The complete documentation on AWS Cognito triggers can be found here."
      },
      {
        "heading": null,
        "depth": null,
        "text": "In this guide, you will learn how to use a post confirmation trigger to save user's information to your DynamoDB table.\nLike mentioned in the previous guides, the easiest way to interact with DynamoDB from Lambda in a Node.js environment is\nto use the DynamoDB document client."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Using this approach you can link a Cognito Identity to an user profile in your application, and have the possibility to list posts by author and be able to show their name, email\n, date of creation, etc instead of their id."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The main advantage of this method is that you don't have to manually create the user in your GraphQL API using a mutation, which is another alternative."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The main issue of this solution is that if you remove an user from AWS Cognito, your application won't know about it."
      },
      {
        "heading": "Scenario",
        "depth": 3,
        "text": "After user sign-up, you want to create an entry in a DynamoDB table with the user's information."
      },
      {
        "heading": "Create GraphQL API",
        "depth": 3,
        "text": "In this step you will create your User table, where the entry with user's information will be saved. This will be done using Amplify GraphQL API."
      },
      {
        "heading": "Create GraphQL API",
        "depth": 3,
        "text": "You can skip this part, if you already have a GraphQL API with an User model."
      },
      {
        "heading": "Create GraphQL API",
        "depth": 3,
        "text": "The CLI should open the GraphQL schema, located at amplify/backend/api/contactapi/schema.graphql, in your text editor. Update the schema with the following and save the file:"
      },
      {
        "heading": "Create the lambda function",
        "depth": 3,
        "text": "This function will be called after user post confirmation."
      },
      {
        "heading": "Create the lambda function",
        "depth": 3,
        "text": "Next open the index.js file associated to your newly created lambda function, and paste the following code :"
      },
      {
        "heading": "Create the lambda function",
        "depth": 3,
        "text": "You can access your table name by calling the environment variable API__USERTABLE_NAME."
      },
      {
        "heading": "Create the lambda function",
        "depth": 3,
        "text": "Deploy the lambda function :"
      },
      {
        "heading": "Create the lambda function",
        "depth": 3,
        "text": "Your lambda function is now ready to use!"
      },
      {
        "heading": "Configure the Post Confirmation trigger",
        "depth": 3,
        "text": "To configure your AWS Cognito trigger to call the lambda function you just created, you should do the following :"
      },
      {
        "heading": "Configure the Post Confirmation trigger",
        "depth": 3,
        "text": "Go to your AWS Console"
      },
      {
        "heading": "Configure the Post Confirmation trigger",
        "depth": 3,
        "text": "Navigate to AWS Cognito service, and choose 'Manage User Pools'"
      },
      {
        "heading": "Configure the Post Confirmation trigger",
        "depth": 3,
        "text": "Select the User Pool related to your application"
      },
      {
        "heading": "Configure the Post Confirmation trigger",
        "depth": 3,
        "text": "Go to 'Triggers' and look for Post Confirmation Trigger, then select your lambda function"
      }
    ],
    "source": "export const meta = {\n  title: `Calling DynamoDB using AWS Cognito triggers`,\n  description: `How to add an entry in DynamoDB, with user's information after sign-up post-confirmation`,\n};\n\nIf you are using AWS Cognito to handle authentication in your application you can use triggers to handle authentication \nevents. For example, send a welcome email after the user signs up. The complete documentation on AWS Cognito triggers can be found [here](https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-identity-pools-working-with-aws-lambda-triggers.html).\n\nIn this guide, you will learn how to use a post confirmation trigger to save user's information to your DynamoDB table.\nLike mentioned in the previous guides, the easiest way to interact with DynamoDB from Lambda in a Node.js environment is \nto use the [DynamoDB document client](https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/DynamoDB/DocumentClient.html).\n\nUsing this approach you can link a Cognito Identity to an user profile in your application, and have the possibility to list posts by author and be able to show their name, email \n, date of creation, etc instead of their id.\n\nThe main advantage of this method is that you don't have to manually create the user in your GraphQL API using a mutation, which is another alternative.\n\nThe main issue of this solution is that if you remove an user from AWS Cognito, your application won't know about it.\n\n### Scenario\n\nAfter user sign-up, you want to create an entry in a DynamoDB table with the user's information.\n\n### Create GraphQL API\n\nIn this step you will create your User table, where the entry with user's information will be saved. This will be done using Amplify GraphQL API.\n\nYou can skip this part, if you already have a GraphQL API with an User model.\n\n```sh\namplify add api\n\n? Here is the GraphQL API that we will create. Select a setting to edit or continue:\n    > Name\n? Provide API name:\n    > contactapi\n? Here is the GraphQL API that we will create. Select a setting to edit or continue:\n    > Authorization modes: API key (default, expiration time: 7 days from now)\n? Choose the default authorization type for the API:\n    > API Key\n? Enter a description for the API key:\n    > public (or some description)\n? After how many days from now the API key should expire:\n    > 365 (or your preferred expiration)\n? Configure additional auth types?\n    > No\n? Here is the GraphQL API that we will create. Select a setting to edit or continue:\n    > Continue\n? Choose a schema template:\n    > Single object with fields (e.g., “Todo” with ID, name, description)\n? Do you want to edit the schema now?\n    > Yes\n```\n\nThe CLI should open the GraphQL schema, located at amplify/backend/api/contactapi/schema.graphql, in your text editor. Update the schema with the following and save the file:\n\n```graphql\ntype User\n  @model\n{\n  id: ID!\n  name: String\n  email: String\n}\n```\n\n### Create the lambda function\n\nThis function will be called after user post confirmation.\n\n```sh\namplify add function\n\n? Provide a friendly name for your resource to be used as a label for this category in the project: mylambda\n? Provide the AWS Lambda function name: mylambda\n? Choose the function runtime that you want to use: NodeJS\n? Choose the function template that you want to use: Hello World\n? Do you want to access other resources created in this project from your Lambda function? Y\n? Select the category: storage\n? Select the operations you want to permit for UserTable: create, read, update, delete\n? Do you want to invoke this function on a recurring schedule? N\n? Do you want to configure Lambda layers for this function? N\n? Do you want to edit the local lambda function now? N\n```\n\nNext open the index.js file associated to your newly created lambda function, and paste the following code : \n\n```js\nvar aws = require('aws-sdk');\nvar ddb = new aws.DynamoDB();\n\nexports.handler = async (event, context) => {\n    \n    let date = new Date();\n\n    if (event.request.userAttributes.sub) {\n\n        let params = {\n            Item: {\n                'id': {S: event.request.userAttributes.sub},\n                '__typename': {S: 'User'},\n                'name': {S: event.request.userAttributes.name},\n                'email': {S: event.request.userAttributes.email},\n                'createdAt': {S: date.toISOString()},\n                'updatedAt': {S: date.toISOString()},\n            },\n            TableName: process.env.API_{YOUR_APP_NAME}_USERTABLE_NAME\n        };\n\n        // Call DynamoDB\n        try {\n            await ddb.putItem(params).promise()\n            console.log(\"Success\");\n        } catch (err) {\n            console.log(\"Error\", err);\n        }\n\n        console.log(\"Success: Everything executed correctly\");\n        context.done(null, event);\n\n    } else {\n        // Nothing to do, the user's email ID is unknown\n        console.log(\"Error: Nothing was written to DynamoDB\");\n        context.done(null, event);\n    }\n};\n```\n\nYou can access your table name by calling the environment variable API_{APP_NAME}_USERTABLE_NAME.\n\nDeploy the lambda function :\n\n```sh\namplify push\n```\n\nYour lambda function is now ready to use!\n\n### Configure the Post Confirmation trigger\n\nTo configure your AWS Cognito trigger to call the lambda function you just created, you should do the following :\n\n- Go to your [AWS Console](https://console.aws.amazon.com/console/home)\n- Navigate to AWS Cognito service, and choose 'Manage User Pools'\n- Select the User Pool related to your application\n- Go to 'Triggers' and look for Post Confirmation Trigger, then select your lambda function\n",
    "meta": {
      "title": "Calling DynamoDB using AWS Cognito triggers - iOS",
      "description": "How to add an entry in DynamoDB, with user's information after sign-up post-confirmation - iOS",
      "subcategory": "Functions",
      "category": "Guides"
    },
    "filename": "/guides/functions/cognito-trigger-lambda-dynamodb/q/platform/ios"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "If you are using AWS Cognito to handle authentication in your application you can use triggers to handle authentication\nevents. For example, send a welcome email after the user signs up. The complete documentation on AWS Cognito triggers can be found here."
      },
      {
        "heading": null,
        "depth": null,
        "text": "In this guide, you will learn how to use a post confirmation trigger to save user's information to your DynamoDB table.\nLike mentioned in the previous guides, the easiest way to interact with DynamoDB from Lambda in a Node.js environment is\nto use the DynamoDB document client."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Using this approach you can link a Cognito Identity to an user profile in your application, and have the possibility to list posts by author and be able to show their name, email\n, date of creation, etc instead of their id."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The main advantage of this method is that you don't have to manually create the user in your GraphQL API using a mutation, which is another alternative."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The main issue of this solution is that if you remove an user from AWS Cognito, your application won't know about it."
      },
      {
        "heading": "Scenario",
        "depth": 3,
        "text": "After user sign-up, you want to create an entry in a DynamoDB table with the user's information."
      },
      {
        "heading": "Create GraphQL API",
        "depth": 3,
        "text": "In this step you will create your User table, where the entry with user's information will be saved. This will be done using Amplify GraphQL API."
      },
      {
        "heading": "Create GraphQL API",
        "depth": 3,
        "text": "You can skip this part, if you already have a GraphQL API with an User model."
      },
      {
        "heading": "Create GraphQL API",
        "depth": 3,
        "text": "The CLI should open the GraphQL schema, located at amplify/backend/api/contactapi/schema.graphql, in your text editor. Update the schema with the following and save the file:"
      },
      {
        "heading": "Create the lambda function",
        "depth": 3,
        "text": "This function will be called after user post confirmation."
      },
      {
        "heading": "Create the lambda function",
        "depth": 3,
        "text": "Next open the index.js file associated to your newly created lambda function, and paste the following code :"
      },
      {
        "heading": "Create the lambda function",
        "depth": 3,
        "text": "You can access your table name by calling the environment variable API__USERTABLE_NAME."
      },
      {
        "heading": "Create the lambda function",
        "depth": 3,
        "text": "Deploy the lambda function :"
      },
      {
        "heading": "Create the lambda function",
        "depth": 3,
        "text": "Your lambda function is now ready to use!"
      },
      {
        "heading": "Configure the Post Confirmation trigger",
        "depth": 3,
        "text": "To configure your AWS Cognito trigger to call the lambda function you just created, you should do the following :"
      },
      {
        "heading": "Configure the Post Confirmation trigger",
        "depth": 3,
        "text": "Go to your AWS Console"
      },
      {
        "heading": "Configure the Post Confirmation trigger",
        "depth": 3,
        "text": "Navigate to AWS Cognito service, and choose 'Manage User Pools'"
      },
      {
        "heading": "Configure the Post Confirmation trigger",
        "depth": 3,
        "text": "Select the User Pool related to your application"
      },
      {
        "heading": "Configure the Post Confirmation trigger",
        "depth": 3,
        "text": "Go to 'Triggers' and look for Post Confirmation Trigger, then select your lambda function"
      }
    ],
    "source": "export const meta = {\n  title: `Calling DynamoDB using AWS Cognito triggers`,\n  description: `How to add an entry in DynamoDB, with user's information after sign-up post-confirmation`,\n};\n\nIf you are using AWS Cognito to handle authentication in your application you can use triggers to handle authentication \nevents. For example, send a welcome email after the user signs up. The complete documentation on AWS Cognito triggers can be found [here](https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-identity-pools-working-with-aws-lambda-triggers.html).\n\nIn this guide, you will learn how to use a post confirmation trigger to save user's information to your DynamoDB table.\nLike mentioned in the previous guides, the easiest way to interact with DynamoDB from Lambda in a Node.js environment is \nto use the [DynamoDB document client](https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/DynamoDB/DocumentClient.html).\n\nUsing this approach you can link a Cognito Identity to an user profile in your application, and have the possibility to list posts by author and be able to show their name, email \n, date of creation, etc instead of their id.\n\nThe main advantage of this method is that you don't have to manually create the user in your GraphQL API using a mutation, which is another alternative.\n\nThe main issue of this solution is that if you remove an user from AWS Cognito, your application won't know about it.\n\n### Scenario\n\nAfter user sign-up, you want to create an entry in a DynamoDB table with the user's information.\n\n### Create GraphQL API\n\nIn this step you will create your User table, where the entry with user's information will be saved. This will be done using Amplify GraphQL API.\n\nYou can skip this part, if you already have a GraphQL API with an User model.\n\n```sh\namplify add api\n\n? Here is the GraphQL API that we will create. Select a setting to edit or continue:\n    > Name\n? Provide API name:\n    > contactapi\n? Here is the GraphQL API that we will create. Select a setting to edit or continue:\n    > Authorization modes: API key (default, expiration time: 7 days from now)\n? Choose the default authorization type for the API:\n    > API Key\n? Enter a description for the API key:\n    > public (or some description)\n? After how many days from now the API key should expire:\n    > 365 (or your preferred expiration)\n? Configure additional auth types?\n    > No\n? Here is the GraphQL API that we will create. Select a setting to edit or continue:\n    > Continue\n? Choose a schema template:\n    > Single object with fields (e.g., “Todo” with ID, name, description)\n? Do you want to edit the schema now?\n    > Yes\n```\n\nThe CLI should open the GraphQL schema, located at amplify/backend/api/contactapi/schema.graphql, in your text editor. Update the schema with the following and save the file:\n\n```graphql\ntype User\n  @model\n{\n  id: ID!\n  name: String\n  email: String\n}\n```\n\n### Create the lambda function\n\nThis function will be called after user post confirmation.\n\n```sh\namplify add function\n\n? Provide a friendly name for your resource to be used as a label for this category in the project: mylambda\n? Provide the AWS Lambda function name: mylambda\n? Choose the function runtime that you want to use: NodeJS\n? Choose the function template that you want to use: Hello World\n? Do you want to access other resources created in this project from your Lambda function? Y\n? Select the category: storage\n? Select the operations you want to permit for UserTable: create, read, update, delete\n? Do you want to invoke this function on a recurring schedule? N\n? Do you want to configure Lambda layers for this function? N\n? Do you want to edit the local lambda function now? N\n```\n\nNext open the index.js file associated to your newly created lambda function, and paste the following code : \n\n```js\nvar aws = require('aws-sdk');\nvar ddb = new aws.DynamoDB();\n\nexports.handler = async (event, context) => {\n    \n    let date = new Date();\n\n    if (event.request.userAttributes.sub) {\n\n        let params = {\n            Item: {\n                'id': {S: event.request.userAttributes.sub},\n                '__typename': {S: 'User'},\n                'name': {S: event.request.userAttributes.name},\n                'email': {S: event.request.userAttributes.email},\n                'createdAt': {S: date.toISOString()},\n                'updatedAt': {S: date.toISOString()},\n            },\n            TableName: process.env.API_{YOUR_APP_NAME}_USERTABLE_NAME\n        };\n\n        // Call DynamoDB\n        try {\n            await ddb.putItem(params).promise()\n            console.log(\"Success\");\n        } catch (err) {\n            console.log(\"Error\", err);\n        }\n\n        console.log(\"Success: Everything executed correctly\");\n        context.done(null, event);\n\n    } else {\n        // Nothing to do, the user's email ID is unknown\n        console.log(\"Error: Nothing was written to DynamoDB\");\n        context.done(null, event);\n    }\n};\n```\n\nYou can access your table name by calling the environment variable API_{APP_NAME}_USERTABLE_NAME.\n\nDeploy the lambda function :\n\n```sh\namplify push\n```\n\nYour lambda function is now ready to use!\n\n### Configure the Post Confirmation trigger\n\nTo configure your AWS Cognito trigger to call the lambda function you just created, you should do the following :\n\n- Go to your [AWS Console](https://console.aws.amazon.com/console/home)\n- Navigate to AWS Cognito service, and choose 'Manage User Pools'\n- Select the User Pool related to your application\n- Go to 'Triggers' and look for Post Confirmation Trigger, then select your lambda function\n",
    "meta": {
      "title": "Calling DynamoDB using AWS Cognito triggers - Android",
      "description": "How to add an entry in DynamoDB, with user's information after sign-up post-confirmation - Android",
      "subcategory": "Functions",
      "category": "Guides"
    },
    "filename": "/guides/functions/cognito-trigger-lambda-dynamodb/q/platform/android"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "If you are using AWS Cognito to handle authentication in your application you can use triggers to handle authentication\nevents. For example, send a welcome email after the user signs up. The complete documentation on AWS Cognito triggers can be found here."
      },
      {
        "heading": null,
        "depth": null,
        "text": "In this guide, you will learn how to use a post confirmation trigger to save user's information to your DynamoDB table.\nLike mentioned in the previous guides, the easiest way to interact with DynamoDB from Lambda in a Node.js environment is\nto use the DynamoDB document client."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Using this approach you can link a Cognito Identity to an user profile in your application, and have the possibility to list posts by author and be able to show their name, email\n, date of creation, etc instead of their id."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The main advantage of this method is that you don't have to manually create the user in your GraphQL API using a mutation, which is another alternative."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The main issue of this solution is that if you remove an user from AWS Cognito, your application won't know about it."
      },
      {
        "heading": "Scenario",
        "depth": 3,
        "text": "After user sign-up, you want to create an entry in a DynamoDB table with the user's information."
      },
      {
        "heading": "Create GraphQL API",
        "depth": 3,
        "text": "In this step you will create your User table, where the entry with user's information will be saved. This will be done using Amplify GraphQL API."
      },
      {
        "heading": "Create GraphQL API",
        "depth": 3,
        "text": "You can skip this part, if you already have a GraphQL API with an User model."
      },
      {
        "heading": "Create GraphQL API",
        "depth": 3,
        "text": "The CLI should open the GraphQL schema, located at amplify/backend/api/contactapi/schema.graphql, in your text editor. Update the schema with the following and save the file:"
      },
      {
        "heading": "Create the lambda function",
        "depth": 3,
        "text": "This function will be called after user post confirmation."
      },
      {
        "heading": "Create the lambda function",
        "depth": 3,
        "text": "Next open the index.js file associated to your newly created lambda function, and paste the following code :"
      },
      {
        "heading": "Create the lambda function",
        "depth": 3,
        "text": "You can access your table name by calling the environment variable API__USERTABLE_NAME."
      },
      {
        "heading": "Create the lambda function",
        "depth": 3,
        "text": "Deploy the lambda function :"
      },
      {
        "heading": "Create the lambda function",
        "depth": 3,
        "text": "Your lambda function is now ready to use!"
      },
      {
        "heading": "Configure the Post Confirmation trigger",
        "depth": 3,
        "text": "To configure your AWS Cognito trigger to call the lambda function you just created, you should do the following :"
      },
      {
        "heading": "Configure the Post Confirmation trigger",
        "depth": 3,
        "text": "Go to your AWS Console"
      },
      {
        "heading": "Configure the Post Confirmation trigger",
        "depth": 3,
        "text": "Navigate to AWS Cognito service, and choose 'Manage User Pools'"
      },
      {
        "heading": "Configure the Post Confirmation trigger",
        "depth": 3,
        "text": "Select the User Pool related to your application"
      },
      {
        "heading": "Configure the Post Confirmation trigger",
        "depth": 3,
        "text": "Go to 'Triggers' and look for Post Confirmation Trigger, then select your lambda function"
      }
    ],
    "source": "export const meta = {\n  title: `Calling DynamoDB using AWS Cognito triggers`,\n  description: `How to add an entry in DynamoDB, with user's information after sign-up post-confirmation`,\n};\n\nIf you are using AWS Cognito to handle authentication in your application you can use triggers to handle authentication \nevents. For example, send a welcome email after the user signs up. The complete documentation on AWS Cognito triggers can be found [here](https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-identity-pools-working-with-aws-lambda-triggers.html).\n\nIn this guide, you will learn how to use a post confirmation trigger to save user's information to your DynamoDB table.\nLike mentioned in the previous guides, the easiest way to interact with DynamoDB from Lambda in a Node.js environment is \nto use the [DynamoDB document client](https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/DynamoDB/DocumentClient.html).\n\nUsing this approach you can link a Cognito Identity to an user profile in your application, and have the possibility to list posts by author and be able to show their name, email \n, date of creation, etc instead of their id.\n\nThe main advantage of this method is that you don't have to manually create the user in your GraphQL API using a mutation, which is another alternative.\n\nThe main issue of this solution is that if you remove an user from AWS Cognito, your application won't know about it.\n\n### Scenario\n\nAfter user sign-up, you want to create an entry in a DynamoDB table with the user's information.\n\n### Create GraphQL API\n\nIn this step you will create your User table, where the entry with user's information will be saved. This will be done using Amplify GraphQL API.\n\nYou can skip this part, if you already have a GraphQL API with an User model.\n\n```sh\namplify add api\n\n? Here is the GraphQL API that we will create. Select a setting to edit or continue:\n    > Name\n? Provide API name:\n    > contactapi\n? Here is the GraphQL API that we will create. Select a setting to edit or continue:\n    > Authorization modes: API key (default, expiration time: 7 days from now)\n? Choose the default authorization type for the API:\n    > API Key\n? Enter a description for the API key:\n    > public (or some description)\n? After how many days from now the API key should expire:\n    > 365 (or your preferred expiration)\n? Configure additional auth types?\n    > No\n? Here is the GraphQL API that we will create. Select a setting to edit or continue:\n    > Continue\n? Choose a schema template:\n    > Single object with fields (e.g., “Todo” with ID, name, description)\n? Do you want to edit the schema now?\n    > Yes\n```\n\nThe CLI should open the GraphQL schema, located at amplify/backend/api/contactapi/schema.graphql, in your text editor. Update the schema with the following and save the file:\n\n```graphql\ntype User\n  @model\n{\n  id: ID!\n  name: String\n  email: String\n}\n```\n\n### Create the lambda function\n\nThis function will be called after user post confirmation.\n\n```sh\namplify add function\n\n? Provide a friendly name for your resource to be used as a label for this category in the project: mylambda\n? Provide the AWS Lambda function name: mylambda\n? Choose the function runtime that you want to use: NodeJS\n? Choose the function template that you want to use: Hello World\n? Do you want to access other resources created in this project from your Lambda function? Y\n? Select the category: storage\n? Select the operations you want to permit for UserTable: create, read, update, delete\n? Do you want to invoke this function on a recurring schedule? N\n? Do you want to configure Lambda layers for this function? N\n? Do you want to edit the local lambda function now? N\n```\n\nNext open the index.js file associated to your newly created lambda function, and paste the following code : \n\n```js\nvar aws = require('aws-sdk');\nvar ddb = new aws.DynamoDB();\n\nexports.handler = async (event, context) => {\n    \n    let date = new Date();\n\n    if (event.request.userAttributes.sub) {\n\n        let params = {\n            Item: {\n                'id': {S: event.request.userAttributes.sub},\n                '__typename': {S: 'User'},\n                'name': {S: event.request.userAttributes.name},\n                'email': {S: event.request.userAttributes.email},\n                'createdAt': {S: date.toISOString()},\n                'updatedAt': {S: date.toISOString()},\n            },\n            TableName: process.env.API_{YOUR_APP_NAME}_USERTABLE_NAME\n        };\n\n        // Call DynamoDB\n        try {\n            await ddb.putItem(params).promise()\n            console.log(\"Success\");\n        } catch (err) {\n            console.log(\"Error\", err);\n        }\n\n        console.log(\"Success: Everything executed correctly\");\n        context.done(null, event);\n\n    } else {\n        // Nothing to do, the user's email ID is unknown\n        console.log(\"Error: Nothing was written to DynamoDB\");\n        context.done(null, event);\n    }\n};\n```\n\nYou can access your table name by calling the environment variable API_{APP_NAME}_USERTABLE_NAME.\n\nDeploy the lambda function :\n\n```sh\namplify push\n```\n\nYour lambda function is now ready to use!\n\n### Configure the Post Confirmation trigger\n\nTo configure your AWS Cognito trigger to call the lambda function you just created, you should do the following :\n\n- Go to your [AWS Console](https://console.aws.amazon.com/console/home)\n- Navigate to AWS Cognito service, and choose 'Manage User Pools'\n- Select the User Pool related to your application\n- Go to 'Triggers' and look for Post Confirmation Trigger, then select your lambda function\n",
    "meta": {
      "title": "Calling DynamoDB using AWS Cognito triggers - JavaScript",
      "description": "How to add an entry in DynamoDB, with user's information after sign-up post-confirmation - JavaScript",
      "subcategory": "Functions",
      "category": "Guides"
    },
    "filename": "/guides/functions/cognito-trigger-lambda-dynamodb/q/platform/js"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In this guide you will learn how to run a GraphQL server in a Lambda function. In this example we will be using Apollo Server and Apollo Server Lambda, but you can use any server implementation you would like."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The end goal is to have an API endpoint, like https://your-api-endpoint.com/graphql, deployed and integrated with a GraphQL server running in a serverless function."
      },
      {
        "heading": "Creating the Amplify project",
        "depth": 3,
        "text": "To get started, create a new Amplify project."
      },
      {
        "heading": "Creating the Amplify project",
        "depth": 3,
        "text": "If you already have an Amplify project created, you can jump to the next step - Creating the GraphQL API and function"
      },
      {
        "heading": "Creating the GraphQL API and function",
        "depth": 3,
        "text": "Next we need to create the API and the Lambda function. Using the api category, the CLI will create a serverless function as well as an http endpoint that we can use for our GraphQL server."
      },
      {
        "heading": "Installing the dependencies",
        "depth": 4,
        "text": "Change into the folder of the Lambda function and install the following dependencies:"
      },
      {
        "heading": "Function code",
        "depth": 3,
        "text": "Now, let's open the code for the function."
      },
      {
        "heading": "Function code",
        "depth": 3,
        "text": "Open amplify/backend/function/apolloserver/src/index.js. Here, you will see the main function handler. Update the function with the following code:"
      },
      {
        "heading": "Function code",
        "depth": 3,
        "text": "Now, we can deploy the function and GraphQL API:"
      },
      {
        "heading": "Function code",
        "depth": 3,
        "text": "Now the API is deployed and you should be able to start interacting with it."
      },
      {
        "heading": "API URL",
        "depth": 3,
        "text": "Once the server is up and running, The url is available in the aws-exports.js file. The final GraphQL endpoint will look something like this:"
      },
      {
        "heading": "API URL",
        "depth": 3,
        "text": "You can also use the GraphQL playground by navigating to the GraphQL endpoint /graphql directly in your browser."
      }
    ],
    "source": "export const meta = {\n  title: `GraphQL Server in Lambda`,\n  description: `How to run an Apollo GraphQL server in a Lambda function`,\n};\n\nIn this guide you will learn how to run a GraphQL server in a Lambda function. In this example we will be using [Apollo Server](https://www.apollographql.com/docs/) and [Apollo Server Lambda](https://github.com/apollographql/apollo-server/tree/master/packages/apollo-server-lambda), but you can use any server implementation you would like.\n\nThe end goal is to have an API endpoint, like `https://your-api-endpoint.com/graphql`, deployed and integrated with a GraphQL server running in a serverless function.\n\n### Creating the Amplify project\n\nTo get started, create a new Amplify project.\n\n<Callout>\n\nIf you already have an Amplify project created, you can jump to the next step - Creating the GraphQL API and function\n\n</Callout>\n\n```sh\namplify init\n\n# Choose your environment name and default text editor\n# You can answer the defaults for the rest of the questions and then choose the profile you created when you ran amplify configure\n```\n\n### Creating the GraphQL API and function\n\nNext we need to create the API and the Lambda function. Using the `api` category, the CLI will create a serverless function as well as an http endpoint that we can use for our GraphQL server.\n\n```sh\n$ amplify add api\n\n? Please select from one of the below mentioned services: REST\n? Provide a friendly name for your resource to be used as a label for this category in the project: apolloapi\n? Provide a path (e.g., /items): /graphql\n? Choose a Lambda source: Create a new Lambda function\n? Provide a friendly name for your resource to be used as a label for this category in the project: apolloserver\n? Provide the AWS Lambda function name: apolloserver\n? Choose the function runtime that you want to use: NodeJS\n? Choose the function template that you want to use: Hello World\n? Do you want to access other resources created in this project from your Lambda function? N\n? Do you want to edit the local lambda function now? N\n? Restrict API access: N\n? Do you want to add another path? N\n```\n\n#### Installing the dependencies\n\nChange into the folder of the Lambda function and install the following dependencies:\n\n```sh\ncd amplify/backend/function/apolloserver/src\nnpm install apollo-server-lambda graphql\ncd ../../../../../\n```\n\n### Function code\n\nNow, let's open the code for the function.\n\nOpen __amplify/backend/function/apolloserver/src/index.js__. Here, you will see the main function handler. Update the function with the following code:\n\n```javascript\nconst { ApolloServer, gql } = require('apollo-server-lambda');\n\n/* Construct a schema, using GraphQL schema language */\nconst typeDefs = gql`\n  type Query { hello: String }\n`\n\n/* Provide resolver functions for your schema fields */\nconst resolvers = {\n  Query: {\n    hello: () => 'Hello from Apollo!!',\n  },\n}\n\nconst server = new ApolloServer({\n    typeDefs,\n    resolvers,\n    context: ({ event, context }) => ({\n      headers: event.headers,\n      functionName: context.functionName,\n      event,\n      context,\n    }),\n  })\n  \nexports.handler = server.createHandler({\n  cors: {\n    origin: '*',\n    credentials: true,\n  }\n})\n```\n\nNow, we can deploy the function and GraphQL API:\n\n```sh\namplify push\n```\n\nNow the API is deployed and you should be able to start interacting with it.\n\n### API URL\n\nOnce the server is up and running, The url is available in the aws-exports.js file. The final GraphQL endpoint will look something like this:\n\n```\nhttps://6dbg37jfw5.execute-api.us-east-1.amazonaws.com/<env-name>/graphql\n```\n\nYou can also use the GraphQL playground by navigating to the GraphQL endpoint `/graphql` directly in your browser.",
    "meta": {
      "title": "GraphQL Server in Lambda - iOS",
      "description": "How to run an Apollo GraphQL server in a Lambda function - iOS",
      "subcategory": "Functions",
      "category": "Guides"
    },
    "filename": "/guides/functions/graphql-server-in-lambda/q/platform/ios"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In this guide you will learn how to run a GraphQL server in a Lambda function. In this example we will be using Apollo Server and Apollo Server Lambda, but you can use any server implementation you would like."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The end goal is to have an API endpoint, like https://your-api-endpoint.com/graphql, deployed and integrated with a GraphQL server running in a serverless function."
      },
      {
        "heading": "Creating the Amplify project",
        "depth": 3,
        "text": "To get started, create a new Amplify project."
      },
      {
        "heading": "Creating the Amplify project",
        "depth": 3,
        "text": "If you already have an Amplify project created, you can jump to the next step - Creating the GraphQL API and function"
      },
      {
        "heading": "Creating the GraphQL API and function",
        "depth": 3,
        "text": "Next we need to create the API and the Lambda function. Using the api category, the CLI will create a serverless function as well as an http endpoint that we can use for our GraphQL server."
      },
      {
        "heading": "Installing the dependencies",
        "depth": 4,
        "text": "Change into the folder of the Lambda function and install the following dependencies:"
      },
      {
        "heading": "Function code",
        "depth": 3,
        "text": "Now, let's open the code for the function."
      },
      {
        "heading": "Function code",
        "depth": 3,
        "text": "Open amplify/backend/function/apolloserver/src/index.js. Here, you will see the main function handler. Update the function with the following code:"
      },
      {
        "heading": "Function code",
        "depth": 3,
        "text": "Now, we can deploy the function and GraphQL API:"
      },
      {
        "heading": "Function code",
        "depth": 3,
        "text": "Now the API is deployed and you should be able to start interacting with it."
      },
      {
        "heading": "API URL",
        "depth": 3,
        "text": "Once the server is up and running, The url is available in the aws-exports.js file. The final GraphQL endpoint will look something like this:"
      },
      {
        "heading": "API URL",
        "depth": 3,
        "text": "You can also use the GraphQL playground by navigating to the GraphQL endpoint /graphql directly in your browser."
      }
    ],
    "source": "export const meta = {\n  title: `GraphQL Server in Lambda`,\n  description: `How to run an Apollo GraphQL server in a Lambda function`,\n};\n\nIn this guide you will learn how to run a GraphQL server in a Lambda function. In this example we will be using [Apollo Server](https://www.apollographql.com/docs/) and [Apollo Server Lambda](https://github.com/apollographql/apollo-server/tree/master/packages/apollo-server-lambda), but you can use any server implementation you would like.\n\nThe end goal is to have an API endpoint, like `https://your-api-endpoint.com/graphql`, deployed and integrated with a GraphQL server running in a serverless function.\n\n### Creating the Amplify project\n\nTo get started, create a new Amplify project.\n\n<Callout>\n\nIf you already have an Amplify project created, you can jump to the next step - Creating the GraphQL API and function\n\n</Callout>\n\n```sh\namplify init\n\n# Choose your environment name and default text editor\n# You can answer the defaults for the rest of the questions and then choose the profile you created when you ran amplify configure\n```\n\n### Creating the GraphQL API and function\n\nNext we need to create the API and the Lambda function. Using the `api` category, the CLI will create a serverless function as well as an http endpoint that we can use for our GraphQL server.\n\n```sh\n$ amplify add api\n\n? Please select from one of the below mentioned services: REST\n? Provide a friendly name for your resource to be used as a label for this category in the project: apolloapi\n? Provide a path (e.g., /items): /graphql\n? Choose a Lambda source: Create a new Lambda function\n? Provide a friendly name for your resource to be used as a label for this category in the project: apolloserver\n? Provide the AWS Lambda function name: apolloserver\n? Choose the function runtime that you want to use: NodeJS\n? Choose the function template that you want to use: Hello World\n? Do you want to access other resources created in this project from your Lambda function? N\n? Do you want to edit the local lambda function now? N\n? Restrict API access: N\n? Do you want to add another path? N\n```\n\n#### Installing the dependencies\n\nChange into the folder of the Lambda function and install the following dependencies:\n\n```sh\ncd amplify/backend/function/apolloserver/src\nnpm install apollo-server-lambda graphql\ncd ../../../../../\n```\n\n### Function code\n\nNow, let's open the code for the function.\n\nOpen __amplify/backend/function/apolloserver/src/index.js__. Here, you will see the main function handler. Update the function with the following code:\n\n```javascript\nconst { ApolloServer, gql } = require('apollo-server-lambda');\n\n/* Construct a schema, using GraphQL schema language */\nconst typeDefs = gql`\n  type Query { hello: String }\n`\n\n/* Provide resolver functions for your schema fields */\nconst resolvers = {\n  Query: {\n    hello: () => 'Hello from Apollo!!',\n  },\n}\n\nconst server = new ApolloServer({\n    typeDefs,\n    resolvers,\n    context: ({ event, context }) => ({\n      headers: event.headers,\n      functionName: context.functionName,\n      event,\n      context,\n    }),\n  })\n  \nexports.handler = server.createHandler({\n  cors: {\n    origin: '*',\n    credentials: true,\n  }\n})\n```\n\nNow, we can deploy the function and GraphQL API:\n\n```sh\namplify push\n```\n\nNow the API is deployed and you should be able to start interacting with it.\n\n### API URL\n\nOnce the server is up and running, The url is available in the aws-exports.js file. The final GraphQL endpoint will look something like this:\n\n```\nhttps://6dbg37jfw5.execute-api.us-east-1.amazonaws.com/<env-name>/graphql\n```\n\nYou can also use the GraphQL playground by navigating to the GraphQL endpoint `/graphql` directly in your browser.",
    "meta": {
      "title": "GraphQL Server in Lambda - Android",
      "description": "How to run an Apollo GraphQL server in a Lambda function - Android",
      "subcategory": "Functions",
      "category": "Guides"
    },
    "filename": "/guides/functions/graphql-server-in-lambda/q/platform/android"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In this guide you will learn how to run a GraphQL server in a Lambda function. In this example we will be using Apollo Server and Apollo Server Lambda, but you can use any server implementation you would like."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The end goal is to have an API endpoint, like https://your-api-endpoint.com/graphql, deployed and integrated with a GraphQL server running in a serverless function."
      },
      {
        "heading": "Creating the Amplify project",
        "depth": 3,
        "text": "To get started, create a new Amplify project."
      },
      {
        "heading": "Creating the Amplify project",
        "depth": 3,
        "text": "If you already have an Amplify project created, you can jump to the next step - Creating the GraphQL API and function"
      },
      {
        "heading": "Creating the GraphQL API and function",
        "depth": 3,
        "text": "Next we need to create the API and the Lambda function. Using the api category, the CLI will create a serverless function as well as an http endpoint that we can use for our GraphQL server."
      },
      {
        "heading": "Installing the dependencies",
        "depth": 4,
        "text": "Change into the folder of the Lambda function and install the following dependencies:"
      },
      {
        "heading": "Function code",
        "depth": 3,
        "text": "Now, let's open the code for the function."
      },
      {
        "heading": "Function code",
        "depth": 3,
        "text": "Open amplify/backend/function/apolloserver/src/index.js. Here, you will see the main function handler. Update the function with the following code:"
      },
      {
        "heading": "Function code",
        "depth": 3,
        "text": "Now, we can deploy the function and GraphQL API:"
      },
      {
        "heading": "Function code",
        "depth": 3,
        "text": "Now the API is deployed and you should be able to start interacting with it."
      },
      {
        "heading": "API URL",
        "depth": 3,
        "text": "Once the server is up and running, The url is available in the aws-exports.js file. The final GraphQL endpoint will look something like this:"
      },
      {
        "heading": "API URL",
        "depth": 3,
        "text": "You can also use the GraphQL playground by navigating to the GraphQL endpoint /graphql directly in your browser."
      }
    ],
    "source": "export const meta = {\n  title: `GraphQL Server in Lambda`,\n  description: `How to run an Apollo GraphQL server in a Lambda function`,\n};\n\nIn this guide you will learn how to run a GraphQL server in a Lambda function. In this example we will be using [Apollo Server](https://www.apollographql.com/docs/) and [Apollo Server Lambda](https://github.com/apollographql/apollo-server/tree/master/packages/apollo-server-lambda), but you can use any server implementation you would like.\n\nThe end goal is to have an API endpoint, like `https://your-api-endpoint.com/graphql`, deployed and integrated with a GraphQL server running in a serverless function.\n\n### Creating the Amplify project\n\nTo get started, create a new Amplify project.\n\n<Callout>\n\nIf you already have an Amplify project created, you can jump to the next step - Creating the GraphQL API and function\n\n</Callout>\n\n```sh\namplify init\n\n# Choose your environment name and default text editor\n# You can answer the defaults for the rest of the questions and then choose the profile you created when you ran amplify configure\n```\n\n### Creating the GraphQL API and function\n\nNext we need to create the API and the Lambda function. Using the `api` category, the CLI will create a serverless function as well as an http endpoint that we can use for our GraphQL server.\n\n```sh\n$ amplify add api\n\n? Please select from one of the below mentioned services: REST\n? Provide a friendly name for your resource to be used as a label for this category in the project: apolloapi\n? Provide a path (e.g., /items): /graphql\n? Choose a Lambda source: Create a new Lambda function\n? Provide a friendly name for your resource to be used as a label for this category in the project: apolloserver\n? Provide the AWS Lambda function name: apolloserver\n? Choose the function runtime that you want to use: NodeJS\n? Choose the function template that you want to use: Hello World\n? Do you want to access other resources created in this project from your Lambda function? N\n? Do you want to edit the local lambda function now? N\n? Restrict API access: N\n? Do you want to add another path? N\n```\n\n#### Installing the dependencies\n\nChange into the folder of the Lambda function and install the following dependencies:\n\n```sh\ncd amplify/backend/function/apolloserver/src\nnpm install apollo-server-lambda graphql\ncd ../../../../../\n```\n\n### Function code\n\nNow, let's open the code for the function.\n\nOpen __amplify/backend/function/apolloserver/src/index.js__. Here, you will see the main function handler. Update the function with the following code:\n\n```javascript\nconst { ApolloServer, gql } = require('apollo-server-lambda');\n\n/* Construct a schema, using GraphQL schema language */\nconst typeDefs = gql`\n  type Query { hello: String }\n`\n\n/* Provide resolver functions for your schema fields */\nconst resolvers = {\n  Query: {\n    hello: () => 'Hello from Apollo!!',\n  },\n}\n\nconst server = new ApolloServer({\n    typeDefs,\n    resolvers,\n    context: ({ event, context }) => ({\n      headers: event.headers,\n      functionName: context.functionName,\n      event,\n      context,\n    }),\n  })\n  \nexports.handler = server.createHandler({\n  cors: {\n    origin: '*',\n    credentials: true,\n  }\n})\n```\n\nNow, we can deploy the function and GraphQL API:\n\n```sh\namplify push\n```\n\nNow the API is deployed and you should be able to start interacting with it.\n\n### API URL\n\nOnce the server is up and running, The url is available in the aws-exports.js file. The final GraphQL endpoint will look something like this:\n\n```\nhttps://6dbg37jfw5.execute-api.us-east-1.amazonaws.com/<env-name>/graphql\n```\n\nYou can also use the GraphQL playground by navigating to the GraphQL endpoint `/graphql` directly in your browser.",
    "meta": {
      "title": "GraphQL Server in Lambda - JavaScript",
      "description": "How to run an Apollo GraphQL server in a Lambda function - JavaScript",
      "subcategory": "Functions",
      "category": "Guides"
    },
    "filename": "/guides/functions/graphql-server-in-lambda/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Calling GraphQL API from a Lambda function`,\n  description: `How to interact with a GraphQL API from a Lambda function`,\n};\n\nimport all0 from \"/src/fragments/lib/graphqlapi/graphql-from-node.mdx\";\n\n<Fragments fragments={{all: all0}} />\n",
    "meta": {
      "title": "Calling GraphQL API from a Lambda function - iOS",
      "description": "How to interact with a GraphQL API from a Lambda function - iOS",
      "subcategory": "Functions",
      "category": "Guides"
    },
    "filename": "/guides/functions/graphql-from-lambda/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Calling GraphQL API from a Lambda function`,\n  description: `How to interact with a GraphQL API from a Lambda function`,\n};\n\nimport all0 from \"/src/fragments/lib/graphqlapi/graphql-from-node.mdx\";\n\n<Fragments fragments={{all: all0}} />\n",
    "meta": {
      "title": "Calling GraphQL API from a Lambda function - Android",
      "description": "How to interact with a GraphQL API from a Lambda function - Android",
      "subcategory": "Functions",
      "category": "Guides"
    },
    "filename": "/guides/functions/graphql-from-lambda/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Calling GraphQL API from a Lambda function`,\n  description: `How to interact with a GraphQL API from a Lambda function`,\n};\n\nimport all0 from \"/src/fragments/lib/graphqlapi/graphql-from-node.mdx\";\n\n<Fragments fragments={{all: all0}} />\n",
    "meta": {
      "title": "Calling GraphQL API from a Lambda function - JavaScript",
      "description": "How to interact with a GraphQL API from a Lambda function - JavaScript",
      "subcategory": "Functions",
      "category": "Guides"
    },
    "filename": "/guides/functions/graphql-from-lambda/q/platform/js"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "The easiest way to interact with DynamoDB from Lambda in a Python environment is to use the boto3 DynamoDB client. In this guide you will learn how to interact with a DynamoDB database from a Lambda function using the Python runtime."
      },
      {
        "heading": null,
        "depth": null,
        "text": "You will learn how to perform put_item, get_item, scan, and query operations."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Note that the Amplify-generated Python Lambda functions use Pipenv for packaging. To install a dependency, such as boto3, first change into your function's Amplify folder, then enter the Pipenv virtual environment and install inside it."
      },
      {
        "heading": "Creating an item in DynamoDB from Lambda",
        "depth": 3,
        "text": "To create an item in DynamoDB you can use the put method:"
      },
      {
        "heading": "Getting an item by primary key in DynamoDB from Lambda",
        "depth": 3,
        "text": "To get an item by primary key in DynamoDB you can use the get method. A get request returns a single item given the primary key of that item:"
      },
      {
        "heading": "Scanning a table",
        "depth": 3,
        "text": "A scan returns one or more items and item attributes by accessing every item in a table or a secondary index (limit of 1 MB of data)."
      },
      {
        "heading": "Querying a table",
        "depth": 3,
        "text": "A query returns one or more items and item attributes by querying items from a table by primary key or secondary index."
      }
    ],
    "source": "export const meta = {\n  title: `Calling DynamoDB from a Lambda function in Python`,\n  description: `How to interact with a DynamoDB database from a Lambda function in Python`,\n};\n\nThe easiest way to interact with DynamoDB from Lambda in a Python environment is to use the [boto3 DynamoDB client](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/dynamodb.html). In this guide you will learn how to interact with a DynamoDB database from a Lambda function using the Python runtime.\n\nYou will learn how to perform [put_item](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/dynamodb.html#DynamoDB.Client.put_item), [get_item](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/dynamodb.html#DynamoDB.Client.get_item), [scan](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/dynamodb.html#DynamoDB.Client.scan), and [query](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/dynamodb.html#DynamoDB.Client.query) operations.\n\nNote that the Amplify-generated Python Lambda functions use [Pipenv](https://pypi.org/project/pipenv/) for packaging. To install a dependency, such as `boto3`, first change into your function's Amplify folder, then enter the Pipenv virtual environment and install inside it.\n\n```sh\n$ cd amplify/backend/function/your-function-name\n$ pipenv shell\n$ pipenv install boto3\n```\n### Creating an item in DynamoDB from Lambda\n\nTo create an item in DynamoDB you can use the `put` method:\n\n```python\nimport boto3\n\nclient = boto3.client('dynamodb')\n\ndef handler(event, context):\n  data = client.put_item(\n    TableName='your-table-name',\n    Item={\n        'id': {\n          'S': '005'\n        },\n        'price': {\n          'N': '500'\n        },\n        'name': {\n          'S': 'Yeezys'\n        }\n    }\n  )\n\n  response = {\n      'statusCode': 200,\n      'body': 'successfully created item!',\n      'headers': {\n        'Content-Type': 'application/json',\n        'Access-Control-Allow-Origin': '*'\n      },\n  }\n  \n  return response\n```\n\n### Getting an item by primary key in DynamoDB from Lambda\n\nTo get an item by primary key in DynamoDB you can use the `get` method. A `get` request returns a single item given the primary key of that item:\n\n```python\nimport json\nimport boto3\n\nclient = boto3.client('dynamodb')\n\ndef handler(event, context):\n  data = client.get_item(\n    TableName='your-table-name',\n    Key={\n        'id': {\n          'S': '005'\n        }\n    }\n  )\n\n  response = {\n      'statusCode': 200,\n      'body': json.dumps(data),\n      'headers': {\n        'Content-Type': 'application/json',\n        'Access-Control-Allow-Origin': '*'\n      },\n  }\n  \n  return response\n```\n\n### Scanning a table\n\nA `scan` returns one or more items and item attributes by accessing every item in a table or a secondary index (limit of 1 MB of data).\n\n```python\nimport json\nimport boto3\n\nclient = boto3.client('dynamodb')\n\ndef handler(event, context):\n  data = client.scan(\n    TableName='your-table-name'\n  )\n\n  response = {\n      'statusCode': 200,\n      'body': json.dumps(data),\n      'headers': {\n        'Content-Type': 'application/json',\n        'Access-Control-Allow-Origin': '*'\n      },\n  }\n  \n  return response\n```\n\n### Querying a table\n\nA `query` returns one or more items and item attributes by querying items from a table by primary key or secondary index.\n\n```python\nimport json\nimport boto3\n\nclient = boto3.client('dynamodb')\n\ndef handler(event, context):\n  data = client.query(\n    TableName='your-table-name',\n    IndexName='some-index',\n    KeyConditionExpression='#name = :value',\n    ExpressionAttributeValues={\n      ':value': {\n        'S': 'shoes'\n      }\n    },\n    ExpressionAttributeNames={\n      '#name': 'name'\n    }\n  )\n\n  response = {\n      'statusCode': 200,\n      'body': json.dumps(data),\n      'headers': {\n        'Content-Type': 'application/json',\n        'Access-Control-Allow-Origin': '*'\n      },\n  }\n  \n  return response\n```\n",
    "meta": {
      "title": "Calling DynamoDB from a Lambda function in Python - iOS",
      "description": "How to interact with a DynamoDB database from a Lambda function in Python - iOS",
      "subcategory": "Functions",
      "category": "Guides"
    },
    "filename": "/guides/functions/dynamodb-from-python-lambda/q/platform/ios"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "The easiest way to interact with DynamoDB from Lambda in a Python environment is to use the boto3 DynamoDB client. In this guide you will learn how to interact with a DynamoDB database from a Lambda function using the Python runtime."
      },
      {
        "heading": null,
        "depth": null,
        "text": "You will learn how to perform put_item, get_item, scan, and query operations."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Note that the Amplify-generated Python Lambda functions use Pipenv for packaging. To install a dependency, such as boto3, first change into your function's Amplify folder, then enter the Pipenv virtual environment and install inside it."
      },
      {
        "heading": "Creating an item in DynamoDB from Lambda",
        "depth": 3,
        "text": "To create an item in DynamoDB you can use the put method:"
      },
      {
        "heading": "Getting an item by primary key in DynamoDB from Lambda",
        "depth": 3,
        "text": "To get an item by primary key in DynamoDB you can use the get method. A get request returns a single item given the primary key of that item:"
      },
      {
        "heading": "Scanning a table",
        "depth": 3,
        "text": "A scan returns one or more items and item attributes by accessing every item in a table or a secondary index (limit of 1 MB of data)."
      },
      {
        "heading": "Querying a table",
        "depth": 3,
        "text": "A query returns one or more items and item attributes by querying items from a table by primary key or secondary index."
      }
    ],
    "source": "export const meta = {\n  title: `Calling DynamoDB from a Lambda function in Python`,\n  description: `How to interact with a DynamoDB database from a Lambda function in Python`,\n};\n\nThe easiest way to interact with DynamoDB from Lambda in a Python environment is to use the [boto3 DynamoDB client](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/dynamodb.html). In this guide you will learn how to interact with a DynamoDB database from a Lambda function using the Python runtime.\n\nYou will learn how to perform [put_item](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/dynamodb.html#DynamoDB.Client.put_item), [get_item](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/dynamodb.html#DynamoDB.Client.get_item), [scan](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/dynamodb.html#DynamoDB.Client.scan), and [query](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/dynamodb.html#DynamoDB.Client.query) operations.\n\nNote that the Amplify-generated Python Lambda functions use [Pipenv](https://pypi.org/project/pipenv/) for packaging. To install a dependency, such as `boto3`, first change into your function's Amplify folder, then enter the Pipenv virtual environment and install inside it.\n\n```sh\n$ cd amplify/backend/function/your-function-name\n$ pipenv shell\n$ pipenv install boto3\n```\n### Creating an item in DynamoDB from Lambda\n\nTo create an item in DynamoDB you can use the `put` method:\n\n```python\nimport boto3\n\nclient = boto3.client('dynamodb')\n\ndef handler(event, context):\n  data = client.put_item(\n    TableName='your-table-name',\n    Item={\n        'id': {\n          'S': '005'\n        },\n        'price': {\n          'N': '500'\n        },\n        'name': {\n          'S': 'Yeezys'\n        }\n    }\n  )\n\n  response = {\n      'statusCode': 200,\n      'body': 'successfully created item!',\n      'headers': {\n        'Content-Type': 'application/json',\n        'Access-Control-Allow-Origin': '*'\n      },\n  }\n  \n  return response\n```\n\n### Getting an item by primary key in DynamoDB from Lambda\n\nTo get an item by primary key in DynamoDB you can use the `get` method. A `get` request returns a single item given the primary key of that item:\n\n```python\nimport json\nimport boto3\n\nclient = boto3.client('dynamodb')\n\ndef handler(event, context):\n  data = client.get_item(\n    TableName='your-table-name',\n    Key={\n        'id': {\n          'S': '005'\n        }\n    }\n  )\n\n  response = {\n      'statusCode': 200,\n      'body': json.dumps(data),\n      'headers': {\n        'Content-Type': 'application/json',\n        'Access-Control-Allow-Origin': '*'\n      },\n  }\n  \n  return response\n```\n\n### Scanning a table\n\nA `scan` returns one or more items and item attributes by accessing every item in a table or a secondary index (limit of 1 MB of data).\n\n```python\nimport json\nimport boto3\n\nclient = boto3.client('dynamodb')\n\ndef handler(event, context):\n  data = client.scan(\n    TableName='your-table-name'\n  )\n\n  response = {\n      'statusCode': 200,\n      'body': json.dumps(data),\n      'headers': {\n        'Content-Type': 'application/json',\n        'Access-Control-Allow-Origin': '*'\n      },\n  }\n  \n  return response\n```\n\n### Querying a table\n\nA `query` returns one or more items and item attributes by querying items from a table by primary key or secondary index.\n\n```python\nimport json\nimport boto3\n\nclient = boto3.client('dynamodb')\n\ndef handler(event, context):\n  data = client.query(\n    TableName='your-table-name',\n    IndexName='some-index',\n    KeyConditionExpression='#name = :value',\n    ExpressionAttributeValues={\n      ':value': {\n        'S': 'shoes'\n      }\n    },\n    ExpressionAttributeNames={\n      '#name': 'name'\n    }\n  )\n\n  response = {\n      'statusCode': 200,\n      'body': json.dumps(data),\n      'headers': {\n        'Content-Type': 'application/json',\n        'Access-Control-Allow-Origin': '*'\n      },\n  }\n  \n  return response\n```\n",
    "meta": {
      "title": "Calling DynamoDB from a Lambda function in Python - Android",
      "description": "How to interact with a DynamoDB database from a Lambda function in Python - Android",
      "subcategory": "Functions",
      "category": "Guides"
    },
    "filename": "/guides/functions/dynamodb-from-python-lambda/q/platform/android"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "The easiest way to interact with DynamoDB from Lambda in a Python environment is to use the boto3 DynamoDB client. In this guide you will learn how to interact with a DynamoDB database from a Lambda function using the Python runtime."
      },
      {
        "heading": null,
        "depth": null,
        "text": "You will learn how to perform put_item, get_item, scan, and query operations."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Note that the Amplify-generated Python Lambda functions use Pipenv for packaging. To install a dependency, such as boto3, first change into your function's Amplify folder, then enter the Pipenv virtual environment and install inside it."
      },
      {
        "heading": "Creating an item in DynamoDB from Lambda",
        "depth": 3,
        "text": "To create an item in DynamoDB you can use the put method:"
      },
      {
        "heading": "Getting an item by primary key in DynamoDB from Lambda",
        "depth": 3,
        "text": "To get an item by primary key in DynamoDB you can use the get method. A get request returns a single item given the primary key of that item:"
      },
      {
        "heading": "Scanning a table",
        "depth": 3,
        "text": "A scan returns one or more items and item attributes by accessing every item in a table or a secondary index (limit of 1 MB of data)."
      },
      {
        "heading": "Querying a table",
        "depth": 3,
        "text": "A query returns one or more items and item attributes by querying items from a table by primary key or secondary index."
      }
    ],
    "source": "export const meta = {\n  title: `Calling DynamoDB from a Lambda function in Python`,\n  description: `How to interact with a DynamoDB database from a Lambda function in Python`,\n};\n\nThe easiest way to interact with DynamoDB from Lambda in a Python environment is to use the [boto3 DynamoDB client](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/dynamodb.html). In this guide you will learn how to interact with a DynamoDB database from a Lambda function using the Python runtime.\n\nYou will learn how to perform [put_item](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/dynamodb.html#DynamoDB.Client.put_item), [get_item](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/dynamodb.html#DynamoDB.Client.get_item), [scan](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/dynamodb.html#DynamoDB.Client.scan), and [query](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/dynamodb.html#DynamoDB.Client.query) operations.\n\nNote that the Amplify-generated Python Lambda functions use [Pipenv](https://pypi.org/project/pipenv/) for packaging. To install a dependency, such as `boto3`, first change into your function's Amplify folder, then enter the Pipenv virtual environment and install inside it.\n\n```sh\n$ cd amplify/backend/function/your-function-name\n$ pipenv shell\n$ pipenv install boto3\n```\n### Creating an item in DynamoDB from Lambda\n\nTo create an item in DynamoDB you can use the `put` method:\n\n```python\nimport boto3\n\nclient = boto3.client('dynamodb')\n\ndef handler(event, context):\n  data = client.put_item(\n    TableName='your-table-name',\n    Item={\n        'id': {\n          'S': '005'\n        },\n        'price': {\n          'N': '500'\n        },\n        'name': {\n          'S': 'Yeezys'\n        }\n    }\n  )\n\n  response = {\n      'statusCode': 200,\n      'body': 'successfully created item!',\n      'headers': {\n        'Content-Type': 'application/json',\n        'Access-Control-Allow-Origin': '*'\n      },\n  }\n  \n  return response\n```\n\n### Getting an item by primary key in DynamoDB from Lambda\n\nTo get an item by primary key in DynamoDB you can use the `get` method. A `get` request returns a single item given the primary key of that item:\n\n```python\nimport json\nimport boto3\n\nclient = boto3.client('dynamodb')\n\ndef handler(event, context):\n  data = client.get_item(\n    TableName='your-table-name',\n    Key={\n        'id': {\n          'S': '005'\n        }\n    }\n  )\n\n  response = {\n      'statusCode': 200,\n      'body': json.dumps(data),\n      'headers': {\n        'Content-Type': 'application/json',\n        'Access-Control-Allow-Origin': '*'\n      },\n  }\n  \n  return response\n```\n\n### Scanning a table\n\nA `scan` returns one or more items and item attributes by accessing every item in a table or a secondary index (limit of 1 MB of data).\n\n```python\nimport json\nimport boto3\n\nclient = boto3.client('dynamodb')\n\ndef handler(event, context):\n  data = client.scan(\n    TableName='your-table-name'\n  )\n\n  response = {\n      'statusCode': 200,\n      'body': json.dumps(data),\n      'headers': {\n        'Content-Type': 'application/json',\n        'Access-Control-Allow-Origin': '*'\n      },\n  }\n  \n  return response\n```\n\n### Querying a table\n\nA `query` returns one or more items and item attributes by querying items from a table by primary key or secondary index.\n\n```python\nimport json\nimport boto3\n\nclient = boto3.client('dynamodb')\n\ndef handler(event, context):\n  data = client.query(\n    TableName='your-table-name',\n    IndexName='some-index',\n    KeyConditionExpression='#name = :value',\n    ExpressionAttributeValues={\n      ':value': {\n        'S': 'shoes'\n      }\n    },\n    ExpressionAttributeNames={\n      '#name': 'name'\n    }\n  )\n\n  response = {\n      'statusCode': 200,\n      'body': json.dumps(data),\n      'headers': {\n        'Content-Type': 'application/json',\n        'Access-Control-Allow-Origin': '*'\n      },\n  }\n  \n  return response\n```\n",
    "meta": {
      "title": "Calling DynamoDB from a Lambda function in Python - JavaScript",
      "description": "How to interact with a DynamoDB database from a Lambda function in Python - JavaScript",
      "subcategory": "Functions",
      "category": "Guides"
    },
    "filename": "/guides/functions/dynamodb-from-python-lambda/q/platform/js"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "The easiest way to interact with DynamoDB from Lambda in a Node.js environment is to use the DynamoDB document client. In this guide you will learn how to interact with a DynamoDB database from a Lambda function using the Node.js runtime."
      },
      {
        "heading": null,
        "depth": null,
        "text": "You will learn how to perform put, get, scan, and query operations."
      },
      {
        "heading": "Creating an item in DynamoDB from Lambda",
        "depth": 3,
        "text": "To create an item in DynamoDB you can use the put method:"
      },
      {
        "heading": "Getting an item by primary key in DynamoDB from Lambda",
        "depth": 3,
        "text": "To get an item by primary key in DynamoDB you can use the get method. A get request returns a single item given the primary key of that item:"
      },
      {
        "heading": "Scanning a table",
        "depth": 3,
        "text": "A scan returns one or more items and item attributes by accessing every item in a table or a secondary index (limit of 1 MB of data)."
      },
      {
        "heading": "Querying a table",
        "depth": 3,
        "text": "A query returns one or more items and item attributes by querying items from a table by primary key or secondary index."
      }
    ],
    "source": "export const meta = {\n  title: `Calling DynamoDB from Lambda in Node.js`,\n  description: `How to interact with a DynamoDB database from a Lambda function in Node.js`,\n};\n\nThe easiest way to interact with DynamoDB from Lambda in a Node.js environment is to use the [DynamoDB document client](https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/DynamoDB/DocumentClient.html). In this guide you will learn how to interact with a DynamoDB database from a Lambda function using the Node.js runtime.\n\nYou will learn how to perform [put](https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/DynamoDB/DocumentClient.html#put-property), [get](https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/DynamoDB/DocumentClient.html#get-property), [scan](https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/DynamoDB/DocumentClient.html#scan-property), and [query](https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/DynamoDB/DocumentClient.html#query-property) operations.\n\n### Creating an item in DynamoDB from Lambda\n\nTo create an item in DynamoDB you can use the `put` method:\n\n```js\nconst AWS = require('aws-sdk');\nconst docClient = new AWS.DynamoDB.DocumentClient();\n\nconst params = {\n  TableName : 'your-table-name',\n  /* Item properties will depend on your application concerns */\n  Item: {\n     id: '12345',\n     price: 100.00\n  }\n}\n\nasync function createItem(){\n  try {\n    await docClient.put(params).promise();\n  } catch (err) {\n    return err;\n  }\n}\n\nexports.handler = async (event) => {\n  try {\n    await createItem()\n    return { body: 'Successfully created item!' }\n  } catch (err) {\n    return { error: err }\n  }\n};\n```\n\n### Getting an item by primary key in DynamoDB from Lambda\n\nTo get an item by primary key in DynamoDB you can use the `get` method. A `get` request returns a single item given the primary key of that item:\n\n```js\nconst AWS = require('aws-sdk');\nconst docClient = new AWS.DynamoDB.DocumentClient();\n\nconst params = {\n  TableName : 'your-table-name',\n  /* Item properties will depend on your application concerns */\n  Key: {\n    id: '12345'\n  }\n}\n\nasync function getItem(){\n  try {\n    const data = await docClient.get(params).promise()\n    return data\n  } catch (err) {\n    return err\n  }\n}\n\nexports.handler = async (event, context) => {\n  try {\n    const data = await getItem()\n    return { body: JSON.stringify(data) }\n  } catch (err) {\n    return { error: err }\n  }\n}\n```\n\n### Scanning a table\n\nA `scan` returns one or more items and item attributes by accessing every item in a table or a secondary index (limit of 1 MB of data).\n\n```js\nconst AWS = require('aws-sdk');\nconst docClient = new AWS.DynamoDB.DocumentClient();\n\nconst params = {\n  TableName : 'your-table-name'\n}\n\nasync function listItems(){\n  try {\n    const data = await docClient.scan(params).promise()\n    return data\n  } catch (err) {\n    return err\n  }\n}\n\nexports.handler = async (event, context) => {\n  try {\n    const data = await listItems()\n    return { body: JSON.stringify(data) }\n  } catch (err) {\n    return { error: err }\n  }\n}\n```\n\n### Querying a table\n\nA `query` returns one or more items and item attributes by querying items from a table by primary key or secondary index.\n\n```js\nconst AWS = require('aws-sdk');\nconst docClient = new AWS.DynamoDB.DocumentClient();\n\nvar params = {\n  TableName: 'your-table-name',\n  IndexName: 'some-index',\n  KeyConditionExpression: '#name = :value',\n  ExpressionAttributeValues: { ':value': 'shoes' },\n  ExpressionAttributeNames: { '#name': 'name' }\n}\n\nasync function queryItems(){\n  try {\n    const data = await docClient.query(params).promise()\n    return data\n  } catch (err) {\n    return err\n  }\n}\n\nexports.handler = async (event, context) => {\n  try {\n    const data = await queryItems()\n    return { body: JSON.stringify(data) }\n  } catch (err) {\n    return { error: err }\n  }\n}\n```",
    "meta": {
      "title": "Calling DynamoDB from Lambda in Node.js - iOS",
      "description": "How to interact with a DynamoDB database from a Lambda function in Node.js - iOS",
      "subcategory": "Functions",
      "category": "Guides"
    },
    "filename": "/guides/functions/dynamodb-from-js-lambda/q/platform/ios"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "The easiest way to interact with DynamoDB from Lambda in a Node.js environment is to use the DynamoDB document client. In this guide you will learn how to interact with a DynamoDB database from a Lambda function using the Node.js runtime."
      },
      {
        "heading": null,
        "depth": null,
        "text": "You will learn how to perform put, get, scan, and query operations."
      },
      {
        "heading": "Creating an item in DynamoDB from Lambda",
        "depth": 3,
        "text": "To create an item in DynamoDB you can use the put method:"
      },
      {
        "heading": "Getting an item by primary key in DynamoDB from Lambda",
        "depth": 3,
        "text": "To get an item by primary key in DynamoDB you can use the get method. A get request returns a single item given the primary key of that item:"
      },
      {
        "heading": "Scanning a table",
        "depth": 3,
        "text": "A scan returns one or more items and item attributes by accessing every item in a table or a secondary index (limit of 1 MB of data)."
      },
      {
        "heading": "Querying a table",
        "depth": 3,
        "text": "A query returns one or more items and item attributes by querying items from a table by primary key or secondary index."
      }
    ],
    "source": "export const meta = {\n  title: `Calling DynamoDB from Lambda in Node.js`,\n  description: `How to interact with a DynamoDB database from a Lambda function in Node.js`,\n};\n\nThe easiest way to interact with DynamoDB from Lambda in a Node.js environment is to use the [DynamoDB document client](https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/DynamoDB/DocumentClient.html). In this guide you will learn how to interact with a DynamoDB database from a Lambda function using the Node.js runtime.\n\nYou will learn how to perform [put](https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/DynamoDB/DocumentClient.html#put-property), [get](https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/DynamoDB/DocumentClient.html#get-property), [scan](https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/DynamoDB/DocumentClient.html#scan-property), and [query](https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/DynamoDB/DocumentClient.html#query-property) operations.\n\n### Creating an item in DynamoDB from Lambda\n\nTo create an item in DynamoDB you can use the `put` method:\n\n```js\nconst AWS = require('aws-sdk');\nconst docClient = new AWS.DynamoDB.DocumentClient();\n\nconst params = {\n  TableName : 'your-table-name',\n  /* Item properties will depend on your application concerns */\n  Item: {\n     id: '12345',\n     price: 100.00\n  }\n}\n\nasync function createItem(){\n  try {\n    await docClient.put(params).promise();\n  } catch (err) {\n    return err;\n  }\n}\n\nexports.handler = async (event) => {\n  try {\n    await createItem()\n    return { body: 'Successfully created item!' }\n  } catch (err) {\n    return { error: err }\n  }\n};\n```\n\n### Getting an item by primary key in DynamoDB from Lambda\n\nTo get an item by primary key in DynamoDB you can use the `get` method. A `get` request returns a single item given the primary key of that item:\n\n```js\nconst AWS = require('aws-sdk');\nconst docClient = new AWS.DynamoDB.DocumentClient();\n\nconst params = {\n  TableName : 'your-table-name',\n  /* Item properties will depend on your application concerns */\n  Key: {\n    id: '12345'\n  }\n}\n\nasync function getItem(){\n  try {\n    const data = await docClient.get(params).promise()\n    return data\n  } catch (err) {\n    return err\n  }\n}\n\nexports.handler = async (event, context) => {\n  try {\n    const data = await getItem()\n    return { body: JSON.stringify(data) }\n  } catch (err) {\n    return { error: err }\n  }\n}\n```\n\n### Scanning a table\n\nA `scan` returns one or more items and item attributes by accessing every item in a table or a secondary index (limit of 1 MB of data).\n\n```js\nconst AWS = require('aws-sdk');\nconst docClient = new AWS.DynamoDB.DocumentClient();\n\nconst params = {\n  TableName : 'your-table-name'\n}\n\nasync function listItems(){\n  try {\n    const data = await docClient.scan(params).promise()\n    return data\n  } catch (err) {\n    return err\n  }\n}\n\nexports.handler = async (event, context) => {\n  try {\n    const data = await listItems()\n    return { body: JSON.stringify(data) }\n  } catch (err) {\n    return { error: err }\n  }\n}\n```\n\n### Querying a table\n\nA `query` returns one or more items and item attributes by querying items from a table by primary key or secondary index.\n\n```js\nconst AWS = require('aws-sdk');\nconst docClient = new AWS.DynamoDB.DocumentClient();\n\nvar params = {\n  TableName: 'your-table-name',\n  IndexName: 'some-index',\n  KeyConditionExpression: '#name = :value',\n  ExpressionAttributeValues: { ':value': 'shoes' },\n  ExpressionAttributeNames: { '#name': 'name' }\n}\n\nasync function queryItems(){\n  try {\n    const data = await docClient.query(params).promise()\n    return data\n  } catch (err) {\n    return err\n  }\n}\n\nexports.handler = async (event, context) => {\n  try {\n    const data = await queryItems()\n    return { body: JSON.stringify(data) }\n  } catch (err) {\n    return { error: err }\n  }\n}\n```",
    "meta": {
      "title": "Calling DynamoDB from Lambda in Node.js - Android",
      "description": "How to interact with a DynamoDB database from a Lambda function in Node.js - Android",
      "subcategory": "Functions",
      "category": "Guides"
    },
    "filename": "/guides/functions/dynamodb-from-js-lambda/q/platform/android"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "The easiest way to interact with DynamoDB from Lambda in a Node.js environment is to use the DynamoDB document client. In this guide you will learn how to interact with a DynamoDB database from a Lambda function using the Node.js runtime."
      },
      {
        "heading": null,
        "depth": null,
        "text": "You will learn how to perform put, get, scan, and query operations."
      },
      {
        "heading": "Creating an item in DynamoDB from Lambda",
        "depth": 3,
        "text": "To create an item in DynamoDB you can use the put method:"
      },
      {
        "heading": "Getting an item by primary key in DynamoDB from Lambda",
        "depth": 3,
        "text": "To get an item by primary key in DynamoDB you can use the get method. A get request returns a single item given the primary key of that item:"
      },
      {
        "heading": "Scanning a table",
        "depth": 3,
        "text": "A scan returns one or more items and item attributes by accessing every item in a table or a secondary index (limit of 1 MB of data)."
      },
      {
        "heading": "Querying a table",
        "depth": 3,
        "text": "A query returns one or more items and item attributes by querying items from a table by primary key or secondary index."
      }
    ],
    "source": "export const meta = {\n  title: `Calling DynamoDB from Lambda in Node.js`,\n  description: `How to interact with a DynamoDB database from a Lambda function in Node.js`,\n};\n\nThe easiest way to interact with DynamoDB from Lambda in a Node.js environment is to use the [DynamoDB document client](https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/DynamoDB/DocumentClient.html). In this guide you will learn how to interact with a DynamoDB database from a Lambda function using the Node.js runtime.\n\nYou will learn how to perform [put](https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/DynamoDB/DocumentClient.html#put-property), [get](https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/DynamoDB/DocumentClient.html#get-property), [scan](https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/DynamoDB/DocumentClient.html#scan-property), and [query](https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/DynamoDB/DocumentClient.html#query-property) operations.\n\n### Creating an item in DynamoDB from Lambda\n\nTo create an item in DynamoDB you can use the `put` method:\n\n```js\nconst AWS = require('aws-sdk');\nconst docClient = new AWS.DynamoDB.DocumentClient();\n\nconst params = {\n  TableName : 'your-table-name',\n  /* Item properties will depend on your application concerns */\n  Item: {\n     id: '12345',\n     price: 100.00\n  }\n}\n\nasync function createItem(){\n  try {\n    await docClient.put(params).promise();\n  } catch (err) {\n    return err;\n  }\n}\n\nexports.handler = async (event) => {\n  try {\n    await createItem()\n    return { body: 'Successfully created item!' }\n  } catch (err) {\n    return { error: err }\n  }\n};\n```\n\n### Getting an item by primary key in DynamoDB from Lambda\n\nTo get an item by primary key in DynamoDB you can use the `get` method. A `get` request returns a single item given the primary key of that item:\n\n```js\nconst AWS = require('aws-sdk');\nconst docClient = new AWS.DynamoDB.DocumentClient();\n\nconst params = {\n  TableName : 'your-table-name',\n  /* Item properties will depend on your application concerns */\n  Key: {\n    id: '12345'\n  }\n}\n\nasync function getItem(){\n  try {\n    const data = await docClient.get(params).promise()\n    return data\n  } catch (err) {\n    return err\n  }\n}\n\nexports.handler = async (event, context) => {\n  try {\n    const data = await getItem()\n    return { body: JSON.stringify(data) }\n  } catch (err) {\n    return { error: err }\n  }\n}\n```\n\n### Scanning a table\n\nA `scan` returns one or more items and item attributes by accessing every item in a table or a secondary index (limit of 1 MB of data).\n\n```js\nconst AWS = require('aws-sdk');\nconst docClient = new AWS.DynamoDB.DocumentClient();\n\nconst params = {\n  TableName : 'your-table-name'\n}\n\nasync function listItems(){\n  try {\n    const data = await docClient.scan(params).promise()\n    return data\n  } catch (err) {\n    return err\n  }\n}\n\nexports.handler = async (event, context) => {\n  try {\n    const data = await listItems()\n    return { body: JSON.stringify(data) }\n  } catch (err) {\n    return { error: err }\n  }\n}\n```\n\n### Querying a table\n\nA `query` returns one or more items and item attributes by querying items from a table by primary key or secondary index.\n\n```js\nconst AWS = require('aws-sdk');\nconst docClient = new AWS.DynamoDB.DocumentClient();\n\nvar params = {\n  TableName: 'your-table-name',\n  IndexName: 'some-index',\n  KeyConditionExpression: '#name = :value',\n  ExpressionAttributeValues: { ':value': 'shoes' },\n  ExpressionAttributeNames: { '#name': 'name' }\n}\n\nasync function queryItems(){\n  try {\n    const data = await docClient.query(params).promise()\n    return data\n  } catch (err) {\n    return err\n  }\n}\n\nexports.handler = async (event, context) => {\n  try {\n    const data = await queryItems()\n    return { body: JSON.stringify(data) }\n  } catch (err) {\n    return { error: err }\n  }\n}\n```",
    "meta": {
      "title": "Calling DynamoDB from Lambda in Node.js - JavaScript",
      "description": "How to interact with a DynamoDB database from a Lambda function in Node.js - JavaScript",
      "subcategory": "Functions",
      "category": "Guides"
    },
    "filename": "/guides/functions/dynamodb-from-js-lambda/q/platform/js"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In this guide you will learn how to do three things:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Create a new Lambda function and DynamoDB database that are integrated together"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Create a new DynamoDB Database and integrate it with an existing Lambda function"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Create a new Lambda function and integrate it with an an existing DynamoDB database"
      },
      {
        "heading": "Creating a new Lambda function and DynamoDB database that are integrated",
        "depth": 3,
        "text": "The first thing you will need to do will be to create the DynamoDB table:"
      },
      {
        "heading": "Creating a new Lambda function and DynamoDB database that are integrated",
        "depth": 3,
        "text": "Next, create the function:"
      },
      {
        "heading": "Creating a new Lambda function and DynamoDB database that are integrated",
        "depth": 3,
        "text": "Deploy the function and database:"
      },
      {
        "heading": "Creating a new Lambda function and DynamoDB database that are integrated",
        "depth": 3,
        "text": "Your function and database are now ready to use!"
      },
      {
        "heading": "Creating a new Lambda function and DynamoDB database that are integrated",
        "depth": 3,
        "text": "To learn how to interact with DynamoDB from Lambda, check out Calling DynamoDB from Lambda in Node.js."
      },
      {
        "heading": "Creating a new DynamoDB Database and integrate with an existing Lambda function",
        "depth": 3,
        "text": "First, create the database using the storage category:"
      },
      {
        "heading": "Creating a new DynamoDB Database and integrate with an existing Lambda function",
        "depth": 3,
        "text": "Next, update the function permissions:"
      },
      {
        "heading": "Creating a new DynamoDB Database and integrate with an existing Lambda function",
        "depth": 3,
        "text": "Deploy the database and updates to the Lambda permissions:"
      },
      {
        "heading": "Creating a new DynamoDB Database and integrate with an existing Lambda function",
        "depth": 3,
        "text": "Your function and database are now ready to use!"
      },
      {
        "heading": "Creating a new Lambda function and integrate with an an existing DynamoDB database",
        "depth": 3,
        "text": "To create a new Lambda function integrated with an existing DynamoDB database, you need to grant access to the database in the creation process of the function:"
      },
      {
        "heading": "Creating a new Lambda function and integrate with an an existing DynamoDB database",
        "depth": 3,
        "text": "Deploy the function:"
      },
      {
        "heading": "Creating a new Lambda function and integrate with an an existing DynamoDB database",
        "depth": 3,
        "text": "Your function and database are now ready to use!"
      },
      {
        "heading": "Creating a new Lambda function and integrate with an an existing DynamoDB database",
        "depth": 3,
        "text": "To learn how to interact with DynamoDB from Lambda, check out Calling DynamoDB from Lambda in Node.js."
      }
    ],
    "source": "export const meta = {\n  title: `Integrating DynamoDB with Lambda`,\n  description: `How to integrate a DynamoDB table with a Lambda function`,\n};\n\nIn this guide you will learn how to do three things:\n\n1. Create a new Lambda function and DynamoDB database that are integrated together\n2. Create a new DynamoDB Database and integrate it with an existing Lambda function\n3. Create a new Lambda function and integrate it with an an existing DynamoDB database\n\n### Creating a new Lambda function and DynamoDB database that are integrated\n\nThe first thing you will need to do will be to create the DynamoDB table:\n\n```sh\namplify add storage\n\n? Please select from one of the below mentioned services: NoSQL Database\n? Please provide a friendly name for your resource that will be used to label this category in the project: testtable\n? Please provide table name: testtable\n\n# You can now add columns to the table.\n? What would you like to name this column: id\n? Please choose the data type: String\n? Would you like to add another column? N\n? Please choose partition key for the table: id\n? Do you want to add a sort key to your table? N\n? Do you want to add global secondary indexes to your table? N\n? Do you want to add a Lambda Trigger for your Table? N\n```\n\nNext, create the function:\n\n```sh\namplify add function\n\n? Provide a friendly name for your resource to be used as a label for this category in the project: mylambda\n? Provide the AWS Lambda function name: mylambda\n? Choose the function runtime that you want to use: NodeJS\n? Choose the function template that you want to use: Hello World\n? Do you want to access other resources created in this project from your Lambda function? Y\n? Select the category: storage\n? Select the operations you want to permit for testtable: create, read, update, delete\n? Do you want to invoke this function on a recurring schedule? N\n? Do you want to edit the local lambda function now? N\n```\n\nDeploy the function and database:\n\n```sh\namplify push\n```\n\nYour function and database are now ready to use!\n\nTo learn how to interact with DynamoDB from Lambda, check out [Calling DynamoDB from Lambda in Node.js](/guides/functions/dynamodb-from-js-lambda).\n\n### Creating a new DynamoDB Database and integrate with an existing Lambda function\n\nFirst, create the database using the __storage__ category:\n\n```sh\namplify add storage\n\n? Please select from one of the below mentioned services: NoSQL Database\n? Please provide a friendly name for your resource that will be used to label this category in the project: testtable\n? Please provide table name: testtable\n\n# You can now add columns to the table.\n? What would you like to name this column: id\n? Please choose the data type: String\n? Would you like to add another column? N\n? Please choose partition key for the table: id\n? Do you want to add a sort key to your table? N\n? Do you want to add global secondary indexes to your table? N\n? Do you want to add a Lambda Trigger for your Table? N\n```\n\nNext, update the function permissions:\n\n```sh\namplify update function\n\n? Please select the Lambda Function you would want to update: <your-function>\n? Do you want to update permissions granted to this Lambda function to perform on other resources in your project? Y\n? Select the category: storage\n? Select the operations you want to permit for testtable: create, read, update, delete\n? Do you want to invoke this function on a recurring schedule? N\n? Do you want to edit the local lambda function now? N\n```\n\nDeploy the database and updates to the Lambda permissions:\n\n```sh\namplify push\n```\n\nYour function and database are now ready to use!\n\n### Creating a new Lambda function and integrate with an an existing DynamoDB database\n\nTo create a new Lambda function integrated with an existing DynamoDB database, you need to grant access to the database in the creation process of the function:\n\n```sh\namplify add function\n\n? Provide a friendly name for your resource to be used as a label for this category in the project: mylambda\n? Provide the AWS Lambda function name: mylambda\n? Choose the function runtime that you want to use: NodeJS\n? Choose the function template that you want to use: Hello World\n? Do you want to access other resources created in this project from your Lambda function? Y\n? Select the category: storage\n\n# Select the database you'd like to grant permissions to or go to the next step if there is only one database in the project\n\n? Select the operations you want to permit for <your-table-name>: create, read, update, delete\n? Do you want to invoke this function on a recurring schedule? N\n? Do you want to edit the local lambda function now? N\n```\n\nDeploy the function:\n\n```sh\namplify push\n```\n\nYour function and database are now ready to use!\n\nTo learn how to interact with DynamoDB from Lambda, check out [Calling DynamoDB from Lambda in Node.js](/guides/functions/dynamodb-from-js-lambda).",
    "meta": {
      "title": "Integrating DynamoDB with Lambda - iOS",
      "description": "How to integrate a DynamoDB table with a Lambda function - iOS",
      "subcategory": "Functions",
      "category": "Guides"
    },
    "filename": "/guides/functions/integrating-dynamodb-with-lambda/q/platform/ios"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In this guide you will learn how to do three things:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Create a new Lambda function and DynamoDB database that are integrated together"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Create a new DynamoDB Database and integrate it with an existing Lambda function"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Create a new Lambda function and integrate it with an an existing DynamoDB database"
      },
      {
        "heading": "Creating a new Lambda function and DynamoDB database that are integrated",
        "depth": 3,
        "text": "The first thing you will need to do will be to create the DynamoDB table:"
      },
      {
        "heading": "Creating a new Lambda function and DynamoDB database that are integrated",
        "depth": 3,
        "text": "Next, create the function:"
      },
      {
        "heading": "Creating a new Lambda function and DynamoDB database that are integrated",
        "depth": 3,
        "text": "Deploy the function and database:"
      },
      {
        "heading": "Creating a new Lambda function and DynamoDB database that are integrated",
        "depth": 3,
        "text": "Your function and database are now ready to use!"
      },
      {
        "heading": "Creating a new Lambda function and DynamoDB database that are integrated",
        "depth": 3,
        "text": "To learn how to interact with DynamoDB from Lambda, check out Calling DynamoDB from Lambda in Node.js."
      },
      {
        "heading": "Creating a new DynamoDB Database and integrate with an existing Lambda function",
        "depth": 3,
        "text": "First, create the database using the storage category:"
      },
      {
        "heading": "Creating a new DynamoDB Database and integrate with an existing Lambda function",
        "depth": 3,
        "text": "Next, update the function permissions:"
      },
      {
        "heading": "Creating a new DynamoDB Database and integrate with an existing Lambda function",
        "depth": 3,
        "text": "Deploy the database and updates to the Lambda permissions:"
      },
      {
        "heading": "Creating a new DynamoDB Database and integrate with an existing Lambda function",
        "depth": 3,
        "text": "Your function and database are now ready to use!"
      },
      {
        "heading": "Creating a new Lambda function and integrate with an an existing DynamoDB database",
        "depth": 3,
        "text": "To create a new Lambda function integrated with an existing DynamoDB database, you need to grant access to the database in the creation process of the function:"
      },
      {
        "heading": "Creating a new Lambda function and integrate with an an existing DynamoDB database",
        "depth": 3,
        "text": "Deploy the function:"
      },
      {
        "heading": "Creating a new Lambda function and integrate with an an existing DynamoDB database",
        "depth": 3,
        "text": "Your function and database are now ready to use!"
      },
      {
        "heading": "Creating a new Lambda function and integrate with an an existing DynamoDB database",
        "depth": 3,
        "text": "To learn how to interact with DynamoDB from Lambda, check out Calling DynamoDB from Lambda in Node.js."
      }
    ],
    "source": "export const meta = {\n  title: `Integrating DynamoDB with Lambda`,\n  description: `How to integrate a DynamoDB table with a Lambda function`,\n};\n\nIn this guide you will learn how to do three things:\n\n1. Create a new Lambda function and DynamoDB database that are integrated together\n2. Create a new DynamoDB Database and integrate it with an existing Lambda function\n3. Create a new Lambda function and integrate it with an an existing DynamoDB database\n\n### Creating a new Lambda function and DynamoDB database that are integrated\n\nThe first thing you will need to do will be to create the DynamoDB table:\n\n```sh\namplify add storage\n\n? Please select from one of the below mentioned services: NoSQL Database\n? Please provide a friendly name for your resource that will be used to label this category in the project: testtable\n? Please provide table name: testtable\n\n# You can now add columns to the table.\n? What would you like to name this column: id\n? Please choose the data type: String\n? Would you like to add another column? N\n? Please choose partition key for the table: id\n? Do you want to add a sort key to your table? N\n? Do you want to add global secondary indexes to your table? N\n? Do you want to add a Lambda Trigger for your Table? N\n```\n\nNext, create the function:\n\n```sh\namplify add function\n\n? Provide a friendly name for your resource to be used as a label for this category in the project: mylambda\n? Provide the AWS Lambda function name: mylambda\n? Choose the function runtime that you want to use: NodeJS\n? Choose the function template that you want to use: Hello World\n? Do you want to access other resources created in this project from your Lambda function? Y\n? Select the category: storage\n? Select the operations you want to permit for testtable: create, read, update, delete\n? Do you want to invoke this function on a recurring schedule? N\n? Do you want to edit the local lambda function now? N\n```\n\nDeploy the function and database:\n\n```sh\namplify push\n```\n\nYour function and database are now ready to use!\n\nTo learn how to interact with DynamoDB from Lambda, check out [Calling DynamoDB from Lambda in Node.js](/guides/functions/dynamodb-from-js-lambda).\n\n### Creating a new DynamoDB Database and integrate with an existing Lambda function\n\nFirst, create the database using the __storage__ category:\n\n```sh\namplify add storage\n\n? Please select from one of the below mentioned services: NoSQL Database\n? Please provide a friendly name for your resource that will be used to label this category in the project: testtable\n? Please provide table name: testtable\n\n# You can now add columns to the table.\n? What would you like to name this column: id\n? Please choose the data type: String\n? Would you like to add another column? N\n? Please choose partition key for the table: id\n? Do you want to add a sort key to your table? N\n? Do you want to add global secondary indexes to your table? N\n? Do you want to add a Lambda Trigger for your Table? N\n```\n\nNext, update the function permissions:\n\n```sh\namplify update function\n\n? Please select the Lambda Function you would want to update: <your-function>\n? Do you want to update permissions granted to this Lambda function to perform on other resources in your project? Y\n? Select the category: storage\n? Select the operations you want to permit for testtable: create, read, update, delete\n? Do you want to invoke this function on a recurring schedule? N\n? Do you want to edit the local lambda function now? N\n```\n\nDeploy the database and updates to the Lambda permissions:\n\n```sh\namplify push\n```\n\nYour function and database are now ready to use!\n\n### Creating a new Lambda function and integrate with an an existing DynamoDB database\n\nTo create a new Lambda function integrated with an existing DynamoDB database, you need to grant access to the database in the creation process of the function:\n\n```sh\namplify add function\n\n? Provide a friendly name for your resource to be used as a label for this category in the project: mylambda\n? Provide the AWS Lambda function name: mylambda\n? Choose the function runtime that you want to use: NodeJS\n? Choose the function template that you want to use: Hello World\n? Do you want to access other resources created in this project from your Lambda function? Y\n? Select the category: storage\n\n# Select the database you'd like to grant permissions to or go to the next step if there is only one database in the project\n\n? Select the operations you want to permit for <your-table-name>: create, read, update, delete\n? Do you want to invoke this function on a recurring schedule? N\n? Do you want to edit the local lambda function now? N\n```\n\nDeploy the function:\n\n```sh\namplify push\n```\n\nYour function and database are now ready to use!\n\nTo learn how to interact with DynamoDB from Lambda, check out [Calling DynamoDB from Lambda in Node.js](/guides/functions/dynamodb-from-js-lambda).",
    "meta": {
      "title": "Integrating DynamoDB with Lambda - Android",
      "description": "How to integrate a DynamoDB table with a Lambda function - Android",
      "subcategory": "Functions",
      "category": "Guides"
    },
    "filename": "/guides/functions/integrating-dynamodb-with-lambda/q/platform/android"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In this guide you will learn how to do three things:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Create a new Lambda function and DynamoDB database that are integrated together"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Create a new DynamoDB Database and integrate it with an existing Lambda function"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Create a new Lambda function and integrate it with an an existing DynamoDB database"
      },
      {
        "heading": "Creating a new Lambda function and DynamoDB database that are integrated",
        "depth": 3,
        "text": "The first thing you will need to do will be to create the DynamoDB table:"
      },
      {
        "heading": "Creating a new Lambda function and DynamoDB database that are integrated",
        "depth": 3,
        "text": "Next, create the function:"
      },
      {
        "heading": "Creating a new Lambda function and DynamoDB database that are integrated",
        "depth": 3,
        "text": "Deploy the function and database:"
      },
      {
        "heading": "Creating a new Lambda function and DynamoDB database that are integrated",
        "depth": 3,
        "text": "Your function and database are now ready to use!"
      },
      {
        "heading": "Creating a new Lambda function and DynamoDB database that are integrated",
        "depth": 3,
        "text": "To learn how to interact with DynamoDB from Lambda, check out Calling DynamoDB from Lambda in Node.js."
      },
      {
        "heading": "Creating a new DynamoDB Database and integrate with an existing Lambda function",
        "depth": 3,
        "text": "First, create the database using the storage category:"
      },
      {
        "heading": "Creating a new DynamoDB Database and integrate with an existing Lambda function",
        "depth": 3,
        "text": "Next, update the function permissions:"
      },
      {
        "heading": "Creating a new DynamoDB Database and integrate with an existing Lambda function",
        "depth": 3,
        "text": "Deploy the database and updates to the Lambda permissions:"
      },
      {
        "heading": "Creating a new DynamoDB Database and integrate with an existing Lambda function",
        "depth": 3,
        "text": "Your function and database are now ready to use!"
      },
      {
        "heading": "Creating a new Lambda function and integrate with an an existing DynamoDB database",
        "depth": 3,
        "text": "To create a new Lambda function integrated with an existing DynamoDB database, you need to grant access to the database in the creation process of the function:"
      },
      {
        "heading": "Creating a new Lambda function and integrate with an an existing DynamoDB database",
        "depth": 3,
        "text": "Deploy the function:"
      },
      {
        "heading": "Creating a new Lambda function and integrate with an an existing DynamoDB database",
        "depth": 3,
        "text": "Your function and database are now ready to use!"
      },
      {
        "heading": "Creating a new Lambda function and integrate with an an existing DynamoDB database",
        "depth": 3,
        "text": "To learn how to interact with DynamoDB from Lambda, check out Calling DynamoDB from Lambda in Node.js."
      }
    ],
    "source": "export const meta = {\n  title: `Integrating DynamoDB with Lambda`,\n  description: `How to integrate a DynamoDB table with a Lambda function`,\n};\n\nIn this guide you will learn how to do three things:\n\n1. Create a new Lambda function and DynamoDB database that are integrated together\n2. Create a new DynamoDB Database and integrate it with an existing Lambda function\n3. Create a new Lambda function and integrate it with an an existing DynamoDB database\n\n### Creating a new Lambda function and DynamoDB database that are integrated\n\nThe first thing you will need to do will be to create the DynamoDB table:\n\n```sh\namplify add storage\n\n? Please select from one of the below mentioned services: NoSQL Database\n? Please provide a friendly name for your resource that will be used to label this category in the project: testtable\n? Please provide table name: testtable\n\n# You can now add columns to the table.\n? What would you like to name this column: id\n? Please choose the data type: String\n? Would you like to add another column? N\n? Please choose partition key for the table: id\n? Do you want to add a sort key to your table? N\n? Do you want to add global secondary indexes to your table? N\n? Do you want to add a Lambda Trigger for your Table? N\n```\n\nNext, create the function:\n\n```sh\namplify add function\n\n? Provide a friendly name for your resource to be used as a label for this category in the project: mylambda\n? Provide the AWS Lambda function name: mylambda\n? Choose the function runtime that you want to use: NodeJS\n? Choose the function template that you want to use: Hello World\n? Do you want to access other resources created in this project from your Lambda function? Y\n? Select the category: storage\n? Select the operations you want to permit for testtable: create, read, update, delete\n? Do you want to invoke this function on a recurring schedule? N\n? Do you want to edit the local lambda function now? N\n```\n\nDeploy the function and database:\n\n```sh\namplify push\n```\n\nYour function and database are now ready to use!\n\nTo learn how to interact with DynamoDB from Lambda, check out [Calling DynamoDB from Lambda in Node.js](/guides/functions/dynamodb-from-js-lambda).\n\n### Creating a new DynamoDB Database and integrate with an existing Lambda function\n\nFirst, create the database using the __storage__ category:\n\n```sh\namplify add storage\n\n? Please select from one of the below mentioned services: NoSQL Database\n? Please provide a friendly name for your resource that will be used to label this category in the project: testtable\n? Please provide table name: testtable\n\n# You can now add columns to the table.\n? What would you like to name this column: id\n? Please choose the data type: String\n? Would you like to add another column? N\n? Please choose partition key for the table: id\n? Do you want to add a sort key to your table? N\n? Do you want to add global secondary indexes to your table? N\n? Do you want to add a Lambda Trigger for your Table? N\n```\n\nNext, update the function permissions:\n\n```sh\namplify update function\n\n? Please select the Lambda Function you would want to update: <your-function>\n? Do you want to update permissions granted to this Lambda function to perform on other resources in your project? Y\n? Select the category: storage\n? Select the operations you want to permit for testtable: create, read, update, delete\n? Do you want to invoke this function on a recurring schedule? N\n? Do you want to edit the local lambda function now? N\n```\n\nDeploy the database and updates to the Lambda permissions:\n\n```sh\namplify push\n```\n\nYour function and database are now ready to use!\n\n### Creating a new Lambda function and integrate with an an existing DynamoDB database\n\nTo create a new Lambda function integrated with an existing DynamoDB database, you need to grant access to the database in the creation process of the function:\n\n```sh\namplify add function\n\n? Provide a friendly name for your resource to be used as a label for this category in the project: mylambda\n? Provide the AWS Lambda function name: mylambda\n? Choose the function runtime that you want to use: NodeJS\n? Choose the function template that you want to use: Hello World\n? Do you want to access other resources created in this project from your Lambda function? Y\n? Select the category: storage\n\n# Select the database you'd like to grant permissions to or go to the next step if there is only one database in the project\n\n? Select the operations you want to permit for <your-table-name>: create, read, update, delete\n? Do you want to invoke this function on a recurring schedule? N\n? Do you want to edit the local lambda function now? N\n```\n\nDeploy the function:\n\n```sh\namplify push\n```\n\nYour function and database are now ready to use!\n\nTo learn how to interact with DynamoDB from Lambda, check out [Calling DynamoDB from Lambda in Node.js](/guides/functions/dynamodb-from-js-lambda).",
    "meta": {
      "title": "Integrating DynamoDB with Lambda - JavaScript",
      "description": "How to integrate a DynamoDB table with a Lambda function - JavaScript",
      "subcategory": "Functions",
      "category": "Guides"
    },
    "filename": "/guides/functions/integrating-dynamodb-with-lambda/q/platform/js"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In this guide you will learn how to connect a REST API to an existing Lambda function."
      },
      {
        "heading": null,
        "depth": null,
        "text": "To get started, create a new API:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Deploy the API:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Your API is now ready to use!"
      },
      {
        "heading": null,
        "depth": null,
        "text": "To learn more about how to interact with the API from a client-side application, check out the docs here"
      }
    ],
    "source": "export const meta = {\n  title: `Connecting a REST API to a Lambda function`,\n  description: `How to connect a REST API to a Lambda function`,\n};\n\nIn this guide you will learn how to connect a REST API to an existing Lambda function.\n\nTo get started, create a new API:\n\n```sh\namplify add api\n\n? Please select from one of the below mentioned services: REST\n? Provide a friendly name for your resource to be used as a label for this category in the project: myapi\n? Provide a path (e.g., /book/{isbn}): /hello\n? Choose a Lambda source: Use a Lambda function already added in the current Amplify project\n? Choose the Lambda function to invoke by this path: <your-function-name>\n? Restrict API access: N\n? Do you want to add another path: N\n```\n\nDeploy the API:\n\n```sh\namplify push\n```\n\nYour API is now ready to use!\n\nTo learn more about how to interact with the API from a client-side application, check out the docs [here](/lib/restapi/getting-started)",
    "meta": {
      "title": "Connecting a REST API to a Lambda function - iOS",
      "description": "How to connect a REST API to a Lambda function - iOS",
      "subcategory": "Functions",
      "category": "Guides"
    },
    "filename": "/guides/functions/connecting-a-rest-api/q/platform/ios"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In this guide you will learn how to connect a REST API to an existing Lambda function."
      },
      {
        "heading": null,
        "depth": null,
        "text": "To get started, create a new API:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Deploy the API:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Your API is now ready to use!"
      },
      {
        "heading": null,
        "depth": null,
        "text": "To learn more about how to interact with the API from a client-side application, check out the docs here"
      }
    ],
    "source": "export const meta = {\n  title: `Connecting a REST API to a Lambda function`,\n  description: `How to connect a REST API to a Lambda function`,\n};\n\nIn this guide you will learn how to connect a REST API to an existing Lambda function.\n\nTo get started, create a new API:\n\n```sh\namplify add api\n\n? Please select from one of the below mentioned services: REST\n? Provide a friendly name for your resource to be used as a label for this category in the project: myapi\n? Provide a path (e.g., /book/{isbn}): /hello\n? Choose a Lambda source: Use a Lambda function already added in the current Amplify project\n? Choose the Lambda function to invoke by this path: <your-function-name>\n? Restrict API access: N\n? Do you want to add another path: N\n```\n\nDeploy the API:\n\n```sh\namplify push\n```\n\nYour API is now ready to use!\n\nTo learn more about how to interact with the API from a client-side application, check out the docs [here](/lib/restapi/getting-started)",
    "meta": {
      "title": "Connecting a REST API to a Lambda function - Android",
      "description": "How to connect a REST API to a Lambda function - Android",
      "subcategory": "Functions",
      "category": "Guides"
    },
    "filename": "/guides/functions/connecting-a-rest-api/q/platform/android"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In this guide you will learn how to connect a REST API to an existing Lambda function."
      },
      {
        "heading": null,
        "depth": null,
        "text": "To get started, create a new API:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Deploy the API:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Your API is now ready to use!"
      },
      {
        "heading": null,
        "depth": null,
        "text": "To learn more about how to interact with the API from a client-side application, check out the docs here"
      }
    ],
    "source": "export const meta = {\n  title: `Connecting a REST API to a Lambda function`,\n  description: `How to connect a REST API to a Lambda function`,\n};\n\nIn this guide you will learn how to connect a REST API to an existing Lambda function.\n\nTo get started, create a new API:\n\n```sh\namplify add api\n\n? Please select from one of the below mentioned services: REST\n? Provide a friendly name for your resource to be used as a label for this category in the project: myapi\n? Provide a path (e.g., /book/{isbn}): /hello\n? Choose a Lambda source: Use a Lambda function already added in the current Amplify project\n? Choose the Lambda function to invoke by this path: <your-function-name>\n? Restrict API access: N\n? Do you want to add another path: N\n```\n\nDeploy the API:\n\n```sh\namplify push\n```\n\nYour API is now ready to use!\n\nTo learn more about how to interact with the API from a client-side application, check out the docs [here](/lib/restapi/getting-started)",
    "meta": {
      "title": "Connecting a REST API to a Lambda function - JavaScript",
      "description": "How to connect a REST API to a Lambda function - JavaScript",
      "subcategory": "Functions",
      "category": "Guides"
    },
    "filename": "/guides/functions/connecting-a-rest-api/q/platform/js"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "When you need to call your AppSync API from a Lambda function, you can export your AppSync operations generated by Amplify to a Lambda layer. This reduces the amount of duplicated code, and allows you to interact with the API from Lambda functions across multiple projects."
      },
      {
        "heading": "Set up your layer",
        "depth": 2,
        "text": "Start by creating the layer that will contain your AppSync operations."
      },
      {
        "heading": "Set up your layer",
        "depth": 2,
        "text": "In the ./amplify/backend/function/appsyncOperations/opt folder add the following helper library. The library exports a request function that you can use to send queries or mutations to your AppSync API. You can specify an API KEY to include the x-api-key header in the request. Otherwise the request is signed using SigV4 and the invoked Lambda function's credentials."
      },
      {
        "heading": "Generate compatible code for your layer",
        "depth": 2,
        "text": "Install the Babel dependencies to transpile the GraphQL javascript files generated by the Amplify codegen"
      },
      {
        "heading": "Generate compatible code for your layer",
        "depth": 2,
        "text": "Add a Babel configuration file that specifies the compilation target. The configuration specifies that the only target is NodeJS 12. In ./babel.config.json:"
      },
      {
        "heading": "Generate compatible code for your layer",
        "depth": 2,
        "text": "Add a command to the scripts in your package.json that updates your layer with the latest codegen:"
      },
      {
        "heading": "Generate compatible code for your layer",
        "depth": 2,
        "text": "Make sure to replace <your-lambda-layer-name> with the actual name of your Lambda layer."
      },
      {
        "heading": "Generate compatible code for your layer",
        "depth": 2,
        "text": "You can run this command after you've modified your schema to update the codegen and your layer:"
      },
      {
        "heading": "Generate compatible code for your layer",
        "depth": 2,
        "text": "The opt directory of in your layer now looks like this:"
      },
      {
        "heading": "Generate compatible code for your layer",
        "depth": 2,
        "text": "You can push your changes to the cloud with amplify push."
      },
      {
        "heading": "Generate compatible code for your layer",
        "depth": 2,
        "text": "You can now assign the layer to Lambda functions to easily call your AppSync API. Here's how you can leverage it in a Lambda function that has IAM permissions to call your AppSync API."
      }
    ],
    "source": "export const meta = {\n  title: `Exporting AppSync operations to a Lambda layer for easy reuse`,\n  description: `How to export your AppSync operations to a Lambda layer for easy reuse in your Lambda functions`,\n};\n\nWhen you need to call your AppSync API from a Lambda function, you can export your AppSync operations generated by Amplify to a Lambda layer. This reduces the amount of duplicated code, and allows you to interact with the API from Lambda functions across multiple projects.\n\n## Set up your layer\n\nStart by creating the layer that will contain your AppSync operations.\n\n```sh\n$ amplify add function\n\n? Select which capability you want to add:\n❯ Lambda layer (shared code & resource used across functions)\n\n? Provide a name for your Lambda layer: <your-lambda-layer-name>\n\n? Choose the runtime that you want to use:\n❯ NodeJS\n\n✅ Lambda layer folders & files created:\namplify/backend/function/appsyncOperations\n```\n\nIn the `./amplify/backend/function/appsyncOperations/opt` folder add the following helper library. The library exports a `request` function that you can use to send queries or mutations to your AppSync API. You can specify an API KEY to include the `x-api-key` header in the request. Otherwise the request is signed using SigV4 and the invoked Lambda function's credentials.\n\n```javascript\n// amplify/backend/function/appsyncOperations/opt/appSyncRequest.js\nconst https = require('https')\nconst AWS = require('aws-sdk')\nconst urlParse = require('url').URL\nconst region = process.env.REGION\n\n/**\n *\n * @param {Object} queryDetails the query, operationName, and variables\n * @param {String} appsyncUrl url of your AppSync API\n * @param {String} apiKey the api key to include in headers. if null, will sign with SigV4\n */\nexports.request = (queryDetails, appsyncUrl, apiKey) => {\n  const req = new AWS.HttpRequest(appsyncUrl, region)\n  const endpoint = new urlParse(appsyncUrl).hostname.toString()\n\n  req.method = 'POST'\n  req.path = '/graphql'\n  req.headers.host = endpoint\n  req.headers['Content-Type'] = 'application/json'\n  req.body = JSON.stringify(queryDetails)\n\n  if (apiKey) {\n    req.headers['x-api-key'] = apiKey\n  } else {\n    const signer = new AWS.Signers.V4(req, 'appsync', true)\n    signer.addAuthorization(AWS.config.credentials, AWS.util.date.getDate())\n  }\n\n  return new Promise((resolve, reject) => {\n    const httpRequest = https.request({ ...req, host: endpoint }, (result) => {\n      result.on('data', (data) => {\n        resolve(JSON.parse(data.toString()))\n      })\n    })\n\n    httpRequest.write(req.body)\n    httpRequest.end()\n  })\n}\n```\n\n## Generate compatible code for your layer\n\nInstall the Babel dependencies to transpile the GraphQL javascript files generated by the Amplify codegen\n\n```sh\nnpm i --save-dev @babel/core @babel/cli @babel/preset-env\n```\n\nAdd a Babel configuration file that specifies the compilation target. The configuration specifies that the only target is NodeJS 12. In `./babel.config.json`:\n\n```json\n{\n  \"presets\": [\n    [\n      \"@babel/env\",\n      {\n        \"targets\": {\n          \"node\": \"12\"\n        }\n      }\n    ]\n  ]\n}\n```\n\nAdd a command to the `scripts` in your `package.json` that updates your layer with the latest codegen:\n\n```json\n{\n  \"scripts\": {\n    \"updateAppsyncOperations\": \"amplify api gql-compile && amplify codegen && babel src/graphql --config-file ./babel.config.json -d ./amplify/backend/function/<your-lambda-layer-name>/opt/graphql/\"\n  }\n}\n```\n\nMake sure to replace `<your-lambda-layer-name>` with the actual name of your Lambda layer.\n\nYou can run this command after you've modified your schema to update the codegen and your layer:\n\n```sh\nnpm run updateAppsyncOperations\n```\n\nThe `opt` directory of in your layer now looks like this:\n\n```sh\namplify/backend/function/appsyncOperations/opt\n├── appsyncRequest.js\n└── graphql\n    ├── mutations.js\n    ├── queries.js\n    └── subscriptions.js\n```\n\nYou can push your changes to the cloud with `amplify push`.\n\nYou can now assign the layer to Lambda functions to easily call your AppSync API. Here's how you can leverage it in a Lambda function that has IAM permissions to call your AppSync API.\n\n```javascript\nconst appsyncUrl = process.env.API_AMPLIFYLAYERGUIDE_GRAPHQLAPIENDPOINTOUTPUT\nconst apiKey = process.env.API_AMPLIFYLAYERGUIDE_GRAPHQLAPIKEYOUTPUT\n\nconst { request } = require('/opt/appsyncRequest')\nconst { createTodo } = require('/opt/graphql/mutations')\nconst { listTodos } = require('/opt/graphql/queries')\n\nexports.handler = async (event) => {\n  try {\n    // create a TODO with AWS_IAM auth\n    var result = await request(\n      {\n        query: createTodo,\n        variables: {\n          input: {\n            name: 'new todo',\n            description: 'the first',\n          },\n        },\n      },\n      appsyncUrl\n    )\n    console.log('iam results:', result)\n    \n    // Now, retrieve all TODOs using API_KEY auth\n    result = await request(\n      {\n        query: listTodos,\n        operationName: 'ListTodos',\n      },\n      appsyncUrl,\n      apiKey\n    )\n    console.log('api key results', result)\n  } catch (error) {\n    console.log(error)\n  }\n}\n```\n",
    "meta": {
      "title": "Exporting AppSync operations to a Lambda layer for easy reuse - iOS",
      "description": "How to export your AppSync operations to a Lambda layer for easy reuse in your Lambda functions - iOS",
      "subcategory": "Functions",
      "category": "Guides"
    },
    "filename": "/guides/functions/appsync-operations-to-lambda-layer/q/platform/ios"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "When you need to call your AppSync API from a Lambda function, you can export your AppSync operations generated by Amplify to a Lambda layer. This reduces the amount of duplicated code, and allows you to interact with the API from Lambda functions across multiple projects."
      },
      {
        "heading": "Set up your layer",
        "depth": 2,
        "text": "Start by creating the layer that will contain your AppSync operations."
      },
      {
        "heading": "Set up your layer",
        "depth": 2,
        "text": "In the ./amplify/backend/function/appsyncOperations/opt folder add the following helper library. The library exports a request function that you can use to send queries or mutations to your AppSync API. You can specify an API KEY to include the x-api-key header in the request. Otherwise the request is signed using SigV4 and the invoked Lambda function's credentials."
      },
      {
        "heading": "Generate compatible code for your layer",
        "depth": 2,
        "text": "Install the Babel dependencies to transpile the GraphQL javascript files generated by the Amplify codegen"
      },
      {
        "heading": "Generate compatible code for your layer",
        "depth": 2,
        "text": "Add a Babel configuration file that specifies the compilation target. The configuration specifies that the only target is NodeJS 12. In ./babel.config.json:"
      },
      {
        "heading": "Generate compatible code for your layer",
        "depth": 2,
        "text": "Add a command to the scripts in your package.json that updates your layer with the latest codegen:"
      },
      {
        "heading": "Generate compatible code for your layer",
        "depth": 2,
        "text": "Make sure to replace <your-lambda-layer-name> with the actual name of your Lambda layer."
      },
      {
        "heading": "Generate compatible code for your layer",
        "depth": 2,
        "text": "You can run this command after you've modified your schema to update the codegen and your layer:"
      },
      {
        "heading": "Generate compatible code for your layer",
        "depth": 2,
        "text": "The opt directory of in your layer now looks like this:"
      },
      {
        "heading": "Generate compatible code for your layer",
        "depth": 2,
        "text": "You can push your changes to the cloud with amplify push."
      },
      {
        "heading": "Generate compatible code for your layer",
        "depth": 2,
        "text": "You can now assign the layer to Lambda functions to easily call your AppSync API. Here's how you can leverage it in a Lambda function that has IAM permissions to call your AppSync API."
      }
    ],
    "source": "export const meta = {\n  title: `Exporting AppSync operations to a Lambda layer for easy reuse`,\n  description: `How to export your AppSync operations to a Lambda layer for easy reuse in your Lambda functions`,\n};\n\nWhen you need to call your AppSync API from a Lambda function, you can export your AppSync operations generated by Amplify to a Lambda layer. This reduces the amount of duplicated code, and allows you to interact with the API from Lambda functions across multiple projects.\n\n## Set up your layer\n\nStart by creating the layer that will contain your AppSync operations.\n\n```sh\n$ amplify add function\n\n? Select which capability you want to add:\n❯ Lambda layer (shared code & resource used across functions)\n\n? Provide a name for your Lambda layer: <your-lambda-layer-name>\n\n? Choose the runtime that you want to use:\n❯ NodeJS\n\n✅ Lambda layer folders & files created:\namplify/backend/function/appsyncOperations\n```\n\nIn the `./amplify/backend/function/appsyncOperations/opt` folder add the following helper library. The library exports a `request` function that you can use to send queries or mutations to your AppSync API. You can specify an API KEY to include the `x-api-key` header in the request. Otherwise the request is signed using SigV4 and the invoked Lambda function's credentials.\n\n```javascript\n// amplify/backend/function/appsyncOperations/opt/appSyncRequest.js\nconst https = require('https')\nconst AWS = require('aws-sdk')\nconst urlParse = require('url').URL\nconst region = process.env.REGION\n\n/**\n *\n * @param {Object} queryDetails the query, operationName, and variables\n * @param {String} appsyncUrl url of your AppSync API\n * @param {String} apiKey the api key to include in headers. if null, will sign with SigV4\n */\nexports.request = (queryDetails, appsyncUrl, apiKey) => {\n  const req = new AWS.HttpRequest(appsyncUrl, region)\n  const endpoint = new urlParse(appsyncUrl).hostname.toString()\n\n  req.method = 'POST'\n  req.path = '/graphql'\n  req.headers.host = endpoint\n  req.headers['Content-Type'] = 'application/json'\n  req.body = JSON.stringify(queryDetails)\n\n  if (apiKey) {\n    req.headers['x-api-key'] = apiKey\n  } else {\n    const signer = new AWS.Signers.V4(req, 'appsync', true)\n    signer.addAuthorization(AWS.config.credentials, AWS.util.date.getDate())\n  }\n\n  return new Promise((resolve, reject) => {\n    const httpRequest = https.request({ ...req, host: endpoint }, (result) => {\n      result.on('data', (data) => {\n        resolve(JSON.parse(data.toString()))\n      })\n    })\n\n    httpRequest.write(req.body)\n    httpRequest.end()\n  })\n}\n```\n\n## Generate compatible code for your layer\n\nInstall the Babel dependencies to transpile the GraphQL javascript files generated by the Amplify codegen\n\n```sh\nnpm i --save-dev @babel/core @babel/cli @babel/preset-env\n```\n\nAdd a Babel configuration file that specifies the compilation target. The configuration specifies that the only target is NodeJS 12. In `./babel.config.json`:\n\n```json\n{\n  \"presets\": [\n    [\n      \"@babel/env\",\n      {\n        \"targets\": {\n          \"node\": \"12\"\n        }\n      }\n    ]\n  ]\n}\n```\n\nAdd a command to the `scripts` in your `package.json` that updates your layer with the latest codegen:\n\n```json\n{\n  \"scripts\": {\n    \"updateAppsyncOperations\": \"amplify api gql-compile && amplify codegen && babel src/graphql --config-file ./babel.config.json -d ./amplify/backend/function/<your-lambda-layer-name>/opt/graphql/\"\n  }\n}\n```\n\nMake sure to replace `<your-lambda-layer-name>` with the actual name of your Lambda layer.\n\nYou can run this command after you've modified your schema to update the codegen and your layer:\n\n```sh\nnpm run updateAppsyncOperations\n```\n\nThe `opt` directory of in your layer now looks like this:\n\n```sh\namplify/backend/function/appsyncOperations/opt\n├── appsyncRequest.js\n└── graphql\n    ├── mutations.js\n    ├── queries.js\n    └── subscriptions.js\n```\n\nYou can push your changes to the cloud with `amplify push`.\n\nYou can now assign the layer to Lambda functions to easily call your AppSync API. Here's how you can leverage it in a Lambda function that has IAM permissions to call your AppSync API.\n\n```javascript\nconst appsyncUrl = process.env.API_AMPLIFYLAYERGUIDE_GRAPHQLAPIENDPOINTOUTPUT\nconst apiKey = process.env.API_AMPLIFYLAYERGUIDE_GRAPHQLAPIKEYOUTPUT\n\nconst { request } = require('/opt/appsyncRequest')\nconst { createTodo } = require('/opt/graphql/mutations')\nconst { listTodos } = require('/opt/graphql/queries')\n\nexports.handler = async (event) => {\n  try {\n    // create a TODO with AWS_IAM auth\n    var result = await request(\n      {\n        query: createTodo,\n        variables: {\n          input: {\n            name: 'new todo',\n            description: 'the first',\n          },\n        },\n      },\n      appsyncUrl\n    )\n    console.log('iam results:', result)\n    \n    // Now, retrieve all TODOs using API_KEY auth\n    result = await request(\n      {\n        query: listTodos,\n        operationName: 'ListTodos',\n      },\n      appsyncUrl,\n      apiKey\n    )\n    console.log('api key results', result)\n  } catch (error) {\n    console.log(error)\n  }\n}\n```\n",
    "meta": {
      "title": "Exporting AppSync operations to a Lambda layer for easy reuse - Android",
      "description": "How to export your AppSync operations to a Lambda layer for easy reuse in your Lambda functions - Android",
      "subcategory": "Functions",
      "category": "Guides"
    },
    "filename": "/guides/functions/appsync-operations-to-lambda-layer/q/platform/android"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "When you need to call your AppSync API from a Lambda function, you can export your AppSync operations generated by Amplify to a Lambda layer. This reduces the amount of duplicated code, and allows you to interact with the API from Lambda functions across multiple projects."
      },
      {
        "heading": "Set up your layer",
        "depth": 2,
        "text": "Start by creating the layer that will contain your AppSync operations."
      },
      {
        "heading": "Set up your layer",
        "depth": 2,
        "text": "In the ./amplify/backend/function/appsyncOperations/opt folder add the following helper library. The library exports a request function that you can use to send queries or mutations to your AppSync API. You can specify an API KEY to include the x-api-key header in the request. Otherwise the request is signed using SigV4 and the invoked Lambda function's credentials."
      },
      {
        "heading": "Generate compatible code for your layer",
        "depth": 2,
        "text": "Install the Babel dependencies to transpile the GraphQL javascript files generated by the Amplify codegen"
      },
      {
        "heading": "Generate compatible code for your layer",
        "depth": 2,
        "text": "Add a Babel configuration file that specifies the compilation target. The configuration specifies that the only target is NodeJS 12. In ./babel.config.json:"
      },
      {
        "heading": "Generate compatible code for your layer",
        "depth": 2,
        "text": "Add a command to the scripts in your package.json that updates your layer with the latest codegen:"
      },
      {
        "heading": "Generate compatible code for your layer",
        "depth": 2,
        "text": "Make sure to replace <your-lambda-layer-name> with the actual name of your Lambda layer."
      },
      {
        "heading": "Generate compatible code for your layer",
        "depth": 2,
        "text": "You can run this command after you've modified your schema to update the codegen and your layer:"
      },
      {
        "heading": "Generate compatible code for your layer",
        "depth": 2,
        "text": "The opt directory of in your layer now looks like this:"
      },
      {
        "heading": "Generate compatible code for your layer",
        "depth": 2,
        "text": "You can push your changes to the cloud with amplify push."
      },
      {
        "heading": "Generate compatible code for your layer",
        "depth": 2,
        "text": "You can now assign the layer to Lambda functions to easily call your AppSync API. Here's how you can leverage it in a Lambda function that has IAM permissions to call your AppSync API."
      }
    ],
    "source": "export const meta = {\n  title: `Exporting AppSync operations to a Lambda layer for easy reuse`,\n  description: `How to export your AppSync operations to a Lambda layer for easy reuse in your Lambda functions`,\n};\n\nWhen you need to call your AppSync API from a Lambda function, you can export your AppSync operations generated by Amplify to a Lambda layer. This reduces the amount of duplicated code, and allows you to interact with the API from Lambda functions across multiple projects.\n\n## Set up your layer\n\nStart by creating the layer that will contain your AppSync operations.\n\n```sh\n$ amplify add function\n\n? Select which capability you want to add:\n❯ Lambda layer (shared code & resource used across functions)\n\n? Provide a name for your Lambda layer: <your-lambda-layer-name>\n\n? Choose the runtime that you want to use:\n❯ NodeJS\n\n✅ Lambda layer folders & files created:\namplify/backend/function/appsyncOperations\n```\n\nIn the `./amplify/backend/function/appsyncOperations/opt` folder add the following helper library. The library exports a `request` function that you can use to send queries or mutations to your AppSync API. You can specify an API KEY to include the `x-api-key` header in the request. Otherwise the request is signed using SigV4 and the invoked Lambda function's credentials.\n\n```javascript\n// amplify/backend/function/appsyncOperations/opt/appSyncRequest.js\nconst https = require('https')\nconst AWS = require('aws-sdk')\nconst urlParse = require('url').URL\nconst region = process.env.REGION\n\n/**\n *\n * @param {Object} queryDetails the query, operationName, and variables\n * @param {String} appsyncUrl url of your AppSync API\n * @param {String} apiKey the api key to include in headers. if null, will sign with SigV4\n */\nexports.request = (queryDetails, appsyncUrl, apiKey) => {\n  const req = new AWS.HttpRequest(appsyncUrl, region)\n  const endpoint = new urlParse(appsyncUrl).hostname.toString()\n\n  req.method = 'POST'\n  req.path = '/graphql'\n  req.headers.host = endpoint\n  req.headers['Content-Type'] = 'application/json'\n  req.body = JSON.stringify(queryDetails)\n\n  if (apiKey) {\n    req.headers['x-api-key'] = apiKey\n  } else {\n    const signer = new AWS.Signers.V4(req, 'appsync', true)\n    signer.addAuthorization(AWS.config.credentials, AWS.util.date.getDate())\n  }\n\n  return new Promise((resolve, reject) => {\n    const httpRequest = https.request({ ...req, host: endpoint }, (result) => {\n      result.on('data', (data) => {\n        resolve(JSON.parse(data.toString()))\n      })\n    })\n\n    httpRequest.write(req.body)\n    httpRequest.end()\n  })\n}\n```\n\n## Generate compatible code for your layer\n\nInstall the Babel dependencies to transpile the GraphQL javascript files generated by the Amplify codegen\n\n```sh\nnpm i --save-dev @babel/core @babel/cli @babel/preset-env\n```\n\nAdd a Babel configuration file that specifies the compilation target. The configuration specifies that the only target is NodeJS 12. In `./babel.config.json`:\n\n```json\n{\n  \"presets\": [\n    [\n      \"@babel/env\",\n      {\n        \"targets\": {\n          \"node\": \"12\"\n        }\n      }\n    ]\n  ]\n}\n```\n\nAdd a command to the `scripts` in your `package.json` that updates your layer with the latest codegen:\n\n```json\n{\n  \"scripts\": {\n    \"updateAppsyncOperations\": \"amplify api gql-compile && amplify codegen && babel src/graphql --config-file ./babel.config.json -d ./amplify/backend/function/<your-lambda-layer-name>/opt/graphql/\"\n  }\n}\n```\n\nMake sure to replace `<your-lambda-layer-name>` with the actual name of your Lambda layer.\n\nYou can run this command after you've modified your schema to update the codegen and your layer:\n\n```sh\nnpm run updateAppsyncOperations\n```\n\nThe `opt` directory of in your layer now looks like this:\n\n```sh\namplify/backend/function/appsyncOperations/opt\n├── appsyncRequest.js\n└── graphql\n    ├── mutations.js\n    ├── queries.js\n    └── subscriptions.js\n```\n\nYou can push your changes to the cloud with `amplify push`.\n\nYou can now assign the layer to Lambda functions to easily call your AppSync API. Here's how you can leverage it in a Lambda function that has IAM permissions to call your AppSync API.\n\n```javascript\nconst appsyncUrl = process.env.API_AMPLIFYLAYERGUIDE_GRAPHQLAPIENDPOINTOUTPUT\nconst apiKey = process.env.API_AMPLIFYLAYERGUIDE_GRAPHQLAPIKEYOUTPUT\n\nconst { request } = require('/opt/appsyncRequest')\nconst { createTodo } = require('/opt/graphql/mutations')\nconst { listTodos } = require('/opt/graphql/queries')\n\nexports.handler = async (event) => {\n  try {\n    // create a TODO with AWS_IAM auth\n    var result = await request(\n      {\n        query: createTodo,\n        variables: {\n          input: {\n            name: 'new todo',\n            description: 'the first',\n          },\n        },\n      },\n      appsyncUrl\n    )\n    console.log('iam results:', result)\n    \n    // Now, retrieve all TODOs using API_KEY auth\n    result = await request(\n      {\n        query: listTodos,\n        operationName: 'ListTodos',\n      },\n      appsyncUrl,\n      apiKey\n    )\n    console.log('api key results', result)\n  } catch (error) {\n    console.log(error)\n  }\n}\n```\n",
    "meta": {
      "title": "Exporting AppSync operations to a Lambda layer for easy reuse - JavaScript",
      "description": "How to export your AppSync operations to a Lambda layer for easy reuse in your Lambda functions - JavaScript",
      "subcategory": "Functions",
      "category": "Guides"
    },
    "filename": "/guides/functions/appsync-operations-to-lambda-layer/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Parallel Processing`,\n  description: `How to multiple DataStore operations in parallel.`,\n};\n\nimport ios0 from \"/src/fragments/guides/datastore/parallel-processing-ios.mdx\";\n\n<Fragments fragments={{ios: ios0}} />",
    "meta": {
      "title": "Parallel Processing - iOS",
      "description": "How to multiple DataStore operations in parallel. - iOS",
      "subcategory": "Datastore",
      "category": "Guides"
    },
    "filename": "/guides/datastore/parallel-processing/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Managing user attributes`,\n  description: `How to manage standard and custom user attributes`,\n};\n\nimport js0 from \"/src/fragments/guides/authentication/js/managing-user-attributes.mdx\";\n\n<Fragments fragments={{js: js0}} />\n",
    "meta": {
      "title": "Managing user attributes - JavaScript",
      "description": "How to manage standard and custom user attributes - JavaScript",
      "subcategory": "Authentication",
      "category": "Guides"
    },
    "filename": "/guides/authentication/managing-user-attributes/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Listening for authentication events`,\n  description: `Listening for auth events using the Hub utility`,\n};\n\nimport js0 from \"/src/fragments/guides/authentication/js/listening-for-auth-events.mdx\";\n\n<Fragments fragments={{js: js0}} />\n",
    "meta": {
      "title": "Listening for authentication events - JavaScript",
      "description": "Listening for auth events using the Hub utility - JavaScript",
      "subcategory": "Authentication",
      "category": "Guides"
    },
    "filename": "/guides/authentication/listening-for-auth-events/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Email-only sign up and sign in`,\n  description: `Enabling users to authenticate with only their email`,\n};\n\nimport js0 from \"/src/fragments/guides/authentication/js/email-only-authentication.mdx\";\n\n<Fragments fragments={{js: js0}} />",
    "meta": {
      "title": "Email-only sign up and sign in - JavaScript",
      "description": "Enabling users to authenticate with only their email - JavaScript",
      "subcategory": "Authentication",
      "category": "Guides"
    },
    "filename": "/guides/authentication/email-only-authentication/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Creating a custom authentication flow`,\n  description: `Creating a custom authentication flow with AWS Amplify`,\n};\n\nimport js0 from \"/src/fragments/guides/authentication/js/custom-auth-flow.mdx\";\n\n<Fragments fragments={{js: js0}} />\n",
    "meta": {
      "title": "Creating a custom authentication flow - JavaScript",
      "description": "Creating a custom authentication flow with AWS Amplify - JavaScript",
      "subcategory": "Authentication",
      "category": "Guides"
    },
    "filename": "/guides/authentication/custom-auth-flow/q/platform/js"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In this guide, you will learn how to deploy a Python API."
      },
      {
        "heading": "2. Add the API and function",
        "depth": 2,
        "text": "The CLI should have created a new function located at amplify/backend/function/greetingfunction."
      },
      {
        "heading": "3. Updating the function code",
        "depth": 2,
        "text": "Next, open  amplify/backend/function/greetingfunction/src/index.py and update the code to the following:"
      },
      {
        "heading": "4. Deploy the API",
        "depth": 2,
        "text": "To deploy the API, run the push command:"
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "Here is how you can send a GET request to the API."
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "To learn more about interacting with REST APIs using Amplify, check out the complete documentation here."
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "The API endpoint is located in the aws-exports.js folder."
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "You can also interact directly with the API using this URL and the specified path:"
      }
    ],
    "source": "export const meta = {\n  title: `Python API`,\n  description: `How to deploy a Python API using Amplify Functions`,\n};\n\nIn this guide, you will learn how to deploy a Python API.\n\n## 1. Initialize a new Amplify project\n\n```sh\namplify init\n\n# Follow the steps to give the project a name, environment name, and set the default text editor.\n# Accept defaults for everything else and choose your AWS Profile.\n```\n\n## 2. Add the API and function\n\n```sh\namplify add api\n\n? Please select from one of the below mentioned services: REST\n? Provide a friendly name for your resource to be used as a label for this category in the project: pythonapi\n? Provide a path (e.g., /book/{isbn}): /hello\n? Choose a Lambda source: Create a new Lambda function\n? Provide a friendly name for your resource to be used as a label for this category in the project: greetingfunction\n? Provide the AWS Lambda function name: greetingfunction\n? Choose the function runtime that you want to use: Python\n? Do you want to access other resources created in this project from your Lambda function? N\n? Do you want to invoke this function on a recurring schedule? N\n? Do you want to edit the local lambda function now? N\n? Restrict API access: N\n? Do you want to add another path? N\n```\n\nThe CLI should have created a new function located at **amplify/backend/function/greetingfunction**.\n\n## 3. Updating the function code\n\nNext, open  **amplify/backend/function/greetingfunction/src/index.py** and update the code to the following:\n\n```python\nimport json\nimport datetime\n\ndef handler(event, context):\n\n  current_time = datetime.datetime.now().time()\n\n  body = {\n      'message': 'Hello, the current time is ' + str(current_time)\n  }\n\n  response = {\n      'statusCode': 200,\n      'body': json.dumps(body),\n      'headers': {\n        'Content-Type': 'application/json',\n        'Access-Control-Allow-Origin': '*'\n      },\n  }\n  \n  return response\n```\n\n## 4. Deploy the API\n\nTo deploy the API, run the `push` command:\n\n```sh\namplify push\n```\n\n## 5. Using the API\n\nHere is how you can send a GET request to the API.\n\nimport js0 from \"/src/fragments/guides/api-rest/js/python-api-call.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/guides/api-rest/ios/rest-api-call.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/guides/api-rest/android/rest-api-call.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nTo learn more about interacting with REST APIs using Amplify, check out the complete documentation [here](/lib/restapi/getting-started).\n\nThe API endpoint is located in the `aws-exports.js` folder.\n\nYou can also interact directly with the API using this URL and the specified path:\n\n```sh\ncurl https://<api-id>.execute-api.<api-region>.amazonaws.com/<your-env-name>/hello\n```\n",
    "meta": {
      "title": "Python API - iOS",
      "description": "How to deploy a Python API using Amplify Functions - iOS",
      "subcategory": "API (REST)",
      "category": "Guides"
    },
    "filename": "/guides/api-rest/python-api/q/platform/ios"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In this guide, you will learn how to deploy a Python API."
      },
      {
        "heading": "2. Add the API and function",
        "depth": 2,
        "text": "The CLI should have created a new function located at amplify/backend/function/greetingfunction."
      },
      {
        "heading": "3. Updating the function code",
        "depth": 2,
        "text": "Next, open  amplify/backend/function/greetingfunction/src/index.py and update the code to the following:"
      },
      {
        "heading": "4. Deploy the API",
        "depth": 2,
        "text": "To deploy the API, run the push command:"
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "Here is how you can send a GET request to the API."
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "To learn more about interacting with REST APIs using Amplify, check out the complete documentation here."
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "The API endpoint is located in the aws-exports.js folder."
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "You can also interact directly with the API using this URL and the specified path:"
      }
    ],
    "source": "export const meta = {\n  title: `Python API`,\n  description: `How to deploy a Python API using Amplify Functions`,\n};\n\nIn this guide, you will learn how to deploy a Python API.\n\n## 1. Initialize a new Amplify project\n\n```sh\namplify init\n\n# Follow the steps to give the project a name, environment name, and set the default text editor.\n# Accept defaults for everything else and choose your AWS Profile.\n```\n\n## 2. Add the API and function\n\n```sh\namplify add api\n\n? Please select from one of the below mentioned services: REST\n? Provide a friendly name for your resource to be used as a label for this category in the project: pythonapi\n? Provide a path (e.g., /book/{isbn}): /hello\n? Choose a Lambda source: Create a new Lambda function\n? Provide a friendly name for your resource to be used as a label for this category in the project: greetingfunction\n? Provide the AWS Lambda function name: greetingfunction\n? Choose the function runtime that you want to use: Python\n? Do you want to access other resources created in this project from your Lambda function? N\n? Do you want to invoke this function on a recurring schedule? N\n? Do you want to edit the local lambda function now? N\n? Restrict API access: N\n? Do you want to add another path? N\n```\n\nThe CLI should have created a new function located at **amplify/backend/function/greetingfunction**.\n\n## 3. Updating the function code\n\nNext, open  **amplify/backend/function/greetingfunction/src/index.py** and update the code to the following:\n\n```python\nimport json\nimport datetime\n\ndef handler(event, context):\n\n  current_time = datetime.datetime.now().time()\n\n  body = {\n      'message': 'Hello, the current time is ' + str(current_time)\n  }\n\n  response = {\n      'statusCode': 200,\n      'body': json.dumps(body),\n      'headers': {\n        'Content-Type': 'application/json',\n        'Access-Control-Allow-Origin': '*'\n      },\n  }\n  \n  return response\n```\n\n## 4. Deploy the API\n\nTo deploy the API, run the `push` command:\n\n```sh\namplify push\n```\n\n## 5. Using the API\n\nHere is how you can send a GET request to the API.\n\nimport js0 from \"/src/fragments/guides/api-rest/js/python-api-call.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/guides/api-rest/ios/rest-api-call.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/guides/api-rest/android/rest-api-call.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nTo learn more about interacting with REST APIs using Amplify, check out the complete documentation [here](/lib/restapi/getting-started).\n\nThe API endpoint is located in the `aws-exports.js` folder.\n\nYou can also interact directly with the API using this URL and the specified path:\n\n```sh\ncurl https://<api-id>.execute-api.<api-region>.amazonaws.com/<your-env-name>/hello\n```\n",
    "meta": {
      "title": "Python API - Android",
      "description": "How to deploy a Python API using Amplify Functions - Android",
      "subcategory": "API (REST)",
      "category": "Guides"
    },
    "filename": "/guides/api-rest/python-api/q/platform/android"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In this guide, you will learn how to deploy a Python API."
      },
      {
        "heading": "2. Add the API and function",
        "depth": 2,
        "text": "The CLI should have created a new function located at amplify/backend/function/greetingfunction."
      },
      {
        "heading": "3. Updating the function code",
        "depth": 2,
        "text": "Next, open  amplify/backend/function/greetingfunction/src/index.py and update the code to the following:"
      },
      {
        "heading": "4. Deploy the API",
        "depth": 2,
        "text": "To deploy the API, run the push command:"
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "Here is how you can send a GET request to the API."
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "To learn more about interacting with REST APIs using Amplify, check out the complete documentation here."
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "The API endpoint is located in the aws-exports.js folder."
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "You can also interact directly with the API using this URL and the specified path:"
      }
    ],
    "source": "export const meta = {\n  title: `Python API`,\n  description: `How to deploy a Python API using Amplify Functions`,\n};\n\nIn this guide, you will learn how to deploy a Python API.\n\n## 1. Initialize a new Amplify project\n\n```sh\namplify init\n\n# Follow the steps to give the project a name, environment name, and set the default text editor.\n# Accept defaults for everything else and choose your AWS Profile.\n```\n\n## 2. Add the API and function\n\n```sh\namplify add api\n\n? Please select from one of the below mentioned services: REST\n? Provide a friendly name for your resource to be used as a label for this category in the project: pythonapi\n? Provide a path (e.g., /book/{isbn}): /hello\n? Choose a Lambda source: Create a new Lambda function\n? Provide a friendly name for your resource to be used as a label for this category in the project: greetingfunction\n? Provide the AWS Lambda function name: greetingfunction\n? Choose the function runtime that you want to use: Python\n? Do you want to access other resources created in this project from your Lambda function? N\n? Do you want to invoke this function on a recurring schedule? N\n? Do you want to edit the local lambda function now? N\n? Restrict API access: N\n? Do you want to add another path? N\n```\n\nThe CLI should have created a new function located at **amplify/backend/function/greetingfunction**.\n\n## 3. Updating the function code\n\nNext, open  **amplify/backend/function/greetingfunction/src/index.py** and update the code to the following:\n\n```python\nimport json\nimport datetime\n\ndef handler(event, context):\n\n  current_time = datetime.datetime.now().time()\n\n  body = {\n      'message': 'Hello, the current time is ' + str(current_time)\n  }\n\n  response = {\n      'statusCode': 200,\n      'body': json.dumps(body),\n      'headers': {\n        'Content-Type': 'application/json',\n        'Access-Control-Allow-Origin': '*'\n      },\n  }\n  \n  return response\n```\n\n## 4. Deploy the API\n\nTo deploy the API, run the `push` command:\n\n```sh\namplify push\n```\n\n## 5. Using the API\n\nHere is how you can send a GET request to the API.\n\nimport js0 from \"/src/fragments/guides/api-rest/js/python-api-call.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/guides/api-rest/ios/rest-api-call.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/guides/api-rest/android/rest-api-call.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nTo learn more about interacting with REST APIs using Amplify, check out the complete documentation [here](/lib/restapi/getting-started).\n\nThe API endpoint is located in the `aws-exports.js` folder.\n\nYou can also interact directly with the API using this URL and the specified path:\n\n```sh\ncurl https://<api-id>.execute-api.<api-region>.amazonaws.com/<your-env-name>/hello\n```\n",
    "meta": {
      "title": "Python API - JavaScript",
      "description": "How to deploy a Python API using Amplify Functions - JavaScript",
      "subcategory": "API (REST)",
      "category": "Guides"
    },
    "filename": "/guides/api-rest/python-api/q/platform/js"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In this guide, you will learn how to deploy a Go API."
      },
      {
        "heading": "2. Add the API and function",
        "depth": 2,
        "text": "The CLI should have created a new function located at amplify/backend/function/greetingfunction."
      },
      {
        "heading": "3. Updating the function code",
        "depth": 2,
        "text": "Next, open  amplify/backend/function/greetingfunction/src/main.go and update the code to the following:"
      },
      {
        "heading": "4. Deploy the API",
        "depth": 2,
        "text": "To deploy the API, run the push command:"
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "Here is how you can send a GET request to the API."
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "To learn more about interacting with REST APIs using Amplify, check out the complete documentation here."
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "The API endpoint is located in the aws-exports.js folder."
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "You can also interact directly with the API using this URL and the specified path:"
      }
    ],
    "source": "export const meta = {\n  title: `Go API`,\n  description: `How to deploy a Go API using Amplify Functions`,\n};\n\nIn this guide, you will learn how to deploy a Go API.\n\n## 1. Initialize a new Amplify project\n\n```sh\namplify init\n\n# Follow the steps to give the project a name, environment name, and set the default text editor.\n# Accept defaults for everything else and choose your AWS Profile.\n```\n\n## 2. Add the API and function\n\n```sh\namplify add api\n\n? Please select from one of the below mentioned services: REST\n? Provide a friendly name for your resource to be used as a label for this category in the project: goapi\n? Provide a path (e.g., /book/{isbn}): /hello\n? Choose a Lambda source: Create a new Lambda function\n? Provide a friendly name for your resource to be used as a label for this category in the project: greetingfunction\n? Provide the AWS Lambda function name: greetingfunction\n? Choose the function runtime that you want to use: Go\n? Do you want to access other resources created in this project from your Lambda function? N\n? Do you want to invoke this function on a recurring schedule? N\n? Do you want to edit the local lambda function now? N\n? Restrict API access: N\n? Do you want to add another path? N\n```\n\nThe CLI should have created a new function located at **amplify/backend/function/greetingfunction**.\n\n## 3. Updating the function code\n\nNext, open  **amplify/backend/function/greetingfunction/src/main.go** and update the code to the following:\n\n```go\npackage main\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\ntype Response events.APIGatewayProxyResponse\n\nfunc Handler(ctx context.Context) (Response, error) {\n\tvar buf bytes.Buffer\n\n\tbody, err := json.Marshal(map[string]interface{}{\n\t\t\"message\": \"Congrats! Your function executed successfully!\",\n\t})\n\tif err != nil {\n\t\treturn Response{StatusCode: 404}, err\n\t}\n\tjson.HTMLEscape(&buf, body)\n\n\tresp := Response{\n\t\tStatusCode:      200,\n\t\tIsBase64Encoded: false,\n\t\tBody:            buf.String(),\n\t\tHeaders: map[string]string{\n\t\t\t\"Content-Type\": \"application/json\",\n\t\t\t\"X-MyCompany-Func-Reply\": \"hello-handler\",\n\t\t\t\"Access-Control-Allow-Origin\": \"*\",\n\t\t\t\"Access-Control-Allow-Methods\": \"POST, GET, OPTIONS, PUT, DELETE\",\n\t\t\t\"Access-Control-Allow-Headers\": \"Accept, Content-Type, Content-Length, Accept-Encoding, X-CSRF-Token, Authorization\",\n\t\t},\n\t}\n\n\treturn resp, nil\n}\n\nfunc main() {\n\tlambda.Start(Handler)\n}\n```\n\n## 4. Deploy the API\n\nTo deploy the API, run the `push` command:\n\n```sh\namplify push\n```\n\n## 5. Using the API\n\nHere is how you can send a GET request to the API.\n\nimport js0 from \"/src/fragments/guides/api-rest/js/go-api-call.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/guides/api-rest/ios/rest-api-call.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/guides/api-rest/android/rest-api-call.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nTo learn more about interacting with REST APIs using Amplify, check out the complete documentation [here](/lib/restapi/getting-started).\n\nThe API endpoint is located in the `aws-exports.js` folder.\n\nYou can also interact directly with the API using this URL and the specified path:\n\n```sh\ncurl https://<api-id>.execute-api.<api-region>.amazonaws.com/<your-env-name>/hello\n```\n",
    "meta": {
      "title": "Go API - iOS",
      "description": "How to deploy a Go API using Amplify Functions - iOS",
      "subcategory": "API (REST)",
      "category": "Guides"
    },
    "filename": "/guides/api-rest/go-api/q/platform/ios"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In this guide, you will learn how to deploy a Go API."
      },
      {
        "heading": "2. Add the API and function",
        "depth": 2,
        "text": "The CLI should have created a new function located at amplify/backend/function/greetingfunction."
      },
      {
        "heading": "3. Updating the function code",
        "depth": 2,
        "text": "Next, open  amplify/backend/function/greetingfunction/src/main.go and update the code to the following:"
      },
      {
        "heading": "4. Deploy the API",
        "depth": 2,
        "text": "To deploy the API, run the push command:"
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "Here is how you can send a GET request to the API."
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "To learn more about interacting with REST APIs using Amplify, check out the complete documentation here."
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "The API endpoint is located in the aws-exports.js folder."
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "You can also interact directly with the API using this URL and the specified path:"
      }
    ],
    "source": "export const meta = {\n  title: `Go API`,\n  description: `How to deploy a Go API using Amplify Functions`,\n};\n\nIn this guide, you will learn how to deploy a Go API.\n\n## 1. Initialize a new Amplify project\n\n```sh\namplify init\n\n# Follow the steps to give the project a name, environment name, and set the default text editor.\n# Accept defaults for everything else and choose your AWS Profile.\n```\n\n## 2. Add the API and function\n\n```sh\namplify add api\n\n? Please select from one of the below mentioned services: REST\n? Provide a friendly name for your resource to be used as a label for this category in the project: goapi\n? Provide a path (e.g., /book/{isbn}): /hello\n? Choose a Lambda source: Create a new Lambda function\n? Provide a friendly name for your resource to be used as a label for this category in the project: greetingfunction\n? Provide the AWS Lambda function name: greetingfunction\n? Choose the function runtime that you want to use: Go\n? Do you want to access other resources created in this project from your Lambda function? N\n? Do you want to invoke this function on a recurring schedule? N\n? Do you want to edit the local lambda function now? N\n? Restrict API access: N\n? Do you want to add another path? N\n```\n\nThe CLI should have created a new function located at **amplify/backend/function/greetingfunction**.\n\n## 3. Updating the function code\n\nNext, open  **amplify/backend/function/greetingfunction/src/main.go** and update the code to the following:\n\n```go\npackage main\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\ntype Response events.APIGatewayProxyResponse\n\nfunc Handler(ctx context.Context) (Response, error) {\n\tvar buf bytes.Buffer\n\n\tbody, err := json.Marshal(map[string]interface{}{\n\t\t\"message\": \"Congrats! Your function executed successfully!\",\n\t})\n\tif err != nil {\n\t\treturn Response{StatusCode: 404}, err\n\t}\n\tjson.HTMLEscape(&buf, body)\n\n\tresp := Response{\n\t\tStatusCode:      200,\n\t\tIsBase64Encoded: false,\n\t\tBody:            buf.String(),\n\t\tHeaders: map[string]string{\n\t\t\t\"Content-Type\": \"application/json\",\n\t\t\t\"X-MyCompany-Func-Reply\": \"hello-handler\",\n\t\t\t\"Access-Control-Allow-Origin\": \"*\",\n\t\t\t\"Access-Control-Allow-Methods\": \"POST, GET, OPTIONS, PUT, DELETE\",\n\t\t\t\"Access-Control-Allow-Headers\": \"Accept, Content-Type, Content-Length, Accept-Encoding, X-CSRF-Token, Authorization\",\n\t\t},\n\t}\n\n\treturn resp, nil\n}\n\nfunc main() {\n\tlambda.Start(Handler)\n}\n```\n\n## 4. Deploy the API\n\nTo deploy the API, run the `push` command:\n\n```sh\namplify push\n```\n\n## 5. Using the API\n\nHere is how you can send a GET request to the API.\n\nimport js0 from \"/src/fragments/guides/api-rest/js/go-api-call.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/guides/api-rest/ios/rest-api-call.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/guides/api-rest/android/rest-api-call.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nTo learn more about interacting with REST APIs using Amplify, check out the complete documentation [here](/lib/restapi/getting-started).\n\nThe API endpoint is located in the `aws-exports.js` folder.\n\nYou can also interact directly with the API using this URL and the specified path:\n\n```sh\ncurl https://<api-id>.execute-api.<api-region>.amazonaws.com/<your-env-name>/hello\n```\n",
    "meta": {
      "title": "Go API - Android",
      "description": "How to deploy a Go API using Amplify Functions - Android",
      "subcategory": "API (REST)",
      "category": "Guides"
    },
    "filename": "/guides/api-rest/go-api/q/platform/android"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In this guide, you will learn how to deploy a Go API."
      },
      {
        "heading": "2. Add the API and function",
        "depth": 2,
        "text": "The CLI should have created a new function located at amplify/backend/function/greetingfunction."
      },
      {
        "heading": "3. Updating the function code",
        "depth": 2,
        "text": "Next, open  amplify/backend/function/greetingfunction/src/main.go and update the code to the following:"
      },
      {
        "heading": "4. Deploy the API",
        "depth": 2,
        "text": "To deploy the API, run the push command:"
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "Here is how you can send a GET request to the API."
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "To learn more about interacting with REST APIs using Amplify, check out the complete documentation here."
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "The API endpoint is located in the aws-exports.js folder."
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "You can also interact directly with the API using this URL and the specified path:"
      }
    ],
    "source": "export const meta = {\n  title: `Go API`,\n  description: `How to deploy a Go API using Amplify Functions`,\n};\n\nIn this guide, you will learn how to deploy a Go API.\n\n## 1. Initialize a new Amplify project\n\n```sh\namplify init\n\n# Follow the steps to give the project a name, environment name, and set the default text editor.\n# Accept defaults for everything else and choose your AWS Profile.\n```\n\n## 2. Add the API and function\n\n```sh\namplify add api\n\n? Please select from one of the below mentioned services: REST\n? Provide a friendly name for your resource to be used as a label for this category in the project: goapi\n? Provide a path (e.g., /book/{isbn}): /hello\n? Choose a Lambda source: Create a new Lambda function\n? Provide a friendly name for your resource to be used as a label for this category in the project: greetingfunction\n? Provide the AWS Lambda function name: greetingfunction\n? Choose the function runtime that you want to use: Go\n? Do you want to access other resources created in this project from your Lambda function? N\n? Do you want to invoke this function on a recurring schedule? N\n? Do you want to edit the local lambda function now? N\n? Restrict API access: N\n? Do you want to add another path? N\n```\n\nThe CLI should have created a new function located at **amplify/backend/function/greetingfunction**.\n\n## 3. Updating the function code\n\nNext, open  **amplify/backend/function/greetingfunction/src/main.go** and update the code to the following:\n\n```go\npackage main\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\ntype Response events.APIGatewayProxyResponse\n\nfunc Handler(ctx context.Context) (Response, error) {\n\tvar buf bytes.Buffer\n\n\tbody, err := json.Marshal(map[string]interface{}{\n\t\t\"message\": \"Congrats! Your function executed successfully!\",\n\t})\n\tif err != nil {\n\t\treturn Response{StatusCode: 404}, err\n\t}\n\tjson.HTMLEscape(&buf, body)\n\n\tresp := Response{\n\t\tStatusCode:      200,\n\t\tIsBase64Encoded: false,\n\t\tBody:            buf.String(),\n\t\tHeaders: map[string]string{\n\t\t\t\"Content-Type\": \"application/json\",\n\t\t\t\"X-MyCompany-Func-Reply\": \"hello-handler\",\n\t\t\t\"Access-Control-Allow-Origin\": \"*\",\n\t\t\t\"Access-Control-Allow-Methods\": \"POST, GET, OPTIONS, PUT, DELETE\",\n\t\t\t\"Access-Control-Allow-Headers\": \"Accept, Content-Type, Content-Length, Accept-Encoding, X-CSRF-Token, Authorization\",\n\t\t},\n\t}\n\n\treturn resp, nil\n}\n\nfunc main() {\n\tlambda.Start(Handler)\n}\n```\n\n## 4. Deploy the API\n\nTo deploy the API, run the `push` command:\n\n```sh\namplify push\n```\n\n## 5. Using the API\n\nHere is how you can send a GET request to the API.\n\nimport js0 from \"/src/fragments/guides/api-rest/js/go-api-call.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/guides/api-rest/ios/rest-api-call.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/guides/api-rest/android/rest-api-call.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nTo learn more about interacting with REST APIs using Amplify, check out the complete documentation [here](/lib/restapi/getting-started).\n\nThe API endpoint is located in the `aws-exports.js` folder.\n\nYou can also interact directly with the API using this URL and the specified path:\n\n```sh\ncurl https://<api-id>.execute-api.<api-region>.amazonaws.com/<your-env-name>/hello\n```\n",
    "meta": {
      "title": "Go API - JavaScript",
      "description": "How to deploy a Go API using Amplify Functions - JavaScript",
      "subcategory": "API (REST)",
      "category": "Guides"
    },
    "filename": "/guides/api-rest/go-api/q/platform/js"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In this guide you'll learn how to deploy an Express web server complete with routing."
      },
      {
        "heading": "Initializing the Amplify project",
        "depth": 3,
        "text": "Initialize a new Amplify project:"
      },
      {
        "heading": "Creating the API and function",
        "depth": 3,
        "text": "Next, create the API and web server. To do so, you can use the Amplify add command:"
      },
      {
        "heading": "Creating the API and function",
        "depth": 3,
        "text": "The CLI has created a few things for you:"
      },
      {
        "heading": "Creating the API and function",
        "depth": 3,
        "text": "API endpoint"
      },
      {
        "heading": "Creating the API and function",
        "depth": 3,
        "text": "Lambda function"
      },
      {
        "heading": "Creating the API and function",
        "depth": 3,
        "text": "Web server using Serverless Express in the function"
      },
      {
        "heading": "Creating the API and function",
        "depth": 3,
        "text": "Some boilerplate code for different methods on the /items route"
      },
      {
        "heading": "Updating the function code",
        "depth": 3,
        "text": "Let's open the code for the server."
      },
      {
        "heading": "Updating the function code",
        "depth": 3,
        "text": "Open amplify/backend/function/mylambda/src/index.js."
      },
      {
        "heading": "Updating the function code",
        "depth": 3,
        "text": "In this file you will see the main function handler with the event and context being proxied to an express server located at ./app.js (do not make any changes to this file):"
      },
      {
        "heading": "Updating the function code",
        "depth": 3,
        "text": "Next, open amplify/backend/function/mylambda/src/app.js."
      },
      {
        "heading": "Updating the function code",
        "depth": 3,
        "text": "Here, you will see the code for the express server and some boilerplate for the different HTTP methods for the route you declared."
      },
      {
        "heading": "Updating the function code",
        "depth": 3,
        "text": "Find the route for app.get('/items') and update it to the following:"
      },
      {
        "heading": "Deploying the service",
        "depth": 3,
        "text": "To deploy the API and function, we can run the push command:"
      },
      {
        "heading": "Deploying the service",
        "depth": 3,
        "text": "From here, you may want to add additional path. To do so, run the update command:"
      },
      {
        "heading": "Deploying the service",
        "depth": 3,
        "text": "From there, you can add, update, or remove paths. To learn more about interacting with REST APIs using Amplify, check out the complete documentation here."
      },
      {
        "heading": "Deploying the service",
        "depth": 3,
        "text": "The API endpoint is located in the aws-exports.js folder."
      },
      {
        "heading": "Deploying the service",
        "depth": 3,
        "text": "You can also interact directly with the API using this URL and the specified path:"
      }
    ],
    "source": "export const meta = {\n  title: `Express server`,\n  description: `How to deploy an Express server to AWS using AWS Amplify`,\n};\n\nIn this guide you'll learn how to deploy an [Express](https://expressjs.com/) web server complete with routing.\n\n### Initializing the Amplify project\n\nInitialize a new Amplify project:\n\n```sh\namplify init\n\n# Follow the steps to give the project a name, environment name, and set the default text editor.\n# Accept defaults for everything else and choose your AWS Profile.\n```\n\n### Creating the API and function\n\nNext, create the API and web server. To do so, you can use the Amplify `add` command:\n\n```sh\namplify add api\n\n? Please select from one of the below mentioned services: REST\n? Provide a friendly name for your resource to be used as a label for this category in the project: myapi\n? Provide a path (e.g., /items): /items (or whatever path you would like)\n? Choose a Lambda source: Create a new Lambda function\n? Provide a friendly name for your resource to be used as a label for this category in the project: mylambda\n? Provide the AWS Lambda function name: mylambda\n? Choose the function runtime that you want to use: NodeJS\n? Choose the function template that you want to use: Serverless express function\n? Do you want to access other resources created in this project from your Lambda function? N\n? Do you want to invoke this function on a recurring schedule? N\n? Do you want to edit the local lambda function now? N\n? Restrict API access: N\n? Do you want to add another path? N\n```\n\nThe CLI has created a few things for you:\n\n- API endpoint\n- Lambda function\n- Web server using [Serverless Express](https://github.com/awslabs/aws-serverless-express) in the function\n- Some boilerplate code for different methods on the `/items` route\n\n### Updating the function code\n\nLet's open the code for the server. \n\nOpen __amplify/backend/function/mylambda/src/index.js__.\n\nIn this file you will see the main function handler with the `event` and `context` being proxied to an express server located at `./app.js` (do not make any changes to this file):\n\n```js\nconst awsServerlessExpress = require('aws-serverless-express');\nconst app = require('./app');\n\nconst server = awsServerlessExpress.createServer(app);\n\nexports.handler = (event, context) => {\n  console.log(`EVENT: ${JSON.stringify(event)}`);\n  awsServerlessExpress.proxy(server, event, context);\n};\n\n```\n\nNext, open __amplify/backend/function/mylambda/src/app.js__.\n\nHere, you will see the code for the express server and some boilerplate for the different HTTP methods for the route you declared. \n\nFind the route for `app.get('/items')` and update it to the following:\n\n```js\n// amplify/backend/function/mylambda/src/app.js\napp.get('/items', function(req, res) {\n  const items = ['hello', 'world']\n  res.json({ success: 'get call succeed!', items });\n});\n```\n\n### Deploying the service\n\nTo deploy the API and function, we can run the `push` command:\n\n```sh\namplify push\n```\n\nimport js0 from \"/src/fragments/guides/api-rest/js/express-api-call.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/guides/api-rest/ios/express-api-call.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/guides/api-rest/android/express-api-call.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nFrom here, you may want to add additional path. To do so, run the update command:\n\n```sh\namplify update api\n```\n\nFrom there, you can add, update, or remove paths. To learn more about interacting with REST APIs using Amplify, check out the complete documentation [here](/lib/restapi/getting-started).\n\nThe API endpoint is located in the `aws-exports.js` folder.\n\nYou can also interact directly with the API using this URL and the specified path:\n\n```sh\ncurl https://<api-id>.execute-api.<api-region>.amazonaws.com/<your-env-name>/items\n```\n",
    "meta": {
      "title": "Express Server - iOS",
      "description": "How to deploy an Express server to AWS using AWS Amplify - iOS",
      "subcategory": "API (REST)",
      "category": "Guides"
    },
    "filename": "/guides/api-rest/express-server/q/platform/ios"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In this guide you'll learn how to deploy an Express web server complete with routing."
      },
      {
        "heading": "Initializing the Amplify project",
        "depth": 3,
        "text": "Initialize a new Amplify project:"
      },
      {
        "heading": "Creating the API and function",
        "depth": 3,
        "text": "Next, create the API and web server. To do so, you can use the Amplify add command:"
      },
      {
        "heading": "Creating the API and function",
        "depth": 3,
        "text": "The CLI has created a few things for you:"
      },
      {
        "heading": "Creating the API and function",
        "depth": 3,
        "text": "API endpoint"
      },
      {
        "heading": "Creating the API and function",
        "depth": 3,
        "text": "Lambda function"
      },
      {
        "heading": "Creating the API and function",
        "depth": 3,
        "text": "Web server using Serverless Express in the function"
      },
      {
        "heading": "Creating the API and function",
        "depth": 3,
        "text": "Some boilerplate code for different methods on the /items route"
      },
      {
        "heading": "Updating the function code",
        "depth": 3,
        "text": "Let's open the code for the server."
      },
      {
        "heading": "Updating the function code",
        "depth": 3,
        "text": "Open amplify/backend/function/mylambda/src/index.js."
      },
      {
        "heading": "Updating the function code",
        "depth": 3,
        "text": "In this file you will see the main function handler with the event and context being proxied to an express server located at ./app.js (do not make any changes to this file):"
      },
      {
        "heading": "Updating the function code",
        "depth": 3,
        "text": "Next, open amplify/backend/function/mylambda/src/app.js."
      },
      {
        "heading": "Updating the function code",
        "depth": 3,
        "text": "Here, you will see the code for the express server and some boilerplate for the different HTTP methods for the route you declared."
      },
      {
        "heading": "Updating the function code",
        "depth": 3,
        "text": "Find the route for app.get('/items') and update it to the following:"
      },
      {
        "heading": "Deploying the service",
        "depth": 3,
        "text": "To deploy the API and function, we can run the push command:"
      },
      {
        "heading": "Deploying the service",
        "depth": 3,
        "text": "From here, you may want to add additional path. To do so, run the update command:"
      },
      {
        "heading": "Deploying the service",
        "depth": 3,
        "text": "From there, you can add, update, or remove paths. To learn more about interacting with REST APIs using Amplify, check out the complete documentation here."
      },
      {
        "heading": "Deploying the service",
        "depth": 3,
        "text": "The API endpoint is located in the aws-exports.js folder."
      },
      {
        "heading": "Deploying the service",
        "depth": 3,
        "text": "You can also interact directly with the API using this URL and the specified path:"
      }
    ],
    "source": "export const meta = {\n  title: `Express server`,\n  description: `How to deploy an Express server to AWS using AWS Amplify`,\n};\n\nIn this guide you'll learn how to deploy an [Express](https://expressjs.com/) web server complete with routing.\n\n### Initializing the Amplify project\n\nInitialize a new Amplify project:\n\n```sh\namplify init\n\n# Follow the steps to give the project a name, environment name, and set the default text editor.\n# Accept defaults for everything else and choose your AWS Profile.\n```\n\n### Creating the API and function\n\nNext, create the API and web server. To do so, you can use the Amplify `add` command:\n\n```sh\namplify add api\n\n? Please select from one of the below mentioned services: REST\n? Provide a friendly name for your resource to be used as a label for this category in the project: myapi\n? Provide a path (e.g., /items): /items (or whatever path you would like)\n? Choose a Lambda source: Create a new Lambda function\n? Provide a friendly name for your resource to be used as a label for this category in the project: mylambda\n? Provide the AWS Lambda function name: mylambda\n? Choose the function runtime that you want to use: NodeJS\n? Choose the function template that you want to use: Serverless express function\n? Do you want to access other resources created in this project from your Lambda function? N\n? Do you want to invoke this function on a recurring schedule? N\n? Do you want to edit the local lambda function now? N\n? Restrict API access: N\n? Do you want to add another path? N\n```\n\nThe CLI has created a few things for you:\n\n- API endpoint\n- Lambda function\n- Web server using [Serverless Express](https://github.com/awslabs/aws-serverless-express) in the function\n- Some boilerplate code for different methods on the `/items` route\n\n### Updating the function code\n\nLet's open the code for the server. \n\nOpen __amplify/backend/function/mylambda/src/index.js__.\n\nIn this file you will see the main function handler with the `event` and `context` being proxied to an express server located at `./app.js` (do not make any changes to this file):\n\n```js\nconst awsServerlessExpress = require('aws-serverless-express');\nconst app = require('./app');\n\nconst server = awsServerlessExpress.createServer(app);\n\nexports.handler = (event, context) => {\n  console.log(`EVENT: ${JSON.stringify(event)}`);\n  awsServerlessExpress.proxy(server, event, context);\n};\n\n```\n\nNext, open __amplify/backend/function/mylambda/src/app.js__.\n\nHere, you will see the code for the express server and some boilerplate for the different HTTP methods for the route you declared. \n\nFind the route for `app.get('/items')` and update it to the following:\n\n```js\n// amplify/backend/function/mylambda/src/app.js\napp.get('/items', function(req, res) {\n  const items = ['hello', 'world']\n  res.json({ success: 'get call succeed!', items });\n});\n```\n\n### Deploying the service\n\nTo deploy the API and function, we can run the `push` command:\n\n```sh\namplify push\n```\n\nimport js0 from \"/src/fragments/guides/api-rest/js/express-api-call.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/guides/api-rest/ios/express-api-call.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/guides/api-rest/android/express-api-call.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nFrom here, you may want to add additional path. To do so, run the update command:\n\n```sh\namplify update api\n```\n\nFrom there, you can add, update, or remove paths. To learn more about interacting with REST APIs using Amplify, check out the complete documentation [here](/lib/restapi/getting-started).\n\nThe API endpoint is located in the `aws-exports.js` folder.\n\nYou can also interact directly with the API using this URL and the specified path:\n\n```sh\ncurl https://<api-id>.execute-api.<api-region>.amazonaws.com/<your-env-name>/items\n```\n",
    "meta": {
      "title": "Express Server - Android",
      "description": "How to deploy an Express server to AWS using AWS Amplify - Android",
      "subcategory": "API (REST)",
      "category": "Guides"
    },
    "filename": "/guides/api-rest/express-server/q/platform/android"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In this guide you'll learn how to deploy an Express web server complete with routing."
      },
      {
        "heading": "Initializing the Amplify project",
        "depth": 3,
        "text": "Initialize a new Amplify project:"
      },
      {
        "heading": "Creating the API and function",
        "depth": 3,
        "text": "Next, create the API and web server. To do so, you can use the Amplify add command:"
      },
      {
        "heading": "Creating the API and function",
        "depth": 3,
        "text": "The CLI has created a few things for you:"
      },
      {
        "heading": "Creating the API and function",
        "depth": 3,
        "text": "API endpoint"
      },
      {
        "heading": "Creating the API and function",
        "depth": 3,
        "text": "Lambda function"
      },
      {
        "heading": "Creating the API and function",
        "depth": 3,
        "text": "Web server using Serverless Express in the function"
      },
      {
        "heading": "Creating the API and function",
        "depth": 3,
        "text": "Some boilerplate code for different methods on the /items route"
      },
      {
        "heading": "Updating the function code",
        "depth": 3,
        "text": "Let's open the code for the server."
      },
      {
        "heading": "Updating the function code",
        "depth": 3,
        "text": "Open amplify/backend/function/mylambda/src/index.js."
      },
      {
        "heading": "Updating the function code",
        "depth": 3,
        "text": "In this file you will see the main function handler with the event and context being proxied to an express server located at ./app.js (do not make any changes to this file):"
      },
      {
        "heading": "Updating the function code",
        "depth": 3,
        "text": "Next, open amplify/backend/function/mylambda/src/app.js."
      },
      {
        "heading": "Updating the function code",
        "depth": 3,
        "text": "Here, you will see the code for the express server and some boilerplate for the different HTTP methods for the route you declared."
      },
      {
        "heading": "Updating the function code",
        "depth": 3,
        "text": "Find the route for app.get('/items') and update it to the following:"
      },
      {
        "heading": "Deploying the service",
        "depth": 3,
        "text": "To deploy the API and function, we can run the push command:"
      },
      {
        "heading": "Deploying the service",
        "depth": 3,
        "text": "From here, you may want to add additional path. To do so, run the update command:"
      },
      {
        "heading": "Deploying the service",
        "depth": 3,
        "text": "From there, you can add, update, or remove paths. To learn more about interacting with REST APIs using Amplify, check out the complete documentation here."
      },
      {
        "heading": "Deploying the service",
        "depth": 3,
        "text": "The API endpoint is located in the aws-exports.js folder."
      },
      {
        "heading": "Deploying the service",
        "depth": 3,
        "text": "You can also interact directly with the API using this URL and the specified path:"
      }
    ],
    "source": "export const meta = {\n  title: `Express server`,\n  description: `How to deploy an Express server to AWS using AWS Amplify`,\n};\n\nIn this guide you'll learn how to deploy an [Express](https://expressjs.com/) web server complete with routing.\n\n### Initializing the Amplify project\n\nInitialize a new Amplify project:\n\n```sh\namplify init\n\n# Follow the steps to give the project a name, environment name, and set the default text editor.\n# Accept defaults for everything else and choose your AWS Profile.\n```\n\n### Creating the API and function\n\nNext, create the API and web server. To do so, you can use the Amplify `add` command:\n\n```sh\namplify add api\n\n? Please select from one of the below mentioned services: REST\n? Provide a friendly name for your resource to be used as a label for this category in the project: myapi\n? Provide a path (e.g., /items): /items (or whatever path you would like)\n? Choose a Lambda source: Create a new Lambda function\n? Provide a friendly name for your resource to be used as a label for this category in the project: mylambda\n? Provide the AWS Lambda function name: mylambda\n? Choose the function runtime that you want to use: NodeJS\n? Choose the function template that you want to use: Serverless express function\n? Do you want to access other resources created in this project from your Lambda function? N\n? Do you want to invoke this function on a recurring schedule? N\n? Do you want to edit the local lambda function now? N\n? Restrict API access: N\n? Do you want to add another path? N\n```\n\nThe CLI has created a few things for you:\n\n- API endpoint\n- Lambda function\n- Web server using [Serverless Express](https://github.com/awslabs/aws-serverless-express) in the function\n- Some boilerplate code for different methods on the `/items` route\n\n### Updating the function code\n\nLet's open the code for the server. \n\nOpen __amplify/backend/function/mylambda/src/index.js__.\n\nIn this file you will see the main function handler with the `event` and `context` being proxied to an express server located at `./app.js` (do not make any changes to this file):\n\n```js\nconst awsServerlessExpress = require('aws-serverless-express');\nconst app = require('./app');\n\nconst server = awsServerlessExpress.createServer(app);\n\nexports.handler = (event, context) => {\n  console.log(`EVENT: ${JSON.stringify(event)}`);\n  awsServerlessExpress.proxy(server, event, context);\n};\n\n```\n\nNext, open __amplify/backend/function/mylambda/src/app.js__.\n\nHere, you will see the code for the express server and some boilerplate for the different HTTP methods for the route you declared. \n\nFind the route for `app.get('/items')` and update it to the following:\n\n```js\n// amplify/backend/function/mylambda/src/app.js\napp.get('/items', function(req, res) {\n  const items = ['hello', 'world']\n  res.json({ success: 'get call succeed!', items });\n});\n```\n\n### Deploying the service\n\nTo deploy the API and function, we can run the `push` command:\n\n```sh\namplify push\n```\n\nimport js0 from \"/src/fragments/guides/api-rest/js/express-api-call.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/guides/api-rest/ios/express-api-call.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/guides/api-rest/android/express-api-call.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nFrom here, you may want to add additional path. To do so, run the update command:\n\n```sh\namplify update api\n```\n\nFrom there, you can add, update, or remove paths. To learn more about interacting with REST APIs using Amplify, check out the complete documentation [here](/lib/restapi/getting-started).\n\nThe API endpoint is located in the `aws-exports.js` folder.\n\nYou can also interact directly with the API using this URL and the specified path:\n\n```sh\ncurl https://<api-id>.execute-api.<api-region>.amazonaws.com/<your-env-name>/items\n```\n",
    "meta": {
      "title": "Express Server - JavaScript",
      "description": "How to deploy an Express server to AWS using AWS Amplify - JavaScript",
      "subcategory": "API (REST)",
      "category": "Guides"
    },
    "filename": "/guides/api-rest/express-server/q/platform/js"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In this guide, you will learn how to deploy a Node.js API."
      },
      {
        "heading": "2. Add the API and function",
        "depth": 2,
        "text": "The CLI should have created a new function located at amplify/backend/function/greetingfunction."
      },
      {
        "heading": "3. Updating the function code",
        "depth": 2,
        "text": "Next, open  amplify/backend/function/greetingfunction/src/index.js and update the code to the following:"
      },
      {
        "heading": "4. Deploy the API",
        "depth": 2,
        "text": "To deploy the API, run the push command:"
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "Here is how you can send a GET request to the API."
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "To learn more about interacting with REST APIs using Amplify, check out the complete documentation here."
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "The API endpoint is located in the aws-exports.js folder."
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "You can also interact directly with the API using this URL and the specified path:"
      }
    ],
    "source": "export const meta = {\n  title: `NodeJS API`,\n  description: `How to deploy a NodeJS API using Amplify Functions`,\n};\n\nIn this guide, you will learn how to deploy a Node.js API.\n\n## 1. Initialize a new Amplify project\n\n```sh\namplify init\n\n# Follow the steps to give the project a name, environment name, and set the default text editor.\n# Accept defaults for everything else and choose your AWS Profile.\n```\n\n## 2. Add the API and function\n\n```sh\namplify add api\n\n? Please select from one of the below mentioned services: REST\n? Provide a friendly name for your resource to be used as a label for this category in the project: nodeapi\n? Provide a path (e.g., /book/{isbn}): /hello\n? Choose a Lambda source: Create a new Lambda function\n? Provide a friendly name for your resource to be used as a label for this category in the project: greetingfunction\n? Provide the AWS Lambda function name: greetingfunction\n? Choose the function runtime that you want to use: NodeJS\n? Choose the function template that you want to use: Hello World\n? Do you want to access other resources created in this project from your Lambda function? N\n? Do you want to invoke this function on a recurring schedule? N\n? Do you want to edit the local lambda function now? N\n? Restrict API access: N\n? Do you want to add another path? N\n```\n\nThe CLI should have created a new function located at **amplify/backend/function/greetingfunction**.\n\n## 3. Updating the function code\n\nNext, open  **amplify/backend/function/greetingfunction/src/index.js** and update the code to the following:\n\n```js\nexports.handler = async (event) => {\n  const body = {\n      message: \"Hello from Lambda\"\n  }\n  const response = {\n      statusCode: 200,\n      body: JSON.stringify(body),\n      headers: {\n          \"Access-Control-Allow-Origin\": \"*\",\n      }\n  };\n  return response;\n};\n```\n\n## 4. Deploy the API\n\nTo deploy the API, run the `push` command:\n\n```sh\namplify push\n```\n\n## 5. Using the API\n\nHere is how you can send a GET request to the API.\n\nimport js0 from \"/src/fragments/guides/api-rest/js/rest-api-call.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/guides/api-rest/ios/rest-api-call.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/guides/api-rest/android/rest-api-call.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nTo learn more about interacting with REST APIs using Amplify, check out the complete documentation [here](/lib/restapi/getting-started).\n\nThe API endpoint is located in the `aws-exports.js` folder.\n\nYou can also interact directly with the API using this URL and the specified path:\n\n```sh\ncurl https://<api-id>.execute-api.<api-region>.amazonaws.com/<your-env-name>/hello\n```\n",
    "meta": {
      "title": "NodeJS API - iOS",
      "description": "How to deploy a NodeJS API using Amplify Functions - iOS",
      "subcategory": "API (REST)",
      "category": "Guides"
    },
    "filename": "/guides/api-rest/node-api/q/platform/ios"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In this guide, you will learn how to deploy a Node.js API."
      },
      {
        "heading": "2. Add the API and function",
        "depth": 2,
        "text": "The CLI should have created a new function located at amplify/backend/function/greetingfunction."
      },
      {
        "heading": "3. Updating the function code",
        "depth": 2,
        "text": "Next, open  amplify/backend/function/greetingfunction/src/index.js and update the code to the following:"
      },
      {
        "heading": "4. Deploy the API",
        "depth": 2,
        "text": "To deploy the API, run the push command:"
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "Here is how you can send a GET request to the API."
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "To learn more about interacting with REST APIs using Amplify, check out the complete documentation here."
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "The API endpoint is located in the aws-exports.js folder."
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "You can also interact directly with the API using this URL and the specified path:"
      }
    ],
    "source": "export const meta = {\n  title: `NodeJS API`,\n  description: `How to deploy a NodeJS API using Amplify Functions`,\n};\n\nIn this guide, you will learn how to deploy a Node.js API.\n\n## 1. Initialize a new Amplify project\n\n```sh\namplify init\n\n# Follow the steps to give the project a name, environment name, and set the default text editor.\n# Accept defaults for everything else and choose your AWS Profile.\n```\n\n## 2. Add the API and function\n\n```sh\namplify add api\n\n? Please select from one of the below mentioned services: REST\n? Provide a friendly name for your resource to be used as a label for this category in the project: nodeapi\n? Provide a path (e.g., /book/{isbn}): /hello\n? Choose a Lambda source: Create a new Lambda function\n? Provide a friendly name for your resource to be used as a label for this category in the project: greetingfunction\n? Provide the AWS Lambda function name: greetingfunction\n? Choose the function runtime that you want to use: NodeJS\n? Choose the function template that you want to use: Hello World\n? Do you want to access other resources created in this project from your Lambda function? N\n? Do you want to invoke this function on a recurring schedule? N\n? Do you want to edit the local lambda function now? N\n? Restrict API access: N\n? Do you want to add another path? N\n```\n\nThe CLI should have created a new function located at **amplify/backend/function/greetingfunction**.\n\n## 3. Updating the function code\n\nNext, open  **amplify/backend/function/greetingfunction/src/index.js** and update the code to the following:\n\n```js\nexports.handler = async (event) => {\n  const body = {\n      message: \"Hello from Lambda\"\n  }\n  const response = {\n      statusCode: 200,\n      body: JSON.stringify(body),\n      headers: {\n          \"Access-Control-Allow-Origin\": \"*\",\n      }\n  };\n  return response;\n};\n```\n\n## 4. Deploy the API\n\nTo deploy the API, run the `push` command:\n\n```sh\namplify push\n```\n\n## 5. Using the API\n\nHere is how you can send a GET request to the API.\n\nimport js0 from \"/src/fragments/guides/api-rest/js/rest-api-call.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/guides/api-rest/ios/rest-api-call.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/guides/api-rest/android/rest-api-call.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nTo learn more about interacting with REST APIs using Amplify, check out the complete documentation [here](/lib/restapi/getting-started).\n\nThe API endpoint is located in the `aws-exports.js` folder.\n\nYou can also interact directly with the API using this URL and the specified path:\n\n```sh\ncurl https://<api-id>.execute-api.<api-region>.amazonaws.com/<your-env-name>/hello\n```\n",
    "meta": {
      "title": "NodeJS API - Android",
      "description": "How to deploy a NodeJS API using Amplify Functions - Android",
      "subcategory": "API (REST)",
      "category": "Guides"
    },
    "filename": "/guides/api-rest/node-api/q/platform/android"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In this guide, you will learn how to deploy a Node.js API."
      },
      {
        "heading": "2. Add the API and function",
        "depth": 2,
        "text": "The CLI should have created a new function located at amplify/backend/function/greetingfunction."
      },
      {
        "heading": "3. Updating the function code",
        "depth": 2,
        "text": "Next, open  amplify/backend/function/greetingfunction/src/index.js and update the code to the following:"
      },
      {
        "heading": "4. Deploy the API",
        "depth": 2,
        "text": "To deploy the API, run the push command:"
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "Here is how you can send a GET request to the API."
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "To learn more about interacting with REST APIs using Amplify, check out the complete documentation here."
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "The API endpoint is located in the aws-exports.js folder."
      },
      {
        "heading": "5. Using the API",
        "depth": 2,
        "text": "You can also interact directly with the API using this URL and the specified path:"
      }
    ],
    "source": "export const meta = {\n  title: `NodeJS API`,\n  description: `How to deploy a NodeJS API using Amplify Functions`,\n};\n\nIn this guide, you will learn how to deploy a Node.js API.\n\n## 1. Initialize a new Amplify project\n\n```sh\namplify init\n\n# Follow the steps to give the project a name, environment name, and set the default text editor.\n# Accept defaults for everything else and choose your AWS Profile.\n```\n\n## 2. Add the API and function\n\n```sh\namplify add api\n\n? Please select from one of the below mentioned services: REST\n? Provide a friendly name for your resource to be used as a label for this category in the project: nodeapi\n? Provide a path (e.g., /book/{isbn}): /hello\n? Choose a Lambda source: Create a new Lambda function\n? Provide a friendly name for your resource to be used as a label for this category in the project: greetingfunction\n? Provide the AWS Lambda function name: greetingfunction\n? Choose the function runtime that you want to use: NodeJS\n? Choose the function template that you want to use: Hello World\n? Do you want to access other resources created in this project from your Lambda function? N\n? Do you want to invoke this function on a recurring schedule? N\n? Do you want to edit the local lambda function now? N\n? Restrict API access: N\n? Do you want to add another path? N\n```\n\nThe CLI should have created a new function located at **amplify/backend/function/greetingfunction**.\n\n## 3. Updating the function code\n\nNext, open  **amplify/backend/function/greetingfunction/src/index.js** and update the code to the following:\n\n```js\nexports.handler = async (event) => {\n  const body = {\n      message: \"Hello from Lambda\"\n  }\n  const response = {\n      statusCode: 200,\n      body: JSON.stringify(body),\n      headers: {\n          \"Access-Control-Allow-Origin\": \"*\",\n      }\n  };\n  return response;\n};\n```\n\n## 4. Deploy the API\n\nTo deploy the API, run the `push` command:\n\n```sh\namplify push\n```\n\n## 5. Using the API\n\nHere is how you can send a GET request to the API.\n\nimport js0 from \"/src/fragments/guides/api-rest/js/rest-api-call.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/guides/api-rest/ios/rest-api-call.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/guides/api-rest/android/rest-api-call.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nTo learn more about interacting with REST APIs using Amplify, check out the complete documentation [here](/lib/restapi/getting-started).\n\nThe API endpoint is located in the `aws-exports.js` folder.\n\nYou can also interact directly with the API using this URL and the specified path:\n\n```sh\ncurl https://<api-id>.execute-api.<api-region>.amazonaws.com/<your-env-name>/hello\n```\n",
    "meta": {
      "title": "NodeJS API - JavaScript",
      "description": "How to deploy a NodeJS API using Amplify Functions - JavaScript",
      "subcategory": "API (REST)",
      "category": "Guides"
    },
    "filename": "/guides/api-rest/node-api/q/platform/js"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "The GraphQL Transform Library provides a @function directive that enables the configuration of AWS Lambda function resolvers within your GraphQL API. In this guide you will learn how to use Lambda functions as GraphQL resolvers to interact with other services and APIs using the @function directive."
      },
      {
        "heading": "Creating basic query and mutation Function resolvers",
        "depth": 2,
        "text": "To get started, let's take a look at a GraphQL schema with a query and a mutation that has the data source set as a Lambda function."
      },
      {
        "heading": "Creating basic query and mutation Function resolvers",
        "depth": 2,
        "text": "Using the @function directive, you can specify a Lambda function to be invoked as the GraphQL resolver."
      },
      {
        "heading": "Creating basic query and mutation Function resolvers",
        "depth": 2,
        "text": "In this guide, you'll learn how to enable Lambda function resolvers in a GraphQL API."
      },
      {
        "heading": "Creating the functions",
        "depth": 3,
        "text": "To get started, create the first Lambda function:"
      },
      {
        "heading": "Creating the functions",
        "depth": 3,
        "text": "Open the function code (located at amplify/backend/function/echofunction/src/index.js) and press enter:"
      },
      {
        "heading": "Creating the functions",
        "depth": 3,
        "text": "This function will just return the value of the msg property passed in as an argument."
      },
      {
        "heading": "Lambda event information",
        "depth": 4,
        "text": "The event object will contain the following properties:"
      },
      {
        "heading": "Lambda event information",
        "depth": 4,
        "text": "In the above function we've used the arguments property to get the values passed in as arguments to the function."
      },
      {
        "heading": "Lambda event information",
        "depth": 4,
        "text": "Next, create another Lambda function:"
      },
      {
        "heading": "Lambda event information",
        "depth": 4,
        "text": "Next, update the function code (located at amplify/backend/function/addingfunction/src/index.js) to the following and press enter:"
      },
      {
        "heading": "Lambda event information",
        "depth": 4,
        "text": "This function will add two numbers together and return the result."
      },
      {
        "heading": "Creating the GraphQL API",
        "depth": 3,
        "text": "Now that the functions have been created, you can create the GraphQL API:"
      },
      {
        "heading": "Creating the GraphQL API",
        "depth": 3,
        "text": "Next, update the base GraphQL schema (located at amplify/backend/api/gqllambda/schema.graphql) with the following code and press enter:"
      },
      {
        "heading": "Creating the GraphQL API",
        "depth": 3,
        "text": "Now deploy the functions and GraphQL API:"
      },
      {
        "heading": "Querying the GraphQL API",
        "depth": 3,
        "text": "Now, you can run the following queries and mutations to interact with the API:"
      },
      {
        "heading": "Creating a resolver that interacts with another API",
        "depth": 2,
        "text": "Next, we'll create a function that will interact with a public Cryptocurrency REST API."
      },
      {
        "heading": "Creating a resolver that interacts with another API",
        "depth": 2,
        "text": "Create another function:"
      },
      {
        "heading": "Creating a resolver that interacts with another API",
        "depth": 2,
        "text": "Next, update the function code (located at amplify/backend/function/cryptofunction/src/index.js) to the following and press enter:"
      },
      {
        "heading": "Creating a resolver that interacts with another API",
        "depth": 2,
        "text": "Next, install the axios library in the function src folder and change back into the root directory:"
      },
      {
        "heading": "Creating a resolver that interacts with another API",
        "depth": 2,
        "text": "Now, update the GraphQL schema and add a getCoins resolver to the Query type:"
      },
      {
        "heading": "Creating a resolver that interacts with another API",
        "depth": 2,
        "text": "Next, deploy the updates:"
      },
      {
        "heading": "Creating a resolver that interacts with another API",
        "depth": 2,
        "text": "Now you can query the GraphQL API using the new getCoins query."
      },
      {
        "heading": "Query with limit",
        "depth": 4,
        "text": "To learn more about the @function directive, check out the GraphQL Transform documentation here."
      }
    ],
    "source": "export const meta = {\n  title: `How to use Lambda GraphQL Resolvers`,\n  description: `How to use Lambda GraphQL resolvers to interact with other services`,\n};\n\nThe [GraphQL Transform Library](/cli/graphql/custom-business-logic#lambda-function-resolver) provides a `@function` directive that enables the configuration of AWS Lambda function resolvers within your GraphQL API. In this guide you will learn how to use Lambda functions as GraphQL resolvers to interact with other services and APIs using the `@function` directive.\n\n## Creating basic query and mutation Function resolvers\n\nTo get started, let's take a look at a GraphQL schema with a query and a mutation that has the data source set as a Lambda function.\n\n```graphql\n# A query that returns the arguments\ntype Query {\n  echo(msg: String): String @function(name: \"functionName-${env}\")\n}\n\n# A mutation that adds two numbers\ntype Mutation {\n  add(number1: Int, number2: Int): Int @function(name: \"functionName-${env}\")\n}\n```\n\nUsing the `@function` directive, you can specify a Lambda function to be invoked as the GraphQL resolver.\n\nIn this guide, you'll learn how to enable Lambda function resolvers in a GraphQL API.\n\n### Creating the functions\n\nTo get started, create the first Lambda function:\n\n```sh\namplify add function\n\n? Provide a friendly name for your resource to be used as a label for this category in the project: echofunction\n? Provide the AWS Lambda function name: echofunction\n? Choose the function runtime that you want to use: NodeJS\n? Choose the function template that you want to use: Hello World\n? Do you want to access other resources created in this project from your Lambda function? No\n? Do you want to invoke this function on a recurring schedule? No\n? Do you want to edit the local lambda function now? Yes\n```\n\nOpen the function code (located at __amplify/backend/function/echofunction/src/index.js__) and press enter:\n\n```js\nexports.handler = async (event) => {\n    const response = event.arguments.msg\n    return response;\n};\n```\n\nThis function will just return the value of the `msg` property passed in as an argument.\n\n#### Lambda event information\n\nThe `event` object will contain the following properties:\n\n```js\n/*\nevent = {\n  \"typeName\": \"Query\" or \"Mutation\", Filled dynamically based on @function usage location\n  \"fieldName\": Filled dynamically based on @function usage location\n  \"arguments\": { msg }, GraphQL field arguments\n  \"identity\": {}, AppSync identity object\n  \"source\": {}, The object returned by the parent resolver. E.G. if resolving field 'Post.comments', the source is the Post object\n  \"request\": {}, AppSync request object. Contains things like headers\n  \"prev\": {} If using the built-in pipeline resolver support, this contains the object returned by the previous function.\n}\n*/\n```\n\nIn the above function we've used the `arguments` property to get the values passed in as arguments to the function.\n\nNext, create another Lambda function:\n\n```sh\namplify add function\n\n? Provide a friendly name for your resource to be used as a label for this category in the project: addingfunction\n? Provide the AWS Lambda function name: addfunction\n? Choose the function runtime that you want to use: NodeJS\n? Choose the function template that you want to use: Hello World\n? Do you want to access other resources created in this project from your Lambda function? No\n? Do you want to invoke this function on a recurring schedule? No\n? Do you want to edit the local lambda function now? Yes\n```\n\nNext, update the function code (located at __amplify/backend/function/addingfunction/src/index.js__) to the following and press enter:\n\n```js\nexports.handler = async (event) => {\n    /* Add number1 and number2, return the result */\n    const response = event.arguments.number1 + event.arguments.number2\n    return response;\n};\n```\n\nThis function will add two numbers together and return the result.\n\n### Creating the GraphQL API\n\nNow that the functions have been created, you can create the GraphQL API:\n\n```sh\namplify add api\n\n? Please select from one of the below mentioned services:\n  > GraphQL\n? Here is the GraphQL API that we will create. Select a setting to edit or continue:\n  > Name\n? Provide API name:\n  > gqllambda\n? Here is the GraphQL API that we will create. Select a setting to edit or continue:\n  > Authorization modes: API key (default, expiration time: 7 days from now)\n? Choose the default authorization type for the API:\n  > API Key\n? Enter a description for the API key:\n  > public (or some description)\n? After how many days from now the API key should expire:\n  > 365 (or your preferred expiration)\n? Configure additional auth types?\n  > No\n? Here is the GraphQL API that we will create. Select a setting to edit or continue:\n  > Continue\n? Choose a schema template:\n  > Single object with fields (e.g., “Todo” with ID, name, description)\n? Do you want to edit the schema now?\n  > Y\n```\n\nNext, update the base GraphQL schema (located at __amplify/backend/api/gqllambda/schema.graphql__) with the following code and press enter:\n\n```graphql\ntype Query {\n  echo(msg: String): String @function(name: \"echofunction-${env}\")\n}\n\ntype Mutation {\n  add(number1: Int, number2: Int): Int @function(name: \"addingfunction-${env}\")\n}\n```\n\nNow deploy the functions and GraphQL API:\n\n```sh\namplify push\n```\n\n### Querying the GraphQL API\n\nNow, you can run the following queries and mutations to interact with the API:\n\n```graphql\nquery echo {\n  echo(msg: \"Hello world!\")\n}\n\nmutation add {\n  add(number1: 1100, number2:100)\n}\n```\n\n## Creating a resolver that interacts with another API\n\nNext, we'll create a function that will interact with a public Cryptocurrency REST API.\n\nCreate another function:\n\n```sh\namplify add function\n```\n\nNext, update the function code (located at __amplify/backend/function/cryptofunction/src/index.js__) to the following and press enter:\n\n```javascript\nconst axios = require('axios')\n\nexports.handler = async (event) => {\n    let limit = 10\n    if (event.arguments.limit) {\n        limit = event.arguments.limit\n    }\n    const url = `https://api.coinlore.net/api/tickers/?limit=${limit}`\n    let response = await axios.get(url)\n    return JSON.stringify(response.data.data);\n};\n```\n\nNext, install the axios library in the function __src__ folder and change back into the root directory:\n\n```sh\ncd amplify/backend/function/cryptofunction/src\nnpm install axios\ncd ../../../../../\n```\n\nNow, update the GraphQL schema and add a `getCoins` resolver to the Query type:\n\n```graphql\ntype Query {\n  echo(msg: String): String @function(name: \"gqlfunc-${env}\")\n  getCoins(limit: Int): String @function(name: \"cryptofunction-${env}\")\n}\n```\n\nNext, deploy the updates:\n\n```sh\namplify push\n```\n\nNow you can query the GraphQL API using the new `getCoins` query.\n\n#### Basic query\n\n```graphql\nquery getCoins {\n  getCoins\n}\n```\n\n#### Query with limit\n\n```graphql\nquery getCoins {\n  getCoins(limit: 100)\n}\n```\n\nTo learn more about the `@function` directive, check out the GraphQL Transform documentation [here](/cli/graphql/custom-business-logic#lambda-function-resolver).\n",
    "meta": {
      "title": "How to use Lambda GraphQL Resolvers - iOS",
      "description": "How to use Lambda GraphQL resolvers to interact with other services - iOS",
      "subcategory": "API (GraphQL)",
      "category": "Guides"
    },
    "filename": "/guides/api-graphql/lambda-resolvers/q/platform/ios"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "The GraphQL Transform Library provides a @function directive that enables the configuration of AWS Lambda function resolvers within your GraphQL API. In this guide you will learn how to use Lambda functions as GraphQL resolvers to interact with other services and APIs using the @function directive."
      },
      {
        "heading": "Creating basic query and mutation Function resolvers",
        "depth": 2,
        "text": "To get started, let's take a look at a GraphQL schema with a query and a mutation that has the data source set as a Lambda function."
      },
      {
        "heading": "Creating basic query and mutation Function resolvers",
        "depth": 2,
        "text": "Using the @function directive, you can specify a Lambda function to be invoked as the GraphQL resolver."
      },
      {
        "heading": "Creating basic query and mutation Function resolvers",
        "depth": 2,
        "text": "In this guide, you'll learn how to enable Lambda function resolvers in a GraphQL API."
      },
      {
        "heading": "Creating the functions",
        "depth": 3,
        "text": "To get started, create the first Lambda function:"
      },
      {
        "heading": "Creating the functions",
        "depth": 3,
        "text": "Open the function code (located at amplify/backend/function/echofunction/src/index.js) and press enter:"
      },
      {
        "heading": "Creating the functions",
        "depth": 3,
        "text": "This function will just return the value of the msg property passed in as an argument."
      },
      {
        "heading": "Lambda event information",
        "depth": 4,
        "text": "The event object will contain the following properties:"
      },
      {
        "heading": "Lambda event information",
        "depth": 4,
        "text": "In the above function we've used the arguments property to get the values passed in as arguments to the function."
      },
      {
        "heading": "Lambda event information",
        "depth": 4,
        "text": "Next, create another Lambda function:"
      },
      {
        "heading": "Lambda event information",
        "depth": 4,
        "text": "Next, update the function code (located at amplify/backend/function/addingfunction/src/index.js) to the following and press enter:"
      },
      {
        "heading": "Lambda event information",
        "depth": 4,
        "text": "This function will add two numbers together and return the result."
      },
      {
        "heading": "Creating the GraphQL API",
        "depth": 3,
        "text": "Now that the functions have been created, you can create the GraphQL API:"
      },
      {
        "heading": "Creating the GraphQL API",
        "depth": 3,
        "text": "Next, update the base GraphQL schema (located at amplify/backend/api/gqllambda/schema.graphql) with the following code and press enter:"
      },
      {
        "heading": "Creating the GraphQL API",
        "depth": 3,
        "text": "Now deploy the functions and GraphQL API:"
      },
      {
        "heading": "Querying the GraphQL API",
        "depth": 3,
        "text": "Now, you can run the following queries and mutations to interact with the API:"
      },
      {
        "heading": "Creating a resolver that interacts with another API",
        "depth": 2,
        "text": "Next, we'll create a function that will interact with a public Cryptocurrency REST API."
      },
      {
        "heading": "Creating a resolver that interacts with another API",
        "depth": 2,
        "text": "Create another function:"
      },
      {
        "heading": "Creating a resolver that interacts with another API",
        "depth": 2,
        "text": "Next, update the function code (located at amplify/backend/function/cryptofunction/src/index.js) to the following and press enter:"
      },
      {
        "heading": "Creating a resolver that interacts with another API",
        "depth": 2,
        "text": "Next, install the axios library in the function src folder and change back into the root directory:"
      },
      {
        "heading": "Creating a resolver that interacts with another API",
        "depth": 2,
        "text": "Now, update the GraphQL schema and add a getCoins resolver to the Query type:"
      },
      {
        "heading": "Creating a resolver that interacts with another API",
        "depth": 2,
        "text": "Next, deploy the updates:"
      },
      {
        "heading": "Creating a resolver that interacts with another API",
        "depth": 2,
        "text": "Now you can query the GraphQL API using the new getCoins query."
      },
      {
        "heading": "Query with limit",
        "depth": 4,
        "text": "To learn more about the @function directive, check out the GraphQL Transform documentation here."
      }
    ],
    "source": "export const meta = {\n  title: `How to use Lambda GraphQL Resolvers`,\n  description: `How to use Lambda GraphQL resolvers to interact with other services`,\n};\n\nThe [GraphQL Transform Library](/cli/graphql/custom-business-logic#lambda-function-resolver) provides a `@function` directive that enables the configuration of AWS Lambda function resolvers within your GraphQL API. In this guide you will learn how to use Lambda functions as GraphQL resolvers to interact with other services and APIs using the `@function` directive.\n\n## Creating basic query and mutation Function resolvers\n\nTo get started, let's take a look at a GraphQL schema with a query and a mutation that has the data source set as a Lambda function.\n\n```graphql\n# A query that returns the arguments\ntype Query {\n  echo(msg: String): String @function(name: \"functionName-${env}\")\n}\n\n# A mutation that adds two numbers\ntype Mutation {\n  add(number1: Int, number2: Int): Int @function(name: \"functionName-${env}\")\n}\n```\n\nUsing the `@function` directive, you can specify a Lambda function to be invoked as the GraphQL resolver.\n\nIn this guide, you'll learn how to enable Lambda function resolvers in a GraphQL API.\n\n### Creating the functions\n\nTo get started, create the first Lambda function:\n\n```sh\namplify add function\n\n? Provide a friendly name for your resource to be used as a label for this category in the project: echofunction\n? Provide the AWS Lambda function name: echofunction\n? Choose the function runtime that you want to use: NodeJS\n? Choose the function template that you want to use: Hello World\n? Do you want to access other resources created in this project from your Lambda function? No\n? Do you want to invoke this function on a recurring schedule? No\n? Do you want to edit the local lambda function now? Yes\n```\n\nOpen the function code (located at __amplify/backend/function/echofunction/src/index.js__) and press enter:\n\n```js\nexports.handler = async (event) => {\n    const response = event.arguments.msg\n    return response;\n};\n```\n\nThis function will just return the value of the `msg` property passed in as an argument.\n\n#### Lambda event information\n\nThe `event` object will contain the following properties:\n\n```js\n/*\nevent = {\n  \"typeName\": \"Query\" or \"Mutation\", Filled dynamically based on @function usage location\n  \"fieldName\": Filled dynamically based on @function usage location\n  \"arguments\": { msg }, GraphQL field arguments\n  \"identity\": {}, AppSync identity object\n  \"source\": {}, The object returned by the parent resolver. E.G. if resolving field 'Post.comments', the source is the Post object\n  \"request\": {}, AppSync request object. Contains things like headers\n  \"prev\": {} If using the built-in pipeline resolver support, this contains the object returned by the previous function.\n}\n*/\n```\n\nIn the above function we've used the `arguments` property to get the values passed in as arguments to the function.\n\nNext, create another Lambda function:\n\n```sh\namplify add function\n\n? Provide a friendly name for your resource to be used as a label for this category in the project: addingfunction\n? Provide the AWS Lambda function name: addfunction\n? Choose the function runtime that you want to use: NodeJS\n? Choose the function template that you want to use: Hello World\n? Do you want to access other resources created in this project from your Lambda function? No\n? Do you want to invoke this function on a recurring schedule? No\n? Do you want to edit the local lambda function now? Yes\n```\n\nNext, update the function code (located at __amplify/backend/function/addingfunction/src/index.js__) to the following and press enter:\n\n```js\nexports.handler = async (event) => {\n    /* Add number1 and number2, return the result */\n    const response = event.arguments.number1 + event.arguments.number2\n    return response;\n};\n```\n\nThis function will add two numbers together and return the result.\n\n### Creating the GraphQL API\n\nNow that the functions have been created, you can create the GraphQL API:\n\n```sh\namplify add api\n\n? Please select from one of the below mentioned services:\n  > GraphQL\n? Here is the GraphQL API that we will create. Select a setting to edit or continue:\n  > Name\n? Provide API name:\n  > gqllambda\n? Here is the GraphQL API that we will create. Select a setting to edit or continue:\n  > Authorization modes: API key (default, expiration time: 7 days from now)\n? Choose the default authorization type for the API:\n  > API Key\n? Enter a description for the API key:\n  > public (or some description)\n? After how many days from now the API key should expire:\n  > 365 (or your preferred expiration)\n? Configure additional auth types?\n  > No\n? Here is the GraphQL API that we will create. Select a setting to edit or continue:\n  > Continue\n? Choose a schema template:\n  > Single object with fields (e.g., “Todo” with ID, name, description)\n? Do you want to edit the schema now?\n  > Y\n```\n\nNext, update the base GraphQL schema (located at __amplify/backend/api/gqllambda/schema.graphql__) with the following code and press enter:\n\n```graphql\ntype Query {\n  echo(msg: String): String @function(name: \"echofunction-${env}\")\n}\n\ntype Mutation {\n  add(number1: Int, number2: Int): Int @function(name: \"addingfunction-${env}\")\n}\n```\n\nNow deploy the functions and GraphQL API:\n\n```sh\namplify push\n```\n\n### Querying the GraphQL API\n\nNow, you can run the following queries and mutations to interact with the API:\n\n```graphql\nquery echo {\n  echo(msg: \"Hello world!\")\n}\n\nmutation add {\n  add(number1: 1100, number2:100)\n}\n```\n\n## Creating a resolver that interacts with another API\n\nNext, we'll create a function that will interact with a public Cryptocurrency REST API.\n\nCreate another function:\n\n```sh\namplify add function\n```\n\nNext, update the function code (located at __amplify/backend/function/cryptofunction/src/index.js__) to the following and press enter:\n\n```javascript\nconst axios = require('axios')\n\nexports.handler = async (event) => {\n    let limit = 10\n    if (event.arguments.limit) {\n        limit = event.arguments.limit\n    }\n    const url = `https://api.coinlore.net/api/tickers/?limit=${limit}`\n    let response = await axios.get(url)\n    return JSON.stringify(response.data.data);\n};\n```\n\nNext, install the axios library in the function __src__ folder and change back into the root directory:\n\n```sh\ncd amplify/backend/function/cryptofunction/src\nnpm install axios\ncd ../../../../../\n```\n\nNow, update the GraphQL schema and add a `getCoins` resolver to the Query type:\n\n```graphql\ntype Query {\n  echo(msg: String): String @function(name: \"gqlfunc-${env}\")\n  getCoins(limit: Int): String @function(name: \"cryptofunction-${env}\")\n}\n```\n\nNext, deploy the updates:\n\n```sh\namplify push\n```\n\nNow you can query the GraphQL API using the new `getCoins` query.\n\n#### Basic query\n\n```graphql\nquery getCoins {\n  getCoins\n}\n```\n\n#### Query with limit\n\n```graphql\nquery getCoins {\n  getCoins(limit: 100)\n}\n```\n\nTo learn more about the `@function` directive, check out the GraphQL Transform documentation [here](/cli/graphql/custom-business-logic#lambda-function-resolver).\n",
    "meta": {
      "title": "How to use Lambda GraphQL Resolvers - Android",
      "description": "How to use Lambda GraphQL resolvers to interact with other services - Android",
      "subcategory": "API (GraphQL)",
      "category": "Guides"
    },
    "filename": "/guides/api-graphql/lambda-resolvers/q/platform/android"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "The GraphQL Transform Library provides a @function directive that enables the configuration of AWS Lambda function resolvers within your GraphQL API. In this guide you will learn how to use Lambda functions as GraphQL resolvers to interact with other services and APIs using the @function directive."
      },
      {
        "heading": "Creating basic query and mutation Function resolvers",
        "depth": 2,
        "text": "To get started, let's take a look at a GraphQL schema with a query and a mutation that has the data source set as a Lambda function."
      },
      {
        "heading": "Creating basic query and mutation Function resolvers",
        "depth": 2,
        "text": "Using the @function directive, you can specify a Lambda function to be invoked as the GraphQL resolver."
      },
      {
        "heading": "Creating basic query and mutation Function resolvers",
        "depth": 2,
        "text": "In this guide, you'll learn how to enable Lambda function resolvers in a GraphQL API."
      },
      {
        "heading": "Creating the functions",
        "depth": 3,
        "text": "To get started, create the first Lambda function:"
      },
      {
        "heading": "Creating the functions",
        "depth": 3,
        "text": "Open the function code (located at amplify/backend/function/echofunction/src/index.js) and press enter:"
      },
      {
        "heading": "Creating the functions",
        "depth": 3,
        "text": "This function will just return the value of the msg property passed in as an argument."
      },
      {
        "heading": "Lambda event information",
        "depth": 4,
        "text": "The event object will contain the following properties:"
      },
      {
        "heading": "Lambda event information",
        "depth": 4,
        "text": "In the above function we've used the arguments property to get the values passed in as arguments to the function."
      },
      {
        "heading": "Lambda event information",
        "depth": 4,
        "text": "Next, create another Lambda function:"
      },
      {
        "heading": "Lambda event information",
        "depth": 4,
        "text": "Next, update the function code (located at amplify/backend/function/addingfunction/src/index.js) to the following and press enter:"
      },
      {
        "heading": "Lambda event information",
        "depth": 4,
        "text": "This function will add two numbers together and return the result."
      },
      {
        "heading": "Creating the GraphQL API",
        "depth": 3,
        "text": "Now that the functions have been created, you can create the GraphQL API:"
      },
      {
        "heading": "Creating the GraphQL API",
        "depth": 3,
        "text": "Next, update the base GraphQL schema (located at amplify/backend/api/gqllambda/schema.graphql) with the following code and press enter:"
      },
      {
        "heading": "Creating the GraphQL API",
        "depth": 3,
        "text": "Now deploy the functions and GraphQL API:"
      },
      {
        "heading": "Querying the GraphQL API",
        "depth": 3,
        "text": "Now, you can run the following queries and mutations to interact with the API:"
      },
      {
        "heading": "Creating a resolver that interacts with another API",
        "depth": 2,
        "text": "Next, we'll create a function that will interact with a public Cryptocurrency REST API."
      },
      {
        "heading": "Creating a resolver that interacts with another API",
        "depth": 2,
        "text": "Create another function:"
      },
      {
        "heading": "Creating a resolver that interacts with another API",
        "depth": 2,
        "text": "Next, update the function code (located at amplify/backend/function/cryptofunction/src/index.js) to the following and press enter:"
      },
      {
        "heading": "Creating a resolver that interacts with another API",
        "depth": 2,
        "text": "Next, install the axios library in the function src folder and change back into the root directory:"
      },
      {
        "heading": "Creating a resolver that interacts with another API",
        "depth": 2,
        "text": "Now, update the GraphQL schema and add a getCoins resolver to the Query type:"
      },
      {
        "heading": "Creating a resolver that interacts with another API",
        "depth": 2,
        "text": "Next, deploy the updates:"
      },
      {
        "heading": "Creating a resolver that interacts with another API",
        "depth": 2,
        "text": "Now you can query the GraphQL API using the new getCoins query."
      },
      {
        "heading": "Query with limit",
        "depth": 4,
        "text": "To learn more about the @function directive, check out the GraphQL Transform documentation here."
      }
    ],
    "source": "export const meta = {\n  title: `How to use Lambda GraphQL Resolvers`,\n  description: `How to use Lambda GraphQL resolvers to interact with other services`,\n};\n\nThe [GraphQL Transform Library](/cli/graphql/custom-business-logic#lambda-function-resolver) provides a `@function` directive that enables the configuration of AWS Lambda function resolvers within your GraphQL API. In this guide you will learn how to use Lambda functions as GraphQL resolvers to interact with other services and APIs using the `@function` directive.\n\n## Creating basic query and mutation Function resolvers\n\nTo get started, let's take a look at a GraphQL schema with a query and a mutation that has the data source set as a Lambda function.\n\n```graphql\n# A query that returns the arguments\ntype Query {\n  echo(msg: String): String @function(name: \"functionName-${env}\")\n}\n\n# A mutation that adds two numbers\ntype Mutation {\n  add(number1: Int, number2: Int): Int @function(name: \"functionName-${env}\")\n}\n```\n\nUsing the `@function` directive, you can specify a Lambda function to be invoked as the GraphQL resolver.\n\nIn this guide, you'll learn how to enable Lambda function resolvers in a GraphQL API.\n\n### Creating the functions\n\nTo get started, create the first Lambda function:\n\n```sh\namplify add function\n\n? Provide a friendly name for your resource to be used as a label for this category in the project: echofunction\n? Provide the AWS Lambda function name: echofunction\n? Choose the function runtime that you want to use: NodeJS\n? Choose the function template that you want to use: Hello World\n? Do you want to access other resources created in this project from your Lambda function? No\n? Do you want to invoke this function on a recurring schedule? No\n? Do you want to edit the local lambda function now? Yes\n```\n\nOpen the function code (located at __amplify/backend/function/echofunction/src/index.js__) and press enter:\n\n```js\nexports.handler = async (event) => {\n    const response = event.arguments.msg\n    return response;\n};\n```\n\nThis function will just return the value of the `msg` property passed in as an argument.\n\n#### Lambda event information\n\nThe `event` object will contain the following properties:\n\n```js\n/*\nevent = {\n  \"typeName\": \"Query\" or \"Mutation\", Filled dynamically based on @function usage location\n  \"fieldName\": Filled dynamically based on @function usage location\n  \"arguments\": { msg }, GraphQL field arguments\n  \"identity\": {}, AppSync identity object\n  \"source\": {}, The object returned by the parent resolver. E.G. if resolving field 'Post.comments', the source is the Post object\n  \"request\": {}, AppSync request object. Contains things like headers\n  \"prev\": {} If using the built-in pipeline resolver support, this contains the object returned by the previous function.\n}\n*/\n```\n\nIn the above function we've used the `arguments` property to get the values passed in as arguments to the function.\n\nNext, create another Lambda function:\n\n```sh\namplify add function\n\n? Provide a friendly name for your resource to be used as a label for this category in the project: addingfunction\n? Provide the AWS Lambda function name: addfunction\n? Choose the function runtime that you want to use: NodeJS\n? Choose the function template that you want to use: Hello World\n? Do you want to access other resources created in this project from your Lambda function? No\n? Do you want to invoke this function on a recurring schedule? No\n? Do you want to edit the local lambda function now? Yes\n```\n\nNext, update the function code (located at __amplify/backend/function/addingfunction/src/index.js__) to the following and press enter:\n\n```js\nexports.handler = async (event) => {\n    /* Add number1 and number2, return the result */\n    const response = event.arguments.number1 + event.arguments.number2\n    return response;\n};\n```\n\nThis function will add two numbers together and return the result.\n\n### Creating the GraphQL API\n\nNow that the functions have been created, you can create the GraphQL API:\n\n```sh\namplify add api\n\n? Please select from one of the below mentioned services:\n  > GraphQL\n? Here is the GraphQL API that we will create. Select a setting to edit or continue:\n  > Name\n? Provide API name:\n  > gqllambda\n? Here is the GraphQL API that we will create. Select a setting to edit or continue:\n  > Authorization modes: API key (default, expiration time: 7 days from now)\n? Choose the default authorization type for the API:\n  > API Key\n? Enter a description for the API key:\n  > public (or some description)\n? After how many days from now the API key should expire:\n  > 365 (or your preferred expiration)\n? Configure additional auth types?\n  > No\n? Here is the GraphQL API that we will create. Select a setting to edit or continue:\n  > Continue\n? Choose a schema template:\n  > Single object with fields (e.g., “Todo” with ID, name, description)\n? Do you want to edit the schema now?\n  > Y\n```\n\nNext, update the base GraphQL schema (located at __amplify/backend/api/gqllambda/schema.graphql__) with the following code and press enter:\n\n```graphql\ntype Query {\n  echo(msg: String): String @function(name: \"echofunction-${env}\")\n}\n\ntype Mutation {\n  add(number1: Int, number2: Int): Int @function(name: \"addingfunction-${env}\")\n}\n```\n\nNow deploy the functions and GraphQL API:\n\n```sh\namplify push\n```\n\n### Querying the GraphQL API\n\nNow, you can run the following queries and mutations to interact with the API:\n\n```graphql\nquery echo {\n  echo(msg: \"Hello world!\")\n}\n\nmutation add {\n  add(number1: 1100, number2:100)\n}\n```\n\n## Creating a resolver that interacts with another API\n\nNext, we'll create a function that will interact with a public Cryptocurrency REST API.\n\nCreate another function:\n\n```sh\namplify add function\n```\n\nNext, update the function code (located at __amplify/backend/function/cryptofunction/src/index.js__) to the following and press enter:\n\n```javascript\nconst axios = require('axios')\n\nexports.handler = async (event) => {\n    let limit = 10\n    if (event.arguments.limit) {\n        limit = event.arguments.limit\n    }\n    const url = `https://api.coinlore.net/api/tickers/?limit=${limit}`\n    let response = await axios.get(url)\n    return JSON.stringify(response.data.data);\n};\n```\n\nNext, install the axios library in the function __src__ folder and change back into the root directory:\n\n```sh\ncd amplify/backend/function/cryptofunction/src\nnpm install axios\ncd ../../../../../\n```\n\nNow, update the GraphQL schema and add a `getCoins` resolver to the Query type:\n\n```graphql\ntype Query {\n  echo(msg: String): String @function(name: \"gqlfunc-${env}\")\n  getCoins(limit: Int): String @function(name: \"cryptofunction-${env}\")\n}\n```\n\nNext, deploy the updates:\n\n```sh\namplify push\n```\n\nNow you can query the GraphQL API using the new `getCoins` query.\n\n#### Basic query\n\n```graphql\nquery getCoins {\n  getCoins\n}\n```\n\n#### Query with limit\n\n```graphql\nquery getCoins {\n  getCoins(limit: 100)\n}\n```\n\nTo learn more about the `@function` directive, check out the GraphQL Transform documentation [here](/cli/graphql/custom-business-logic#lambda-function-resolver).\n",
    "meta": {
      "title": "How to use Lambda GraphQL Resolvers - JavaScript",
      "description": "How to use Lambda GraphQL resolvers to interact with other services - JavaScript",
      "subcategory": "API (GraphQL)",
      "category": "Guides"
    },
    "filename": "/guides/api-graphql/lambda-resolvers/q/platform/js"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In this guide you will learn how to implement sorting in a GraphQL API. In our example, you will implement sorting results by date in either an ascending or descending order by implementing an additional data access pattern leveraging a DynamoDB Global Secondary Index using the @index GraphQL Transformer directive."
      },
      {
        "heading": "Overview",
        "depth": 3,
        "text": "To get started, let's start with a basic GraphQL schema for a Todo app:"
      },
      {
        "heading": "Overview",
        "depth": 3,
        "text": "When the API is created with an @model directive, the following queries will automatically be created for you:"
      },
      {
        "heading": "Overview",
        "depth": 3,
        "text": "Next, take a look at the ModelTodoConnection type to get an idea of the data that will be returned when the listTodos query is run:"
      },
      {
        "heading": "Overview",
        "depth": 3,
        "text": "By default, the listTodos query will return the items array unordered. Many times you will need these items to be ordered by title, by creation date, or in some other way."
      },
      {
        "heading": "Overview",
        "depth": 3,
        "text": "To enable this, you can use the @index directive. This directive will allow you to set a custom sortKey on any field in your API."
      },
      {
        "heading": "Implementation",
        "depth": 3,
        "text": "In this example, you will enable sorting by the createdAt field. By default, Amplify will populate this createdAt field with a timestamp if none is passed in."
      },
      {
        "heading": "Implementation",
        "depth": 3,
        "text": "To enable this, update your schema with the following:"
      },
      {
        "heading": "Implementation",
        "depth": 3,
        "text": "When created a Todo, you must now populate the type field for this to work properly."
      },
      {
        "heading": "Implementation",
        "depth": 3,
        "text": "Next, create a few todos being sure to populate the type field:"
      },
      {
        "heading": "Implementation",
        "depth": 3,
        "text": "Now, you can query for todos by date in an ascending or descending order using the new todosByDate query:"
      },
      {
        "heading": "Implementation",
        "depth": 3,
        "text": "To learn more about the @index directive, check out the documentation here"
      }
    ],
    "source": "export const meta = {\n  title: `GraphQL query with sorting by date`,\n  description: `How to implement sorting in a GraphQL query`,\n};\n\nIn this guide you will learn how to implement sorting in a GraphQL API. In our example, you will implement sorting results by date in either an ascending or descending order by implementing an additional data access pattern leveraging a DynamoDB Global Secondary Index using the `@index` GraphQL Transformer directive.\n\n### Overview\n\nTo get started, let's start with a basic GraphQL schema for a Todo app:\n\n```graphql\ntype Todo @model {\n  id: ID!\n  title: String!\n}\n```\n\nWhen the API is created with an `@model` directive, the following queries will automatically be created for you:\n\n```graphql\ntype Query {\n  getTodo(id: ID!): Todo\n  listTodos(filter: ModelTodoFilterInput, limit: Int, nextToken: String): ModelTodoConnection\n}\n```\n\nNext, take a look at the `ModelTodoConnection` type to get an idea of the data that will be returned when the `listTodos` query is run:\n\n```graphql\ntype ModelTodoConnection {\n  items: [Todo]\n  nextToken: String\n}\n```\n\nBy default, the `listTodos` query will return the `items` array __unordered__. Many times you will need these items to be ordered by title, by creation date, or in some other way.\n\nTo enable this, you can use the [@index](/cli/graphql/data-modeling) directive. This directive will allow you to set a custom `sortKey` on any field in your API.\n\n### Implementation\n\nIn this example, you will enable sorting by the `createdAt` field. By default, Amplify will populate this `createdAt` field with a timestamp if none is passed in.\n\nTo enable this, update your schema with the following:\n\n```graphql\ntype Todo @model {\n  id: ID!\n  title: String!\n  type: String! @index(name: \"todosByDate\", queryField: \"todosByDate\", sortKeyFields: [\"createdAt\"])\n  createdAt: String!\n}\n```\n\n<Callout>\n\nWhen created a Todo, you must now populate the `type` field for this to work properly.\n\n</Callout>\n\nNext, create a few todos being sure to populate the `type` field:\n\n```graphql\nmutation createTodo {\n  createTodo(input: {\n    title: \"Todo 1\"\n    type: \"Todo\"\n  }) {\n    id\n    title\n  }\n}\n```\n\nNow, you can query for todos by date in an ascending or descending order using the new `todosByDate` query:\n\n```graphql\nquery todosByDate {\n  todosByDate(\n    type: \"Todo\"\n    sortDirection: ASC\n  ) {\n    items {\n      id\n      title\n      createdAt\n    }\n  }\n}\n\nquery todosByDateDescending {\n  todosByDate(\n    type: \"Todo\"\n    sortDirection: DESC\n  ) {\n    items {\n      id\n      title\n      createdAt\n    }\n  }\n}\n```\n\nTo learn more about the `@index` directive, check out the documentation [here](/cli/graphql/data-modeling)\n",
    "meta": {
      "title": "GraphQL query with sorting by date - iOS",
      "description": "How to implement sorting in a GraphQL query - iOS",
      "subcategory": "API (GraphQL)",
      "category": "Guides"
    },
    "filename": "/guides/api-graphql/query-with-sorting/q/platform/ios"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In this guide you will learn how to implement sorting in a GraphQL API. In our example, you will implement sorting results by date in either an ascending or descending order by implementing an additional data access pattern leveraging a DynamoDB Global Secondary Index using the @index GraphQL Transformer directive."
      },
      {
        "heading": "Overview",
        "depth": 3,
        "text": "To get started, let's start with a basic GraphQL schema for a Todo app:"
      },
      {
        "heading": "Overview",
        "depth": 3,
        "text": "When the API is created with an @model directive, the following queries will automatically be created for you:"
      },
      {
        "heading": "Overview",
        "depth": 3,
        "text": "Next, take a look at the ModelTodoConnection type to get an idea of the data that will be returned when the listTodos query is run:"
      },
      {
        "heading": "Overview",
        "depth": 3,
        "text": "By default, the listTodos query will return the items array unordered. Many times you will need these items to be ordered by title, by creation date, or in some other way."
      },
      {
        "heading": "Overview",
        "depth": 3,
        "text": "To enable this, you can use the @index directive. This directive will allow you to set a custom sortKey on any field in your API."
      },
      {
        "heading": "Implementation",
        "depth": 3,
        "text": "In this example, you will enable sorting by the createdAt field. By default, Amplify will populate this createdAt field with a timestamp if none is passed in."
      },
      {
        "heading": "Implementation",
        "depth": 3,
        "text": "To enable this, update your schema with the following:"
      },
      {
        "heading": "Implementation",
        "depth": 3,
        "text": "When created a Todo, you must now populate the type field for this to work properly."
      },
      {
        "heading": "Implementation",
        "depth": 3,
        "text": "Next, create a few todos being sure to populate the type field:"
      },
      {
        "heading": "Implementation",
        "depth": 3,
        "text": "Now, you can query for todos by date in an ascending or descending order using the new todosByDate query:"
      },
      {
        "heading": "Implementation",
        "depth": 3,
        "text": "To learn more about the @index directive, check out the documentation here"
      }
    ],
    "source": "export const meta = {\n  title: `GraphQL query with sorting by date`,\n  description: `How to implement sorting in a GraphQL query`,\n};\n\nIn this guide you will learn how to implement sorting in a GraphQL API. In our example, you will implement sorting results by date in either an ascending or descending order by implementing an additional data access pattern leveraging a DynamoDB Global Secondary Index using the `@index` GraphQL Transformer directive.\n\n### Overview\n\nTo get started, let's start with a basic GraphQL schema for a Todo app:\n\n```graphql\ntype Todo @model {\n  id: ID!\n  title: String!\n}\n```\n\nWhen the API is created with an `@model` directive, the following queries will automatically be created for you:\n\n```graphql\ntype Query {\n  getTodo(id: ID!): Todo\n  listTodos(filter: ModelTodoFilterInput, limit: Int, nextToken: String): ModelTodoConnection\n}\n```\n\nNext, take a look at the `ModelTodoConnection` type to get an idea of the data that will be returned when the `listTodos` query is run:\n\n```graphql\ntype ModelTodoConnection {\n  items: [Todo]\n  nextToken: String\n}\n```\n\nBy default, the `listTodos` query will return the `items` array __unordered__. Many times you will need these items to be ordered by title, by creation date, or in some other way.\n\nTo enable this, you can use the [@index](/cli/graphql/data-modeling) directive. This directive will allow you to set a custom `sortKey` on any field in your API.\n\n### Implementation\n\nIn this example, you will enable sorting by the `createdAt` field. By default, Amplify will populate this `createdAt` field with a timestamp if none is passed in.\n\nTo enable this, update your schema with the following:\n\n```graphql\ntype Todo @model {\n  id: ID!\n  title: String!\n  type: String! @index(name: \"todosByDate\", queryField: \"todosByDate\", sortKeyFields: [\"createdAt\"])\n  createdAt: String!\n}\n```\n\n<Callout>\n\nWhen created a Todo, you must now populate the `type` field for this to work properly.\n\n</Callout>\n\nNext, create a few todos being sure to populate the `type` field:\n\n```graphql\nmutation createTodo {\n  createTodo(input: {\n    title: \"Todo 1\"\n    type: \"Todo\"\n  }) {\n    id\n    title\n  }\n}\n```\n\nNow, you can query for todos by date in an ascending or descending order using the new `todosByDate` query:\n\n```graphql\nquery todosByDate {\n  todosByDate(\n    type: \"Todo\"\n    sortDirection: ASC\n  ) {\n    items {\n      id\n      title\n      createdAt\n    }\n  }\n}\n\nquery todosByDateDescending {\n  todosByDate(\n    type: \"Todo\"\n    sortDirection: DESC\n  ) {\n    items {\n      id\n      title\n      createdAt\n    }\n  }\n}\n```\n\nTo learn more about the `@index` directive, check out the documentation [here](/cli/graphql/data-modeling)\n",
    "meta": {
      "title": "GraphQL query with sorting by date - Android",
      "description": "How to implement sorting in a GraphQL query - Android",
      "subcategory": "API (GraphQL)",
      "category": "Guides"
    },
    "filename": "/guides/api-graphql/query-with-sorting/q/platform/android"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In this guide you will learn how to implement sorting in a GraphQL API. In our example, you will implement sorting results by date in either an ascending or descending order by implementing an additional data access pattern leveraging a DynamoDB Global Secondary Index using the @index GraphQL Transformer directive."
      },
      {
        "heading": "Overview",
        "depth": 3,
        "text": "To get started, let's start with a basic GraphQL schema for a Todo app:"
      },
      {
        "heading": "Overview",
        "depth": 3,
        "text": "When the API is created with an @model directive, the following queries will automatically be created for you:"
      },
      {
        "heading": "Overview",
        "depth": 3,
        "text": "Next, take a look at the ModelTodoConnection type to get an idea of the data that will be returned when the listTodos query is run:"
      },
      {
        "heading": "Overview",
        "depth": 3,
        "text": "By default, the listTodos query will return the items array unordered. Many times you will need these items to be ordered by title, by creation date, or in some other way."
      },
      {
        "heading": "Overview",
        "depth": 3,
        "text": "To enable this, you can use the @index directive. This directive will allow you to set a custom sortKey on any field in your API."
      },
      {
        "heading": "Implementation",
        "depth": 3,
        "text": "In this example, you will enable sorting by the createdAt field. By default, Amplify will populate this createdAt field with a timestamp if none is passed in."
      },
      {
        "heading": "Implementation",
        "depth": 3,
        "text": "To enable this, update your schema with the following:"
      },
      {
        "heading": "Implementation",
        "depth": 3,
        "text": "When created a Todo, you must now populate the type field for this to work properly."
      },
      {
        "heading": "Implementation",
        "depth": 3,
        "text": "Next, create a few todos being sure to populate the type field:"
      },
      {
        "heading": "Implementation",
        "depth": 3,
        "text": "Now, you can query for todos by date in an ascending or descending order using the new todosByDate query:"
      },
      {
        "heading": "Implementation",
        "depth": 3,
        "text": "To learn more about the @index directive, check out the documentation here"
      }
    ],
    "source": "export const meta = {\n  title: `GraphQL query with sorting by date`,\n  description: `How to implement sorting in a GraphQL query`,\n};\n\nIn this guide you will learn how to implement sorting in a GraphQL API. In our example, you will implement sorting results by date in either an ascending or descending order by implementing an additional data access pattern leveraging a DynamoDB Global Secondary Index using the `@index` GraphQL Transformer directive.\n\n### Overview\n\nTo get started, let's start with a basic GraphQL schema for a Todo app:\n\n```graphql\ntype Todo @model {\n  id: ID!\n  title: String!\n}\n```\n\nWhen the API is created with an `@model` directive, the following queries will automatically be created for you:\n\n```graphql\ntype Query {\n  getTodo(id: ID!): Todo\n  listTodos(filter: ModelTodoFilterInput, limit: Int, nextToken: String): ModelTodoConnection\n}\n```\n\nNext, take a look at the `ModelTodoConnection` type to get an idea of the data that will be returned when the `listTodos` query is run:\n\n```graphql\ntype ModelTodoConnection {\n  items: [Todo]\n  nextToken: String\n}\n```\n\nBy default, the `listTodos` query will return the `items` array __unordered__. Many times you will need these items to be ordered by title, by creation date, or in some other way.\n\nTo enable this, you can use the [@index](/cli/graphql/data-modeling) directive. This directive will allow you to set a custom `sortKey` on any field in your API.\n\n### Implementation\n\nIn this example, you will enable sorting by the `createdAt` field. By default, Amplify will populate this `createdAt` field with a timestamp if none is passed in.\n\nTo enable this, update your schema with the following:\n\n```graphql\ntype Todo @model {\n  id: ID!\n  title: String!\n  type: String! @index(name: \"todosByDate\", queryField: \"todosByDate\", sortKeyFields: [\"createdAt\"])\n  createdAt: String!\n}\n```\n\n<Callout>\n\nWhen created a Todo, you must now populate the `type` field for this to work properly.\n\n</Callout>\n\nNext, create a few todos being sure to populate the `type` field:\n\n```graphql\nmutation createTodo {\n  createTodo(input: {\n    title: \"Todo 1\"\n    type: \"Todo\"\n  }) {\n    id\n    title\n  }\n}\n```\n\nNow, you can query for todos by date in an ascending or descending order using the new `todosByDate` query:\n\n```graphql\nquery todosByDate {\n  todosByDate(\n    type: \"Todo\"\n    sortDirection: ASC\n  ) {\n    items {\n      id\n      title\n      createdAt\n    }\n  }\n}\n\nquery todosByDateDescending {\n  todosByDate(\n    type: \"Todo\"\n    sortDirection: DESC\n  ) {\n    items {\n      id\n      title\n      createdAt\n    }\n  }\n}\n```\n\nTo learn more about the `@index` directive, check out the documentation [here](/cli/graphql/data-modeling)\n",
    "meta": {
      "title": "GraphQL query with sorting by date - JavaScript",
      "description": "How to implement sorting in a GraphQL query - JavaScript",
      "subcategory": "API (GraphQL)",
      "category": "Guides"
    },
    "filename": "/guides/api-graphql/query-with-sorting/q/platform/js"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In this guide you will learn how to implement pagination in your GraphQL API."
      },
      {
        "heading": null,
        "depth": null,
        "text": "When working with a large record set, you may want to only fetch the first N number of items. For example, let's start with a basic GraphQL schema for a Todo app:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "When the API is created with an @model directive, the following queries will automatically be created for you:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Next, take a look at the ModelTodoConnection type to get an idea of the data that will be returned when the listTodos query is run:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "When querying the API using the listTodos query, the return type will be of ModelTodoConnection, meaning you can return both an array of Todos and a nextToken."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The nextToken is what is used to handle pagination. If the nextToken is null, that means that there is no more data to return from the API. If the nextToken is present, you can use the value as an argument to the next listTodos query to return the next selection set from the API."
      },
      {
        "heading": null,
        "depth": null,
        "text": "To test this out, try creating 5 todos using a mutation like this:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Next, you can set the limit of the number of todos in a query by passing in a limit argument. In this query, you'll set the limit to 2 items and request a nextToken as a return value:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Now, to query the next 2 items from the API, you can pass this nextToken as the argument:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "When there are no other items left to be returned, the nextToken in the response will be set to null."
      }
    ],
    "source": "export const meta = {\n  title: `GraphQL pagination`,\n  description: `How to implement pagination with GraphQL `,\n};\n\nIn this guide you will learn how to implement pagination in your GraphQL API.\n\nWhen working with a large record set, you may want to only fetch the first __N__ number of items. For example, let's start with a basic GraphQL schema for a Todo app:\n\n```graphql\ntype Todo @model {\n  id: ID!\n  title: String!\n  description: String \n}\n```\n\nWhen the API is created with an `@model` directive, the following queries will automatically be created for you:\n\n```graphql\ntype Query {\n  getTodo(id: ID!): Todo\n  listTodos(filter: ModelTodoFilterInput, limit: Int, nextToken: String): ModelTodoConnection\n}\n```\n\nNext, take a look at the `ModelTodoConnection` type to get an idea of the data that will be returned when the `listTodos` query is run:\n\n```graphql\ntype ModelTodoConnection {\n  items: [Todo]\n  nextToken: String\n}\n```\n\nWhen querying the API using the `listTodos` query, the return type will be of `ModelTodoConnection`, meaning you can return both an array of `Todos` and a `nextToken`.\n\nThe `nextToken` is what is used to handle pagination. If the `nextToken` is `null`, that means that there is no more data to return from the API. If the `nextToken` is present, you can use the value as an argument to the next `listTodos` query to return the next selection set from the API.\n\nTo test this out, try creating 5 todos using a mutation like this:\n\n```sh\nmutation createTodo {\n  createTodo(input: {\n    title: \"Todo 1\"\n    description: \"My first todo\"\n  }) {\n    id\n    title\n    description\n  }\n}\n```\n\nNext, you can set the limit of the number of todos in a query by passing in a `limit` argument. In this query, you'll set the limit to 2 items and request a `nextToken` as a return value:\n\n```graphql\nquery listTodos {\n  listTodos(limit: 2) {\n    items {\n      id\n      title\n      description\n    }\n    nextToken\n  }\n}\n```\n\n Now, to query the next 2 items from the API, you can pass this `nextToken` as the argument:\n\n```graphql\nquery listTodos {\n  listTodos(limit: 2, nextToken: <your_token>) {\n    items {\n      id\n      title\n      description\n    }\n    nextToken\n  }\n}\n```\n\nWhen there are no other items left to be returned, the `nextToken` in the response will be set to null.\n\nimport js0 from \"/src/fragments/guides/api-graphql/js/graphql-pagination.mdx\";\n\n<Fragments fragments={{js: js0}} /> ",
    "meta": {
      "title": "GraphQL pagination - iOS",
      "description": "How to implement pagination with GraphQL  - iOS",
      "subcategory": "API (GraphQL)",
      "category": "Guides"
    },
    "filename": "/guides/api-graphql/graphql-pagination/q/platform/ios"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In this guide you will learn how to implement pagination in your GraphQL API."
      },
      {
        "heading": null,
        "depth": null,
        "text": "When working with a large record set, you may want to only fetch the first N number of items. For example, let's start with a basic GraphQL schema for a Todo app:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "When the API is created with an @model directive, the following queries will automatically be created for you:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Next, take a look at the ModelTodoConnection type to get an idea of the data that will be returned when the listTodos query is run:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "When querying the API using the listTodos query, the return type will be of ModelTodoConnection, meaning you can return both an array of Todos and a nextToken."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The nextToken is what is used to handle pagination. If the nextToken is null, that means that there is no more data to return from the API. If the nextToken is present, you can use the value as an argument to the next listTodos query to return the next selection set from the API."
      },
      {
        "heading": null,
        "depth": null,
        "text": "To test this out, try creating 5 todos using a mutation like this:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Next, you can set the limit of the number of todos in a query by passing in a limit argument. In this query, you'll set the limit to 2 items and request a nextToken as a return value:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Now, to query the next 2 items from the API, you can pass this nextToken as the argument:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "When there are no other items left to be returned, the nextToken in the response will be set to null."
      }
    ],
    "source": "export const meta = {\n  title: `GraphQL pagination`,\n  description: `How to implement pagination with GraphQL `,\n};\n\nIn this guide you will learn how to implement pagination in your GraphQL API.\n\nWhen working with a large record set, you may want to only fetch the first __N__ number of items. For example, let's start with a basic GraphQL schema for a Todo app:\n\n```graphql\ntype Todo @model {\n  id: ID!\n  title: String!\n  description: String \n}\n```\n\nWhen the API is created with an `@model` directive, the following queries will automatically be created for you:\n\n```graphql\ntype Query {\n  getTodo(id: ID!): Todo\n  listTodos(filter: ModelTodoFilterInput, limit: Int, nextToken: String): ModelTodoConnection\n}\n```\n\nNext, take a look at the `ModelTodoConnection` type to get an idea of the data that will be returned when the `listTodos` query is run:\n\n```graphql\ntype ModelTodoConnection {\n  items: [Todo]\n  nextToken: String\n}\n```\n\nWhen querying the API using the `listTodos` query, the return type will be of `ModelTodoConnection`, meaning you can return both an array of `Todos` and a `nextToken`.\n\nThe `nextToken` is what is used to handle pagination. If the `nextToken` is `null`, that means that there is no more data to return from the API. If the `nextToken` is present, you can use the value as an argument to the next `listTodos` query to return the next selection set from the API.\n\nTo test this out, try creating 5 todos using a mutation like this:\n\n```sh\nmutation createTodo {\n  createTodo(input: {\n    title: \"Todo 1\"\n    description: \"My first todo\"\n  }) {\n    id\n    title\n    description\n  }\n}\n```\n\nNext, you can set the limit of the number of todos in a query by passing in a `limit` argument. In this query, you'll set the limit to 2 items and request a `nextToken` as a return value:\n\n```graphql\nquery listTodos {\n  listTodos(limit: 2) {\n    items {\n      id\n      title\n      description\n    }\n    nextToken\n  }\n}\n```\n\n Now, to query the next 2 items from the API, you can pass this `nextToken` as the argument:\n\n```graphql\nquery listTodos {\n  listTodos(limit: 2, nextToken: <your_token>) {\n    items {\n      id\n      title\n      description\n    }\n    nextToken\n  }\n}\n```\n\nWhen there are no other items left to be returned, the `nextToken` in the response will be set to null.\n\nimport js0 from \"/src/fragments/guides/api-graphql/js/graphql-pagination.mdx\";\n\n<Fragments fragments={{js: js0}} /> ",
    "meta": {
      "title": "GraphQL pagination - Android",
      "description": "How to implement pagination with GraphQL  - Android",
      "subcategory": "API (GraphQL)",
      "category": "Guides"
    },
    "filename": "/guides/api-graphql/graphql-pagination/q/platform/android"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In this guide you will learn how to implement pagination in your GraphQL API."
      },
      {
        "heading": null,
        "depth": null,
        "text": "When working with a large record set, you may want to only fetch the first N number of items. For example, let's start with a basic GraphQL schema for a Todo app:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "When the API is created with an @model directive, the following queries will automatically be created for you:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Next, take a look at the ModelTodoConnection type to get an idea of the data that will be returned when the listTodos query is run:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "When querying the API using the listTodos query, the return type will be of ModelTodoConnection, meaning you can return both an array of Todos and a nextToken."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The nextToken is what is used to handle pagination. If the nextToken is null, that means that there is no more data to return from the API. If the nextToken is present, you can use the value as an argument to the next listTodos query to return the next selection set from the API."
      },
      {
        "heading": null,
        "depth": null,
        "text": "To test this out, try creating 5 todos using a mutation like this:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Next, you can set the limit of the number of todos in a query by passing in a limit argument. In this query, you'll set the limit to 2 items and request a nextToken as a return value:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Now, to query the next 2 items from the API, you can pass this nextToken as the argument:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "When there are no other items left to be returned, the nextToken in the response will be set to null."
      }
    ],
    "source": "export const meta = {\n  title: `GraphQL pagination`,\n  description: `How to implement pagination with GraphQL `,\n};\n\nIn this guide you will learn how to implement pagination in your GraphQL API.\n\nWhen working with a large record set, you may want to only fetch the first __N__ number of items. For example, let's start with a basic GraphQL schema for a Todo app:\n\n```graphql\ntype Todo @model {\n  id: ID!\n  title: String!\n  description: String \n}\n```\n\nWhen the API is created with an `@model` directive, the following queries will automatically be created for you:\n\n```graphql\ntype Query {\n  getTodo(id: ID!): Todo\n  listTodos(filter: ModelTodoFilterInput, limit: Int, nextToken: String): ModelTodoConnection\n}\n```\n\nNext, take a look at the `ModelTodoConnection` type to get an idea of the data that will be returned when the `listTodos` query is run:\n\n```graphql\ntype ModelTodoConnection {\n  items: [Todo]\n  nextToken: String\n}\n```\n\nWhen querying the API using the `listTodos` query, the return type will be of `ModelTodoConnection`, meaning you can return both an array of `Todos` and a `nextToken`.\n\nThe `nextToken` is what is used to handle pagination. If the `nextToken` is `null`, that means that there is no more data to return from the API. If the `nextToken` is present, you can use the value as an argument to the next `listTodos` query to return the next selection set from the API.\n\nTo test this out, try creating 5 todos using a mutation like this:\n\n```sh\nmutation createTodo {\n  createTodo(input: {\n    title: \"Todo 1\"\n    description: \"My first todo\"\n  }) {\n    id\n    title\n    description\n  }\n}\n```\n\nNext, you can set the limit of the number of todos in a query by passing in a `limit` argument. In this query, you'll set the limit to 2 items and request a `nextToken` as a return value:\n\n```graphql\nquery listTodos {\n  listTodos(limit: 2) {\n    items {\n      id\n      title\n      description\n    }\n    nextToken\n  }\n}\n```\n\n Now, to query the next 2 items from the API, you can pass this `nextToken` as the argument:\n\n```graphql\nquery listTodos {\n  listTodos(limit: 2, nextToken: <your_token>) {\n    items {\n      id\n      title\n      description\n    }\n    nextToken\n  }\n}\n```\n\nWhen there are no other items left to be returned, the `nextToken` in the response will be set to null.\n\nimport js0 from \"/src/fragments/guides/api-graphql/js/graphql-pagination.mdx\";\n\n<Fragments fragments={{js: js0}} /> ",
    "meta": {
      "title": "GraphQL pagination - JavaScript",
      "description": "How to implement pagination with GraphQL  - JavaScript",
      "subcategory": "API (GraphQL)",
      "category": "Guides"
    },
    "filename": "/guides/api-graphql/graphql-pagination/q/platform/js"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In this guide you will learn how to create a custom GraphQL subscription that will only by connected and triggered by a mutation containing a specific ID as an argument."
      },
      {
        "heading": null,
        "depth": null,
        "text": "When using the Amplify GraphQL transform library, there will often be times when you need to expand the GraphQL schema and operations created by the @model directive. A common use case is when fine grained control is needed for GraphQL subscriptions."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Take for example the following GraphQL schema:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "By default, subscriptions will be created for the following mutations:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "One operation that is not covered is if you wanted to only subscribe to comments for a specific post."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Because the schema has a one to many relationship enabled between posts and comments, you can use the auto-generated field postCommentsId that defines the relationship between the post and the comment to set this up in a new Subscription definition."
      },
      {
        "heading": null,
        "depth": null,
        "text": "To implement this, you could update the schema with the following:"
      }
    ],
    "source": "export const meta = {\n  title: `How to create GraphQL subscriptions by id`,\n  description: `How to create a custom GraphQL subscription that will listen by id`,\n};\n\nIn this guide you will learn how to create a custom GraphQL subscription that will only by connected and triggered by a mutation containing a specific ID as an argument.\n\nWhen using the Amplify GraphQL transform library, there will often be times when you need to expand the GraphQL schema and operations created by the `@model` directive. A common use case is when fine grained control is needed for GraphQL subscriptions.\n\nTake for example the following GraphQL schema:\n\n```graphql\ntype Post @model {\n  id: ID!\n  title: String!\n  content: String\n  comments: [Comment] @hasMany\n}\n\ntype Comment @model {\n  id: ID!\n  content: String\n}\n```\n\nBy default, subscriptions will be created for the following mutations:\n\n```graphql\n# Post type\nonCreatePost\nonUpdatePost\nonDeletePost\n\n# Comment type\nonCreateComment\nonUpdateComment\nonDeleteComment\n```\n\nOne operation that is not covered is if you wanted to only subscribe to comments for a specific post.\n\nBecause the schema has a one to many relationship enabled between posts and comments, you can use the auto-generated field `postCommentsId` that defines the relationship between the post and the comment to set this up in a new Subscription definition.\n\nTo implement this, you could update the schema with the following:\n\n```graphql\ntype Post @model {\n  id: ID!\n  title: String!\n  content: String\n  comments: [Comment] @hasMany\n}\n\ntype Comment @model {\n  id: ID!\n  content: String\n  postCommentsId: ID!\n}\n\ntype Subscription {\n  onCommentByPostId(postCommentsId: ID!): Comment\n    @aws_subscribe(mutations: [\"createComment\"])\n}\n\n```\n\nimport ios0 from \"/src/fragments/guides/api-graphql/ios/subscriptions-by-id.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport js1 from \"/src/fragments/guides/api-graphql/js/subscriptions-by-id.mdx\";\n\n<Fragments fragments={{js: js1}} />\n\nimport android2 from \"/src/fragments/guides/api-graphql/android/subscriptions-by-id.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/guides/api-graphql/flutter/subscriptions-by-id.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "How to create GraphQL subscriptions by id - Flutter",
      "description": "How to create a custom GraphQL subscription that will listen by id - Flutter",
      "subcategory": "API (GraphQL)",
      "category": "Guides"
    },
    "filename": "/guides/api-graphql/subscriptions-by-id/q/platform/flutter"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In this guide you will learn how to create a custom GraphQL subscription that will only by connected and triggered by a mutation containing a specific ID as an argument."
      },
      {
        "heading": null,
        "depth": null,
        "text": "When using the Amplify GraphQL transform library, there will often be times when you need to expand the GraphQL schema and operations created by the @model directive. A common use case is when fine grained control is needed for GraphQL subscriptions."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Take for example the following GraphQL schema:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "By default, subscriptions will be created for the following mutations:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "One operation that is not covered is if you wanted to only subscribe to comments for a specific post."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Because the schema has a one to many relationship enabled between posts and comments, you can use the auto-generated field postCommentsId that defines the relationship between the post and the comment to set this up in a new Subscription definition."
      },
      {
        "heading": null,
        "depth": null,
        "text": "To implement this, you could update the schema with the following:"
      }
    ],
    "source": "export const meta = {\n  title: `How to create GraphQL subscriptions by id`,\n  description: `How to create a custom GraphQL subscription that will listen by id`,\n};\n\nIn this guide you will learn how to create a custom GraphQL subscription that will only by connected and triggered by a mutation containing a specific ID as an argument.\n\nWhen using the Amplify GraphQL transform library, there will often be times when you need to expand the GraphQL schema and operations created by the `@model` directive. A common use case is when fine grained control is needed for GraphQL subscriptions.\n\nTake for example the following GraphQL schema:\n\n```graphql\ntype Post @model {\n  id: ID!\n  title: String!\n  content: String\n  comments: [Comment] @hasMany\n}\n\ntype Comment @model {\n  id: ID!\n  content: String\n}\n```\n\nBy default, subscriptions will be created for the following mutations:\n\n```graphql\n# Post type\nonCreatePost\nonUpdatePost\nonDeletePost\n\n# Comment type\nonCreateComment\nonUpdateComment\nonDeleteComment\n```\n\nOne operation that is not covered is if you wanted to only subscribe to comments for a specific post.\n\nBecause the schema has a one to many relationship enabled between posts and comments, you can use the auto-generated field `postCommentsId` that defines the relationship between the post and the comment to set this up in a new Subscription definition.\n\nTo implement this, you could update the schema with the following:\n\n```graphql\ntype Post @model {\n  id: ID!\n  title: String!\n  content: String\n  comments: [Comment] @hasMany\n}\n\ntype Comment @model {\n  id: ID!\n  content: String\n  postCommentsId: ID!\n}\n\ntype Subscription {\n  onCommentByPostId(postCommentsId: ID!): Comment\n    @aws_subscribe(mutations: [\"createComment\"])\n}\n\n```\n\nimport ios0 from \"/src/fragments/guides/api-graphql/ios/subscriptions-by-id.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport js1 from \"/src/fragments/guides/api-graphql/js/subscriptions-by-id.mdx\";\n\n<Fragments fragments={{js: js1}} />\n\nimport android2 from \"/src/fragments/guides/api-graphql/android/subscriptions-by-id.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/guides/api-graphql/flutter/subscriptions-by-id.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "How to create GraphQL subscriptions by id - iOS",
      "description": "How to create a custom GraphQL subscription that will listen by id - iOS",
      "subcategory": "API (GraphQL)",
      "category": "Guides"
    },
    "filename": "/guides/api-graphql/subscriptions-by-id/q/platform/ios"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In this guide you will learn how to create a custom GraphQL subscription that will only by connected and triggered by a mutation containing a specific ID as an argument."
      },
      {
        "heading": null,
        "depth": null,
        "text": "When using the Amplify GraphQL transform library, there will often be times when you need to expand the GraphQL schema and operations created by the @model directive. A common use case is when fine grained control is needed for GraphQL subscriptions."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Take for example the following GraphQL schema:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "By default, subscriptions will be created for the following mutations:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "One operation that is not covered is if you wanted to only subscribe to comments for a specific post."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Because the schema has a one to many relationship enabled between posts and comments, you can use the auto-generated field postCommentsId that defines the relationship between the post and the comment to set this up in a new Subscription definition."
      },
      {
        "heading": null,
        "depth": null,
        "text": "To implement this, you could update the schema with the following:"
      }
    ],
    "source": "export const meta = {\n  title: `How to create GraphQL subscriptions by id`,\n  description: `How to create a custom GraphQL subscription that will listen by id`,\n};\n\nIn this guide you will learn how to create a custom GraphQL subscription that will only by connected and triggered by a mutation containing a specific ID as an argument.\n\nWhen using the Amplify GraphQL transform library, there will often be times when you need to expand the GraphQL schema and operations created by the `@model` directive. A common use case is when fine grained control is needed for GraphQL subscriptions.\n\nTake for example the following GraphQL schema:\n\n```graphql\ntype Post @model {\n  id: ID!\n  title: String!\n  content: String\n  comments: [Comment] @hasMany\n}\n\ntype Comment @model {\n  id: ID!\n  content: String\n}\n```\n\nBy default, subscriptions will be created for the following mutations:\n\n```graphql\n# Post type\nonCreatePost\nonUpdatePost\nonDeletePost\n\n# Comment type\nonCreateComment\nonUpdateComment\nonDeleteComment\n```\n\nOne operation that is not covered is if you wanted to only subscribe to comments for a specific post.\n\nBecause the schema has a one to many relationship enabled between posts and comments, you can use the auto-generated field `postCommentsId` that defines the relationship between the post and the comment to set this up in a new Subscription definition.\n\nTo implement this, you could update the schema with the following:\n\n```graphql\ntype Post @model {\n  id: ID!\n  title: String!\n  content: String\n  comments: [Comment] @hasMany\n}\n\ntype Comment @model {\n  id: ID!\n  content: String\n  postCommentsId: ID!\n}\n\ntype Subscription {\n  onCommentByPostId(postCommentsId: ID!): Comment\n    @aws_subscribe(mutations: [\"createComment\"])\n}\n\n```\n\nimport ios0 from \"/src/fragments/guides/api-graphql/ios/subscriptions-by-id.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport js1 from \"/src/fragments/guides/api-graphql/js/subscriptions-by-id.mdx\";\n\n<Fragments fragments={{js: js1}} />\n\nimport android2 from \"/src/fragments/guides/api-graphql/android/subscriptions-by-id.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/guides/api-graphql/flutter/subscriptions-by-id.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "How to create GraphQL subscriptions by id - Android",
      "description": "How to create a custom GraphQL subscription that will listen by id - Android",
      "subcategory": "API (GraphQL)",
      "category": "Guides"
    },
    "filename": "/guides/api-graphql/subscriptions-by-id/q/platform/android"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In this guide you will learn how to create a custom GraphQL subscription that will only by connected and triggered by a mutation containing a specific ID as an argument."
      },
      {
        "heading": null,
        "depth": null,
        "text": "When using the Amplify GraphQL transform library, there will often be times when you need to expand the GraphQL schema and operations created by the @model directive. A common use case is when fine grained control is needed for GraphQL subscriptions."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Take for example the following GraphQL schema:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "By default, subscriptions will be created for the following mutations:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "One operation that is not covered is if you wanted to only subscribe to comments for a specific post."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Because the schema has a one to many relationship enabled between posts and comments, you can use the auto-generated field postCommentsId that defines the relationship between the post and the comment to set this up in a new Subscription definition."
      },
      {
        "heading": null,
        "depth": null,
        "text": "To implement this, you could update the schema with the following:"
      }
    ],
    "source": "export const meta = {\n  title: `How to create GraphQL subscriptions by id`,\n  description: `How to create a custom GraphQL subscription that will listen by id`,\n};\n\nIn this guide you will learn how to create a custom GraphQL subscription that will only by connected and triggered by a mutation containing a specific ID as an argument.\n\nWhen using the Amplify GraphQL transform library, there will often be times when you need to expand the GraphQL schema and operations created by the `@model` directive. A common use case is when fine grained control is needed for GraphQL subscriptions.\n\nTake for example the following GraphQL schema:\n\n```graphql\ntype Post @model {\n  id: ID!\n  title: String!\n  content: String\n  comments: [Comment] @hasMany\n}\n\ntype Comment @model {\n  id: ID!\n  content: String\n}\n```\n\nBy default, subscriptions will be created for the following mutations:\n\n```graphql\n# Post type\nonCreatePost\nonUpdatePost\nonDeletePost\n\n# Comment type\nonCreateComment\nonUpdateComment\nonDeleteComment\n```\n\nOne operation that is not covered is if you wanted to only subscribe to comments for a specific post.\n\nBecause the schema has a one to many relationship enabled between posts and comments, you can use the auto-generated field `postCommentsId` that defines the relationship between the post and the comment to set this up in a new Subscription definition.\n\nTo implement this, you could update the schema with the following:\n\n```graphql\ntype Post @model {\n  id: ID!\n  title: String!\n  content: String\n  comments: [Comment] @hasMany\n}\n\ntype Comment @model {\n  id: ID!\n  content: String\n  postCommentsId: ID!\n}\n\ntype Subscription {\n  onCommentByPostId(postCommentsId: ID!): Comment\n    @aws_subscribe(mutations: [\"createComment\"])\n}\n\n```\n\nimport ios0 from \"/src/fragments/guides/api-graphql/ios/subscriptions-by-id.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport js1 from \"/src/fragments/guides/api-graphql/js/subscriptions-by-id.mdx\";\n\n<Fragments fragments={{js: js1}} />\n\nimport android2 from \"/src/fragments/guides/api-graphql/android/subscriptions-by-id.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/guides/api-graphql/flutter/subscriptions-by-id.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "How to create GraphQL subscriptions by id - JavaScript",
      "description": "How to create a custom GraphQL subscription that will listen by id - JavaScript",
      "subcategory": "API (GraphQL)",
      "category": "Guides"
    },
    "filename": "/guides/api-graphql/subscriptions-by-id/q/platform/js"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In this guide you will learn how to build and interact with a Form API using Amplify."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The API that we will create is for a basic contact form. The form will allow the user to input their name and phone number, and for us to query for the list of contacts."
      },
      {
        "heading": "Getting started",
        "depth": 3,
        "text": "To get started, create a new Amplify project:"
      },
      {
        "heading": "Getting started",
        "depth": 3,
        "text": "Next, create a GraphQL API:"
      },
      {
        "heading": "Getting started",
        "depth": 3,
        "text": "The CLI should open the GraphQL schema, located at amplify/backend/api/contactapi/schema.graphql, in your text editor. Update the schema with the following and save the file:"
      },
      {
        "heading": "Getting started",
        "depth": 3,
        "text": "In the above schema, we've overriding the default mutations and are specifying that only the createContact mutation be allowed to be created. By doing this, the API does not allow users to update or delete contacts. For more fine grained authorization rules, check out the @auth directive."
      },
      {
        "heading": "Getting started",
        "depth": 3,
        "text": "Next, deploy the API:"
      },
      {
        "heading": "Interacting the API",
        "depth": 3,
        "text": "To create a new contact, you can use the createContact mutation:"
      },
      {
        "heading": "Interacting the API",
        "depth": 3,
        "text": "To query for a list of contacts, you can use the listContacts query:"
      }
    ],
    "source": "export const meta = {\n  title: `Building a Form API with GraphQL`,\n  description: `How to implement pagination with GraphQL`,\n};\n\nIn this guide you will learn how to build and interact with a Form API using Amplify.\n\nThe API that we will create is for a basic contact form. The form will allow the user to input their name and phone number, and for us to query for the list of contacts.\n\n### Getting started\n\nTo get started, create a new Amplify project:\n\n```sh\namplify init\n\n# Choose your environment name and default text editor\n# You can answer the defaults for the rest of the questions and then choose the AWS profile you'd like to use for this project.\n```\n\nNext, create a GraphQL API:\n\n```sh\namplify add api\n\n? Please select from one of the below mentioned services:\n  > GraphQL\n? Here is the GraphQL API that we will create. Select a setting to edit or continue:\n  > Name\n? Provide API name:\n  > contactapi\n? Here is the GraphQL API that we will create. Select a setting to edit or continue:\n  > Authorization modes: API key (default, expiration time: 7 days from now)\n? Choose the default authorization type for the API:\n  > API key\n? Enter a description for the API key:\n  > public\n? After how many days from now the API key should expire (1-365):\n  > 365\n? Configure additional auth types?\n  > No\n? Here is the GraphQL API that we will create. Select a setting to edit or continue:\n  > Continue\n? Choose a schema template:\n  > Single object with fields (e.g., “Todo” with ID, name, description)\n? Do you want to edit the schema now?\n  > Yes\n```\n\nThe CLI should open the GraphQL schema, located at __amplify/backend/api/contactapi/schema.graphql__, in your text editor. Update the schema with the following and save the file:\n\n```graphql\ntype Contact @model(mutations: {\n  create: \"createContact\"\n}) {\n  id: ID!\n  name: String!\n  phone: String!\n}\n```\n\n<Callout>\n\nIn the above schema, we've overriding the default mutations and are specifying that only the `createContact` mutation be allowed to be created. By doing this, the API does not allow users to update or delete contacts. For more fine grained authorization rules, check out the [@auth directive](/cli/graphql/authorization-rules).\n\n</Callout>\n\nNext, deploy the API:\n\n```sh\namplify push --y\n```\n\n### Interacting the API\n\nTo create a new contact, you can use the `createContact` mutation:\n\n```graphql\nmutation createContact {\n  createContact(input: {\n    name: \"Chris\"\n    phone: \"+1-555-555-5555\"\n  }) {\n    id\n    name\n    phone\n  }\n}\n```\n\nTo query for a list of contacts, you can use the `listContacts` query:\n\n```graphql\nquery listContacts {\n  listContacts {\n    items {\n      id\n      name\n      phone\n    }\n  }\n}\n```\n\nimport js0 from \"/src/fragments/guides/api-graphql/js/building-a-form-api.mdx\";\n\n<Fragments fragments={{js: js0}} />\n",
    "meta": {
      "title": "Building a Form API with GraphQL - iOS",
      "description": "How to implement pagination with GraphQL - iOS",
      "subcategory": "API (GraphQL)",
      "category": "Guides"
    },
    "filename": "/guides/api-graphql/building-a-form-api/q/platform/ios"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In this guide you will learn how to build and interact with a Form API using Amplify."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The API that we will create is for a basic contact form. The form will allow the user to input their name and phone number, and for us to query for the list of contacts."
      },
      {
        "heading": "Getting started",
        "depth": 3,
        "text": "To get started, create a new Amplify project:"
      },
      {
        "heading": "Getting started",
        "depth": 3,
        "text": "Next, create a GraphQL API:"
      },
      {
        "heading": "Getting started",
        "depth": 3,
        "text": "The CLI should open the GraphQL schema, located at amplify/backend/api/contactapi/schema.graphql, in your text editor. Update the schema with the following and save the file:"
      },
      {
        "heading": "Getting started",
        "depth": 3,
        "text": "In the above schema, we've overriding the default mutations and are specifying that only the createContact mutation be allowed to be created. By doing this, the API does not allow users to update or delete contacts. For more fine grained authorization rules, check out the @auth directive."
      },
      {
        "heading": "Getting started",
        "depth": 3,
        "text": "Next, deploy the API:"
      },
      {
        "heading": "Interacting the API",
        "depth": 3,
        "text": "To create a new contact, you can use the createContact mutation:"
      },
      {
        "heading": "Interacting the API",
        "depth": 3,
        "text": "To query for a list of contacts, you can use the listContacts query:"
      }
    ],
    "source": "export const meta = {\n  title: `Building a Form API with GraphQL`,\n  description: `How to implement pagination with GraphQL`,\n};\n\nIn this guide you will learn how to build and interact with a Form API using Amplify.\n\nThe API that we will create is for a basic contact form. The form will allow the user to input their name and phone number, and for us to query for the list of contacts.\n\n### Getting started\n\nTo get started, create a new Amplify project:\n\n```sh\namplify init\n\n# Choose your environment name and default text editor\n# You can answer the defaults for the rest of the questions and then choose the AWS profile you'd like to use for this project.\n```\n\nNext, create a GraphQL API:\n\n```sh\namplify add api\n\n? Please select from one of the below mentioned services:\n  > GraphQL\n? Here is the GraphQL API that we will create. Select a setting to edit or continue:\n  > Name\n? Provide API name:\n  > contactapi\n? Here is the GraphQL API that we will create. Select a setting to edit or continue:\n  > Authorization modes: API key (default, expiration time: 7 days from now)\n? Choose the default authorization type for the API:\n  > API key\n? Enter a description for the API key:\n  > public\n? After how many days from now the API key should expire (1-365):\n  > 365\n? Configure additional auth types?\n  > No\n? Here is the GraphQL API that we will create. Select a setting to edit or continue:\n  > Continue\n? Choose a schema template:\n  > Single object with fields (e.g., “Todo” with ID, name, description)\n? Do you want to edit the schema now?\n  > Yes\n```\n\nThe CLI should open the GraphQL schema, located at __amplify/backend/api/contactapi/schema.graphql__, in your text editor. Update the schema with the following and save the file:\n\n```graphql\ntype Contact @model(mutations: {\n  create: \"createContact\"\n}) {\n  id: ID!\n  name: String!\n  phone: String!\n}\n```\n\n<Callout>\n\nIn the above schema, we've overriding the default mutations and are specifying that only the `createContact` mutation be allowed to be created. By doing this, the API does not allow users to update or delete contacts. For more fine grained authorization rules, check out the [@auth directive](/cli/graphql/authorization-rules).\n\n</Callout>\n\nNext, deploy the API:\n\n```sh\namplify push --y\n```\n\n### Interacting the API\n\nTo create a new contact, you can use the `createContact` mutation:\n\n```graphql\nmutation createContact {\n  createContact(input: {\n    name: \"Chris\"\n    phone: \"+1-555-555-5555\"\n  }) {\n    id\n    name\n    phone\n  }\n}\n```\n\nTo query for a list of contacts, you can use the `listContacts` query:\n\n```graphql\nquery listContacts {\n  listContacts {\n    items {\n      id\n      name\n      phone\n    }\n  }\n}\n```\n\nimport js0 from \"/src/fragments/guides/api-graphql/js/building-a-form-api.mdx\";\n\n<Fragments fragments={{js: js0}} />\n",
    "meta": {
      "title": "Building a Form API with GraphQL - Android",
      "description": "How to implement pagination with GraphQL - Android",
      "subcategory": "API (GraphQL)",
      "category": "Guides"
    },
    "filename": "/guides/api-graphql/building-a-form-api/q/platform/android"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In this guide you will learn how to build and interact with a Form API using Amplify."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The API that we will create is for a basic contact form. The form will allow the user to input their name and phone number, and for us to query for the list of contacts."
      },
      {
        "heading": "Getting started",
        "depth": 3,
        "text": "To get started, create a new Amplify project:"
      },
      {
        "heading": "Getting started",
        "depth": 3,
        "text": "Next, create a GraphQL API:"
      },
      {
        "heading": "Getting started",
        "depth": 3,
        "text": "The CLI should open the GraphQL schema, located at amplify/backend/api/contactapi/schema.graphql, in your text editor. Update the schema with the following and save the file:"
      },
      {
        "heading": "Getting started",
        "depth": 3,
        "text": "In the above schema, we've overriding the default mutations and are specifying that only the createContact mutation be allowed to be created. By doing this, the API does not allow users to update or delete contacts. For more fine grained authorization rules, check out the @auth directive."
      },
      {
        "heading": "Getting started",
        "depth": 3,
        "text": "Next, deploy the API:"
      },
      {
        "heading": "Interacting the API",
        "depth": 3,
        "text": "To create a new contact, you can use the createContact mutation:"
      },
      {
        "heading": "Interacting the API",
        "depth": 3,
        "text": "To query for a list of contacts, you can use the listContacts query:"
      }
    ],
    "source": "export const meta = {\n  title: `Building a Form API with GraphQL`,\n  description: `How to implement pagination with GraphQL`,\n};\n\nIn this guide you will learn how to build and interact with a Form API using Amplify.\n\nThe API that we will create is for a basic contact form. The form will allow the user to input their name and phone number, and for us to query for the list of contacts.\n\n### Getting started\n\nTo get started, create a new Amplify project:\n\n```sh\namplify init\n\n# Choose your environment name and default text editor\n# You can answer the defaults for the rest of the questions and then choose the AWS profile you'd like to use for this project.\n```\n\nNext, create a GraphQL API:\n\n```sh\namplify add api\n\n? Please select from one of the below mentioned services:\n  > GraphQL\n? Here is the GraphQL API that we will create. Select a setting to edit or continue:\n  > Name\n? Provide API name:\n  > contactapi\n? Here is the GraphQL API that we will create. Select a setting to edit or continue:\n  > Authorization modes: API key (default, expiration time: 7 days from now)\n? Choose the default authorization type for the API:\n  > API key\n? Enter a description for the API key:\n  > public\n? After how many days from now the API key should expire (1-365):\n  > 365\n? Configure additional auth types?\n  > No\n? Here is the GraphQL API that we will create. Select a setting to edit or continue:\n  > Continue\n? Choose a schema template:\n  > Single object with fields (e.g., “Todo” with ID, name, description)\n? Do you want to edit the schema now?\n  > Yes\n```\n\nThe CLI should open the GraphQL schema, located at __amplify/backend/api/contactapi/schema.graphql__, in your text editor. Update the schema with the following and save the file:\n\n```graphql\ntype Contact @model(mutations: {\n  create: \"createContact\"\n}) {\n  id: ID!\n  name: String!\n  phone: String!\n}\n```\n\n<Callout>\n\nIn the above schema, we've overriding the default mutations and are specifying that only the `createContact` mutation be allowed to be created. By doing this, the API does not allow users to update or delete contacts. For more fine grained authorization rules, check out the [@auth directive](/cli/graphql/authorization-rules).\n\n</Callout>\n\nNext, deploy the API:\n\n```sh\namplify push --y\n```\n\n### Interacting the API\n\nTo create a new contact, you can use the `createContact` mutation:\n\n```graphql\nmutation createContact {\n  createContact(input: {\n    name: \"Chris\"\n    phone: \"+1-555-555-5555\"\n  }) {\n    id\n    name\n    phone\n  }\n}\n```\n\nTo query for a list of contacts, you can use the `listContacts` query:\n\n```graphql\nquery listContacts {\n  listContacts {\n    items {\n      id\n      name\n      phone\n    }\n  }\n}\n```\n\nimport js0 from \"/src/fragments/guides/api-graphql/js/building-a-form-api.mdx\";\n\n<Fragments fragments={{js: js0}} />\n",
    "meta": {
      "title": "Building a Form API with GraphQL - JavaScript",
      "description": "How to implement pagination with GraphQL - JavaScript",
      "subcategory": "API (GraphQL)",
      "category": "Guides"
    },
    "filename": "/guides/api-graphql/building-a-form-api/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `How to Manage Image & File Uploads & Downloads`,\n  description: `How to manage image and file uploads and downloads with GraphQL and AWS Amplify`,\n};\n\nimport js0 from \"/src/fragments/guides/api-graphql/js/image-and-file-uploads.mdx\";\n\n<Fragments fragments={{js: js0}} /> ",
    "meta": {
      "title": "How to Manage Image & File Uploads & Downloads - JavaScript",
      "description": "How to manage image and file uploads and downloads with GraphQL and AWS Amplify - JavaScript",
      "subcategory": "API (GraphQL)",
      "category": "Guides"
    },
    "filename": "/guides/api-graphql/image-and-file-uploads/q/platform/js"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Amplify guides are meant to give you a more in-depth understanding of how to use the Amplify CLI, libraries, and hosting to build out common functionality, end-to-end solutions, and frequently asked for workflows."
      },
      {
        "heading": "Overview",
        "depth": 3,
        "text": "Like the library and CLI documentation, guides are organized by category (Authentication, Hosting, etc..), but some guides may overlap multiple categories (i.e. Functions & API) to demonstrate how to integrate multiple services together."
      },
      {
        "heading": "Overview",
        "depth": 3,
        "text": "Unlike the library and CLI documentation, guides will often combine the CLI and libraries together in a single tutorial. This is done to teach an end-to-end solution using both the service creation and configuration as well as connecting to and interacting with the service from a client-side application."
      },
      {
        "heading": "Contributing",
        "depth": 3,
        "text": "If there is a guide or idea that you would like to see implemented that is not listed, open a GitHub Issue with the details of the use case and it will be reviewed by our team and considered."
      },
      {
        "heading": "Contributing",
        "depth": 3,
        "text": "If you have an idea for a guide that you'd like to write yourself you can submit a pull request. Before writing the guide and submitting the pull request, submit an issue with the details of your idea and you will receive guidance and feedback."
      }
    ],
    "source": "export const meta = {\n  title: `Guides`,\n  description: `The Amplify Command Line Interface (CLI) is a unified toolchain to create, integrate, and manage the AWS cloud services for your app. The CLI is category-based with best practices built in. `,\n  disableTOC: `true`,\n  filterKey: `platform`,\n};\n\nAmplify guides are meant to give you a more in-depth understanding of how to use the Amplify CLI, libraries, and hosting to build out common functionality, end-to-end solutions, and frequently asked for workflows.\n\n### Overview\n\nLike the library and CLI documentation, guides are organized by category (**Authentication**, **Hosting**, etc..), but some guides may overlap multiple categories (i.e. **Functions** & **API**) to demonstrate how to integrate multiple services together.\n\nUnlike the library and CLI documentation, guides will often combine the CLI and libraries together in a single tutorial. This is done to teach an end-to-end solution using both the service creation and configuration as well as connecting to and interacting with the service from a client-side application.\n\n### Contributing\n\nIf there is a guide or idea that you would like to see implemented that is not listed, open a [GitHub Issue](https://github.com/aws-amplify/docs/issues) with the details of the use case and it will be reviewed by our team and considered.\n\nIf you have an idea for a guide that you'd like to write yourself you can submit a [pull request](https://github.com/aws-amplify/docs/pulls). Before writing the guide and submitting the pull request, submit an [issue](https://github.com/aws-amplify/docs/issues) with the details of your idea and you will receive guidance and feedback.\n",
    "meta": {
      "title": "Guides - Flutter",
      "description": "The Amplify Command Line Interface (CLI) is a unified toolchain to create, integrate, and manage the AWS cloud services for your app. The CLI is category-based with best practices built in.  - Flutter",
      "disableTOC": "true",
      "filterKey": "platform",
      "category": "Guides"
    },
    "filename": "/guides/q/platform/flutter"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Amplify guides are meant to give you a more in-depth understanding of how to use the Amplify CLI, libraries, and hosting to build out common functionality, end-to-end solutions, and frequently asked for workflows."
      },
      {
        "heading": "Overview",
        "depth": 3,
        "text": "Like the library and CLI documentation, guides are organized by category (Authentication, Hosting, etc..), but some guides may overlap multiple categories (i.e. Functions & API) to demonstrate how to integrate multiple services together."
      },
      {
        "heading": "Overview",
        "depth": 3,
        "text": "Unlike the library and CLI documentation, guides will often combine the CLI and libraries together in a single tutorial. This is done to teach an end-to-end solution using both the service creation and configuration as well as connecting to and interacting with the service from a client-side application."
      },
      {
        "heading": "Contributing",
        "depth": 3,
        "text": "If there is a guide or idea that you would like to see implemented that is not listed, open a GitHub Issue with the details of the use case and it will be reviewed by our team and considered."
      },
      {
        "heading": "Contributing",
        "depth": 3,
        "text": "If you have an idea for a guide that you'd like to write yourself you can submit a pull request. Before writing the guide and submitting the pull request, submit an issue with the details of your idea and you will receive guidance and feedback."
      }
    ],
    "source": "export const meta = {\n  title: `Guides`,\n  description: `The Amplify Command Line Interface (CLI) is a unified toolchain to create, integrate, and manage the AWS cloud services for your app. The CLI is category-based with best practices built in. `,\n  disableTOC: `true`,\n  filterKey: `platform`,\n};\n\nAmplify guides are meant to give you a more in-depth understanding of how to use the Amplify CLI, libraries, and hosting to build out common functionality, end-to-end solutions, and frequently asked for workflows.\n\n### Overview\n\nLike the library and CLI documentation, guides are organized by category (**Authentication**, **Hosting**, etc..), but some guides may overlap multiple categories (i.e. **Functions** & **API**) to demonstrate how to integrate multiple services together.\n\nUnlike the library and CLI documentation, guides will often combine the CLI and libraries together in a single tutorial. This is done to teach an end-to-end solution using both the service creation and configuration as well as connecting to and interacting with the service from a client-side application.\n\n### Contributing\n\nIf there is a guide or idea that you would like to see implemented that is not listed, open a [GitHub Issue](https://github.com/aws-amplify/docs/issues) with the details of the use case and it will be reviewed by our team and considered.\n\nIf you have an idea for a guide that you'd like to write yourself you can submit a [pull request](https://github.com/aws-amplify/docs/pulls). Before writing the guide and submitting the pull request, submit an [issue](https://github.com/aws-amplify/docs/issues) with the details of your idea and you will receive guidance and feedback.\n",
    "meta": {
      "title": "Guides - iOS",
      "description": "The Amplify Command Line Interface (CLI) is a unified toolchain to create, integrate, and manage the AWS cloud services for your app. The CLI is category-based with best practices built in.  - iOS",
      "disableTOC": "true",
      "filterKey": "platform",
      "category": "Guides"
    },
    "filename": "/guides/q/platform/ios"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Amplify guides are meant to give you a more in-depth understanding of how to use the Amplify CLI, libraries, and hosting to build out common functionality, end-to-end solutions, and frequently asked for workflows."
      },
      {
        "heading": "Overview",
        "depth": 3,
        "text": "Like the library and CLI documentation, guides are organized by category (Authentication, Hosting, etc..), but some guides may overlap multiple categories (i.e. Functions & API) to demonstrate how to integrate multiple services together."
      },
      {
        "heading": "Overview",
        "depth": 3,
        "text": "Unlike the library and CLI documentation, guides will often combine the CLI and libraries together in a single tutorial. This is done to teach an end-to-end solution using both the service creation and configuration as well as connecting to and interacting with the service from a client-side application."
      },
      {
        "heading": "Contributing",
        "depth": 3,
        "text": "If there is a guide or idea that you would like to see implemented that is not listed, open a GitHub Issue with the details of the use case and it will be reviewed by our team and considered."
      },
      {
        "heading": "Contributing",
        "depth": 3,
        "text": "If you have an idea for a guide that you'd like to write yourself you can submit a pull request. Before writing the guide and submitting the pull request, submit an issue with the details of your idea and you will receive guidance and feedback."
      }
    ],
    "source": "export const meta = {\n  title: `Guides`,\n  description: `The Amplify Command Line Interface (CLI) is a unified toolchain to create, integrate, and manage the AWS cloud services for your app. The CLI is category-based with best practices built in. `,\n  disableTOC: `true`,\n  filterKey: `platform`,\n};\n\nAmplify guides are meant to give you a more in-depth understanding of how to use the Amplify CLI, libraries, and hosting to build out common functionality, end-to-end solutions, and frequently asked for workflows.\n\n### Overview\n\nLike the library and CLI documentation, guides are organized by category (**Authentication**, **Hosting**, etc..), but some guides may overlap multiple categories (i.e. **Functions** & **API**) to demonstrate how to integrate multiple services together.\n\nUnlike the library and CLI documentation, guides will often combine the CLI and libraries together in a single tutorial. This is done to teach an end-to-end solution using both the service creation and configuration as well as connecting to and interacting with the service from a client-side application.\n\n### Contributing\n\nIf there is a guide or idea that you would like to see implemented that is not listed, open a [GitHub Issue](https://github.com/aws-amplify/docs/issues) with the details of the use case and it will be reviewed by our team and considered.\n\nIf you have an idea for a guide that you'd like to write yourself you can submit a [pull request](https://github.com/aws-amplify/docs/pulls). Before writing the guide and submitting the pull request, submit an [issue](https://github.com/aws-amplify/docs/issues) with the details of your idea and you will receive guidance and feedback.\n",
    "meta": {
      "title": "Guides - Android",
      "description": "The Amplify Command Line Interface (CLI) is a unified toolchain to create, integrate, and manage the AWS cloud services for your app. The CLI is category-based with best practices built in.  - Android",
      "disableTOC": "true",
      "filterKey": "platform",
      "category": "Guides"
    },
    "filename": "/guides/q/platform/android"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Amplify guides are meant to give you a more in-depth understanding of how to use the Amplify CLI, libraries, and hosting to build out common functionality, end-to-end solutions, and frequently asked for workflows."
      },
      {
        "heading": "Overview",
        "depth": 3,
        "text": "Like the library and CLI documentation, guides are organized by category (Authentication, Hosting, etc..), but some guides may overlap multiple categories (i.e. Functions & API) to demonstrate how to integrate multiple services together."
      },
      {
        "heading": "Overview",
        "depth": 3,
        "text": "Unlike the library and CLI documentation, guides will often combine the CLI and libraries together in a single tutorial. This is done to teach an end-to-end solution using both the service creation and configuration as well as connecting to and interacting with the service from a client-side application."
      },
      {
        "heading": "Contributing",
        "depth": 3,
        "text": "If there is a guide or idea that you would like to see implemented that is not listed, open a GitHub Issue with the details of the use case and it will be reviewed by our team and considered."
      },
      {
        "heading": "Contributing",
        "depth": 3,
        "text": "If you have an idea for a guide that you'd like to write yourself you can submit a pull request. Before writing the guide and submitting the pull request, submit an issue with the details of your idea and you will receive guidance and feedback."
      }
    ],
    "source": "export const meta = {\n  title: `Guides`,\n  description: `The Amplify Command Line Interface (CLI) is a unified toolchain to create, integrate, and manage the AWS cloud services for your app. The CLI is category-based with best practices built in. `,\n  disableTOC: `true`,\n  filterKey: `platform`,\n};\n\nAmplify guides are meant to give you a more in-depth understanding of how to use the Amplify CLI, libraries, and hosting to build out common functionality, end-to-end solutions, and frequently asked for workflows.\n\n### Overview\n\nLike the library and CLI documentation, guides are organized by category (**Authentication**, **Hosting**, etc..), but some guides may overlap multiple categories (i.e. **Functions** & **API**) to demonstrate how to integrate multiple services together.\n\nUnlike the library and CLI documentation, guides will often combine the CLI and libraries together in a single tutorial. This is done to teach an end-to-end solution using both the service creation and configuration as well as connecting to and interacting with the service from a client-side application.\n\n### Contributing\n\nIf there is a guide or idea that you would like to see implemented that is not listed, open a [GitHub Issue](https://github.com/aws-amplify/docs/issues) with the details of the use case and it will be reviewed by our team and considered.\n\nIf you have an idea for a guide that you'd like to write yourself you can submit a [pull request](https://github.com/aws-amplify/docs/pulls). Before writing the guide and submitting the pull request, submit an [issue](https://github.com/aws-amplify/docs/issues) with the details of your idea and you will receive guidance and feedback.\n",
    "meta": {
      "title": "Guides - JavaScript",
      "description": "The Amplify Command Line Interface (CLI) is a unified toolchain to create, integrate, and manage the AWS cloud services for your app. The CLI is category-based with best practices built in.  - JavaScript",
      "disableTOC": "true",
      "filterKey": "platform",
      "category": "Guides"
    },
    "filename": "/guides/q/platform/js"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Amplify Studio File Storage provides a simple mechanism for managing user content for your app in public, protected or private storage folders. In Studio you can specify authorization rules that limit individual user or group access to create, read, update, or delete operations on your files. The File Storage category comes with built-in support for Amazon S3."
      },
      {
        "heading": null,
        "depth": null,
        "text": ""
      },
      {
        "heading": null,
        "depth": null,
        "text": "There are two ways to add file storage to Amplify Studio - import an existing S3 bucket and create a new S3 bucket. Both methods require the authentication category to also be enabled."
      },
      {
        "heading": "To set the authorization modes on new file storage",
        "depth": 2,
        "text": "When you create new file storage for your app, you can edit authorization rules."
      },
      {
        "heading": "To set the authorization modes on new file storage",
        "depth": 2,
        "text": "Sign in to the AWS Management console and open AWS Amplify."
      },
      {
        "heading": "To set the authorization modes on new file storage",
        "depth": 2,
        "text": "In the navigation pane, choose an application."
      },
      {
        "heading": "To set the authorization modes on new file storage",
        "depth": 2,
        "text": "On the application information page, choose Launch Studio."
      },
      {
        "heading": "To set the authorization modes on new file storage",
        "depth": 2,
        "text": "On the Set up menu, choose Storage."
      },
      {
        "heading": "To set the authorization modes on new file storage",
        "depth": 2,
        "text": "On the Storage page, locate the Authorization settings on the bottom of the File storage bucket card."
      },
      {
        "heading": "To set the authorization modes on new file storage",
        "depth": 2,
        "text": "Select your desired authorization settings for Signed-in users, or Guest users (optional)."
      },
      {
        "heading": "To set the authorization modes on new file storage",
        "depth": 2,
        "text": "The authorization modes can always be edited under Set up, Storage."
      },
      {
        "heading": "To set the authorization modes on new file storage",
        "depth": 2,
        "text": "To enable local development after setting up guest permissions, you must allow unauthenticated logins by updating your auth settings. Learn more"
      },
      {
        "heading": "To import file storage",
        "depth": 2,
        "text": "For default file access levels to work, your bucket needs to be configured accordingly:"
      },
      {
        "heading": "To import file storage",
        "depth": 2,
        "text": "private// - Only accessible for the individual user"
      },
      {
        "heading": "To import file storage",
        "depth": 2,
        "text": "protected// - Readable by all users, writable only by the creating user"
      },
      {
        "heading": "To import file storage",
        "depth": 2,
        "text": "public/ - Accessible by all users of your app"
      },
      {
        "heading": "To import file storage",
        "depth": 2,
        "text": "Learn more about how to import file storage."
      },
      {
        "heading": "To set the authorization mode on imported file storage",
        "depth": 2,
        "text": "If you're using an imported S3 bucket with an imported Cognito resource, then you'll need to update the policy of your Cognito Identity Pool's authenticated and unauthenticated role. You'll need to create new managed policies (not inline policies) for these roles."
      },
      {
        "heading": "To set the authorization mode on imported file storage",
        "depth": 2,
        "text": "Learn more about how to configure IAM roles for imported file storage"
      }
    ],
    "source": "export const meta = {\n  title: `File storage`,\n  description: `Get started with Amplify Studio`,\n};\n\nAmplify Studio File Storage provides a simple mechanism for managing user content for your app in public, protected or private storage folders. In Studio you can specify authorization rules that limit individual user or group access to create, read, update, or delete operations on your files. The File Storage category comes with built-in support for Amazon S3.\n\n![Amplify Studio storage start page](/images/console/storageStart.png)\n\nThere are two ways to add file storage to Amplify Studio - import an existing S3 bucket and create a new S3 bucket. Both methods require the authentication category to also be enabled.\n\n## To set the authorization modes on new file storage\n\nWhen you create new file storage for your app, you can edit authorization rules.\n\n1. Sign in to the AWS Management console and open AWS Amplify.\n2. In the navigation pane, choose an application.\n3. On the application information page, choose **Launch Studio**.\n4. On the **Set up** menu, choose **Storage**.\n5. On the **Storage** page, locate the **Authorization settings** on the bottom of the *File storage bucket* card.\n6. Select your desired authorization settings for **Signed-in users**, or **Guest users** _(optional)_.\n\nThe authorization modes can always be edited under **Set up**, **Storage**.\n\n<Callout warning>\nTo enable local development after setting up guest permissions, you must allow unauthenticated logins by updating your auth settings. <a href='/console/storage/develop'>Learn more</a>\n</Callout>\n\n## To import file storage\n\nFor default file access levels to work, your bucket needs to be configured accordingly:\n\n- **private/{user_identity_id}/** - Only accessible for the individual user\n- **protected/{user_identity_id}/** - Readable by all users, writable only by the creating user\n- **public/** - Accessible by all users of your app\n\n[Learn more about how to import file storage.](https://docs.amplify.aws/cli/storage/import/#connect-to-an-imported-s3-bucket-with-amplify-libraries)\n\n## To set the authorization mode on imported file storage\n\nIf you're using an imported S3 bucket with an imported Cognito resource, then you'll need to update the policy of your Cognito Identity Pool's authenticated and unauthenticated role. You'll need to create new managed policies (not inline policies) for these roles.\n\n[Learn more about how to configure IAM roles for imported file storage](https://docs.amplify.aws/cli/storage/import/#configuring-iam-role-to-use-amplify-recommended-policies)\n",
    "meta": {
      "title": "File storage",
      "description": "Get started with Amplify Studio",
      "subcategory": "Storage",
      "category": "Amplify Studio"
    },
    "filename": "/console/storage/file-storage"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Amplify Studio's File browser provides a view of the backend file storage for an application. You can use this feature to test your files and to provide both technical and non-technical team members with the ability to create and update an application's files in real-time instead of building admin views."
      },
      {
        "heading": null,
        "depth": null,
        "text": ""
      },
      {
        "heading": null,
        "depth": null,
        "text": "By default, your storage is created with the following 4 folders:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "private/ - Files here are nested under the user whom owns the file. Only the file owner can access or edit the files."
      },
      {
        "heading": null,
        "depth": null,
        "text": "protected/ - Files here are nested under the user whom owns the file. These files are accessible by all users, but editable only by the file owner."
      },
      {
        "heading": null,
        "depth": null,
        "text": "public/ - Files in here are accessible by all users of your app."
      },
      {
        "heading": null,
        "depth": null,
        "text": "upload/ - Contains files that were uploaded by users. Only the bucket owner has access to these files."
      },
      {
        "heading": "To upload a file",
        "depth": 2,
        "text": "Open Amplify Studio for an app."
      },
      {
        "heading": "To upload a file",
        "depth": 2,
        "text": "On the Manage menu, choose File browser."
      },
      {
        "heading": "To upload a file",
        "depth": 2,
        "text": "On the File browser page, select the folder you want to upload your file to."
      },
      {
        "heading": "To upload a file",
        "depth": 2,
        "text": "There are several ways to upload a file:"
      },
      {
        "heading": "To upload a file",
        "depth": 2,
        "text": "Select Upload, and select a file to upload."
      },
      {
        "heading": "To upload a file",
        "depth": 2,
        "text": "Drag and drop a file or folder onto the Studio file browser page."
      },
      {
        "heading": "To delete a file",
        "depth": 2,
        "text": "Open Amplify Studio for an app."
      },
      {
        "heading": "To delete a file",
        "depth": 2,
        "text": "On the Manage menu, choose File browser."
      },
      {
        "heading": "To delete a file",
        "depth": 2,
        "text": "On the File browser page, select the folder you want to delete your file from."
      },
      {
        "heading": "To delete a file",
        "depth": 2,
        "text": "Select the file you want to delete."
      },
      {
        "heading": "To delete a file",
        "depth": 2,
        "text": "Select the Actions dropdown and then select Delete."
      },
      {
        "heading": "To copy a file",
        "depth": 2,
        "text": "Open Amplify Studio for an app."
      },
      {
        "heading": "To copy a file",
        "depth": 2,
        "text": "On the Manage menu, choose File browser."
      },
      {
        "heading": "To copy a file",
        "depth": 2,
        "text": "On the File browser page, select the folder you want to delete your file from."
      },
      {
        "heading": "To copy a file",
        "depth": 2,
        "text": "Select the file you want to move."
      },
      {
        "heading": "To copy a file",
        "depth": 2,
        "text": "Select the Actions dropdown and then select Copy to."
      },
      {
        "heading": "To copy a file",
        "depth": 2,
        "text": "Select or create the folder you want a copy of your file to be saved to."
      },
      {
        "heading": "To copy a file",
        "depth": 2,
        "text": "Select Copy to copy your file to the selected folder."
      },
      {
        "heading": "To move a file",
        "depth": 2,
        "text": "Open Amplify Studio for an app."
      },
      {
        "heading": "To move a file",
        "depth": 2,
        "text": "On the Manage menu, choose File browser."
      },
      {
        "heading": "To move a file",
        "depth": 2,
        "text": "On the File browser page, select the folder you want to delete your file from."
      },
      {
        "heading": "To move a file",
        "depth": 2,
        "text": "Select the file you want to move."
      },
      {
        "heading": "To move a file",
        "depth": 2,
        "text": "Select the Actions dropdown and then select Move."
      },
      {
        "heading": "To move a file",
        "depth": 2,
        "text": "Select or create the folder you want to move your to."
      },
      {
        "heading": "To move a file",
        "depth": 2,
        "text": "Select Move to move your file to the selected folder."
      },
      {
        "heading": "To test your files",
        "depth": 2,
        "text": "We've provided several shortcuts to test your files in your code."
      },
      {
        "heading": "Copy S3 key",
        "depth": 3,
        "text": "You can copy your file's S3 key either by:"
      },
      {
        "heading": "Copy S3 key",
        "depth": 3,
        "text": "Selecting Actions, and then Copy S3 key."
      },
      {
        "heading": "Copy S3 key",
        "depth": 3,
        "text": "Selecting the copy icon next to your S3 key in the right-hand inspector panel."
      },
      {
        "heading": "Copy get file code snippet",
        "depth": 3,
        "text": "We've provided code snippets for 'get file' in all Amplify supported languages in a code block in the right-hand inspector panel"
      },
      {
        "heading": "Copy object URL",
        "depth": 3,
        "text": "You can copy your file's object URL by Selecting the copy icon next to your object URL in the right-hand inspector panel"
      }
    ],
    "source": "export const meta = {\n  title: `File browser`,\n  description: `Get started with Amplify Studio`,\n};\n\nAmplify Studio's **File browser** provides a view of the backend file storage for an application. You can use this feature to test your files and to provide both technical and non-technical team members with the ability to create and update an application's files in real-time instead of building admin views.\n\n![Amplify Studio file browser](/images/console/fileBrowser.png)\n\nBy default, your storage is created with the following 4 folders:\n\n- **private/** - Files here are nested under the user whom owns the file. Only the file owner can access or edit the files.\n- **protected/** - Files here are nested under the user whom owns the file. These files are accessible by all users, but editable only by the file owner.\n- **public/** - Files in here are accessible by all users of your app.\n- **upload/** - Contains files that were uploaded by users. Only the bucket owner has access to these files.\n\n## To upload a file\n1. Open Amplify Studio for an app.\n2. On the **Manage** menu, choose **File browser**.\n3. On the **File browser** page, select the folder you want to upload your file to.\n4. There are several ways to upload a file:\n    - Select **Upload**, and select a file to upload.\n    - Drag and drop a file or folder onto the Studio file browser page.\n\n## To delete a file\n1. Open Amplify Studio for an app.\n2. On the **Manage** menu, choose **File browser**.\n3. On the **File browser** page, select the folder you want to delete your file from.\n4. Select the file you want to delete.\n5. Select the **Actions** dropdown and then select **Delete**.\n\n## To copy a file\n1. Open Amplify Studio for an app.\n2. On the **Manage** menu, choose **File browser**.\n3. On the **File browser** page, select the folder you want to delete your file from.\n4. Select the file you want to move.\n5. Select the **Actions** dropdown and then select **Copy to**.\n6. Select or create the folder you want a copy of your file to be saved to.\n7. Select **Copy** to copy your file to the selected folder.\n\n## To move a file\n1. Open Amplify Studio for an app.\n2. On the **Manage** menu, choose **File browser**.\n3. On the **File browser** page, select the folder you want to delete your file from.\n4. Select the file you want to move.\n5. Select the **Actions** dropdown and then select **Move**.\n6. Select or create the folder you want to move your to.\n7. Select **Move** to move your file to the selected folder.\n\n## To test your files\nWe've provided several shortcuts to test your files in your code.\n\n### Copy S3 key\nYou can copy your file's S3 key either by:\n- Selecting **Actions**, and then **Copy S3 key**.\n- Selecting the copy icon next to your S3 key in the right-hand inspector panel.\n\n### Copy get file code snippet\nWe've provided code snippets for 'get file' in all Amplify supported languages in a code block in the right-hand inspector panel\n\n### Copy object URL\nYou can copy your file's object URL by Selecting the copy icon next to your object URL in the right-hand inspector panel\n",
    "meta": {
      "title": "File browser",
      "description": "Get started with Amplify Studio",
      "subcategory": "Storage",
      "category": "Amplify Studio"
    },
    "filename": "/console/storage/file-browser"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Clone the example data model to follow along."
      },
      {
        "heading": null,
        "depth": null,
        "text": "We are going to define set up role-based authorization rules for each of the models that we created for our bookstore example. Authorization rules help in restricting who can query or update a table based on certain conditions."
      },
      {
        "heading": "To set an owner authorization rule",
        "depth": 2,
        "text": "Using the Books data model that we created in the Create a data model example, set the authorization mode to Cognito user pool."
      },
      {
        "heading": "To set an owner authorization rule",
        "depth": 2,
        "text": "In the Model pane on the right, expand the Owners window."
      },
      {
        "heading": "To set an owner authorization rule",
        "depth": 2,
        "text": "Choose Create, Read, Update and Delete to specify that Owners have create, read, update, and delete access. The settings look as follows."
      },
      {
        "heading": "To set an owner authorization rule",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "To set a private authorization rule",
        "depth": 2,
        "text": "Using the Books data model that we created in the Create a data model example, set the authorization mode to Cognito user pool."
      },
      {
        "heading": "To set a private authorization rule",
        "depth": 2,
        "text": "In the Model pane on the right, expand the Any signed-in users window."
      },
      {
        "heading": "To set a private authorization rule",
        "depth": 2,
        "text": "Choose Create, Read, and Update to specify that any signed-in authenticated user has create, read, and update, access. The settings look as follows."
      },
      {
        "heading": "To set a private authorization rule",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "To set a group authorization rule",
        "depth": 2,
        "text": "Using the Books data model that we created in the Create a data model example, set the authorization mode to Cognito user pool."
      },
      {
        "heading": "To set a group authorization rule",
        "depth": 2,
        "text": "Create an Editors group using the instructions to create a group. Alternately, you can create a new group from the Add a new rule for... menu."
      },
      {
        "heading": "To set a group authorization rule",
        "depth": 2,
        "text": "In the Model pane on the right, select Editors from the Add a new rule for... menu."
      },
      {
        "heading": "To set a group authorization rule",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "To set a group authorization rule",
        "depth": 2,
        "text": "Choose Create, Read, Update and Delete to specify that signed in users in the Editors group have create, read, update, and delete access. The settings look as follows."
      },
      {
        "heading": "To set a group authorization rule",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "To set a public authorization rule",
        "depth": 2,
        "text": "If you want your data model to be publicly accessible, switch to API_KEY or IAM based authorization."
      },
      {
        "heading": "To set a public authorization rule",
        "depth": 2,
        "text": "Using the Books data model that we created in the Create a data model example, set the authorization mode to API Key."
      },
      {
        "heading": "To set a public authorization rule",
        "depth": 2,
        "text": "In the Model pane on the right, expand the Anyone window. Choose Read to specify that any signed in user has read access to the data in the Book model. The settings look as follows."
      },
      {
        "heading": "To set a public authorization rule",
        "depth": 2,
        "text": ""
      }
    ],
    "source": "export const meta = {\n  title: `Access control`,\n  description: `Set up authorization rules`,\n};\n\n<Callout warning>\n\nClone the [example data model](/console/data/data-model#data-modeling-example) to follow along.\n\n</Callout>\n\nWe are going to define set up role-based authorization rules for each of the models that we created for our bookstore example. Authorization rules help in restricting who can query or update a table based on certain conditions. \n\n## To set an owner authorization rule\n1. Using the *Books* data model that we created in the [Create a data model example](/console/data/data-model#Create-a-data-model-example), set the authorization mode to **Cognito user pool**. \n2. In the **Model** pane on the right, expand the **Owners** window. \n3. Choose **Create**, **Read**, **Update** and **Delete** to specify that *Owners* have create, read, update, and delete access. The settings look as follows.\n\n![GSA](/images/console/10_ownersaccess.png)\n\n## To set a private authorization rule\n1. Using the *Books* data model that we created in the [Create a data model example](/console/data/data-model#Create-a-data-model-example), set the authorization mode to **Cognito user pool**. \n2. In the **Model** pane on the right, expand the **Any signed-in users** window. \n3. Choose **Create**, **Read**, and **Update** to specify that any signed-in authenticated user has create, read, and update, access. The settings look as follows.\n\n![GSA](/images/console/11_privatesaccess.png)\n\n\n## To set a group authorization rule\n1. Using the *Books* data model that we created in the [Create a data model example](/console/data/data-model#Create-a-data-model-example), set the authorization mode to **Cognito user pool**. \n2. Create an *Editors* group using the instructions to [create a group](/console/auth/user-management#To-create-a-group). Alternately, you can create a new group from the **Add a new rule for...** menu.\n3. In the **Model** pane on the right, select *Editors* from the **Add a new rule for...** menu. \n\n![GSA](/images/console/8_menudetaileditors.png)\n\n4. Choose **Create**, **Read**, **Update** and **Delete** to specify that signed in users in the *Editors* group have create, read, update, and delete access. The settings look as follows.\n\n![GSA](/images/console/9_editorgroupaccess.png)\n\n## To set a public authorization rule\n\nIf you want your data model to be publicly accessible, switch to API_KEY or IAM based authorization.\n\n1. Using the *Books* data model that we created in the [Create a data model example](/console/data/data-model#Create-a-data-model-example), set the authorization mode to **API Key**. \n2. In the **Model** pane on the right, expand the **Anyone** window. Choose **Read** to specify that any signed in user has read access to the data in the *Book* model. The settings look as follows.\n\n![GSA](/images/console/7_publicauthreadonly.png)",
    "meta": {
      "title": "Access control",
      "description": "Set up authorization rules",
      "subcategory": "Authorization",
      "category": "Amplify Studio"
    },
    "filename": "/console/authz/permissions"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Authorization is the process of validating what a user can access. In Amplify Studio you can specify authorization rules that limit individual user or group access to create, read, update, or delete operations on your data. Amplify Studio supports owner, public, private, and group based authorization at the model level. When an authorization directive is added to a type, all fields of the type are made available to that mode by default."
      },
      {
        "heading": "To set the authorization mode",
        "depth": 2,
        "text": "As you create a data model for your app, you can use the Inspector Panel on the right side of the Data modeling page to set authorization rules."
      },
      {
        "heading": "To set the authorization mode",
        "depth": 2,
        "text": "Sign in to the AWS Management console and open AWS Amplify."
      },
      {
        "heading": "To set the authorization mode",
        "depth": 2,
        "text": "In the navigation pane, choose an application."
      },
      {
        "heading": "To set the authorization mode",
        "depth": 2,
        "text": "On the application information page, choose the Backend environments tab, then choose Launch Studio."
      },
      {
        "heading": "To set the authorization mode",
        "depth": 2,
        "text": "On the Set up menu, choose Data."
      },
      {
        "heading": "To set the authorization mode",
        "depth": 2,
        "text": "On the Data modeling page, locate the Authorization mode menu in the upper right corner."
      },
      {
        "heading": "To set the authorization mode",
        "depth": 2,
        "text": "Choose one of API Key, Cognito user pool, or IAM."
      },
      {
        "heading": "To set the authorization mode",
        "depth": 2,
        "text": "Skip ahead to set up authorization rules for the bookstore app, or learn about the different authorization modes below."
      },
      {
        "heading": "Authorization modes",
        "depth": 2,
        "text": "The type of authorization rules that you are able to set depends on the authorization mode that you specify. There are three available authorization modes - API_KEY, Cognito User pools, and IAM."
      },
      {
        "heading": "API Key",
        "depth": 3,
        "text": "The API key is the default authorization mode when you first deploy a data model. API Keys are recommended for development purposes or use cases where it is safe to provide public access to an API without specific authentication requirements (i.e. guest users). It is recommended to use API keys when you are getting started with the API development, want to iterate quickly, and don’t want to worry about more complicated authorization methods. Applications expected to be long-lived and widely distributed should not use API keys unless you have use cases where all or part of the application will always support guest access. API keys are valid for 30 days before they need to be rotated."
      },
      {
        "heading": "Cognito user pool",
        "depth": 3,
        "text": "Amplify Authentication is powered by Amazon Cognito User Pools, a fully managed user directory. This the preferred authorization mode with Amplify as it provides finer grained access to your models - scope access to any signed-in user, groups, and owners. Cognito provides a secure way to exchange JWT tokens from User Pools with temporary AWS credentials that allow you to interact with other AWS services."
      },
      {
        "heading": "IAM",
        "depth": 3,
        "text": "With the IAM authorization mode, requests are signed using the AWS Signature Version 4 Signing Process. The IAM public authorization mode is primarily used when your application needs to provide guest (public) access to your data. Guest access is accomplished with IAM using Amazon Cognito Identity Pools unauthenticated identities. The IAM private authorization mode is a great fit when used with backend systems (e.g.: Amazon EC2 instances or AWS Lambda) that can be securely configured with AWS credentials."
      }
    ],
    "source": "export const meta = {\n  title: `Overview`,\n  description: `Get started with Amplify Studio`,\n};\n\nAuthorization is the process of validating what a user can access. In Amplify Studio you can specify authorization rules that limit individual user or group access to create, read, update, or delete operations on your data. Amplify Studio supports owner, public, private, and group based authorization at the model level. When an authorization directive is added to a type, all fields of the type are made available to that mode by default.\n\n## To set the authorization mode\n\nAs you create a data model for your app, you can use the **Inspector Panel** on the right side of the **Data modeling** page to set authorization rules.\n\n1. Sign in to the AWS Management console and open AWS Amplify.\n2. In the navigation pane, choose an application.\n3. On the application information page, choose the **Backend environments** tab, then choose **Launch Studio**.\n4. On the **Set up** menu, choose **Data**.\n5. On the **Data modeling** page, locate the **Authorization mode** menu in the upper right corner.\n6. Choose one of **API Key**, **Cognito user pool**, or **IAM**.\n\nSkip ahead to [set up authorization rules](/console/authz/permissions) for the bookstore app, or learn about the different authorization modes below.\n\n## Authorization modes\n\nThe type of authorization rules that you are able to set depends on the authorization mode that you specify. There are three available authorization modes - API_KEY, Cognito User pools, and IAM. \n\n### API Key\n\nThe API key is the default authorization mode when you first deploy a data model. API Keys are recommended for development purposes or use cases where it is safe to provide public access to an API without specific authentication requirements (i.e. guest users). It is recommended to use API keys when you are getting started with the API development, want to iterate quickly, and don’t want to worry about more complicated authorization methods. Applications expected to be long-lived and widely distributed should not use API keys unless you have use cases where all or part of the application will always support guest access. API keys are valid for 30 days before they need to be rotated.\n\n### Cognito user pool\n\nAmplify Authentication is powered by Amazon Cognito User Pools, a fully managed user directory. This the preferred authorization mode with Amplify as it provides finer grained access to your models - scope access to any signed-in user, groups, and owners. Cognito provides a secure way to exchange JWT tokens from User Pools with temporary AWS credentials that allow you to interact with other AWS services. \n\n### IAM\n\nWith the IAM authorization mode, requests are signed using the AWS Signature Version 4 Signing Process. The IAM public authorization mode is primarily used when your application needs to provide guest (public) access to your data. Guest access is accomplished with IAM using Amazon Cognito Identity Pools unauthenticated identities. The IAM private authorization mode is a great fit when used with backend systems (e.g.: Amazon EC2 instances or AWS Lambda) that can be securely configured with AWS credentials. ",
    "meta": {
      "title": "Overview",
      "description": "Get started with Amplify Studio",
      "subcategory": "Authorization",
      "category": "Amplify Studio"
    },
    "filename": "/console/authz/authorization"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "You can import existing Amazon Cognito resources into your Amplify project using Amplify Studio. To get started, choose Authentication from the Set up menu in your app's Studio. On the Authentication page, choose Reuse existing Amazon Cognito resources."
      },
      {
        "heading": null,
        "depth": null,
        "text": "This feature is particularly useful if you’re trying to do the following:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Authorize user access to fields/tables in Amplify Studio's data model"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Manage users and groups from Amplify Studio (instead of having to login to the AWS console)"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Reuse the imported auth resource across Amplify environments"
      },
      {
        "heading": "Import an existing Cognito user pool",
        "depth": 2,
        "text": "To successfully import your user pool, your user pools require at least two app clients with the following conditions:"
      },
      {
        "heading": "Import an existing Cognito user pool",
        "depth": 2,
        "text": "At least one “Web app client”: an app client without a client secret"
      },
      {
        "heading": "Import an existing Cognito user pool",
        "depth": 2,
        "text": "At least one “Native app client“: an app client with a client secret"
      },
      {
        "heading": "Import an existing Cognito user pool",
        "depth": 2,
        "text": "The client secret is used by applications that have a server-side component that secure the client secret, which is why the native app client needs one."
      },
      {
        "heading": "Import an existing Cognito user pool",
        "depth": 2,
        "text": "To complete the import procedure, run the amplify push command."
      },
      {
        "heading": "Import an existing Cognito user pool",
        "depth": 2,
        "text": "Learn more about getting started with User Pools\nor\nconfiguring a User Pool App Client"
      },
      {
        "heading": "Import an existing identity pool",
        "depth": 2,
        "text": "In order to successfully import your identity pool, it must have both of the user pool app clients must meet the following requirements:"
      },
      {
        "heading": "Import an existing identity pool",
        "depth": 2,
        "text": "An Authenticated Role with a trust relationship to your identity pool"
      },
      {
        "heading": "Import an existing identity pool",
        "depth": 2,
        "text": "An optional Unauthenticated Role if you want to use any guest user access for your Amplify categories (For example, guest access for your Amazon S3 buckets or REST API endpoints)."
      },
      {
        "heading": "Import an existing identity pool",
        "depth": 2,
        "text": "These roles are usually automatically configured when you create a new identity pool enabling “Unauthenticated” access and have an Amazon Cognito user pool as an authentication provider."
      },
      {
        "heading": "Import an existing identity pool",
        "depth": 2,
        "text": "Learn more about getting started with Identity Pools."
      },
      {
        "heading": "Import and update your source code",
        "depth": 2,
        "text": "Choose Import on the bottom of the page to complete the import procedure. Update your source code by running the following command:"
      },
      {
        "heading": "Import and update your source code",
        "depth": 2,
        "text": "Next, generate the necessary GraphQL files by running the following command:"
      },
      {
        "heading": "Import and update your source code",
        "depth": 2,
        "text": "After running this command, the following occurs:"
      },
      {
        "heading": "Import and update your source code",
        "depth": 2,
        "text": "Your Amplify Library configuration files (aws-exports.js, amplifyconfiguration.json) are automatically populated with your chosen Amazon Cognito resource information"
      },
      {
        "heading": "Import and update your source code",
        "depth": 2,
        "text": "Your designated existing Amazon Cognito resource is provided as the authentication and authorization mechanism for all auth-dependent categories (API, Storage and more)"
      },
      {
        "heading": "Import and update your source code",
        "depth": 2,
        "text": "Lambda functions are enabled to access the chosen Amazon Cognito resource if you permit it."
      },
      {
        "heading": "Multi-environment support",
        "depth": 2,
        "text": "When you clone an environment or create a new one, you’ll be required to import your Amazon Cognito resources."
      },
      {
        "heading": "Multi-environment support",
        "depth": 2,
        "text": "If you want to have Amplify manage your authorization resources in a new environment, unlink the imported Cognito resource and add authorization to your new environment. This will create new Amplify-managed authorization resources in the new environment."
      },
      {
        "heading": "Unlink an existing Amazon Cognito user pool or identity pool",
        "depth": 2,
        "text": "In order to unlink your existing Amazon Cognito resource, click Unlink Cognito User Pool and Identity Pool on the bottom of the Authentication page and follow the prompt to confirm this action. This only unlinks the Amazon Cognito resource referenced from the Amplify project. It does not delete the Amazon Cognito resource itself."
      }
    ],
    "source": "export const meta = {\n  title: `Import Amazon Cognito resources`,\n  description: `Configure Amplify Studio to use existing Amazon Cognito user pool and identity pool resources as an authentication and authorization mechanism for other Amplify categories ( For example, API, Storage, and more).`,\n};\n\nYou can import existing Amazon Cognito resources into your Amplify project using Amplify Studio. To get started, choose **Authentication** from the **Set up** menu in your app's Studio. On the **Authentication** page, choose **Reuse existing Amazon Cognito resources**.\n\nThis feature is particularly useful if you’re trying to do the following:\n\n- Authorize user access to fields/tables in Amplify Studio's data model\n- Manage users and groups from Amplify Studio (instead of having to login to the AWS console)\n- Reuse the imported auth resource across Amplify environments\n\n## Import an existing Cognito user pool\nTo successfully import your user pool, your user pools require at least two app clients with the following conditions:\n\n- At least one “Web app client”: an app client without a client secret\n- At least one “Native app client“: an app client with a client secret\n\nThe client secret is used by applications that have a server-side component that secure the client secret, which is why the native app client needs one.\n\nTo complete the import procedure, run the `amplify push` command.\n\n[Learn more about getting started with User Pools](https://docs.aws.amazon.com/cognito/latest/developerguide/getting-started-with-cognito-user-pools.html)\nor \n[configuring a User Pool App Client](https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-settings-client-apps.html)\n\n## Import an existing identity pool\nIn order to successfully import your identity pool, it must have both of the user pool app clients must meet the following requirements:\n\n- An Authenticated Role with a trust relationship to your identity pool\n- An optional Unauthenticated Role if you want to use any guest user access for your Amplify categories (For example, guest access for your Amazon S3 buckets or REST API endpoints).\n\nThese roles are usually automatically configured when you create a new identity pool enabling “Unauthenticated” access and have an Amazon Cognito user pool as an authentication provider.\n\n[Learn more about getting started with Identity Pools.](https://docs.aws.amazon.com/cognito/latest/developerguide/getting-started-with-identity-pools.html)\n\n## Import and update your source code\n\nChoose **Import** on the bottom of the page to complete the import procedure. Update your source code by running the following command: \n```bash\namplify pull\n```\nNext, generate the necessary GraphQL files by running the following command:\n```bash\namplify codegen add\n```\n\nAfter running this command, the following occurs:\n- Your Amplify Library configuration files (aws-exports.js, amplifyconfiguration.json) are automatically populated with your chosen Amazon Cognito resource information\n- Your designated existing Amazon Cognito resource is provided as the authentication and authorization mechanism for all auth-dependent categories (API, Storage and more)\n- Lambda functions are enabled to access the chosen Amazon Cognito resource if you permit it.\n\n## Multi-environment support\nWhen you clone an environment or create a new one, you’ll be required to import your Amazon Cognito resources.\n\nIf you want to have Amplify manage your authorization resources in a new environment, unlink the imported Cognito resource and add authorization to your new environment. This will create new Amplify-managed authorization resources in the new environment.\n  \n## Unlink an existing Amazon Cognito user pool or identity pool\nIn order to unlink your existing Amazon Cognito resource, click **Unlink Cognito User Pool and Identity Pool** on the bottom of the **Authentication** page and follow the prompt to confirm this action. This only unlinks the Amazon Cognito resource referenced from the Amplify project. It does not delete the Amazon Cognito resource itself.\n",
    "meta": {
      "title": "Import Amazon Cognito resources",
      "description": "Configure Amplify Studio to use existing Amazon Cognito user pool and identity pool resources as an authentication and authorization mechanism for other Amplify categories ( For example, API, Storage, and more).",
      "subcategory": "Authentication",
      "category": "Amplify Studio"
    },
    "filename": "/console/auth/import"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In Amplify Studio, you can create and manage users and groups, edit user attributes, and suspend users."
      },
      {
        "heading": null,
        "depth": null,
        "text": "This topic shows you how to create and manage your app's users and groups. To set authorization rules that allow these users and groups to perform create, read, update, or delete operations on your app data, see Authorization."
      },
      {
        "heading": "To create a user",
        "depth": 2,
        "text": "Open Studio for an app."
      },
      {
        "heading": "To create a user",
        "depth": 2,
        "text": "On the Manage menu, choose User management."
      },
      {
        "heading": "To create a user",
        "depth": 2,
        "text": "On the User management page, choose the Users tab and then choose Create user."
      },
      {
        "heading": "To create a user",
        "depth": 2,
        "text": "In the Create user window, for Unique identifier enter a username, email address, or phone number. For Temporary password enter a password."
      },
      {
        "heading": "To create a user",
        "depth": 2,
        "text": "Choose Create user."
      },
      {
        "heading": "To modify access for a user",
        "depth": 2,
        "text": "Open Studio for an app."
      },
      {
        "heading": "To modify access for a user",
        "depth": 2,
        "text": "On the Manage menu, choose User management."
      },
      {
        "heading": "To modify access for a user",
        "depth": 2,
        "text": "On the User management page, choose the Users tab."
      },
      {
        "heading": "To modify access for a user",
        "depth": 2,
        "text": "Select the name of the user to manage."
      },
      {
        "heading": "To modify access for a user",
        "depth": 2,
        "text": "On the Actions menu, choose the action to perform on the user. The options are Reset password, Delete, Suspend, or Reactivate."
      },
      {
        "heading": "To modify access for a user",
        "depth": 2,
        "text": "For each menu option, a confirmation window is displayed. Follow the instructions in the confirmation window to complete the action on the user."
      },
      {
        "heading": "To create a group",
        "depth": 2,
        "text": "Open Studio for an app."
      },
      {
        "heading": "To create a group",
        "depth": 2,
        "text": "On the Manage menu, choose User management."
      },
      {
        "heading": "To create a group",
        "depth": 2,
        "text": "On the User management page, choose the Groups tab and then choose Create group."
      },
      {
        "heading": "To create a group",
        "depth": 2,
        "text": "In the Create group window, for Title enter a name for the group."
      },
      {
        "heading": "To create a group",
        "depth": 2,
        "text": "Choose Create group."
      },
      {
        "heading": "To add a user to a group",
        "depth": 2,
        "text": "Open Studio for an app."
      },
      {
        "heading": "To add a user to a group",
        "depth": 2,
        "text": "On the Manage menu, choose User management."
      },
      {
        "heading": "To add a user to a group",
        "depth": 2,
        "text": "On the User management page, choose the Groups tab."
      },
      {
        "heading": "To add a user to a group",
        "depth": 2,
        "text": "Select the name of the group to add users to."
      },
      {
        "heading": "To add a user to a group",
        "depth": 2,
        "text": "Choose Add user(s)."
      },
      {
        "heading": "To add a user to a group",
        "depth": 2,
        "text": "In the Add users to group window, choose how you want to search for users to add from the Search menu. You can choose Email, Phone number, or Username."
      },
      {
        "heading": "To add a user to a group",
        "depth": 2,
        "text": "Choose one user or multiple users to add to the group and then choose Add users."
      },
      {
        "heading": "To delete a group",
        "depth": 2,
        "text": "Open Studio for an app."
      },
      {
        "heading": "To delete a group",
        "depth": 2,
        "text": "On the Manage menu, choose User management."
      },
      {
        "heading": "To delete a group",
        "depth": 2,
        "text": "On the User management page, choose the Groups tab."
      },
      {
        "heading": "To delete a group",
        "depth": 2,
        "text": "In the Groups section, select the name of the group to delete."
      },
      {
        "heading": "To delete a group",
        "depth": 2,
        "text": "Choose Delete."
      },
      {
        "heading": "To delete a group",
        "depth": 2,
        "text": "A confirmation window is displayed. Enter Delete and choose, Confirm deletion."
      }
    ],
    "source": "export const meta = {\n  title: `Manage authentication for users and groups`,\n  description: `Manage authentication for users and groups`,\n};\n\nIn Amplify Studio, you can create and manage users and groups, edit user attributes, and suspend users.\n\nThis topic shows you how to create and manage your app's users and groups. To set authorization rules that allow these users and groups to perform create, read, update, or delete operations on your app data, see [Authorization](/console/authz/authorization).\n\n## To create a user\n1. Open Studio for an app.\n2. On the **Manage** menu, choose **User management**.\n3. On the **User management** page, choose the **Users** tab and then choose **Create user**.\n4. In the **Create user** window, for **Unique identifier** enter a username, email address, or phone number. For **Temporary password** enter a password.\n5. Choose **Create user**.\n\n## To modify access for a user\n1. Open Studio for an app.\n2. On the **Manage** menu, choose **User management**.\n3. On the **User management** page, choose the **Users** tab.\n4. Select the name of the user to manage.\n5. On the **Actions** menu, choose the action to perform on the user. The options are **Reset password**, **Delete**, **Suspend**, or **Reactivate**.\n6. For each menu option, a confirmation window is displayed. Follow the instructions in the confirmation window to complete the action on the user. \n\n## To create a group\n1. Open Studio for an app.\n2. On the **Manage** menu, choose **User management**. \n3. On the **User management** page, choose the **Groups** tab and then choose **Create group**.\n4. In the **Create group** window, for **Title** enter a name for the group.\n5. Choose **Create group**.\n\n## To add a user to a group\n1. Open Studio for an app.\n2. On the **Manage** menu, choose **User management**. \n3. On the **User management** page, choose the **Groups** tab.\n4. Select the name of the group to add users to.\n5. Choose **Add user(s)**.\n6. In the **Add users to group** window, choose how you want to search for users to add from the **Search** menu. You can choose *Email*, *Phone number*, or *Username*.\n7. Choose one user or multiple users to add to the group and then choose **Add users**.\n\n## To delete a group\n1. Open Studio for an app.\n2. On the **Manage** menu, choose **User management**. \n3. On the **User management** page, choose the **Groups** tab.\n4. In the **Groups** section, select the name of the group to delete.\n5. Choose **Delete**.\n6. A confirmation window is displayed. Enter *Delete* and choose, **Confirm deletion**.\n\n",
    "meta": {
      "title": "Manage authentication for users and groups",
      "description": "Manage authentication for users and groups",
      "subcategory": "Authentication",
      "category": "Amplify Studio"
    },
    "filename": "/console/auth/user-management"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Authentication is the process of verifying the identity of a user. Writing the code for an application's login flow can be difficult and time consuming. In Amplify Studio, you can easily add a complete Amazon Cognito authentication solution to your app. You simply specify the log-in method, such as email and password, Amazon, Google, Facebook, or Sign in with Apple, and you are provided with the authentication UI component for the entire authentication flow."
      },
      {
        "heading": null,
        "depth": null,
        "text": "If you choose to add one of the social sign-in login mechanisms, you will also need to specify an app ID, app secret, and redirect URIs. To learn more about how social sign-in works, see Social sign-in (OAuth)."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Multi-factor authentication (MFA) increases security for your app by adding an authentication method and not relying solely on the username and password. AWS Amplify uses Amazon Cognito to provide MFA. To learn more, see Multi-factor authentication."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Note that you must configure and deploy authentication for your application before you can create users and groups or apply authorization rules to your data models."
      },
      {
        "heading": "To configure how users log in to an app",
        "depth": 2,
        "text": "Sign in to the AWS Management console and open AWS Amplify."
      },
      {
        "heading": "To configure how users log in to an app",
        "depth": 2,
        "text": "In the navigation pane, choose an application."
      },
      {
        "heading": "To configure how users log in to an app",
        "depth": 2,
        "text": "On the application information page, choose the Backend environments tab, then choose Launch Studio."
      },
      {
        "heading": "To configure how users log in to an app",
        "depth": 2,
        "text": "On the Set up menu, choose Authentication."
      },
      {
        "heading": "To configure how users log in to an app",
        "depth": 2,
        "text": "In the Configure log in section, choose a login mechanism to add from the Add login mechanism list. Valid options are Username, Phone number, Facebook, Google, Amazon, and Sign in with Apple. If you choose one of the social sign-in mechanisms, Facebook, Google, Amazon, or Sign in with Apple you will also need to enter your App ID, App Secret, and redirect URLs."
      },
      {
        "heading": "To configure how users log in to an app",
        "depth": 2,
        "text": "(Optional) Add multi-factor authentication (MFA).  MFA is set to Off by default. To turn on MFA, do the following in the Multi-factor authentication section:"
      },
      {
        "heading": "To configure how users log in to an app",
        "depth": 2,
        "text": "Choose Enforced to require MFA for all users or choose Optional to allow individual users to enable MFA."
      },
      {
        "heading": "To configure how users log in to an app",
        "depth": 2,
        "text": "(Optional) Choose SMS, and enter your SMS message."
      },
      {
        "heading": "To configure how users log in to an app",
        "depth": 2,
        "text": "(Optional) Choose Authenticator Application if you want your app to load with an authentication flow that includes sign up and sign in."
      },
      {
        "heading": "To configure how users log in to an app",
        "depth": 2,
        "text": "In the Configure sign up section, expand Password protection settings and customize the password policy settings to enforce.\nu6. Choose Save and Deploy. This starts a CloudFormation deployment with the progress displayed in the upper right corner of the page."
      },
      {
        "heading": "To configure how users log in to an app",
        "depth": 2,
        "text": "Login mechanism settings, and sign up settings can't be changed after you deploy authentication. To change these settings, you must first delete the deployed authentication and then create and deploy new settings. You can, however, add new login mechanisms, add multi-factor authentication, and update the password protection settings."
      },
      {
        "heading": "To reset authentication configuration settings",
        "depth": 2,
        "text": "Sign in to the AWS Management console and open AWS Amplify."
      },
      {
        "heading": "To reset authentication configuration settings",
        "depth": 2,
        "text": "In the navigation pane, choose an application."
      },
      {
        "heading": "To reset authentication configuration settings",
        "depth": 2,
        "text": "On the application information page, choose the Backend environments tab, then choose Launch Studio."
      },
      {
        "heading": "To reset authentication configuration settings",
        "depth": 2,
        "text": "On the Set up menu, choose Authentication."
      },
      {
        "heading": "To reset authentication configuration settings",
        "depth": 2,
        "text": "At the end of the Authentication page, choose Reset all authentication settings and users."
      },
      {
        "heading": "To reset authentication configuration settings",
        "depth": 2,
        "text": "In the Delete authentication confirmation window, choose Delete all authentication rules."
      },
      {
        "heading": "To reset authentication configuration settings",
        "depth": 2,
        "text": "The deployment progress displays in the upper right corner of the page."
      },
      {
        "heading": "To reset authentication configuration settings",
        "depth": 2,
        "text": "After the delete authentication deployment completes, deploy new authentication rules by following the steps in the preceding procedure for configuring how users log in to an app."
      }
    ],
    "source": "export const meta = {\n  title: `Authentication`,\n  description: `Getting started with authentication for an app`,\n};\n\nAuthentication is the process of verifying the identity of a user. Writing the code for an application's login flow can be difficult and time consuming. In Amplify Studio, you can easily add a complete [Amazon Cognito](https://aws.amazon.com/cognito/) authentication solution to your app. You simply specify the log-in method, such as email and password, Amazon, Google, Facebook, or Sign in with Apple, and you are provided with the authentication UI component for the entire authentication flow. \n\nIf you choose to add one of the social sign-in login mechanisms, you will also need to specify an app ID, app secret, and redirect URIs. To learn more about how social sign-in works, see [Social sign-in (OAuth)](/lib/auth/social).\n\nMulti-factor authentication (MFA) increases security for your app by adding an authentication method and not relying solely on the username and password. AWS Amplify uses Amazon Cognito to provide MFA. To learn more, see [Multi-factor authentication](/lib/auth/mfa).\n\nNote that you must configure and deploy authentication for your application before you can [create users and groups](/console/auth/user-management) or apply [authorization rules](/console/authz/authorization) to your data models.\n\n## To configure how users log in to an app\n1. Sign in to the AWS Management console and open AWS Amplify.\n2. In the navigation pane, choose an application.\n3. On the application information page, choose the **Backend environments** tab, then choose **Launch Studio**.\n4. On the **Set up** menu, choose **Authentication**.\n5. In the **Configure log in** section, choose a login mechanism to add from the **Add login mechanism** list. Valid options are *Username*, *Phone number*, *Facebook*, *Google*, *Amazon*, and *Sign in with Apple*. If you choose one of the social sign-in mechanisms, *Facebook*, *Google*, *Amazon*, or *Sign in with Apple* you will also need to enter your *App ID*, *App Secret*, and redirect URLs.\n6. (Optional) Add multi-factor authentication (MFA).  MFA is set to **Off** by default. To turn on MFA, do the following in the **Multi-factor authentication** section:\n  * Choose **Enforced** to require MFA for all users or choose **Optional** to allow individual users to enable MFA. \n  * (Optional) Choose **SMS**, and enter your SMS message. \n  * (Optional) Choose **Authenticator Application** if you want your app to load with an authentication flow that includes sign up and sign in.\n5. In the **Configure sign up** section, expand **Password protection settings** and customize the password policy settings to enforce.\nu6. Choose **Save and Deploy**. This starts a CloudFormation deployment with the progress displayed in the upper right corner of the page.\n\nLogin mechanism settings, and sign up settings can't be changed after you deploy authentication. To change these settings, you must first delete the deployed authentication and then create and deploy new settings. You can, however, add new login mechanisms, add multi-factor authentication, and update the password protection settings.\n\n[\\\\]: * (Is the last sentence above true?)\n\n## To reset authentication configuration settings\n1. Sign in to the AWS Management console and open AWS Amplify.\n2. In the navigation pane, choose an application.\n3. On the application information page, choose the **Backend environments** tab, then choose **Launch Studio**.\n4. On the **Set up** menu, choose **Authentication**.\n5. At the end of the **Authentication** page, choose **Reset all authentication settings and users**.\n6. In the **Delete authentication** confirmation window, choose **Delete all authentication rules**.\n5. The deployment progress displays in the upper right corner of the page.\n6. After the delete authentication deployment completes, deploy new authentication rules by following the steps in the preceding procedure [for configuring how users log in to an app](/console/auth/authentication#to-configure-how-users-log-in-to-an-app).\n\n[\\\\]: * (What is the consequence of doing the above? What should we warn about?)\n",
    "meta": {
      "title": "Authentication",
      "description": "Getting started with authentication for an app",
      "subcategory": "Authentication",
      "category": "Amplify Studio"
    },
    "filename": "/console/auth/authentication"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "The Amplify Studio Content management view provides a tabular view of the backend data for an application. You can use this feature to test your models and to provide both technical and non-technical team members with the ability to create and update an application's data in real-time instead of building admin views."
      },
      {
        "heading": null,
        "depth": null,
        "text": ""
      },
      {
        "heading": null,
        "depth": null,
        "text": "The Data modeling topic guides you through several examples for creating data models and setting the relationships between them. The following content management procedures, reference the Book and Author tables that were created in the data modeling example in order to demonstrate how to perform operations on your data."
      },
      {
        "heading": "To create data",
        "depth": 2,
        "text": "Open Studio for an app."
      },
      {
        "heading": "To create data",
        "depth": 2,
        "text": "On the Manage menu, choose Content."
      },
      {
        "heading": "To create data",
        "depth": 2,
        "text": "On the Content page, select the table to update from the Select table menu. For this example, select the Author table."
      },
      {
        "heading": "To create data",
        "depth": 2,
        "text": "Choose Create author."
      },
      {
        "heading": "To create data",
        "depth": 2,
        "text": "In the Add Author window, specify your custom values for the fields in the table. For this example, enter Martha for the firstName field and enter Riviera for the lastName field."
      },
      {
        "heading": "To create data",
        "depth": 2,
        "text": "Choose Save author."
      },
      {
        "heading": "To seed data",
        "depth": 2,
        "text": "Open Studio for an app."
      },
      {
        "heading": "To seed data",
        "depth": 2,
        "text": "On the Manage menu, choose Content."
      },
      {
        "heading": "To seed data",
        "depth": 2,
        "text": "On the Content page, select the table to update from the Select table menu. For this example, select the Author table."
      },
      {
        "heading": "To seed data",
        "depth": 2,
        "text": "On the Actions menu, choose Auto-generate data."
      },
      {
        "heading": "To seed data",
        "depth": 2,
        "text": "In the Auto-generate data window, specify how many rows of data you want to generate and constraints for the generated data."
      },
      {
        "heading": "To seed data",
        "depth": 2,
        "text": "Choose Generate data."
      },
      {
        "heading": "To seed data",
        "depth": 2,
        "text": "Seed data is auto-generated using Faker."
      },
      {
        "heading": "To edit data",
        "depth": 2,
        "text": "Open Studio for an app."
      },
      {
        "heading": "To edit data",
        "depth": 2,
        "text": "On the Manage menu, choose Content."
      },
      {
        "heading": "To edit data",
        "depth": 2,
        "text": "On the Content page, select the table to update from the Select table menu. For this example, select the Author table that we used in the previous procedure."
      },
      {
        "heading": "To edit data",
        "depth": 2,
        "text": "From the list of records, select the record to update. For this example, select Martha Riviera. Let's assume that the last name of the author is misspelled and needs to be corrected."
      },
      {
        "heading": "To edit data",
        "depth": 2,
        "text": "On the Actions menu, choose Edit."
      },
      {
        "heading": "To edit data",
        "depth": 2,
        "text": "In the Edit Author window, change the spelling of the author's last name. Enter Rivera in the lastName field, then choose Save author."
      },
      {
        "heading": "To create and link data",
        "depth": 2,
        "text": "When you create a new instance in a table, you can also link it to an instance in another table based on the relationships between the data models."
      },
      {
        "heading": "To create and link data",
        "depth": 2,
        "text": "Open Studio for an app."
      },
      {
        "heading": "To create and link data",
        "depth": 2,
        "text": "On the Manage menu, choose Content."
      },
      {
        "heading": "To create and link data",
        "depth": 2,
        "text": "On the Content page, select the table to update from the Select table menu. For this example, select the Book table, to add a new instance of a book."
      },
      {
        "heading": "To create and link data",
        "depth": 2,
        "text": "Choose Create book. For title, enter All About Dogs."
      },
      {
        "heading": "To create and link data",
        "depth": 2,
        "text": "Let's link this book to the Martha Rivera author instance that we edited in the previous procedure. Choose Link to an existing Author, then choose Martha Rivera from the list of Author instances. Note that you have the option to link to an an author because a relationship was defined between the Book and Author tables during the data modeling process."
      },
      {
        "heading": "To create and link data",
        "depth": 2,
        "text": "View the details for the All About Dogs instance in the Book table, and Martha Rivera is listed as an author."
      },
      {
        "heading": "To delete data",
        "depth": 2,
        "text": "Open Studio for an app."
      },
      {
        "heading": "To delete data",
        "depth": 2,
        "text": "On the Manage menu, choose Content."
      },
      {
        "heading": "To delete data",
        "depth": 2,
        "text": "On the Content page, select the table to update from the Select table menu. For this example, select the Author table that we used in the previous procedure."
      },
      {
        "heading": "To delete data",
        "depth": 2,
        "text": "From the list of records in the table, select the record to delete. For this example, select Martha Rivera. On the Actions menu, then choose Delete."
      },
      {
        "heading": "To delete data",
        "depth": 2,
        "text": "In the Delete item confirmation window, choose Delete."
      },
      {
        "heading": "To download data",
        "depth": 2,
        "text": "Open Studio for an app."
      },
      {
        "heading": "To download data",
        "depth": 2,
        "text": "On the Manage menu, choose Content."
      },
      {
        "heading": "To download data",
        "depth": 2,
        "text": "On the Actions menu you have two options for downloading data."
      },
      {
        "heading": "To download data",
        "depth": 2,
        "text": "Choose Download selected items to CSV to download only the selected rows of data."
      },
      {
        "heading": "To download data",
        "depth": 2,
        "text": "Choose Download results to CSV to download all rows of data on the currently selected page."
      },
      {
        "heading": "To download data",
        "depth": 2,
        "text": "Once you have selected a download option, your data should immediately start downloading as a CSV."
      },
      {
        "heading": "Create or edit data in markdown",
        "depth": 2,
        "text": "You can also edit and store the data as markdown with the markdown editor. This is especially useful for blogs, news, marketing, or content-focused apps where you want the app UI to be styled appropriately. The markdown editor is available by choosing Edit in markdown when you are in the Edit window for a data instance."
      },
      {
        "heading": "Create or edit data in markdown",
        "depth": 2,
        "text": ""
      }
    ],
    "source": "export const meta = {\n  title: `Content management`,\n  description: `Get started with Amplify Studio`,\n};\n\nThe Amplify Studio **Content** management view provides a tabular view of the backend data for an application. You can use this feature to test your models and to provide both technical and non-technical team members with the ability to create and update an application's data in real-time instead of building admin views.\n\n![cms](/images/console/cms.png)\n\nThe [Data modeling](/console/data/data-model) topic guides you through several examples for creating data models and setting the relationships between them. The following content management procedures, reference the *Book* and *Author* tables that were created in the data modeling example in order to demonstrate how to perform operations on your data.\n\n## To create data\n1. Open Studio for an app.\n2. On the **Manage** menu, choose **Content**.\n3. On the **Content** page, select the table to update from the **Select table** menu. For this example, select the *Author* table.\n4. Choose **Create author**.\n5. In the **Add Author** window, specify your custom values for the fields in the table. For this example, enter *Martha* for the *firstName* field and enter *Riviera* for the *lastName* field.\n6. Choose **Save author**.\n\n## To seed data\n1. Open Studio for an app.\n2. On the **Manage** menu, choose **Content**.\n3. On the **Content** page, select the table to update from the **Select table** menu. For this example, select the *Author* table.\n4. On the **Actions** menu, choose **Auto-generate data**.\n5. In the **Auto-generate data** window, specify how many rows of data you want to generate and constraints for the generated data. \n6. Choose **Generate data**.\n\n<Callout warning>\nSeed data is auto-generated using <a href='https://faker.readthedocs.io/en/master/'>Faker</a>. \n</Callout>\n\n## To edit data\n1. Open Studio for an app.\n2. On the **Manage** menu, choose **Content**.\n3. On the **Content** page, select the table to update from the **Select table** menu. For this example, select the *Author* table that we used in the previous procedure.\n4. From the list of records, select the record to update. For this example, select *Martha Riviera*. Let's assume that the last name of the author is misspelled and needs to be corrected.\n5. On the **Actions** menu, choose **Edit**.\n6. In the **Edit Author** window, change the spelling of the author's last name. Enter *Rivera* in the *lastName* field, then choose **Save author**.\n\n## To create and link data\nWhen you create a new instance in a table, you can also link it to an instance in another table based on the relationships between the data models. \n\n1. Open Studio for an app.\n2. On the **Manage** menu, choose **Content**.\n3. On the **Content** page, select the table to update from the **Select table** menu. For this example, select the *Book* table, to add a new instance of a book. \n4. Choose **Create book**. For *title*, enter *All About Dogs*. \n5. Let's link this book to the *Martha Rivera* author instance that we edited in the previous procedure. Choose **Link to an existing Author**, then choose *Martha Rivera* from the list of *Author* instances. Note that you have the option to link to an an author because a relationship was defined between the *Book* and *Author* tables during the data modeling process.\n6. View the details for the *All About Dogs* instance in the *Book* table, and *Martha Rivera* is listed as an author. \n\n## To delete data\n1. Open Studio for an app.\n2. On the **Manage** menu, choose **Content**.\n3. On the **Content** page, select the table to update from the **Select table** menu. For this example, select the *Author* table that we used in the previous procedure.\n4. From the list of records in the table, select the record to delete. For this example, select *Martha Rivera*. On the **Actions** menu, then choose **Delete**.\n5. In the **Delete item** confirmation window, choose **Delete**.\n\n## To download data\n1. Open Studio for an app.\n2. On the **Manage** menu, choose **Content**.\n3. On the **Actions** menu you have two options for downloading data.\n  1. Choose **Download selected items to CSV** to download only the selected rows of data.\n  2. Choose **Download results to CSV** to download all rows of data on the currently selected page.\n4. Once you have selected a download option, your data should immediately start downloading as a CSV.\n\n## Create or edit data in markdown\nYou can also edit and store the data as markdown with the markdown editor. This is especially useful for blogs, news, marketing, or content-focused apps where you want the app UI to be styled appropriately. The markdown editor is available by choosing **Edit in markdown** when you are in the **Edit** window for a data instance.\n\n![cms](/images/console/cms.png)\n",
    "meta": {
      "title": "Content management",
      "description": "Get started with Amplify Studio",
      "subcategory": "Data",
      "category": "Amplify Studio"
    },
    "filename": "/console/data/content-management"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Clone the example data model to follow along"
      },
      {
        "heading": "Model data for a one to one relationship",
        "depth": 2,
        "text": "In this scenario, the bookstore maintains a list of ISBN numbers to track the books it sells. Each book has only one ISBN number and each ISBN number is assigned to only one book. This is an example of a one to one (1:1) data relationship between ISBN numbers and books. Use the following instructions to model the Book and ISBN data types and their relationship in Studio."
      },
      {
        "heading": "Model data for a one to one relationship",
        "depth": 2,
        "text": "In the cloned schema, define the one to one data relationship between ISBN and Book, as each book has a single ISBN number and each ISBN number is associated with a single book. On the ISBN type, choose Add a relationship."
      },
      {
        "heading": "Model data for a one to one relationship",
        "depth": 2,
        "text": "In the Add relationship window, in the Select related model menu, choose Book. For the relationship type, choose One ISBN to one Book. For Relationship name, enter Book. Choose Save. The relationship should look like the following."
      },
      {
        "heading": "Model data for a one to one relationship",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Model data for a one to one relationship",
        "depth": 2,
        "text": "When you return to the Data modeling page, the ISBN model will be updated with the relationship information. Now repeat the same steps for the Book model - define a 1:1 relationship from Book to ISBN."
      },
      {
        "heading": "Model data for a one to many relationship",
        "depth": 2,
        "text": "Now let's create a data model for publishers. Each book in the bookstore has only one publisher. However, each publisher can publish many books. This represents a one to many relationship (1:n) between publishers and books that we can model in our example."
      },
      {
        "heading": "Model data for a one to many relationship",
        "depth": 2,
        "text": "In the cloned schema, select the Publisher model."
      },
      {
        "heading": "Model data for a one to many relationship",
        "depth": 2,
        "text": "For the Publisher model, choose Add a relationship."
      },
      {
        "heading": "Model data for a one to many relationship",
        "depth": 2,
        "text": "In the Add relationship window, in the Select related model menu, choose Book. For the relationship type, choose One Publisher to many Book. For Relationship name, enter books. Choose Save. The relationship should look like the following."
      },
      {
        "heading": "Model data for a one to many relationship",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Model data for a many to many relationship",
        "depth": 2,
        "text": "Let's add a final data model for authors to our example. A book can have a single author or multiple authors. Therefore, a book in the bookstore can be written by many authors and each author can write many books. This is a many to many (m:n)data relationship between books and authors that we can model in our example."
      },
      {
        "heading": "Model data for a many to many relationship",
        "depth": 2,
        "text": "In the cloned schema, select the Author model."
      },
      {
        "heading": "Model data for a many to many relationship",
        "depth": 2,
        "text": "For the Author model, choose Add a relationship."
      },
      {
        "heading": "Model data for a many to many relationship",
        "depth": 2,
        "text": "In the Add relationship window, choose Book from the Select related model menu. For the relationship type, choose Many Author to many Book. For Relationship name, enter a meaningful name, such as Book. Choose Save. The relationship should look like the following."
      },
      {
        "heading": "Model data for a many to many relationship",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Model data for a many to many relationship",
        "depth": 2,
        "text": "Studio does not support custom naming. Changing the auto-generated name will break Studio."
      },
      {
        "heading": "Test data model works as expected",
        "depth": 2,
        "text": "When you are finished modeling your data and defining the data relationships, you can save and deploy the models to an Amplify backend environment."
      },
      {
        "heading": "Test data model works as expected",
        "depth": 2,
        "text": "Choose Deploy in the upper right corner of the Data modeling page."
      },
      {
        "heading": "Test data model works as expected",
        "depth": 2,
        "text": "If you are working in the sandbox, on the Deploy to AWS page, either choose Create an AWS account or Login to deploy AWS Account and proceed with the deployment process."
      },
      {
        "heading": "Test data model works as expected",
        "depth": 2,
        "text": "If you are working in Studio from your AWS account, the deployment status displays in the upper right corner of the page."
      },
      {
        "heading": "Test data model works as expected",
        "depth": 2,
        "text": "Navigate to the Content tab and create data in the tables. You should be able to create and link records from different models. For more information, see Manage content."
      }
    ],
    "source": "export const meta = {\n  title: `Relationships`,\n  description: `Get started with Amplify Studio`,\n};\n\n<Callout warning>\n\nClone the [example data model](/console/data/data-model#data-modeling-example) to follow along\n\n</Callout>\n\n## Model data for a one to one relationship\nimport gqlv2callout from \"/src/fragments/cli/gqlv2callout.mdx\";\n\n<Fragments fragments={{all: gqlv2callout}} />\n\n In this scenario, the bookstore maintains a list of ISBN numbers to track the books it sells. Each book has only one ISBN number and each ISBN number is assigned to only one book. This is an example of a one to one (1:1) data relationship between ISBN numbers and books. Use the following instructions to model the *Book* and *ISBN* data types and their relationship in Studio. \n\n1. In the cloned schema, define the one to one data relationship between `ISBN` and `Book`, as each book has a single ISBN number and each ISBN number is associated with a single book. On the ISBN type, choose **Add a relationship**. \n1. In the **Add relationship** window, in the **Select related model** menu, choose `Book`. For the relationship type, choose **One ISBN to one Book**. For **Relationship name**, enter `Book`. Choose **Save**. The relationship should look like the following.\n\n![GSA](/images/console/3_createOnetooneRelationship.png)\n\nWhen you return to the **Data modeling** page, the `ISBN` model will be updated with the relationship information. Now repeat the same steps for the `Book` model - define a 1:1 relationship from Book to ISBN.\n\n## Model data for a one to many relationship\n\n<Fragments fragments={{all: gqlv2callout}} />\n\nNow let's create a data model for publishers. Each book in the bookstore has only one publisher. However, each publisher can publish many books. This represents a one to many relationship (1:n) between publishers and books that we can model in our example.\n\n1. In the cloned schema, select the `Publisher` model.\n1. For the `Publisher` model, choose **Add a relationship**.\n1. In the **Add relationship** window, in the **Select related model** menu, choose `Book`. For the relationship type, choose **One Publisher to many Book**. For **Relationship name**, enter `books`. Choose **Save**. The relationship should look like the following.\n\n![GSA](/images/console/5_onetomanyCardinality.png)\n\n## Model data for a many to many relationship\n\nLet's add a final data model for authors to our example. A book can have a single author or multiple authors. Therefore, a book in the bookstore can be written by many authors and each author can write many books. This is a many to many (m:n)data relationship between books and authors that we can model in our example.\n\n1. In the cloned schema, select the `Author` model.\n4. For the `Author` model, choose **Add a relationship**.\n5. In the **Add relationship** window, choose `Book` from the **Select related model** menu. For the relationship type, choose **Many Author to many Book**. For **Relationship name**, enter a meaningful name, such as `Book`. Choose **Save**. The relationship should look like the following.\n\n![GSA](/images/console/6_manytomanyCardinality.png)\n\n<Callout warning>\nStudio does not support custom naming. Changing the auto-generated name will break Studio.\n</Callout>\n\n## Test data model works as expected\n\nWhen you are finished modeling your data and defining the data relationships, you can save and deploy the models to an Amplify backend environment.\n\n1. Choose **Deploy** in the upper right corner of the **Data modeling** page.\n\n2. If you are working in the sandbox, on the **Deploy to AWS** page, either choose **Create an AWS account** or **Login to deploy AWS Account** and proceed with the deployment process.\n\n3. If you are working in Studio from your AWS account, the deployment status displays in the upper right corner of the page.\n\n4. Navigate to the **Content** tab and create data in the tables. You should be able to create and link records from different models. For more information, see [Manage content](/console/data/content-management).\n",
    "meta": {
      "title": "Relationships",
      "description": "Get started with Amplify Studio",
      "subcategory": "Data",
      "category": "Amplify Studio"
    },
    "filename": "/console/data/relationships"
  },
  {
    "searchableText": [
      {
        "heading": "Data modeling example",
        "depth": 2,
        "text": "In this example we will build a data model for a bookstore to maintain information about books, authors, and publishers with relationships and authorization rules. The schema template below is a starting point for the bookstore backend."
      },
      {
        "heading": "Data modeling example",
        "depth": 2,
        "text": "Clone in Sandbox"
      },
      {
        "heading": "Data modeling example",
        "depth": 2,
        "text": "A bookstore data model template with four models called Book, ISBN,\nPublisher, and Author"
      },
      {
        "heading": "Data modeling example",
        "depth": 2,
        "text": "Skip ahead to relationships or read below on how data modeling works in Amplify Studio."
      },
      {
        "heading": "Data modeling in Amplify Studio",
        "depth": 2,
        "text": "The Studio data model designer provides a visual way to define your app's data model, relationships, and authorization rules. Studio generates a schema.graphql GraphQL Transform for the data model you create. To learn more about how the GraphQl transform works, see GraphQL Transform Overview."
      },
      {
        "heading": "Data modeling in Amplify Studio",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Data modeling in Amplify Studio",
        "depth": 2,
        "text": "All data models built with Studio work with Amplify DataStore out-of-the-box. DataStore is an on-device storage engine that automatically synchronizes data between your mobile and web apps and your database in the AWS cloud to help you build real-time and offline apps faster."
      },
      {
        "heading": "Data modeling in Amplify Studio",
        "depth": 2,
        "text": "The experience for modeling data is the same in the sandbox and in Studio. With an AWS account, you will have real-time data synchronization capabilities and you will also be able to set authorization rules on your models. For more information, see Authorization. All data models are provisioned in your account as AWS AppSync GraphQL APIs and Amazon DynamoDB tables. As with every feature of Studio, it can be further extended with the CLI."
      }
    ],
    "source": "export const meta = {\n  title: \"Data modeling\",\n  description: \"Get started with Amplify Studio\",\n};\n\n## Data modeling example\n\nIn this example we will build a data model for a bookstore to maintain information about books, authors, and publishers with relationships and authorization rules. The schema template below is a starting point for the bookstore backend.\n\n<Grid grid-gap=\"2\" columns={1} className=\"margin-top-lg margin-bottom-lg\">\n  <Card\n    external\n    href=\"https://sandbox.amplifyapp.com/schema-design/4f1a9f51-5783-4da5-9db1-60ce071e6539/clone\"\n    containertag=\"amplify-external-link\"\n  >\n    <CardGraphic alt=\"Amplify Studio logo\" src=\"/images/console/adminui.svg\" />\n    <CardDetail>\n      <h4>Clone in Sandbox</h4>\n      <p>\n        A bookstore data model template with four models called Book, ISBN,\n        Publisher, and Author\n      </p>\n    </CardDetail>\n  </Card>\n</Grid>\n<br />\n\nSkip ahead to [relationships](/console/data/relationships) or read below on how data modeling works in Amplify Studio.\n\n## Data modeling in Amplify Studio\n\nThe Studio data model designer provides a visual way to define your app's data model, relationships, and authorization rules. Studio generates a `schema.graphql` GraphQL Transform for the data model you create. To learn more about how the GraphQl transform works, see [GraphQL Transform Overview](/cli/graphql-transformer/overview).\n\n![datamodel](/images/console/datamodel.gif)\n\nAll data models built with Studio work with Amplify DataStore out-of-the-box. [DataStore](/lib/datastore/getting-started) is an on-device storage engine that automatically synchronizes data between your mobile and web apps and your database in the AWS cloud to help you build real-time and offline apps faster.\n\nThe experience for modeling data is the same in the sandbox and in Studio. With an AWS account, you will have real-time data synchronization capabilities and you will also be able to set authorization rules on your models. For more information, see [Authorization](/console/authz/authorization). All data models are provisioned in your account as AWS AppSync GraphQL APIs and Amazon DynamoDB tables. As with every feature of Studio, it can be further extended with the CLI.\n",
    "meta": {
      "title": "Data modeling",
      "description": "Get started with Amplify Studio",
      "subcategory": "Data",
      "category": "Amplify Studio"
    },
    "filename": "/console/data/data-model"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "We're constantly improving Amplify Studio to make Figma-to-React code conversion better but there are some constraints that need to be taken into account."
      },
      {
        "heading": "Make sure to mark frames as components in Figma",
        "depth": 2,
        "text": "Amplify Studio only converts Figma components. If you only have a Figma \"frame\", Studio will ignore it because frames tend to be used to layout a set of components."
      },
      {
        "heading": "Make sure to mark frames as components in Figma",
        "depth": 2,
        "text": "Learn more about how Figma components work and how to create them with the video below from the Figma team:"
      },
      {
        "heading": "Fonts aren't automatically integrated",
        "depth": 2,
        "text": "By default, Amplify Studio doesn't automatically export the font from the Figma file and download it as part of your src/ui-components/ folder. To workaround this, you can include the font like you'd usually do yourself in your React app."
      },
      {
        "heading": "Fonts aren't automatically integrated",
        "depth": 2,
        "text": "Review the Adding Fonts documentation from the Create React App on how to configure this."
      },
      {
        "heading": "Try to use Figma Auto layout whenever possible",
        "depth": 2,
        "text": "Figma \"Auto layout\" can make a component significantly more responsive than used fixed position of elements. Think of Figma's Auto layout as \"Flexboxes\" (display: flex) in CSS."
      },
      {
        "heading": "Try to use Figma Auto layout whenever possible",
        "depth": 2,
        "text": "Learn more about how Figma's Auto layout works with the video below from the Figma team:"
      },
      {
        "heading": "Represent UI element states in code (hover, active)",
        "depth": 2,
        "text": "Amplify Studio currently doesn't support Figma-to-React code conversion of UI state. For example, if you want to add a hover effect to a button, you need to override the component behavior in code instead of creating a hover variant in Figma."
      },
      {
        "heading": "Figma variants must have the same child elements",
        "depth": 2,
        "text": "The Figma variants are required to have the same component structure. If the variants don't have the same child elements, then Amplify Studio will not be able to import the component."
      },
      {
        "heading": "Figma variants must have the same child elements",
        "depth": 2,
        "text": "In the example below the \"base\" variant has the same child elements as the \"small variant\". You can still make changes to each individual element."
      },
      {
        "heading": "Figma variants must have the same child elements",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Use \"Hug contents\" and \"Fill container\" to ensure components resize correctly",
        "depth": 2,
        "text": "To ensure your components resize correctly when elements get assigned with real-world data, use Figma's \"Constraints\" feature. This is commonly the source of the issue if your text wraps unexpectedly or elements are cut-off unexpectedly. It allows you to specify whether an element should \"Hug its contents\" or \"Fill the container its in\" when resized."
      },
      {
        "heading": "Use \"Hug contents\" and \"Fill container\" to ensure components resize correctly",
        "depth": 2,
        "text": "Learn more about how Figma's Constraints works with the video below from the Figma team:"
      }
    ],
    "source": "export const meta = {\n  title: `Figma-to-Code best practices`,\n  description: `Constraints of Amplify Studio's Figma-to-React capabilities`,\n};\n\nWe're constantly improving Amplify Studio to make Figma-to-React code conversion better but there are some constraints that need to be taken into account.\n\n## Make sure to mark frames as components in Figma\nAmplify Studio only converts Figma components. If you only have a Figma \"frame\", Studio will ignore it because frames tend to be used to layout a set of components.\n\nLearn more about how Figma components work and how to create them with the video below from the Figma team:\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube-nocookie.com/embed/k74IrUNaJVk?start=40\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n## Fonts aren't automatically integrated\n\nBy default, Amplify Studio doesn't automatically export the font from the Figma file and download it as part of your `src/ui-components/` folder. To workaround this, you can include the font like you'd usually do yourself in your React app. \n\nReview the [Adding Fonts](https://create-react-app.dev/docs/adding-images-fonts-and-files/) documentation from the Create React App on how to configure this.\n\n## Try to use Figma Auto layout whenever possible\n\nFigma \"Auto layout\" can make a component significantly more responsive than used fixed position of elements. Think of Figma's Auto layout as \"Flexboxes\" (`display: flex`) in CSS. \n\nLearn more about how Figma's Auto layout works with the video below from the Figma team:\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube-nocookie.com/embed/PNJxeD29ZTg\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n## Represent UI element states in code (hover, active)\n\nAmplify Studio currently doesn't support Figma-to-React code conversion of UI state. For example, if you want to add a hover effect to a button, you need to [override the component behavior in code](/console/uibuilder/override/#set-hover-states-on-icons) instead of creating a hover variant in Figma.\n\n## Figma variants must have the same child elements\n\nThe Figma variants are required to have the same component structure. If the variants don't have the same child elements, then Amplify Studio will not be able to import the component.\n\nIn the example below the \"base\" variant has the same child elements as the \"small variant\". You can still make changes to each individual element.\n\n![Image showing that the component structure needs to be the same](/images/studio/responsive/component-structure.png)\n\n## Use \"Hug contents\" and \"Fill container\" to ensure components resize correctly\n\nTo ensure your components resize correctly when elements get assigned with real-world data, use Figma's \"Constraints\" feature. This is commonly the source of the issue if your text wraps unexpectedly or elements are cut-off unexpectedly. It allows you to specify whether an element should \"Hug its contents\" or \"Fill the container its in\" when resized.\n\nLearn more about how Figma's Constraints works with the video below from the Figma team:\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube-nocookie.com/embed/LHY9cm_2zwU?start=15\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
    "meta": {
      "title": "Figma-to-Code best practices",
      "description": "Constraints of Amplify Studio's Figma-to-React capabilities",
      "subcategory": "UI development (React)",
      "category": "Amplify Studio"
    },
    "filename": "/console/uibuilder/bestpractices"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "When you run amplify pull, Amplify automatically generates JSX and TS versions of your Figma components. You cannot directly edit the code for these components as they will get overwritten on the next pull, but we have exposed mechanisms to extend the code."
      },
      {
        "heading": "Extend generated code via component prop",
        "depth": 3,
        "text": "When using Figma created components, you can use any exposed component props. The example code below shows how you can add pagination to a collection. The isPaginated prop is a property of the <Collection/> component. Similarly, you can use any prop such as gap or isSearchable to extend the collection."
      },
      {
        "heading": "Extend generated components via overrides prop",
        "depth": 3,
        "text": "All generated code exposes an overrides prop on all components and children to give you full control over extending generated code. The following example shows how to override the color of the title of the FAQItem component, that is part of the default Figma file, to red."
      },
      {
        "heading": "Extend generated components via overrides prop",
        "depth": 3,
        "text": "In Studio, navigate to the FAQItem component"
      },
      {
        "heading": "Extend generated components via overrides prop",
        "depth": 3,
        "text": "Find the name of the text element, in this case Title"
      },
      {
        "heading": "Extend generated components via overrides prop",
        "depth": 3,
        "text": "Wherever you are rendering the FAQItem add an overrides prop."
      },
      {
        "heading": "Extend generated components via overrides prop",
        "depth": 3,
        "text": ""
      },
      {
        "heading": "Extend generated collections via overrideItems prop",
        "depth": 3,
        "text": "All generated Collection code exposes an overrideItems prop to give you full control to extend each collection item with context its data item. overrideItems expects a function that accepts an { item, index } parameter and returns the override props that should be applied to each collection item."
      },
      {
        "heading": "Extend generated collections via overrideItems prop",
        "depth": 3,
        "text": "The following example shows how to override each collection item to show a different color based on their index in the collection and alerts the user of which the clicked home."
      },
      {
        "heading": "Extend generated collections via overrideItems prop",
        "depth": 3,
        "text": ""
      },
      {
        "heading": "Extend generated collections via overrideItems prop",
        "depth": 3,
        "text": "If you want to override a prop for a specific element within a collection item, pass an override object to overrideItems."
      },
      {
        "heading": "Nesting collections",
        "depth": 3,
        "text": "Component slots within collections allow you to render additional nested collections. For example, use nested collections to generate a collection of posts, each with its own collection of comments."
      },
      {
        "heading": "Nesting collections",
        "depth": 3,
        "text": "In this example, we have two collections: AmpligramCollection and CommentViewCollection.  These are bound to the Post and Comment data models, which have a one-to-many relationship."
      },
      {
        "heading": "Nesting collections",
        "depth": 3,
        "text": "By nesting the CommentViewCollection within the comment component slot in the AmpligramCollection, and using the overrideItems prop, we can render each Post with its related Comments."
      },
      {
        "heading": "Add business logic during or after action execution",
        "depth": 3,
        "text": "Use the Amplify Hub to listen to actions that are executed via UI event handlers and then add your custom business logic."
      },
      {
        "heading": "Add business logic during or after action execution",
        "depth": 3,
        "text": "In the example above, you can add your own custom business logic, when the customer clicks on a \"Sign out\" button. The Amplify Hub provides Studio-generated events on the ui channel. The format of action binding Hub events is actions:[category]:[action_name]:[status]:"
      },
      {
        "heading": "Add business logic during or after action execution",
        "depth": 3,
        "text": "| Action name  | Description  |\n|---|---|\n| actions:core:navigate:started | Navigate action started |\n| actions:core:navigate:finished | Navigate action finished (possibly with errors) |\n| actions:datastore:create:started | DataStore create action started |\n| actions:datastore:create:finished | DataStore create action finished |\n| actions:datastore:update:started | DataStore update action started |\n| actions:datastore:update:finished | DataStore update action finished (possibly with errors) |\n| actions:datastore:delete:started | DataStore delete action started |\n| actions:datastore:delete:finished | DataStore delete action finished (possibly with errors) |\n| actions:auth:signout:started  | SignOut action started |\n| actions:auth:signout:finished | SignOut action finished (possibly with errors) |"
      },
      {
        "heading": "Modify generated code",
        "depth": 2,
        "text": "You can't directly customize all generated component code, as changes will be overwritten on the next amplify pull. However, the following workaround is available if you want to take control of component modifications."
      },
      {
        "heading": "Modify generated code",
        "depth": 2,
        "text": "Duplicate the generated JSX and TS file inside ui-components (e.g. Ampligram)"
      },
      {
        "heading": "Modify generated code",
        "depth": 2,
        "text": "Change the name of the files to something else (e.g. Ampligram2) and update the function names to match as well."
      },
      {
        "heading": "Modify generated code",
        "depth": 2,
        "text": "Update index.js to include the new export (e.g. export { default as Ampligram2 } from \"./Ampligram2\";)"
      },
      {
        "heading": "Modify generated code",
        "depth": 2,
        "text": "Import the duplicated component wherever you want."
      },
      {
        "heading": "Modify generated code",
        "depth": 2,
        "text": "The next amplify pull will not overwrite this new file."
      },
      {
        "heading": "Example use cases",
        "depth": 2,
        "text": "The following code snippets show how you can handle specific scenarios in your app."
      },
      {
        "heading": "Make a component responsive",
        "depth": 3,
        "text": "Figma components that use Auto layout are automatically mapped to responsive React components. However, some components may require further customizations."
      },
      {
        "heading": "Make a component responsive",
        "depth": 3,
        "text": "Use breakpoints to define behavior:"
      },
      {
        "heading": "Make a component responsive",
        "depth": 3,
        "text": "or"
      },
      {
        "heading": "Set hover states on icons",
        "depth": 3,
        "text": "The following example shows how to override an icon with a CSS class name."
      },
      {
        "heading": "Set hover states on icons",
        "depth": 3,
        "text": ""
      },
      {
        "heading": "Save form data",
        "depth": 3,
        "text": "Amplify Studio provides data action bindings but if you can also self-manage the form submission states and workflows in code."
      },
      {
        "heading": "Save form data",
        "depth": 3,
        "text": "Get the override keys based on the element name in Studio and then set onChange handlers. For example TextFieldzoh is the name of the \"name input field\" component."
      },
      {
        "heading": "Save form data",
        "depth": 3,
        "text": ""
      },
      {
        "heading": "Navigation from parent to detail views",
        "depth": 3,
        "text": "Amplify Studio provides navigation action bindings but if you want to integrate with your own routing system, you can also self-manage the navigation actions."
      },
      {
        "heading": "Navigation from parent to detail views",
        "depth": 3,
        "text": "For example, you want to click on an item in a collection to get to detail views. Use the overrideItems prop to modify each element's property within a collection. The return value of overrideItems will be applied as an override onto the collection item's component."
      }
    ],
    "source": "export const meta = {\n  title: `Extend via code`,\n  description: `Figma to React code with Amplify Studio`,\n};\n\nWhen you run `amplify pull`, Amplify automatically generates JSX and TS versions of your Figma components. You cannot directly edit the code for these components as they will get overwritten on the next `pull`, but we have exposed mechanisms to extend the code. \n\n## Extend generated code\n\n### Extend generated code via component prop\nWhen using Figma created components, you can use any exposed component props. The example code below shows how you can add pagination to a collection. The `isPaginated` prop is a property of the [`<Collection/>`](https://ui.docs.amplify.aws/react/components/collection) component. Similarly, you can use any prop such as `gap` or `isSearchable` to extend the collection.\n\n```\nimport {AmpligramCollection} from './ui-components'\n...\n\n<AmpligramCollection isPaginated itemsPerPage={3}/>\n...\n\n```\n\n### Extend generated components via overrides prop\nAll generated code exposes an `overrides` prop on all components and children to give you full control over extending generated code. The following example shows how to override the color of the title of the `FAQItem` component, that is part of the default Figma file, to red.\n\n1. In Studio, navigate to the `FAQItem` component \n2. Find the name of the text element, in this case `Title`\n3. Wherever you are rendering the `FAQItem` add an `overrides` prop.\n\n<table>\n<tbody>\n<tr>\n<td>\n\n![override](/images/console/ui-override.png)\n\n</td>\n<td>\n\n```jsx\nimport {FAQItem} from './ui-components'\n...\n...                //⬇️ Element name shown in Studio\n<FAQItem overrides={{\"Title\": { color: \"red\" } }}/>\n```\n</td>\n</tr>\n</tbody>\n</table>\n\n### Extend generated collections via overrideItems prop\nAll generated Collection code exposes an `overrideItems` prop to give you full control to extend each collection item with context its data item. `overrideItems` expects a function that accepts an `{ item, index }` parameter and returns the override props that should be applied to each collection item.\n\nThe following example shows how to override each collection item to show a different color based on their index in the collection and alerts the user of which the clicked home.\n\n```jsx\n<HomeCollection overrideItems={({ item, index }) => ({\n  backgroundColor: index % 2 === 0 ? 'white' : 'lightgray',\n  onClick: () => alert(`Home with id: ${item.id} and ${item.address} clicked!`)\n})} />\n```\n\n![Collection item shows a different color based on their index in the collection and alerts the user of which the clicked home](/images/console/collection-override.gif)\n\nIf you want to override a prop for a specific element within a collection item, pass an override object to `overrideItems`.\n\n```jsx\n<HomeCollection overrideItems={(item, index) => ({ overrides: { Share: { fontWeight: 'bold'}}})}\n```\n\n### Nesting collections\nComponent slots within collections allow you to render additional nested collections. For example, use nested collections to generate a collection of posts, each with its own collection of comments.  \n\nIn this example, we have two collections: `AmpligramCollection` and `CommentViewCollection`.  These are bound to the `Post` and `Comment` data models, which have a [one-to-many relationship](/console/data/relationships/).  \n\nBy nesting the `CommentViewCollection` within the `comment` component slot in the `AmpligramCollection`, and using the `overrideItems` prop, we can render each Post with its related Comments.\n\n```jsx\nimport { \n  AmpligramCollection, \n  CommentViewCollection \n} from './ui-components'\n\nfunction App() {\n  return (\n    <AmpligramCollection overrideItems={({ item, index }) => ({\n      comments: <CommentViewCollection items={item.Comments} />\n    })} />\n  );\n}\nexport default App;\n```\n\n### Add business logic during or after action execution\nUse the Amplify Hub to listen to actions that are executed via [UI event handlers](/console/uibuilder/eventhandling) and then add your custom business logic.\n\n```jsx\nimport { Hub } from 'aws-amplify'\n\n...\nHub.listen(\"ui\", (capsule) => {\n  if (capsule.payload.event === \"actions:auth:signout:finished\") {\n    // Do something after signout\n  }\n});\n```\n\nIn the example above, you can add your own custom business logic, when the customer clicks on a \"Sign out\" button. The Amplify `Hub` provides Studio-generated events on the `ui` channel. The format of action binding Hub events is `actions:[category]:[action_name]:[status]`:\n\n| Action name  | Description  |\n|---|---|\n| actions:core:navigate:started | [Navigate action](/console/uibuilder/eventhandling/#bind-ui-to-navigation-actions) started |\n| actions:core:navigate:finished | [Navigate action](/console/uibuilder/eventhandling/#bind-ui-to-navigation-actions) finished (possibly with errors) |\n| actions:datastore:create:started | [DataStore create action](/console/uibuilder/eventhandling/#create-a-record-in-database) started |\n| actions:datastore:create:finished | [DataStore create action](/console/uibuilder/eventhandling/#create-a-record-in-database) finished |\n| actions:datastore:update:started | [DataStore update action](/console/uibuilder/eventhandling/#update-a-record-from-database) started |\n| actions:datastore:update:finished | [DataStore update action](/console/uibuilder/eventhandling/#update-a-record-from-database) finished (possibly with errors) |\n| actions:datastore:delete:started | [DataStore delete action](/console/uibuilder/eventhandling/#delete-a-record-from-database) started |\n| actions:datastore:delete:finished | [DataStore delete action](/console/uibuilder/eventhandling/#delete-a-record-from-database) finished (possibly with errors) |\n| actions:auth:signout:started  | [SignOut action](/console/uibuilder/eventhandling/#bind-ui-to-sign-out-actions) started |\n| actions:auth:signout:finished | [SignOut action](/console/uibuilder/eventhandling/#bind-ui-to-sign-out-actions) finished (possibly with errors) |\n\n## Modify generated code\nYou can't directly customize all generated component code, as changes will be overwritten on the next `amplify pull`. However, the following workaround is available if you want to take control of component modifications.\n\n1. Duplicate the generated JSX and TS file inside `ui-components` (e.g. `Ampligram`)\n2. Change the name of the files to something else (e.g. `Ampligram2`) and update the function names to match as well.\n3. Update `index.js` to include the new export (e.g. `export { default as Ampligram2 } from \"./Ampligram2\";`)\n4. Import the duplicated component wherever you want.\n\nThe next `amplify pull` will not overwrite this new file.\n\n## Example use cases\nThe following code snippets show how you can handle specific scenarios in your app.\n\n### Add Pagination to a collection\n\n```\nimport {AmpligramCollection} from './ui-components'\n...\n\n<AmpligramCollection isPaginated itemsPerPage={3}/>\n...\n\n```\n### Make a component responsive\nFigma components that use *Auto layout* are automatically mapped to responsive React components. However, some components may require further customizations. \n\nUse breakpoints to define behavior:\n\n```jsx\n <NavBar width={{ small: \"300px\", large: \"600px\", xl: \"800px\" }}/>\n```\n\nor \n\n```jsx\n <NavBar width={\"100vw\"}/>\n```\n\n### Set hover states on icons\n\nThe following example shows how to override an icon with a CSS class name.\n\n<table>\n<tbody>\n<tr>\n<td>\n\n```jsx\n// App.css\n.custom-btn:hover {\n   transform: scale(1.2);\n}\n\n// App.jsx\nconst iconOverrides = {\n  \"Button\": {\n     className: \"custom-btn\"\n  }\n}\n\n<HeroLayout1 overrides={iconOverrides} />\n```\n\n</td>\n<td>\n\n![Hover override using class names](/images/console/hover-override.gif)\n\n</td>\n</tr>\n</tbody>\n</table>\n\n\n### Save form data\n\nAmplify Studio provides [data action bindings](/console/uibuilder/eventhandling#bind-ui-to-create-update-or-delete-a-data-record) but if you can also self-manage the form submission states and workflows in code.\n\nGet the override keys based on the element name in Studio and then set `onChange` handlers. For example `TextFieldzoh` is the name of the \"name input field\" component.\n\n![Studio interface showing the form field names](/images/console/form-override.png)\n\n```jsx\nconst [name, setName] = useState(\"\");\nconst [location, setLocation] = useState(\"\");\nconst [email, setEmail] = useState(\"\");\n  \nconst profileOverrides = {\n  \"TextFieldzoh\": {\n    onChange: (event) => { setName(event.target.value) }\n  },\n  \"TextFieldzwu\": {\n    onChange: (event) => { setLocation(event.target.value) }\n  },\n  \"TextFieldsdk\": {\n    onChange: (event) => { setEmail(event.target.value) }\n  },\n  \"Button\": {\n    onClick: () => alert(`Saving form ${name} ${location} ${email}`)\n  }\n}\n\nreturn (\n    ...\n    <EditProfile overrides={profileOverrides}/>\n    ...\n)\n```\n\n### Navigation from parent to detail views\n\nAmplify Studio provides [navigation action bindings](/console/uibuilder/eventhandling/#bind-ui-to-navigation-actions) but if you want to integrate with your own routing system, you can also self-manage the navigation actions. \n\nFor example, you want to click on an item in a collection to get to detail views. Use the `overrideItems` prop to modify each element's property within a collection. The return value of `overrideItems` will be applied as an override onto the collection item's component.\n\n```jsx\n<HomeCollection overrideItems={({item, index}) => ({\n  style: {\n    cursor: \"pointer\"\n  },\n  onClick: () => {\n    // The actual redirect can happen whichever way you want\n    // `item` represent the data item that is passed into the \n    // collection item. In this case, it's a \"home\".\n  }\n})} />\n```",
    "meta": {
      "title": "Extend with code",
      "description": "Figma to React code with Amplify Studio",
      "subcategory": "UI development (React)",
      "category": "Amplify Studio"
    },
    "filename": "/console/uibuilder/override"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "You can use Amplify Studio to dynamically toggle between different component variants based on your app's breakpoint. For example, you can have the navigation bar shrink to a smaller size as the window gets smaller."
      },
      {
        "heading": null,
        "depth": null,
        "text": ""
      },
      {
        "heading": "1. Setup Figma components with responsive variants",
        "depth": 2,
        "text": "By default, all Amplify UI provides the following breakpoints as part of the Amplify UI theme:"
      },
      {
        "heading": "1. Setup Figma components with responsive variants",
        "depth": 2,
        "text": "Configure your Figma components with variants with names that match the breakpoint values. In the example below, our TopBar component has the following variants:"
      },
      {
        "heading": "1. Setup Figma components with responsive variants",
        "depth": 2,
        "text": "variation: default"
      },
      {
        "heading": "1. Setup Figma components with responsive variants",
        "depth": 2,
        "text": "variation: small"
      },
      {
        "heading": "1. Setup Figma components with responsive variants",
        "depth": 2,
        "text": "The small variation should be shown when the screen size falls below the \"small\" breakpoint."
      },
      {
        "heading": "1. Setup Figma components with responsive variants",
        "depth": 2,
        "text": "IMPORTANT: The variants are required to have the same component structure. If the variants don't have the same child elements, then Amplify Studio will not be able to import the component."
      },
      {
        "heading": "1. Setup Figma components with responsive variants",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "2. Render component variants in code based on breakpoints",
        "depth": 2,
        "text": "In your React code, use the useBreakpoint hook to dynamically toggle between the different variants of the component. In the example below, it should show the \"default\" variant when the breakpoint is medium and above and the \"small\" variant when it's \"small\" when the breakpoints of small and below are triggered:"
      }
    ],
    "source": "export const meta = {\n  title: `Responsive Components`,\n  description: `Learn how to configure Figma-to-Code components in order for them to scale according to breakpoints`,\n};\n\nYou can use Amplify Studio to dynamically toggle between different component variants based on your app's breakpoint. For example, you can have the navigation bar shrink to a smaller size as the window gets smaller.\n\n![GIF showing a responsive header design](/images/studio/responsive/responsive-header.gif)\n\n## 1. Setup Figma components with responsive variants\n\nBy default, all Amplify UI provides the following [breakpoints as part of the Amplify UI theme](https://ui.docs.amplify.aws/react/theming/responsive#breakpoints):\n\n```\n{\n  base: '0',\n  small: '480px',\n  medium: '768px',\n  large: '992px',\n  xl: '1280px',\n  xxl: '1536px',\n}\n```\n\nConfigure your Figma components with variants with names that match the breakpoint values. In the example below, our `TopBar` component has the following variants:\n- `variation: default`\n- `variation: small`\n\nThe small variation should be shown when the screen size falls below the \"small\" breakpoint.\n\n<Callout warning>\n\n**IMPORTANT:** The variants are required to have the same component structure. If the variants don't have the same child elements, then Amplify Studio will not be able to import the component.\n\n![Image showing that the component structure needs to be the same](/images/studio/responsive/component-structure.png)\n\n</Callout>\n\n## 2. Render component variants in code based on breakpoints\n\nIn your React code, use the `useBreakpoint` hook to dynamically toggle between the different variants of the component. In the example below, it should show the \"default\" variant when the breakpoint is medium and above and the \"small\" variant when it's \"small\" when the breakpoints of small and below are triggered:\n\n```js\nimport { TopBar } from './ui-components'\nimport { useBreakpointValue } from '@aws-amplify/ui-react'\n\nfunction App() {\n  const variant = useBreakpointValue({\n    small: 'small',\n    medium: 'default',\n  });\n  return (\n    <div className=\"App\">\n      <TopBar\n        width=\"100vw\"\n        variation={variant}\n      />\n    </div>\n  )\n}",
    "meta": {
      "title": "Responsive components",
      "description": "Learn how to configure Figma-to-Code components in order for them to scale according to breakpoints",
      "subcategory": "UI development (React)",
      "category": "Amplify Studio"
    },
    "filename": "/console/uibuilder/responsive"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Use Amplify Theme Editor to customize the UI primitives in your Figma file to match your brand's look and feel. Amplify Studio allows you to visually configure the Amplify UI theme definition."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The plugin saves your theme directly in the Figma file itself so when you sync your Studio app with Figma it will automatically bring in the updated theme as well."
      },
      {
        "heading": "Install Amplify Theme Editor (Figma plugin)",
        "depth": 2,
        "text": "To install the Amplify Theme Editor:"
      },
      {
        "heading": "Install Amplify Theme Editor (Figma plugin)",
        "depth": 2,
        "text": "Go to the Amplify Theme Editor Figma plugin page"
      },
      {
        "heading": "Install Amplify Theme Editor (Figma plugin)",
        "depth": 2,
        "text": "Click \"Install\" on the top-right corner"
      },
      {
        "heading": "Install Amplify Theme Editor (Figma plugin)",
        "depth": 2,
        "text": "Go to your Figma file"
      },
      {
        "heading": "Install Amplify Theme Editor (Figma plugin)",
        "depth": 2,
        "text": "Right-click an empty area of the canvas and select Plugins > Amplify Theme Editor or use the Figma quick actions menu by pressing command/control + / then typing \"AWS Amplify\""
      },
      {
        "heading": "1. Modify brand colors",
        "depth": 3,
        "text": "Select your own brand color or choose a preset. Your brand color affects almost every single UI primitive and allows you to quickly modify your components look and feel to match your brand."
      },
      {
        "heading": "1. Modify brand colors",
        "depth": 3,
        "text": ""
      },
      {
        "heading": "1. Modify brand colors",
        "depth": 3,
        "text": "Amplify Theme Editor will automatically cascade color levels 10 - 100. You can modify the auto-generated levels further by selecting the level and tweaking the HEX or HSL values to your exact specification."
      },
      {
        "heading": "2. Use brand colors in Figma",
        "depth": 3,
        "text": "Every color listed in the Amplify Theme Editor is also available as a Figma color style."
      },
      {
        "heading": "2. Use brand colors in Figma",
        "depth": 3,
        "text": ""
      },
      {
        "heading": "2. Use brand colors in Figma",
        "depth": 3,
        "text": "You can choose any layer and assign the fill to your brand colors. Updating the brand colors in the plugin will update the color styles."
      },
      {
        "heading": "2. Use brand colors in Figma",
        "depth": 3,
        "text": ""
      },
      {
        "heading": "2. Use brand colors in Figma",
        "depth": 3,
        "text": "The Figma plugin creates color styles that match the colors in the theme. But any changes to color styles directly won't have an effect on the theme."
      },
      {
        "heading": "3. Modify UI primitive colors",
        "depth": 3,
        "text": "Individual primitives such as Alerts have their own bindings for color to fine-tune their look and feel as well. This is especially useful as you start defining colors for states such as \"success\", \"warning\", \"error\", or \"info\"."
      },
      {
        "heading": "3. Modify UI primitive colors",
        "depth": 3,
        "text": "To change colors of UI primitives:"
      },
      {
        "heading": "3. Modify UI primitive colors",
        "depth": 3,
        "text": "Open the Amplify Theme Editor"
      },
      {
        "heading": "3. Modify UI primitive colors",
        "depth": 3,
        "text": "Click on the \"Component\" tab"
      },
      {
        "heading": "3. Modify UI primitive colors",
        "depth": 3,
        "text": "Select the value you want to edit. For example: components.badge.error.backgroundColor. You can also filter the list of component tokens with the search bar at the top"
      },
      {
        "heading": "3. Modify UI primitive colors",
        "depth": 3,
        "text": "Choose a new color"
      },
      {
        "heading": "3. Modify UI primitive colors",
        "depth": 3,
        "text": "Click \"Update theme\""
      },
      {
        "heading": "3. Modify UI primitive colors",
        "depth": 3,
        "text": ""
      },
      {
        "heading": "3. Modify UI primitive colors",
        "depth": 3,
        "text": "Colors in the theme can either be references to other colors or exact Hex, HSL, or RGB values."
      },
      {
        "heading": "3. Modify UI primitive colors",
        "depth": 3,
        "text": ""
      },
      {
        "heading": "Space",
        "depth": 2,
        "text": "Each Amplify UI theme contains definitions for spacing such as \"small\", \"large\", or \"xl\". You can define the spacing scale within the \"Space\" tab in the Amplify Theme Editor."
      },
      {
        "heading": "Space",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Space",
        "depth": 2,
        "text": "To apply spacing tokens to your own components:"
      },
      {
        "heading": "Space",
        "depth": 2,
        "text": "Open the Amplify Theme Editor"
      },
      {
        "heading": "Space",
        "depth": 2,
        "text": "Click on the \"Apply\" tab"
      },
      {
        "heading": "Space",
        "depth": 2,
        "text": "Select a frame"
      },
      {
        "heading": "Space",
        "depth": 2,
        "text": "Configure it as a reference by entering {space.<SPACING_TOKEN>}. For example: {space.small}"
      },
      {
        "heading": "Space",
        "depth": 2,
        "text": "Click \"Update theme\""
      },
      {
        "heading": "Space",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Font sizes",
        "depth": 2,
        "text": "To update the font sizes in the theme:"
      },
      {
        "heading": "Font sizes",
        "depth": 2,
        "text": "Open the Amplify Theme Editor"
      },
      {
        "heading": "Font sizes",
        "depth": 2,
        "text": "Click on the \"Font sizes\" tab"
      },
      {
        "heading": "Font sizes",
        "depth": 2,
        "text": "Click on any of the font sizes to edit it"
      },
      {
        "heading": "Font sizes",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Font sizes",
        "depth": 2,
        "text": "You can input 'rem' values or 'px' values. Updating font sizes will update the primitives, text styles, as well as any Figma layers that use that font size."
      },
      {
        "heading": "Borders",
        "depth": 2,
        "text": "You can edit border widths and radii in addition to colors as well."
      },
      {
        "heading": "Borders",
        "depth": 2,
        "text": "To update the font sizes in the theme:"
      },
      {
        "heading": "Borders",
        "depth": 2,
        "text": "Open the Amplify Theme Editor"
      },
      {
        "heading": "Borders",
        "depth": 2,
        "text": "Click on the \"Borders\" tab"
      },
      {
        "heading": "Borders",
        "depth": 2,
        "text": "Click on any of the border widths or radii to edit it"
      },
      {
        "heading": "Borders",
        "depth": 2,
        "text": "You can apply these border values to your own components by selecting the 'Apply' tab and selecting a frame component. Subsequent changes to the core border widths and radii will update any usage in your Figma document."
      },
      {
        "heading": "Borders",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Borders",
        "depth": 2,
        "text": "If you have any issues, please let us know by filing an issue on Github."
      }
    ],
    "source": "export const meta = {\n  title: `Theming`,\n  description: `Configure your Amplify-generated UI components to match your brand using the Amplify Theme Editor Figma plugin`,\n};\n\nUse [Amplify Theme Editor](https://www.figma.com/community/plugin/1040722185526429545/AWS-Amplify-Theme-Editor) to customize the UI primitives in your Figma file to match your brand's look and feel. Amplify Studio allows you to visually configure the [Amplify UI theme](https://ui.docs.amplify.aws/react/theming) definition.\n\nThe plugin saves your theme directly in the Figma file itself so when you sync your Studio app with Figma it will automatically bring in the updated theme as well.\n\n## Install Amplify Theme Editor (Figma plugin)\n\nTo install the Amplify Theme Editor:\n1. Go to the [Amplify Theme Editor Figma plugin page](https://www.figma.com/community/plugin/1040722185526429545/AWS-Amplify-Theme-Editor)\n2. Click \"Install\" on the top-right corner\n3. Go to your Figma file\n4. Right-click an empty area of the canvas and select **Plugins** > **Amplify Theme Editor** or use the Figma quick actions menu by pressing command/control + / then typing \"AWS Amplify\"\n\n## Colors\n\n### 1. Modify brand colors\n\nSelect your own brand color or choose a preset. Your brand color affects almost every single UI primitive and allows you to quickly modify your components look and feel to match your brand.\n\n![Modify brand colors](/images/studio/theming/pick-brand-color.gif)\n\nAmplify Theme Editor will automatically cascade color levels 10 - 100. You can modify the auto-generated levels further by selecting the level and tweaking the HEX or HSL values to your exact specification.\n\n### 2. Use brand colors in Figma\n\nEvery color listed in the Amplify Theme Editor is also available as a Figma color style.\n\n![Use brand colors in Figma](/images/studio/theming/color-styles.gif)\n\nYou can choose any layer and assign the fill to your brand colors. Updating the brand colors in the plugin will update the color styles.\n\n![Auto-cascading brand color levels](/images/studio/theming/brand-color-cascade.gif)\n\n<Callout>\n  The Figma plugin creates color styles that match the colors in the theme. But any changes to color styles directly won't have an effect on the theme.\n</Callout>\n\n### 3. Modify UI primitive colors\n\nIndividual primitives such as Alerts have their own bindings for color to fine-tune their look and feel as well. This is especially useful as you start defining colors for states such as \"success\", \"warning\", \"error\", or \"info\".\n\nTo change colors of UI primitives:\n1. Open the Amplify Theme Editor\n2. Click on the \"Component\" tab\n3. Select the value you want to edit. For example: `components.badge.error.backgroundColor`. You can also filter the list of component tokens with the search bar at the top\n4. Choose a new color\n5. Click \"Update theme\"\n\n![Modify UI primitive colors](/images/studio/theming/component-color.gif)\n\nColors in the theme can either be references to *other* colors or exact Hex, HSL, or RGB values.\n\n![Modify UI primitive colors with HSL](/images/studio/theming/component-color-hsl.gif)\n\n## Space\n\nEach Amplify UI theme contains definitions for spacing such as \"small\", \"large\", or \"xl\". You can define the spacing scale within the \"Space\" tab in the Amplify Theme Editor.\n\n![Use space definitions in Figma](/images/studio/theming/space.gif)\n\nTo apply spacing tokens to your own components:\n1. Open the Amplify Theme Editor\n2. Click on the \"Apply\" tab\n3. Select a frame\n4. Configure it as a reference by entering `{space.<SPACING_TOKEN>}`. For example: `{space.small}`\n5. Click \"Update theme\"\n\n![Apply theme values in Figma](/images/studio/theming/apply.gif)\n\n\n## Font sizes\n\nTo update the font sizes in the theme:\n1. Open the Amplify Theme Editor\n2. Click on the \"Font sizes\" tab\n3. Click on any of the font sizes to edit it\n\n![Use font sizes in Figma](/images/studio/theming/font-size.gif)\n\nYou can input 'rem' values or 'px' values. Updating font sizes will update the primitives, text styles, as well as any Figma layers that use that font size.\n\n## Borders\n\nYou can edit border widths and radii in addition to colors as well.\n\nTo update the font sizes in the theme:\n1. Open the Amplify Theme Editor\n2. Click on the \"Borders\" tab\n3. Click on any of the border widths or radii to edit it\n\nYou can apply these border values to your own components by selecting the 'Apply' tab and selecting a frame component. Subsequent changes to the core border widths and radii will update any usage in your Figma document.\n\n![Use borders in Figma](/images/studio/theming/border.gif)\n\n\n<Callout>\n\n  If you have any issues, please let us know by [filing an issue on Github](https://github.com/aws-amplify/amplify-adminui/issues).\n\n</Callout>\n",
    "meta": {
      "title": "Theming",
      "description": "Configure your Amplify-generated UI components to match your brand using the Amplify Theme Editor Figma plugin",
      "subcategory": "UI development (React)",
      "category": "Amplify Studio"
    },
    "filename": "/console/uibuilder/theming"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Component slots allow you to nest other components as React code within your Studio-generated UI components. You can use component slots to create dynamically generated child components, like Comments on a Post, or to replace a child element altogether."
      },
      {
        "heading": "Adding a component slot",
        "depth": 2,
        "text": "First, you'll need a component."
      },
      {
        "heading": "Adding a component slot",
        "depth": 2,
        "text": "Log into Amplify and navigate to Studio."
      },
      {
        "heading": "Adding a component slot",
        "depth": 2,
        "text": "On the left-hand navigation bar, click UI Library"
      },
      {
        "heading": "Adding a component slot",
        "depth": 2,
        "text": "Select a Figma component from your UI Library that you've imported into Studio.\nIf you don't have any Figma components already, you can start with Amplify's Figma UI file."
      },
      {
        "heading": "Adding a component slot",
        "depth": 2,
        "text": "Configure that component by clicking the Configure button in the upper right-hand corner."
      },
      {
        "heading": "Adding a component slot",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Adding a component slot",
        "depth": 2,
        "text": "Next, you'll add a component slot to this component."
      },
      {
        "heading": "Adding a component slot",
        "depth": 2,
        "text": "On the left-hand side, you'll see the elements of your component. Select a Figma Frame () within your component."
      },
      {
        "heading": "Adding a component slot",
        "depth": 2,
        "text": "In this example, the \"Area\" frame is selected."
      },
      {
        "heading": "Adding a component slot",
        "depth": 2,
        "text": "On the right-hand panel, click the \"Convert to a slot\" button. This will add a new prop to your UI component. Any JSX element you pass into that prop will be rendered in the generated component slot."
      },
      {
        "heading": "Adding a component slot",
        "depth": 2,
        "text": "Optionally, change your your property name."
      },
      {
        "heading": "Adding a component slot",
        "depth": 2,
        "text": "In this example, the property has been renamed \"comments\""
      },
      {
        "heading": "Adding a component slot",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Adding a component slot",
        "depth": 2,
        "text": "Want to undo your component slot creation?"
      },
      {
        "heading": "Adding a component slot",
        "depth": 2,
        "text": "Locate your component slot in the Component properties (top-right corner), click the triple-dot menu, and click Erase property to remove the component slot."
      },
      {
        "heading": "Importing your component",
        "depth": 3,
        "text": "Once you've added a component slot to your component, click the Get component code button at the bottom of the screen to see instructions on the next steps."
      },
      {
        "heading": "Importing your component",
        "depth": 3,
        "text": "Copy the amplify pull command, and run it in your Terminal"
      },
      {
        "heading": "Importing your component",
        "depth": 3,
        "text": "Copy the import code and paste it in your React app code"
      },
      {
        "heading": "Importing your component",
        "depth": 3,
        "text": "Lastly, render the component"
      },
      {
        "heading": "Importing your component",
        "depth": 3,
        "text": "Here's how the code above would render in your app. Some minor styling has been added to help with visibility."
      },
      {
        "heading": "Importing your component",
        "depth": 3,
        "text": ""
      },
      {
        "heading": "Using your component slot to replace individual child components",
        "depth": 3,
        "text": "To use the component slot, pass a child component as a property of the parent component, using the prop name you picked earlier. Then, the content you pass will be rendered as a child of the component."
      },
      {
        "heading": "Using your component slot to replace individual child components",
        "depth": 3,
        "text": "Here's how the code above would render in your app. Some styling has been added to the comments to help with display."
      },
      {
        "heading": "Using your component slot to replace individual child components",
        "depth": 3,
        "text": ""
      },
      {
        "heading": "Adding component slots to collections",
        "depth": 3,
        "text": "Any component can be converted to a collection and bound to data, and that includes components with component slots.  With a collection, you can extend your component via code using the overrideItems prop to generate unique content within each component slot."
      },
      {
        "heading": "Adding component slots to collections",
        "depth": 3,
        "text": "Here, the Ampligram collection is mapped to a data model called Post. The Post model has a field called Comment, which contains an array of all the Comments associated with this Post. Each of these items in the Comment array is then mapped to the \"comments\" component slot we created."
      },
      {
        "heading": "Adding component slots to collections",
        "depth": 3,
        "text": "Dynamically rendering child components is where component slots get very useful - you can even pass another collection into this component slot."
      },
      {
        "heading": "Adding component slots to collections",
        "depth": 3,
        "text": "The code below will render an Ampligram for each Post in the AmpligramCollection. Then, the Comments for each Post will render in the \"comments\" component slot."
      },
      {
        "heading": "Adding component slots to collections",
        "depth": 3,
        "text": "In this example, the first Post has 2 comments, but the second post has none."
      },
      {
        "heading": "Adding component slots to collections",
        "depth": 3,
        "text": ""
      }
    ],
    "source": "export const meta = {\n  title: `Component slots`,\n  description: `Add component slots to Amplify-generated Figma-to-code components.  Use this to support nested components or collections in React code.`,\n};\n\nComponent slots allow you to nest other components as React code within your Studio-generated UI components. You can use component slots to create dynamically generated child components, like Comments on a Post, or to replace a child element altogether.\n\n## Adding a component slot\nFirst, you'll need a component.  \n1. Log into Amplify and [navigate to Studio](/console/adminui/start/).\n\n2. On the left-hand navigation bar, click UI Library\n\n3. Select a Figma component from your UI Library that you've imported into Studio.\n*If you don't have any Figma components already, you can start with [Amplify's Figma UI file](/console/uibuilder/figmatocode/).*\n\n4. Configure that component by clicking the **Configure** button in the upper right-hand corner.\n\n![Animated image of opening a component and clicking the gear icon to configure](/images/console/slots-console1.gif)\n\nNext, you'll add a component slot to this component.  \n1. On the left-hand side, you'll see the elements of your component. Select a Figma **Frame** (![Figma frame icon](/images/console/figma-frame-icon.png)) within your component.  \n\n  In this example, the \"Area\" frame is selected.\n\n2. On the right-hand panel, click the \"Convert to a slot\" button. This will add a new prop to your UI component. Any JSX element you pass into that prop will be rendered in the generated component slot.\n\n3. Optionally, change your your property name.  \n\n  In this example, the property has been renamed \"comments\"\n\n![Animated image of selecting a frame and add a component slot](/images/console/slots-console2.gif)\n\n<Callout warning>\n\nWant to undo your component slot creation?  \n\nLocate your component slot in the **Component properties** (top-right corner), click the triple-dot menu, and click **Erase property** to remove the component slot.\n\n</Callout>\n\n## Render the component with component slots in React code\n### Importing your component\nOnce you've added a component slot to your component, click the **Get component code** button at the bottom of the screen to see instructions on the next steps.  \n1. Copy the `amplify pull` command, and run it in your Terminal\n2. Copy the import code and paste it in your React app code\n3. Lastly, render the component\n\n```jsx\n/*Import your component*/\nimport { \n  Ampligram \n} from './ui-components'\n\nfunction App() {\n  return (\n    /*Add your component below*/\n    <Ampligram  style={styles.post}/> \n  );\n}\nconst styles = {\n  post: { width: 400, margin: '0 auto', padding: 20},\n}\nexport default App;\n```\n\nHere's how the code above would render in your app. *Some minor styling has been added to help with visibility.*\n\n![Screenshot of an imported component with a component slot](/images/console/slots1.png)\n\n### Using your component slot to replace individual child components\nTo use the component slot, pass a child component as a property of the parent component, using the prop name you picked earlier. Then, the content you pass will be rendered as a child of the component.  \n\n\n````jsx\nimport { \n  Ampligram \n} from '.ui-components'\n\nfunction App() {\n  return (\n    <Ampligram style={styles.post} comments={\n      /* Pass your content into the component slot */\n      <div style={styles.comment}> \n        <h1>Hi mom!</h1>\n        <p>Thanks for checking out my app</p>\n      </div>\n    }/>\n  );\n}\nconst styles = {\n  post: { width: 400, margin: '0 auto', padding: 20},\n  comment: { paddingLeft: 30, textAlign: 'left'},\n}\nexport default App;\n````\n\nHere's how the code above would render in your app. *Some styling has been added to the comments to help with display.*\n\n![Screenshot of a component with static text in the component slot](/images/console/slots2.png)\n\n### Adding component slots to collections\nAny component can be [converted to a collection](/console/uibuilder/collections/) and bound to data, and that includes components with component slots.  With a collection, you can [extend your component via code](/console/uibuilder/override/) using the `overrideItems` prop to generate unique content within each component slot.  \n\nHere, the Ampligram collection is mapped to a data model called Post. The Post model has a field called Comment, which contains an array of all the Comments associated with this Post. Each of these items in the Comment array is then mapped to the \"comments\" component slot we created.  \n\nDynamically rendering child components is where component slots get very useful - you can even [pass another collection](/console/uibuilder/override/#nesting-collections) into this component slot. \n\nThe code below will render an Ampligram for each Post in the AmpligramCollection. Then, the Comments for each Post will render in the \"comments\" component slot.  \n\nIn this example, the first Post has 2 comments, but the second post has none.\n\n```jsx\nimport { \n  AmpligramCollection \n} from './ui-components'\n\nfunction App() {\n  return (\n    <AmpligramCollection style={styles.post} overrideItems={({ item }) => ({\n      comments: \n      <div style={styles.post}>\n        {item.Comments.map(comment => <div>{comment.content}</div>)}\n      </div>\n    })} />\n  );\n}\nconst styles = {\n  post: { width: 400, margin: '0 auto', padding: 20},\n  comment: { paddingLeft: 30, textAlign: 'left'},\n}\nexport default App;\n```\n\n![Screenshot of component with dynamic content in the component slot](/images/console/slots3.png)\n",
    "meta": {
      "title": "Component slots",
      "description": "Add component slots to Amplify-generated Figma-to-code components.  Use this to support nested components or collections in React code.",
      "subcategory": "UI development (React)",
      "category": "Amplify Studio"
    },
    "filename": "/console/uibuilder/slots"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Collections are any list of repeating items. You can visually create a collection from any individual component by selecting the Create collection button in the top right corner of the UI component editor. All collections are generated as code with real-time subscriptions automatically set up."
      },
      {
        "heading": "Data binding",
        "depth": 2,
        "text": "Amplify Studio offers a visual way to bind collections to items in your data model. Collection items can be filtered, sorted, or linked to specific records from the content management view."
      },
      {
        "heading": "Data binding",
        "depth": 2,
        "text": "Create a collection from a component"
      },
      {
        "heading": "Data binding",
        "depth": 2,
        "text": "Link collection to a data model"
      },
      {
        "heading": "Data binding",
        "depth": 2,
        "text": "Define a data set with either a dynamic query or specific records."
      },
      {
        "heading": "Data binding",
        "depth": 2,
        "text": "Components that already have data model bindings, automatically map data to child elements. For components that do not have data model bindings,"
      },
      {
        "heading": "Data binding",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Dynamic query",
        "depth": 3,
        "text": "A dynamic query allows you to sort and filter data from the content view to show relevant data."
      },
      {
        "heading": "Dynamic query",
        "depth": 3,
        "text": ""
      },
      {
        "heading": "Specific records",
        "depth": 3,
        "text": "Link the collection to specific items in your database."
      },
      {
        "heading": "Specific records",
        "depth": 3,
        "text": ""
      },
      {
        "heading": "Edit layout",
        "depth": 2,
        "text": "You can edit some of the Amplify UI collection properties directly in Studio. Changes to the layout properties (e.g. List vs. grid, direction, order, padding) are reflected in the real-time preview."
      },
      {
        "heading": "Edit layout",
        "depth": 2,
        "text": ""
      }
    ],
    "source": "export const meta = {\n  title: `Working with collections`,\n  description: `Collections`,\n};\n\nCollections are any list of repeating items. You can visually create a collection from any individual component by selecting the **Create collection** button in the top right corner of the UI component editor. All collections are generated as code with real-time subscriptions automatically set up.\n\n## Data binding\n\nAmplify Studio offers a visual way to bind collections to items in your data model. Collection items can be filtered, sorted, or linked to specific records from the content management view.\n\n1. Create a collection from a component\n2. Link collection to a data model\n3. Define a data set with either a dynamic query or specific records.\n4. Components that already have data model bindings, automatically map data to child elements. For components that do not have data model bindings, \n\n![Screenshot showing data binding](/images/console/ui-collections-databind.png)\n\n### Dynamic query\n\nA dynamic query allows you to sort and filter data from the content view to show relevant data.\n\n![Screenshot showing dynamic query binding](/images/console/ui-collections-dynamicquery.png)\n\n### Specific records\n\nLink the collection to specific items in your database.\n\n![Screenshot showing specific record binding](/images/console/ui-collections-specific.png)\n\n## Edit layout\n\nYou can edit some of the Amplify UI [collection properties](https://ui.docs.amplify.aws/react/components/collection) directly in Studio. Changes to the layout properties (e.g. List vs. grid, direction, order, padding) are reflected in the real-time preview.\n\n![Screenshot showing collection layout edit](/images/console/ui-collections-layout.png)",
    "meta": {
      "title": "Collections",
      "description": "Collections",
      "subcategory": "UI development (React)",
      "category": "Amplify Studio"
    },
    "filename": "/console/uibuilder/collections"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Amplify Studio offers the ability to bind UI component events (onClick, onChange, and more) to actions to build interactive components. Use the UI component editor to map UI components' events to actions for navigation, data manipulation, authentication, and more. All data bindings get automatically included in generated code."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Select an UI element such as a button"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Click Set onClick action on Child properties panel"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Select an action to bind it to the UI element"
      },
      {
        "heading": "Bind UI to navigation actions",
        "depth": 2,
        "text": "You can bind UI elements to navigation actions. Navigation actions include the ability to go to a URL, open a URL in a new tab, scroll to an anchor, and refresh the page."
      },
      {
        "heading": "Go to URL",
        "depth": 3,
        "text": "The \"Go to URL\" action navigates the customer to the designated URL. You can also construct the URL with dynamic data provided by the component's top-level properties."
      },
      {
        "heading": "Go to URL",
        "depth": 3,
        "text": "Select the Go to URL"
      },
      {
        "heading": "Go to URL",
        "depth": 3,
        "text": "Enter the target URL. For example: https://support.example.com"
      },
      {
        "heading": "Go to URL",
        "depth": 3,
        "text": "|Studio interface to \"Go to URL\"|Live app navigating to the URL|\n|-|-|\n| | |"
      },
      {
        "heading": "Go to URL",
        "depth": 3,
        "text": "Dynamically navigate to a specific item's URL in a collection by concatenating the item's id. In the example below, the URL is concatenated with home's id field."
      },
      {
        "heading": "Go to URL",
        "depth": 3,
        "text": ""
      },
      {
        "heading": "Open URL in new tab",
        "depth": 3,
        "text": "Select \"Open URL in new tab\" to open the target URL in a new tab. Similar to Go to URL, you can also construct the URL with dynamic data provided by the component's top-level properties."
      },
      {
        "heading": "Scroll to anchor",
        "depth": 3,
        "text": "You can bind an onClick action to scroll to a designated anchor (based on HTML's id attribute) on the page. For example, have a table of contents section that then navigates to a specific element in a UI."
      },
      {
        "heading": "Scroll to anchor",
        "depth": 3,
        "text": "Select the Scroll to anchor"
      },
      {
        "heading": "Scroll to anchor",
        "depth": 3,
        "text": "Enter lorem-ipsum as the value"
      },
      {
        "heading": "Scroll to anchor",
        "depth": 3,
        "text": "In your app code add an HTML element with id=\"lorem-ipsum\""
      },
      {
        "heading": "Scroll to anchor",
        "depth": 3,
        "text": ""
      },
      {
        "heading": "Refresh page",
        "depth": 3,
        "text": "Select \"Refresh\" to execute a browser refresh of the current page."
      },
      {
        "heading": "Bind UI to create, update, or delete a data record",
        "depth": 2,
        "text": "You can bind UI elements to data actions. Data actions include the ability to create, update, and delete records from your database."
      },
      {
        "heading": "Bind UI to create, update, or delete a data record",
        "depth": 2,
        "text": "Make sure to mark the component as a form for accessibility."
      },
      {
        "heading": "Bind UI to create, update, or delete a data record",
        "depth": 2,
        "text": "Select the top element from the element tree"
      },
      {
        "heading": "Bind UI to create, update, or delete a data record",
        "depth": 2,
        "text": "Add a new child property named as"
      },
      {
        "heading": "Bind UI to create, update, or delete a data record",
        "depth": 2,
        "text": "Set the value to form"
      },
      {
        "heading": "Bind UI to create, update, or delete a data record",
        "depth": 2,
        "text": "This will render the component within an HTML <form /> element."
      },
      {
        "heading": "Create a record in database",
        "depth": 3,
        "text": "You can create a new record based on the values provided by input fields. For example, you have a form to create a new \"Home\" for a rental listing site. The form contains inputs for the address, price, and an image URL."
      },
      {
        "heading": "Create a record in database",
        "depth": 3,
        "text": "Select the \"Submit\" button element"
      },
      {
        "heading": "Create a record in database",
        "depth": 3,
        "text": "Add an onClick action to the element"
      },
      {
        "heading": "Create a record in database",
        "depth": 3,
        "text": "Choose the \"Create\" data action"
      },
      {
        "heading": "Create a record in database",
        "depth": 3,
        "text": "Select the database model to create a record for"
      },
      {
        "heading": "Create a record in database",
        "depth": 3,
        "text": "Map the model fields to input values"
      },
      {
        "heading": "Create a record in database",
        "depth": 3,
        "text": ""
      },
      {
        "heading": "Create a record in database",
        "depth": 3,
        "text": "Render the component with the \"Create\" data action. Pro tip: Amplify Studio's collection components synchronizes data in real-time. If a new record is available in the database, it will automatically sync to the app."
      },
      {
        "heading": "Create a record in database",
        "depth": 3,
        "text": ""
      },
      {
        "heading": "Update a record from database",
        "depth": 3,
        "text": "You can update an existing record using the \"Update\" data action. For example, users can click on a home in a collection and update its values with a form."
      },
      {
        "heading": "Update a record from database",
        "depth": 3,
        "text": "Select the \"Submit\" button element"
      },
      {
        "heading": "Update a record from database",
        "depth": 3,
        "text": "Add an onClick action to the element"
      },
      {
        "heading": "Update a record from database",
        "depth": 3,
        "text": "Choose the \"Update\" data action"
      },
      {
        "heading": "Update a record from database",
        "depth": 3,
        "text": "Select the database model to create a record for"
      },
      {
        "heading": "Update a record from database",
        "depth": 3,
        "text": "Enter the ID of the record to update"
      },
      {
        "heading": "Update a record from database",
        "depth": 3,
        "text": "Map the model fields to input values"
      },
      {
        "heading": "Update a record from database",
        "depth": 3,
        "text": ""
      },
      {
        "heading": "Update a record from database",
        "depth": 3,
        "text": "Use the overrideItems property in collections to configure an onClick handler to select a home to update. Optionally, configure the form's placeholder values to be the current home value."
      },
      {
        "heading": "Update a record from database",
        "depth": 3,
        "text": "Pro tip: Amplify Studio's collection components synchronizes data in real-time. If a record is updated in the database, it will automatically sync to the app."
      },
      {
        "heading": "Update a record from database",
        "depth": 3,
        "text": ""
      },
      {
        "heading": "Delete a record from database",
        "depth": 3,
        "text": "You can delete a new record based on a model's ID field. For example, if you have a modal to delete a \"Home\" from a rental listing site."
      },
      {
        "heading": "Delete a record from database",
        "depth": 3,
        "text": "Select the \"Delete\" button element"
      },
      {
        "heading": "Delete a record from database",
        "depth": 3,
        "text": "Add an onClick action to the element"
      },
      {
        "heading": "Delete a record from database",
        "depth": 3,
        "text": "Choose the \"Delete\" data action"
      },
      {
        "heading": "Delete a record from database",
        "depth": 3,
        "text": "Select the database model to delete from"
      },
      {
        "heading": "Delete a record from database",
        "depth": 3,
        "text": "Map the ID value to a property"
      },
      {
        "heading": "Delete a record from database",
        "depth": 3,
        "text": ""
      },
      {
        "heading": "Delete a record from database",
        "depth": 3,
        "text": "In your app code, you can set an onClick handler for Home collections to show the delete modal. Then, set the DeleteHome component's home property to configure which home to delete. You can also listen in to the ui Hub events to dismiss the modal after the record is deleted."
      },
      {
        "heading": "Delete a record from database",
        "depth": 3,
        "text": ""
      },
      {
        "heading": "Bind UI event to modify another UI element",
        "depth": 2,
        "text": "Use the element modification action binding to introduce more UI-level interactivity for your components. For example, you can configure hover effects, trigger color changes when a user clicks on an element, or toggle visibility on other elements based on user interactions. To add a hover effect to an element:"
      },
      {
        "heading": "Bind UI event to modify another UI element",
        "depth": 2,
        "text": "Set the \"onMouseEnter\" property"
      },
      {
        "heading": "Bind UI event to modify another UI element",
        "depth": 2,
        "text": "Select \"Modify element property\""
      },
      {
        "heading": "Bind UI event to modify another UI element",
        "depth": 2,
        "text": "Select the component you want to modify"
      },
      {
        "heading": "Bind UI event to modify another UI element",
        "depth": 2,
        "text": "Select the \"backgroundColor\" as an example"
      },
      {
        "heading": "Bind UI event to modify another UI element",
        "depth": 2,
        "text": "Update the desired background color value"
      },
      {
        "heading": "Bind UI event to modify another UI element",
        "depth": 2,
        "text": "Repeat with \"onMouseLeave\" property to reset the background value"
      },
      {
        "heading": "Bind UI event to modify another UI element",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Bind UI to \"sign out\" actions",
        "depth": 2,
        "text": "Use the \"Sign out\" actions to sign out the user from the app. Choose to either sign out from the current device or across all devices, also known as global sign out."
      },
      {
        "heading": "Bind UI to \"sign out\" actions",
        "depth": 2,
        "text": "Select the \"Sign out\" button element"
      },
      {
        "heading": "Bind UI to \"sign out\" actions",
        "depth": 2,
        "text": "Add an onClick action to the element"
      },
      {
        "heading": "Bind UI to \"sign out\" actions",
        "depth": 2,
        "text": "Choose the \"Sign out from this device\" data action"
      },
      {
        "heading": "Bind UI to \"sign out\" actions",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Bind UI to \"sign out\" actions",
        "depth": 2,
        "text": "The sign out actions work in combination with the Authenticator component. When you sign out, the Authenticator will appear to request the user to sign-in again."
      },
      {
        "heading": "Bind UI to \"sign out\" actions",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Handle UI changes after action execution",
        "depth": 2,
        "text": "In case you want to add additional business logic after an action is executed, review Add additional business logic before or after action execution. You can use this capability to dismiss a modal after a data record was created, send analytics event after action, or display loading indicators when a record is being created."
      }
    ],
    "source": "export const meta = {\n  title: `UI event handler`,\n  description: `Figma to React code with Amplify Studio`,\n};\n\nAmplify Studio offers the ability to bind UI component events (`onClick`, `onChange`, and more) to actions to build interactive components. Use the UI component editor to map UI components' events to actions for navigation, data manipulation, authentication, and more. All data bindings get automatically included in generated code.\n\n1. Select an UI element such as a button\n2. Click `Set onClick action` on **Child properties** panel\n3. Select an action to bind it to the UI element\n\n## Bind UI to navigation actions\n\nYou can bind UI elements to navigation actions. Navigation actions include the ability to go to a URL, open a URL in a new tab, scroll to an anchor, and refresh the page.\n\n### Go to URL\n\nThe \"Go to URL\" action navigates the customer to the designated URL. You can also construct the URL with dynamic data provided by the component's top-level properties.\n\n1. Select the `Go to URL`\n2. Enter the target URL. For example: `https://support.example.com`\n\n|Studio interface to \"Go to URL\"|Live app navigating to the URL|\n|-|-|\n|![Studio interface to configure \"Go to URL\"](/images/console/go_to_url_studio.png) | ![Interactive website](/images/console/go_to_url_app.gif)|\n\n3. Dynamically navigate to a specific item's URL in a collection by concatenating the item's id. In the example below, the URL is concatenated with `home`'s `id` field.\n\n![Studio interface to dynamically bind URL to element ID](/images/console/go_to_url_collection.png) \n\n### Open URL in new tab\n\nSelect \"Open URL in new tab\" to open the target URL in a new tab. Similar to [Go to URL](#go-to-url), you can also construct the URL with dynamic data provided by the component's top-level properties. \n\n### Scroll to anchor\n\nYou can bind an onClick action to scroll to a designated anchor (based on HTML's `id` attribute) on the page. For example, have a table of contents section that then navigates to a specific element in a UI.\n\n1. Select the `Scroll to anchor`\n2. Enter `lorem-ipsum` as the value\n3. In your app code add an HTML element with `id=\"lorem-ipsum\"`\n\n<table>\n<tbody>\n<tr>\n  <td>\n\n```jsx\nimport { HeroLayout1 } from './ui-components'\n\n<div className=\"App\">\n  <HeroLayout1 />\n  ...\n  <div id=\"lorem-ipsum\">\n    <h2>Lorem Ipsum</h2>\n    <p>\n      Here is a description of my new feature.\n    </p>\n  </div>\n  ...\n</div>\n```\n\n</td>\n<td>\n\n![Scroll to a specific element's id](/images/console/scroll_to_anchor.gif) \n\n</td>\n</tr>\n</tbody>\n</table>\n\n\n### Refresh page\n\nSelect \"Refresh\" to execute a browser refresh of the current page.\n\n## Bind UI to create, update, or delete a data record\n\nYou can bind UI elements to data actions. Data actions include the ability to create, update, and delete records from your database. \n\n<Callout warning>\n\nMake sure to mark the component as a `form` for accessibility.\n1. Select the top element from the element tree\n2. Add a new child property named `as`\n3. Set the value to `form`\n\nThis will render the component within an HTML `<form />` element.\n\n</Callout>\n\n### Create a record in database\n\nYou can create a new record based on the values provided by input fields. For example, you have a form to create a new \"Home\" for a rental listing site. The form contains inputs for the address, price, and an image URL.\n\n<table>\n<tbody>\n<tr>\n<td>\n\n1. Select the \"Submit\" button element\n2. Add an onClick action to the element\n3. Choose the \"Create\" data action \n4. Select the database model to create a record for\n5. Map the model fields to input values\n\n</td>\n<td>\n\n\n![Studio console experience to create a record](/images/console/create_data_studio.gif)\n\n</td>\n</tr>\n</tbody>\n</table>\n\nRender the component with the \"Create\" data action. **Pro tip:** Amplify Studio's collection components synchronizes data in real-time. If a new record is available in the database, it will automatically sync to the app.\n\n```jsx\nimport { NewHomeInput, HomeCollection } from './ui-components'\n\n...\n<div>\n  <NewHomeInput />\n  <HomeCollection />\n</div>\n```\n\n![In app record create data action binding](/images/console/create_data_app.gif)\n\n### Update a record from database\n\nYou can update an existing record using the \"Update\" data action. For example, users can click on a home in a collection and update its values with a form.\n\n<table>\n  <tbody>\n<tr>\n<td>\n\n1. Select the \"Submit\" button element\n2. Add an onClick action to the element\n3. Choose the \"Update\" data action \n4. Select the database model to create a record for\n5. Enter the ID of the record to update\n6. Map the model fields to input values\n\n</td>\n<td>\n\n\n![Studio console experience to create a record](/images/console/update_data_studio.gif)\n\n</td>\n</tr>\n</tbody>\n</table>\n\nUse the `overrideItems` property in collections to configure an `onClick` handler to select a home to update. Optionally, configure the form's placeholder values to be the current home value.\n\n**Pro tip:** Amplify Studio's collection components synchronizes data in real-time. If a record is updated in the database, it will automatically sync to the app.\n\n```jsx\nimport { UpdateHome, HomeCollection } from './ui-components'\nimport { useState } from 'react'\n\n...\n\nfunction App() {\n  const [updateHome, setUpdateHome] = useState()\n  return (\n    <div>\n      <UpdateHome home={updateHome}/>\n      <HomeCollection overrideItems={({ item }) => ({\n        onClick: () => setUpdateHome(item)\n      })} />\n    </div>\n  )\n}\n```\n\n![In app record update data action binding](/images/console/update_data_app.gif)\n\n### Delete a record from database\n\nYou can delete a new record based on a model's ID field. For example, if you have a modal to delete a \"Home\" from a rental listing site.\n\n<table>\n  <tbody>\n<tr>\n<td>\n\n1. Select the \"Delete\" button element\n2. Add an onClick action to the element\n3. Choose the \"Delete\" data action \n4. Select the database model to delete from\n5. Map the ID value to a property\n\n</td>\n<td>\n\n\n![Studio console experience to create a record](/images/console/delete_data_studio.gif)\n\n</td>\n</tr>\n</tbody>\n</table>\n\nIn your app code, you can set an onClick handler for Home collections to show the delete modal. Then, set the `DeleteHome` component's `home` property to configure which home to delete. You can also listen in to the `ui` Hub events to dismiss the modal after the record is deleted. \n\n```jsx\nimport { HomeCollection, DeleteHome } from './ui-components'\nimport { Hub } from 'aws-amplify'\nimport { useState, useEffect } from 'react'\n\n...\n\nfunction App() {\n  const [showDeleteHome, setShowDeleteHome] = useState()\n  useEffect(() => {\n    Hub.listen('ui', ({ payload }) => {\n      if (payload.event === 'actions:datastore:delete:finished') {\n        setShowDeleteHome()\n      }\n    })\n  }, [setShowDeleteHome])\n\n  return (\n    <div className=\"App\">\n      <HomeCollection overrideItems={({ item }) => ({\n        onClick: () => setShowDeleteHome(item)\n      })} />\n      {showDeleteHome &&\n        <div className='modal'>\n          <DeleteHome home={showDeleteHome} />\n        </div>}\n    </div>\n  );\n}\n```\n\n![Delete a record in-app experience](/images/console/delete_data_app.gif) \n\n## Bind UI event to modify another UI element\n\nUse the element modification action binding to introduce more UI-level interactivity for your components. For example, you can configure hover effects, trigger color changes when a user clicks on an element, or toggle visibility on other elements based on user interactions. To add a hover effect to an element:\n\n1. Set the \"onMouseEnter\" property\n2. Select \"Modify element property\"\n3. Select the component you want to modify\n4. Select the \"backgroundColor\" as an example\n5. Update the desired background color value\n6. Repeat with \"onMouseLeave\" property to reset the background value\n\n![Studio experience to configure hover effects](/images/console/modify_element_studio.gif) \n\n## Bind UI to \"sign out\" actions\n\nUse the \"Sign out\" actions to sign out the user from the app. Choose to either sign out from the current device or across all devices, also known as global sign out. \n\n<table>\n<tbody>\n<tr>\n<td>\n\n1. Select the \"Sign out\" button element\n2. Add an onClick action to the element\n3. Choose the \"Sign out from this device\" data action \n\n</td>\n<td>\n\n\n![Studio console experience to configure a sign out action](/images/console/sign_out_studio.gif)\n\n</td>\n</tr>\n</tbody>\n</table>\n\nThe sign out actions work in combination with the [`Authenticator` component](https://ui.docs.amplify.aws/react/components/authenticator). When you sign out, the Authenticator will appear to request the user to sign-in again.\n\n```jsx\nimport { withAuthenticator } from '@aws-amplify/ui-react'\nimport { UserInfo } from './ui-components'\n\nfunction App() {\n  return <UserInfo />\n}\n\nexport default withAuthenticator(App);\n```\n\n![Sign out experience in-app](/images/console/sign_out_app.gif) \n\n## Handle UI changes after action execution\n\nIn case you want to add additional business logic after an action is executed, review [Add additional business logic before or after action execution](/console/uibuilder/override/#add-business-logic-during-or-after-action-execution). You can use this capability to dismiss a modal after a data record was created, send analytics event after action, or display loading indicators when a record is being created.\n",
    "meta": {
      "title": "UI event handler",
      "description": "Figma to React code with Amplify Studio",
      "subcategory": "UI development (React)",
      "category": "Amplify Studio"
    },
    "filename": "/console/uibuilder/eventhandling"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Amplify Studio offers visual data binding capabilities to bind UI components to data to build dynamic components. Use the UI component editor to map fields to static values, or map fields to your backend data model. All data bindings get automatically included in generated code."
      },
      {
        "heading": "UI component editor",
        "depth": 2,
        "text": "The UI component editor allows you to bind elements in your component to actual data."
      },
      {
        "heading": "UI component editor",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "1. Elements tree",
        "depth": 3,
        "text": "The elements tree shows the composition of the component in Figma. Each layer in Figma maps to a specific Amplify UI primitive. For example, a frame in Figma maps to a <Flex> component in the Amplify UI library. Clicking on a layer will highlight the element in the live preview."
      },
      {
        "heading": "2. Live component preview",
        "depth": 3,
        "text": "The live preview is a representation of the React component! If you inspect the component in the browser developer tools, you will see that each element in the component maps to real code. Click on any element within a component to select a specific child component. This will highlight the layer in the elements tree as well as bring up all relevant child properties for that component."
      },
      {
        "heading": "3. Component properties",
        "depth": 3,
        "text": "Just like in React, you can set props on your parent component. React components use props to communicate with each other. Every parent component can pass some information to its child components by giving them props. To learn more about React props visit their documentation. Amplify Studio supports Scalar (String, Number, Boolean) and Data model component types."
      },
      {
        "heading": "4. Child properties",
        "depth": 3,
        "text": "Clicking on any child elements within the live preview allows you to set child prop values. You can either set static values or pass prop values from the parent component. Child props will map to props available on the UI primitives. For example, if you select a <Button> component, you will be able to set props such as variation, size and see the live preview update with the values."
      },
      {
        "heading": "5. Component controls",
        "depth": 3,
        "text": "You can perform the following actions on a component:"
      },
      {
        "heading": "5. Component controls",
        "depth": 3,
        "text": "Edit component in Figma: This will deep link you into the Figma file to edit the component."
      },
      {
        "heading": "5. Component controls",
        "depth": 3,
        "text": "Shuffle preview data: When you bind UI to static data or data from data models, use shuffle preview to see how your component renders with different data.\n"
      },
      {
        "heading": "5. Component controls",
        "depth": 3,
        "text": "Create collection: Create a collection out of a component. Learn more."
      },
      {
        "heading": "5. Component controls",
        "depth": 3,
        "text": "Get component code: Use this React component in your app."
      },
      {
        "heading": "Bind UI to data from data models",
        "depth": 2,
        "text": "You need to deploy a data model in order to bind to data. Clone the Home example."
      },
      {
        "heading": "Bind UI to data from data models",
        "depth": 2,
        "text": "With Amplify Studio you can bind elements in your UI component to actual backend data from your database by passing component properties with a Data model type down to the child elements."
      },
      {
        "heading": "Bind UI to data from data models",
        "depth": 2,
        "text": "Add Component property named foo. Reference your data model (e.g. Home) as the type."
      },
      {
        "heading": "Bind UI to data from data models",
        "depth": 2,
        "text": "Click on an image child element in your UI component."
      },
      {
        "heading": "Bind UI to data from data models",
        "depth": 2,
        "text": "Choose Set prop for child properties. From the Prop dropdown, choose src, and for value, link to home.image_url.\nThe live preview should update to an image from your database. Continue to repeat the same steps for different child elements such as text fields, inputs etc."
      },
      {
        "heading": "Bind UI to data from data models",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Bind UI to static data",
        "depth": 2,
        "text": "You can bind text labels to static values. Use one of the following two methods to bind UI elements to static values."
      },
      {
        "heading": "Pass component property default value to child props",
        "depth": 3,
        "text": "The following example demonstrates how to set the text label's value to the component's default value."
      },
      {
        "heading": "Pass component property default value to child props",
        "depth": 3,
        "text": "Add a Component property named foo of type String with a default value of Hello world."
      },
      {
        "heading": "Pass component property default value to child props",
        "depth": 3,
        "text": "Click on a text child element in your UI component."
      },
      {
        "heading": "Pass component property default value to child props",
        "depth": 3,
        "text": "Choose Set prop for child properties. From the Prop dropdown, choose label and for value, link to foo.\nThe live preview should update to display \"Hello world\"."
      },
      {
        "heading": "Pass component property default value to child props",
        "depth": 3,
        "text": ""
      },
      {
        "heading": "Directly set child props",
        "depth": 3,
        "text": "You can directly set child prop values with all available properties. In the following example, we are setting the label prop to \"Explore\" and the color prop to \"orange\"."
      },
      {
        "heading": "Directly set child props",
        "depth": 3,
        "text": ""
      },
      {
        "heading": "Apply modifiers",
        "depth": 2,
        "text": "Modifiers let you apply custom logic to renders child prop values."
      },
      {
        "heading": "Conditionals",
        "depth": 3,
        "text": "You can apply conditional logic on values of child props. The following example demonstrates how you can conditionally set the value of a child prop based on custom logic."
      },
      {
        "heading": "Conditionals",
        "depth": 3,
        "text": ""
      },
      {
        "heading": "Concatenations",
        "depth": 3,
        "text": "You can apply concatenations on values of child props. The following example demonstrates how to add a $ sign before displaying a price."
      },
      {
        "heading": "Concatenations",
        "depth": 3,
        "text": ""
      }
    ],
    "source": "export const meta = {\n  title: `Data binding`,\n  description: `Figma to React code with Amplify Studio`,\n};\n\nAmplify Studio offers visual data binding capabilities to bind UI components to data to build dynamic components. Use the UI component editor to map fields to static values, or map fields to your backend data model. All data bindings get automatically included in generated code.\n\n## UI component editor\n\nThe UI component editor allows you to bind elements in your component to actual data. \n\n![Screenshot showing UI component editor](/images/console/ui-component-editor.png)\n\n### 1. Elements tree\nThe elements tree shows the composition of the component in Figma. Each layer in Figma maps to a specific Amplify UI primitive. For example, a frame in Figma maps to a [`<Flex>`](https://ui.docs.amplify.aws/react/components/flex) component in the Amplify UI library. Clicking on a layer will highlight the element in the live preview.\n\n### 2. Live component preview\nThe live preview is a representation of the React component! If you inspect the component in the browser developer tools, you will see that each element in the component maps to real code. Click on any element within a component to select a specific child component. This will highlight the layer in the elements tree as well as bring up all relevant child properties for that component.\n\n### 3. Component properties\nJust like in React, you can set props on your parent component. React components use props to communicate with each other. Every parent component can pass some information to its child components by giving them props. To learn more about React props visit their [documentation](https://beta.reactjs.org/learn/passing-props-to-a-component). Amplify Studio supports Scalar (String, Number, Boolean) and Data model component types. \n\n### 4. Child properties\nClicking on any child elements within the live preview allows you to set child prop values. You can either set static values or pass prop values from the parent component. Child props will map to props available on the UI primitives. For example, if you select a [`<Button>`](https://ui.docs.amplify.aws/react/components/button) component, you will be able to set props such as `variation`, `size` and see the live preview update with the values. \n\n### 5. Component controls\nYou can perform the following actions on a component:\n1. **Edit component in Figma**: This will deep link you into the Figma file to edit the component.\n2. **Shuffle preview data**: When you bind UI to static data or data from data models, use shuffle preview to see how your component renders with different data.\n  ![shuffle](/images/console/ui-shuffle.gif)\n3. **Create collection**: Create a collection out of a component. [Learn more](/console/uibuilder/collections).\n4. **Get component code**: Use this React component in your app.\n\n## Bind UI to data from data models\n\n<Callout>\n\nYou need to deploy a data model in order to bind to data. [Clone the Home example](https://sandbox.amplifyapp.com/schema-design/a66f071a-4eea-4277-8d03-a851f2a08e79/clone).\n\n</Callout>\n\nWith Amplify Studio you can bind elements in your UI component to actual backend data from your database by passing component properties with a Data model type down to the child elements.\n\n1. Add Component property named `foo`. Reference your data model (e.g. `Home`) as the type.\n2. Click on an image child element in your UI component.\n3. Choose **Set prop** for child properties. From the **Prop** dropdown, choose `src`, and for value, link to `home.image_url`.\nThe live preview should update to an image from your database. Continue to repeat the same steps for different child elements such as text fields, inputs etc.\n\n![GIF showing how to bind a UI element to data](/images/console/ui-databind.gif)\n\n## Bind UI to static data\n\nYou can bind text labels to static values. Use one of the following two methods to bind UI elements to static values.\n\n### Pass component property default value to child props\nThe following example demonstrates how to set the text label's value to the component's default value.\n1. Add a Component property named `foo` of type `String` with a default value of `Hello world`.\n2. Click on a text child element in your UI component.\n3. Choose **Set prop** for child properties. From the **Prop** dropdown, choose `label` and for value, link to `foo`.\nThe live preview should update to display \"Hello world\".\n\n![Screenshot showing static data binding](/images/console/ui-staticbind.png)\n\n### Directly set child props\nYou can directly set child prop values with all available properties. In the following example, we are setting the `label` prop to \"Explore\" and the `color` prop to \"orange\".\n\n![Screenshot showing static data binding](/images/console/ui-staticbind2.png)\n\n\n## Apply modifiers\n\nModifiers let you apply custom logic to renders child prop values.\n\n### Conditionals \n\nYou can apply conditional logic on values of child props. The following example demonstrates how you can conditionally set the value of a child prop based on custom logic.\n\n![conditional](/images/console/ui-conditional.png)\n\n### Concatenations\n\nYou can apply concatenations on values of child props. The following example demonstrates how to add a `$` sign before displaying a price.\n\n![concatenation](/images/console/ui-concat.png)\n",
    "meta": {
      "title": "Data binding",
      "description": "Figma to React code with Amplify Studio",
      "subcategory": "UI development (React)",
      "category": "Amplify Studio"
    },
    "filename": "/console/uibuilder/databinding"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Amplify Studio offers an integration with Figma, allowing you to generate clean React code by importing your Figma design file. Figma is a browser-based UI and UX design application that is used to build high-fidelity designs. In the standard product development lifecycle, UI or UX designers build mockups that get implemented as code by developers. Amplify Studio automatically converts any Figma component in your Figma file to a React component that is then usable in your app."
      },
      {
        "heading": "Step 1: Set up Figma file",
        "depth": 2,
        "text": "To get started, all you have to do is link your Studio project to a Figma file. While you can link any Figma file to Studio, for the best end to end experience, we recommend starting with our Figma file. To get started from scratch, duplicate our Figma UI file."
      },
      {
        "heading": "Step 1: Set up Figma file",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Step 1: Set up Figma file",
        "depth": 2,
        "text": "This file contains the following pages:"
      },
      {
        "heading": "Step 1: Set up Figma file",
        "depth": 2,
        "text": "README: The README page explains how to use the Figma file to create new components, theme primitives, and customize layout and styling."
      },
      {
        "heading": "Step 1: Set up Figma file",
        "depth": 2,
        "text": "Primitives: Primitives are building-block components such as alerts, buttons, and badges. These primitives correspond to the Amplify UI primitives and get exported to code with all the primitive properties."
      },
      {
        "heading": "Step 1: Set up Figma file",
        "depth": 2,
        "text": "My components: This page contains all of the custom components built using the primitives. Amplify provides dozens of components such as news feed, social media, and marketing hero components to get you started. Customize these to match your needs or build your own components."
      },
      {
        "heading": "Step 1: Set up Figma file",
        "depth": 2,
        "text": "Examples: This is for demonstration purposes only, to show designers how to use our components to build entire pages."
      },
      {
        "heading": "Step 1: Set up Figma file",
        "depth": 2,
        "text": "Please follow the README in our Figma file to learn how to create your components to optimize for code quality."
      },
      {
        "heading": "Step 2: Link Figma file in Studio",
        "depth": 2,
        "text": "In Amplify Studio, enter the URL for the Figma file you just created (or duplicated). You will be asked to authenticate with Figma."
      },
      {
        "heading": "Step 2: Link Figma file in Studio",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Step 2: Link Figma file in Studio",
        "depth": 2,
        "text": "After authenticating with Figma, you will see a list of components that you can sync. Choose Accept all to import all components, or walkthrough them one-by-one to make sure they are visually acceptable. Once you complete the sync, you should see a list of components that have been imported. All previews of the components are live renders of the actual coded components. Open your dev tools inspector to check it out!"
      },
      {
        "heading": "Step 2: Link Figma file in Studio",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Step 3: Pull UI components code in your project",
        "depth": 2,
        "text": "In Studio, pick a component and choose Configure to get to the component editor screen. Choose Get component code at the bottom of the page."
      },
      {
        "heading": "Step 3: Pull UI components code in your project",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Step 3: Pull UI components code in your project",
        "depth": 2,
        "text": "Go to the Initial project setup tab and follow the setup instructions."
      },
      {
        "heading": "Step 3: Pull UI components code in your project",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Step 3: Pull UI components code in your project",
        "depth": 2,
        "text": "Amplify generates all UI component code into src/ui-components, as JSX and TS files. All generated code is built with primitives from the Amplify UI library. Although you have access to inspect the component code, you cannot modify it directly as we will override any changes on the next amplify pull."
      },
      {
        "heading": "Step 3: Pull UI components code in your project",
        "depth": 2,
        "text": "Once that is done, you can use the components anywhere in your app. Learn how to customize these UI components in code."
      },
      {
        "heading": "Upgrading Figma files",
        "depth": 2,
        "text": "Duplicate the new Figma community file into your Figma account.\n"
      },
      {
        "heading": "Upgrading Figma files",
        "depth": 2,
        "text": "(optional) Delete all the components in the 'My Components' page of the new Figma file."
      },
      {
        "heading": "Upgrading Figma files",
        "depth": 2,
        "text": "Copy everything in the 'My Components' page of your old Figma file and paste it into the 'My Components' page of the new Figma file."
      },
      {
        "heading": "Upgrading Figma files",
        "depth": 2,
        "text": "Go through each component on the 'My Components' page and update the broken component instances to point to the local components on the 'Primitives' page. Unfortunately, there is no easy way to bulk update component instances in Figma. This is important because if you do not do this, your design might look ok, but the React code it generates won't use the Amplify UI components.\n"
      },
      {
        "heading": "1.2.0: July 25 2022",
        "depth": 4,
        "text": "Update supported Amplify UI React version to 3.1.0."
      },
      {
        "heading": "1.2.0: July 25 2022",
        "depth": 4,
        "text": "Add TextAreaField primitive component. You can change any existing TextField into a TextAreaField by selecting the desired TextField instance and choosing \"TextAreaField\" under the Swap Instance dropdown.\n"
      },
      {
        "heading": "1.0.0: March 2 2022",
        "depth": 4,
        "text": "Fixing primitive component layer names to map properly to React props."
      },
      {
        "heading": "1.0.0: March 2 2022",
        "depth": 4,
        "text": "Removing the Icon primitive and adding a custom Icon component. This change allows for easier icon customization."
      },
      {
        "heading": "1.0.0: March 2 2022",
        "depth": 4,
        "text": "Fixing visual discrepancies between Figma file and React components."
      },
      {
        "heading": "1.0.0: March 2 2022",
        "depth": 4,
        "text": "Re-organizing primitive component variants to make the default variant more expected. For example, default size and default variation of the button instead of the primary variation."
      },
      {
        "heading": "1.0.0: March 2 2022",
        "depth": 4,
        "text": "Adding version number to the Figma file"
      }
    ],
    "source": "export const meta = {\n  title: \"Figma to code\",\n  description: \"Figma to React code with Amplify Studio\",\n};\n\nAmplify Studio offers an integration with Figma, allowing you to generate clean React code by importing your Figma design file. [Figma](https://figma.com/) is a browser-based UI and UX design application that is used to build high-fidelity designs. In the standard product development lifecycle, UI or UX designers build mockups that get implemented as code by developers. Amplify Studio automatically converts any [Figma component](https://help.figma.com/hc/en-us/articles/360038662654-Guide-to-Components-in-Figma) in your Figma file to a [React component](https://reactjs.org/docs/components-and-props.html) that is then usable in your app.\n\n## Step 1: Set up Figma file\n\nTo get started, all you have to do is link your Studio project to a Figma file. While you can link any Figma file to Studio, for the best end to end experience, we recommend starting with our Figma file. To get started from scratch, **[duplicate our Figma UI file](https://www.figma.com/community/file/1047600760128127424)**.\n\n![figma](/images/console/ui-figma-file.png)\n\nThis file contains the following pages:\n\n- **README**: The README page explains how to use the Figma file to create new components, theme primitives, and customize layout and styling.\n- **Primitives**: Primitives are building-block components such as alerts, buttons, and badges. These primitives correspond to the [Amplify UI primitives](https://ui.docs.amplify.aws/react/components) and get exported to code with all the primitive properties.\n- **My components**: This page contains all of the custom components built using the primitives. Amplify provides dozens of components such as news feed, social media, and marketing hero components to get you started. Customize these to match your needs or build your own components.\n- **Examples**: This is for demonstration purposes only, to show designers how to use our components to build entire pages.\n\nPlease follow the README in our Figma file to learn how to create your components to optimize for code quality.\n\n## Step 2: Link Figma file in Studio\n\nIn Amplify Studio, enter the URL for the Figma file you just created (or duplicated). You will be asked to authenticate with Figma.\n\n![figma](/images/console/ui-figma-to-studio.png)\n\nAfter authenticating with Figma, you will see a list of components that you can sync. Choose **Accept all** to import all components, or walkthrough them one-by-one to make sure they are visually acceptable. Once you complete the sync, you should see a list of components that have been imported. All previews of the components are live renders of the actual coded components. Open your dev tools inspector to check it out!\n\n![figma](/images/console/ui-figma-sync.png)\n\n## Step 3: Pull UI components code in your project\n\nIn Studio, pick a component and choose **Configure** to get to the component editor screen. Choose **Get component code** at the bottom of the page.\n\n![figma](/images/console/ui-getcomponent-code.png)\n\nGo to the **Initial project setup** tab and follow the setup instructions.\n\n![figma](/images/console/ui-getcomponent-code2.png)\n\nAmplify generates all UI component code into `src/ui-components`, as JSX and TS files. All generated code is built with primitives from the Amplify UI library. Although you have access to inspect the component code, you cannot modify it directly as we will override any changes on the next `amplify pull`.\n\nOnce that is done, you can use the components anywhere in your app. Learn how to **[customize these UI components in code](/console/uibuilder/override)**.\n\n```\nimport { ComponentA, ComponentB }  from './ui-components';\n\n```\n\n## Upgrading Figma files\n\n1. Duplicate the new [Figma community file](https://www.figma.com/community/file/1047600760128127424) into your Figma account.\n![Duplicate the new figma file](/images/console/ui-figma-file.png)\n1. (optional) Delete all the components in the 'My Components' page of the new Figma file.\n1. Copy everything in the 'My Components' page of your old Figma file and paste it into the 'My Components' page of the new Figma file.\n1. Go through each component on the 'My Components' page and update the broken component instances to point to the local components on the 'Primitives' page. Unfortunately, there is no easy way to bulk update component instances in Figma. **This is important because if you do not do this, your design might look ok, but the React code it generates won't use the [Amplify UI components](https://ui.docs.amplify.aws).**\n![Reattach figma components](/images/console/figma-upgrade-reattach.gif)\n\n\n### Figma file changelog\n\n#### 1.2.0: July 25 2022\n\n* Update supported Amplify UI React version to 3.1.0.\n* Add TextAreaField primitive component. You can change any existing TextField into a TextAreaField by selecting the desired TextField instance and choosing \"TextAreaField\" under the Swap Instance dropdown.\n![Convert TextField to TextArea](/images/console/ui-figma-textfield-to-textarea.gif)\n\n#### 1.0.0: March 2 2022\n\n* Fixing primitive component layer names to map properly to React props.\n* Removing the Icon primitive and adding a custom Icon component. This change allows for easier icon customization.\n* Fixing visual discrepancies between Figma file and React components.\n* Re-organizing primitive component variants to make the default variant more expected. For example, default size and default variation of the button instead of the primary variation.\n* Adding version number to the Figma file\n",
    "meta": {
      "title": "Figma to code",
      "description": "Figma to React code with Amplify Studio",
      "subcategory": "UI development (React)",
      "category": "Amplify Studio"
    },
    "filename": "/console/uibuilder/figmatocode"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "The generated UI components accept properties available on the \"Flex\" component or properties available on the \"Collection\" component."
      },
      {
        "heading": null,
        "depth": null,
        "text": "For example, to make a component go full width you can use all the properties available on an Amplify UI “Flex” component. In this case, I've set width={“100vw”} for the NavBar and the MarketingFooter, so it scales with my browser window size. We can also enable pagination for NewHomes by setting the isPaginated and itemsPerPage properties."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Now, you can change the window size and also paginate through the collection as well."
      },
      {
        "heading": null,
        "depth": null,
        "text": ""
      },
      {
        "heading": null,
        "depth": null,
        "text": "There are many more customizations you can apply in code such as applying overrides to child elements, setting up onClick handlers for collection items, or set hover states on icons. Review Extend via Code in the Amplify Studio documentation."
      }
    ],
    "source": "export const meta = {\n  title: `Write app code`,\n  description: `Create a database and GraphQL API.`,\n};\n\nThe generated UI components accept properties available on the [\"Flex\" component](https://ui.docs.amplify.aws/react/components/flex) or properties available on the [\"Collection\" component](https://ui.docs.amplify.aws/react/components/collection).\n\nFor example, to make a component go full width you can use all the properties available on an Amplify UI “Flex” component. In this case, I've set `width={“100vw”}` for the `NavBar` and the `MarketingFooter`, so it scales with my browser window size. We can also enable pagination for `NewHomes` by setting the `isPaginated` and `itemsPerPage` properties.\n\n```js\nimport './App.css';\nimport { NewHomes, NavBar, MarketingFooter } from './ui-components'\n\nfunction App() {\n  return (\n    <div className=\"App\">\n      <NavBar width={\"100vw\"}/>\n      <NewHomes isPaginated itemsPerPage={3}/>\n      <MarketingFooter width={\"100vw\"}/>\n    </div>\n  );\n}\n\nexport default App;\n```\n\nNow, you can change the window size and also paginate through the collection as well.\n\n![GIF showing responsive app](/images/studio/responsive.gif)\n\nThere are many more customizations you can apply in code such as applying overrides to child elements, setting up onClick handlers for collection items, or set hover states on icons. Review [Extend via Code](/console/uibuilder/override) in the Amplify Studio documentation.",
    "meta": {
      "title": "Write React code",
      "description": "Create a database and GraphQL API.",
      "subcategory": "Tutorial",
      "category": "Amplify Studio"
    },
    "filename": "/console/tutorial/code"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Amplify Studio also allows you to build lists and grids based on individual UI components. Let's create a \"NewHomes\" grid that showcases the latest homes added to the app."
      },
      {
        "heading": "Create a collection",
        "depth": 2,
        "text": "To get started, choose the Create collection button in the top right corner in the UI component editor."
      },
      {
        "heading": "Create a collection",
        "depth": 2,
        "text": "Specify a name for the new collection component, or use the default name provided by Studio. For this example, we'll name the collection NewHomes."
      },
      {
        "heading": "Modify collection styling",
        "depth": 2,
        "text": "On the left side of the component editor, you can modify all the style settings for your collection. In our case, we'll choose a grid and apply column and margin settings to add spacing between the items."
      },
      {
        "heading": "Modify collection styling",
        "depth": 2,
        "text": "Select Grid as the Type"
      },
      {
        "heading": "Modify collection styling",
        "depth": 2,
        "text": "Change Columns to 3"
      },
      {
        "heading": "Modify collection styling",
        "depth": 2,
        "text": "Add Padding to 10px on all sides"
      },
      {
        "heading": "Modify collection styling",
        "depth": 2,
        "text": "Your collection should look similar to the following:"
      },
      {
        "heading": "Modify collection styling",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Modify collection data",
        "depth": 2,
        "text": "Next, let's populate the list with all recently created homes. By default, Amplify Studio renders collections with all records from the specified model. For our example, we will apply a sort condition to sort the records by the most recently created homes."
      },
      {
        "heading": "Modify collection data",
        "depth": 2,
        "text": "Modify the rendered data set by choosing View/Edit on the panel on the right side. Then choose Add sort and select createdAt and Descending as the sort condition."
      },
      {
        "heading": "Modify collection data",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Modify collection data",
        "depth": 2,
        "text": "Once configured, choose Create data set to display your collection sorted by the most recently created time stamp."
      },
      {
        "heading": "Use a collection in your app",
        "depth": 2,
        "text": "Similar to individual components, choose Get component code to get your React code for the collection."
      },
      {
        "heading": "Use a collection in your app",
        "depth": 2,
        "text": "Run amplify pull to sync all your components, including the NewHomes collection, into your local ./ui-components folder."
      },
      {
        "heading": "Use a collection in your app",
        "depth": 2,
        "text": "Import the NewHomes collection from ./ui-components and then render it in your React app. For example:"
      }
    ],
    "source": "export const meta = {\n  title: `Collections`,\n  description: `Figma to React code with Amplify Studio`,\n};\n\nAmplify Studio also allows you to build lists and grids based on individual UI components. Let's create a \"NewHomes\" grid that showcases the latest homes added to the app.\n\n## Create a collection\nTo get started, choose the **Create collection** button in the top right corner in the UI component editor.\n\nSpecify a name for the new collection component, or use the default name provided by Studio. For this example, we'll name the collection `NewHomes`.\n\n## Modify collection styling\n\nOn the left side of the component editor, you can modify all the style settings for your collection. In our case, we'll choose a grid and apply column and margin settings to add spacing between the items.\n\n1. Select **Grid** as the *Type*\n2. Change *Columns* to **3**\n3. Add *Padding* to **10px** on all sides\n\nYour collection should look similar to the following:\n\n![Screenshot of collection stylings applied](/images/studio/collection-layout.png)\n\n## Modify collection data\n\nNext, let's populate the list with all recently created homes. By default, Amplify Studio renders collections with all records from the specified model. For our example, we will apply a sort condition to sort the records by the most recently created homes.\n\nModify the rendered data set by choosing **View/Edit** on the panel on the right side. Then choose **Add sort** and select **createdAt** and **Descending** as the sort condition.\n\n![Screenshot of collection data applied](/images/studio/collection-data.png)\n\nOnce configured, choose **Create data set** to display your collection sorted by the most recently created time stamp.\n\n## Use a collection in your app\n\nSimilar to individual components, choose **Get component code** to get your React code for the collection.\n\nRun `amplify pull` to sync all your components, including the `NewHomes` collection, into your local `./ui-components` folder.\n\nImport the `NewHomes` collection from `./ui-components` and then render it in your React app. For example:\n\n```js\nimport { NewHomes } from './ui-components'\n...\n  return <div>\n    <NewHomes />\n  </div>\n...\n```",
    "meta": {
      "title": "Collections",
      "description": "Figma to React code with Amplify Studio",
      "subcategory": "Tutorial",
      "category": "Amplify Studio"
    },
    "filename": "/console/tutorial/collections"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Studio also allows you to bind UI elements to real backend data. Add properties to components, then reference the properties in your child UI elements. To get started, navigate into a UI component by choosing the Configure button in the UI Library. For this example, we'll use the CardB component."
      },
      {
        "heading": "Add a component property",
        "depth": 2,
        "text": "To add a property, choose Add prop and set a name for your property. For this example, create a new property called home with the type Home."
      },
      {
        "heading": "Set child property values",
        "depth": 2,
        "text": "Select a child element such as the \"$99 USD\" Text element and choose Set prop. Here, you are able to set all available properties for that child element. Configure the label for the text element and set the value to \"Price: $\" and then select Command + Enter on your keyboard to concatenate another value such as home.price."
      },
      {
        "heading": "Set child property values",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Set child property values",
        "depth": 2,
        "text": "Bind the address text element's label to home.address and the image's src to home.image_url."
      },
      {
        "heading": "Set child property values",
        "depth": 2,
        "text": "You are also able to set traditional HTML properties through Studio. For example, hide the text element containing \"4bds 3 ba 2,530 sqft - Active\" by setting the display to none."
      },
      {
        "heading": "Shuffle preview data",
        "depth": 2,
        "text": "To see how your component scales with different data, choose the Shuffle preview data button. This selects a random record in your database and applies it as a property to preview the component."
      },
      {
        "heading": "Shuffle preview data",
        "depth": 2,
        "text": ""
      }
    ],
    "source": "export const meta = {\n  title: `Connect UI to data`,\n  description: `Figma to React code with Amplify Studio`,\n};\n\nStudio also allows you to bind UI elements to real backend data. Add properties to components, then reference the properties in your child UI elements. To get started, navigate into a UI component by choosing the **Configure** button in the **UI Library**. For this example, we'll use the *CardB* component.\n\n## Add a component property\n\nTo add a property, choose **Add prop** and set a name for your property. For this example, create a new property called `home` with the type `Home`.\n\n## Set child property values\n\nSelect a child element such as the \"$99 USD\" Text element and choose **Set prop**. Here, you are able to set all available properties for that child element. Configure the `label` for the text element and set the value to \"Price: $\" and then select *Command + Enter* on your keyboard to concatenate another value such as `home.price`.\n\n![Screenshot of UI bound to data](/images/studio/data-binding.png)\n\nBind the address text element's `label` to `home.address` and the image's `src` to `home.image_url`.\n\nYou are also able to set traditional HTML properties through Studio. For example, hide the text element containing \"4bds 3 ba 2,530 sqft - Active\" by setting the `display` to `none`.\n\n## Shuffle preview data\nTo see how your component scales with different data, choose the **Shuffle preview data** button. This selects a random record in your database and applies it as a property to preview the component.\n\n![Video of Shuffle Preview](/images/studio/shuffle-preview.gif)\n",
    "meta": {
      "title": "Bind UI to data",
      "description": "Figma to React code with Amplify Studio",
      "subcategory": "Tutorial",
      "category": "Amplify Studio"
    },
    "filename": "/console/tutorial/bindui"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Amplify Studio provides a visual way to create your app's data model and manage the contents of your database."
      },
      {
        "heading": "Create data model",
        "depth": 2,
        "text": "To get started, from the Set up menu, choose Data. On the Data modeling page, choose Add model to create your first data model. Think of a model as a table in your database."
      },
      {
        "heading": "Create data model",
        "depth": 2,
        "text": "In this case, we'll create a Home model and add a few fields like address (String), price (Float), and image_url (String)."
      },
      {
        "heading": "Create data model",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Create data model",
        "depth": 2,
        "text": "You can take this further by adding more data models to your app and creating relationships between them."
      },
      {
        "heading": "Create data model",
        "depth": 2,
        "text": "Once you're ready, choose Save and Deploy to deploy your data model to the cloud."
      },
      {
        "heading": "Create data model",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Browse and auto-generate your app data",
        "depth": 2,
        "text": "After your backend is deployed, choose Content on the Manage menu to start browsing your app data. Amplify Studio also provides a feature to auto-generate seed data to help you test your app faster."
      },
      {
        "heading": "Browse and auto-generate your app data",
        "depth": 2,
        "text": "Choose Auto-generate data from the Actions menu."
      },
      {
        "heading": "Browse and auto-generate your app data",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Browse and auto-generate your app data",
        "depth": 2,
        "text": "The auto-generate seed data functionality also allows you to set constraints to make the generated seed data more semantically accurate. In our case, set a constraint for address as \"Street address\"."
      },
      {
        "heading": "Browse and auto-generate your app data",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Browse and auto-generate your app data",
        "depth": 2,
        "text": "Five records are now created. To better showcase image support for the rest of this tutorial, select each record and modify the image_url to a publicly reachable image URL."
      }
    ],
    "source": "export const meta = {\n  title: `Model data`,\n  description: `Create a database and GraphQL API.`,\n};\n\nAmplify Studio provides a visual way to create your app's data model and manage the contents of your database.\n\n## Create data model\n\nTo get started, from the **Set up** menu, choose **Data**. On the **Data modeling** page, choose **Add model** to create your first data model. Think of a model as a table in your database.\n\nIn this case, we'll create a `Home` model and add a few fields like `address (String)`, `price (Float)`, and `image_url (String)`. \n\n![Screenshot showing the \"Add Model\" button](/images/studio/add-model.png)\n\nYou can take this further by adding more data models to your app and creating relationships between them. \n\nOnce you're ready, choose **Save and Deploy** to deploy your data model to the cloud.\n\n![Screenshot showing the \"Save and Deploy\" button](/images/studio/deploy.png)\n\n## Browse and auto-generate your app data\n\nAfter your backend is deployed, choose **Content** on the **Manage** menu to start browsing your app data. Amplify Studio also provides a feature to *auto-generate seed data* to help you test your app faster.\n\nChoose **Auto-generate data** from the **Actions** menu.\n\n![Screenshot showing the \"Auto-generate seed data\" button](/images/studio/seed-data.png)\n\nThe auto-generate seed data functionality also allows you to set constraints to make the generated seed data more semantically accurate. In our case, set a constraint for `address` as \"Street address\".\n\n![Screenshot showing the seed data constraints](/images/studio/seed-constraints.png)\n\nFive records are now created. To better showcase image support for the rest of this tutorial, select each record and modify the `image_url` to a publicly reachable image URL.",
    "meta": {
      "title": "Model database",
      "description": "Create a database and GraphQL API.",
      "subcategory": "Tutorial",
      "category": "Amplify Studio"
    },
    "filename": "/console/tutorial/data"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "With Studio’s new “UI Library”, you can sync components from Figma to React code. Amplify also provides you with a handy Figma file to get started faster. The Amplify Figma file includes both UI primitives and component templates. You can also create your own component in Figma! In this tutorial, we'll create a home listings app using Amplify Studio."
      },
      {
        "heading": "Create UI components in Figma",
        "depth": 2,
        "text": "Clone the Amplify UI Figma file\n\nThe Amplify UI Figma file provides a starting point for your app. It includes common UI primitives and pre-built UI components."
      },
      {
        "heading": "Create UI components in Figma",
        "depth": 2,
        "text": "Explore the UI primitives and templates"
      },
      {
        "heading": "Create UI components in Figma",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Create UI components in Figma",
        "depth": 2,
        "text": "Primitives are common UI components that allow you to build complete applications that fit your brand, like Buttons, Text Fields, and Badges."
      },
      {
        "heading": "Create UI components in Figma",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Create UI components in Figma",
        "depth": 2,
        "text": "Templates are Figma components that leverage the primitives to enhance your UI even further, such as Hero Cards, Profile Cards, and Product Detail Cards."
      },
      {
        "heading": "Create UI components in Figma",
        "depth": 2,
        "text": "Create a custom component in Figma"
      },
      {
        "heading": "Create UI components in Figma",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Sync components with Figma",
        "depth": 2,
        "text": "Back in Studio, choose the “Sync from Figma” button to review all the components from your Figma file."
      },
      {
        "heading": "Sync components with Figma",
        "depth": 2,
        "text": "Paste in the URL of your Figma file to start syncing. If this is your first time syncing from Figma, you need to grant Amplify Studio access to your Figma account."
      },
      {
        "heading": "Sync components with Figma",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Sync components with Figma",
        "depth": 2,
        "text": "Either choose Accept all or review individual components with the Reject and Accept buttons."
      },
      {
        "heading": "Sync components with Figma",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Use component in code",
        "depth": 2,
        "text": "Now that your components are synced, navigate to a component and choose Configure. To get your React code, choose Get component code."
      },
      {
        "heading": "Use component in code",
        "depth": 2,
        "text": "Follow the instructions in the modal. If this is your first time setting up the UI components in your app, make sure to complete Initial project setup first to install all dependencies."
      },
      {
        "heading": "Use component in code",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Use component in code",
        "depth": 2,
        "text": "Next, run amplify pull to sync all your components into your local code base. A new ui-components folder with all the UI components is created."
      },
      {
        "heading": "Use component in code",
        "depth": 2,
        "text": "Import the UI component you want from ./ui-components and then render it in your React app. For example:"
      }
    ],
    "source": "export const meta = {\n  title: `Build UI`,\n  description: `Figma to React code with Amplify Studio`,\n};\n\nWith Studio’s new “UI Library”, you can sync components from Figma to React code. Amplify also provides you with a handy Figma file to get started faster. The Amplify Figma file includes both UI primitives and component templates. You can also create your own component in Figma! In this tutorial, we'll create a home listings app using Amplify Studio.\n\n## Create UI components in Figma\n\n1. **Clone the [Amplify UI Figma file](https://www.figma.com/community/file/1047600760128127424)**\n![Screenshot showing how to sync with Figma](/images/studio/sync-with-figma.png)\nThe Amplify UI Figma file provides a starting point for your app. It includes common UI primitives and pre-built UI components.\n\n2. **Explore the UI primitives and templates**\n\n![Screenshot of Figma file showing the primitives](/images/studio/primitives.png)\n\nPrimitives are common UI components that allow you to build complete applications that fit your brand, like Buttons, Text Fields, and Badges.\n\n![Screenshot of Figma file showing the templates](/images/studio/templates.png)\n\nTemplates are Figma components that leverage the primitives to enhance your UI even further, such as Hero Cards, Profile Cards, and Product Detail Cards.\n\n3. **Create a custom component in Figma**\n\n![Video showing how to create a component in Figma](/images/studio/create-component.gif)\n\n## Sync components with Figma\n\nBack in Studio, choose the “Sync from Figma” button to review all the components from your Figma file. \n\nPaste in the URL of your Figma file to start syncing. If this is your first time syncing from Figma, you need to grant Amplify Studio access to your Figma account.\n\n![Screenshot showing where to get Figma URL](/images/studio/figma-link.png)\n\nEither choose **Accept all** or review individual components with the **Reject** and **Accept** buttons.\n\n![Screenshot showing component review when syncing with Figma](/images/studio/sync-review.png)\n\n## Use component in code\n\nNow that your components are synced, navigate to a component and choose **Configure**. To get your React code, choose **Get component code**.\n\nFollow the instructions in the modal. If this is your first time setting up the UI components in your app, make sure to complete **Initial project setup** first to install all dependencies.\n\n![Screenshot showing how to get the component code](/images/studio/get-code.png)\n\nNext, run `amplify pull` to sync all your components into your local code base. A new `ui-components` folder with all the UI components is created.\n\nImport the UI component you want from `./ui-components` and then render it in your React app. For example:\n\n```js\nimport { CardB } from './ui-components'\n...\n  return <div>\n    <CardB />\n  </div>\n...\n```",
    "meta": {
      "title": "Build UI",
      "description": "Figma to React code with Amplify Studio",
      "subcategory": "Tutorial",
      "category": "Amplify Studio"
    },
    "filename": "/console/tutorial/buildui"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "If your app is set up to use Amplify's web hosting features, you can access Amplify Studio with the custom domain for your app's frontend. For example, if you host your app at https://example.com, you can set up a friendly redirect to Studio for the app at a domain address such as https://example.com/amplify/studio."
      },
      {
        "heading": null,
        "depth": null,
        "text": "When you connect a custom domain, the process for updating the DNS settings with your third-party DNS provider varies.  For more information about connecting custom domains, see Set up custom domains in the AWS Amplify Console User Guide. That topic includes instructions for updating your DNS settings with GoDaddy, Google Domains, and Amazon Route 53."
      },
      {
        "heading": "To set up custom domain access for Studio",
        "depth": 2,
        "text": "Sign in to the AWS Management Console and open AWS Amplify."
      },
      {
        "heading": "To set up custom domain access for Studio",
        "depth": 2,
        "text": "Choose the app that you want to connect to a custom domain for Studio access."
      },
      {
        "heading": "To set up custom domain access for Studio",
        "depth": 2,
        "text": "In the navigation pane, choose App settings, Domain management."
      },
      {
        "heading": "To set up custom domain access for Studio",
        "depth": 2,
        "text": "On the Domain management page, choose Add domain."
      },
      {
        "heading": "To set up custom domain access for Studio",
        "depth": 2,
        "text": "Under Add domain, for Domain, enter your root domain, and then choose Configure domain."
      },
      {
        "heading": "To set up custom domain access for Studio",
        "depth": 2,
        "text": "At the bottom of the Add domain page, select the Set up redirects for custom domain to point to Studio checkbox."
      },
      {
        "heading": "To set up custom domain access for Studio",
        "depth": 2,
        "text": "Update the DNS management settings for your domain with your DNS provider. Note that verification of domain ownership and DNS propagation for third-party domains can take up to 48 hours."
      },
      {
        "heading": "To set up custom domain access for Studio",
        "depth": 2,
        "text": "After your app is successfully connected to your custom domain, you can access Studio at your domain address with /amplify/staging appended. For example, if your app's domain is https://example.com, by default you can access Studio at https://example.com/amplify/staging. You can also customize the domain address with a custom redirect rule."
      },
      {
        "heading": "To add a redirect rule for Studio access",
        "depth": 2,
        "text": "Sign in to the AWS Management Console and open AWS Amplify."
      },
      {
        "heading": "To add a redirect rule for Studio access",
        "depth": 2,
        "text": "Choose the app that you want to add a redirect rule to for Studio access."
      },
      {
        "heading": "To add a redirect rule for Studio access",
        "depth": 2,
        "text": "In the navigation pane, choose App settings, Amplify Studio settings."
      },
      {
        "heading": "To add a redirect rule for Studio access",
        "depth": 2,
        "text": "The Domain management section displays the redirect rules for Studio."
      },
      {
        "heading": "To add a redirect rule for Studio access",
        "depth": 2,
        "text": "Choose Manage."
      },
      {
        "heading": "To add a redirect rule for Studio access",
        "depth": 2,
        "text": "Choose Add redirect rule, and then do the following:"
      },
      {
        "heading": "To add a redirect rule for Studio access",
        "depth": 2,
        "text": "For Source, enter a custom redirect rule, for example /amplify/studio."
      },
      {
        "heading": "To add a redirect rule for Studio access",
        "depth": 2,
        "text": "For Target, select the backend environment to open Studio for, for example, staging."
      },
      {
        "heading": "To add a redirect rule for Studio access",
        "depth": 2,
        "text": "Choose Save."
      },
      {
        "heading": "To add a redirect rule for Studio access",
        "depth": 2,
        "text": "In this example, if an app is hosted at https://example.com, Studio for the staging backend is available at https://example.com/amplify/studio."
      }
    ],
    "source": "export const meta = {\n  title: `Custom domains`,\n  description: `Access Amplify Studio on a custom domain`,\n};\n\nIf your app is set up to use Amplify's web hosting features, you can access Amplify Studio with the custom domain for your app's frontend. For example, if you host your app at `https://example.com`, you can set up a friendly redirect to Studio for the app at a domain address such as `https://example.com/amplify/studio`.\n\nWhen you connect a custom domain, the process for updating the DNS settings with your third-party DNS provider varies.  For more information about connecting custom domains, see [Set up custom domains](https://docs.aws.amazon.com/amplify/latest/userguide/custom-domains.html) in the *AWS Amplify Console User Guide*. That topic includes instructions for updating your DNS settings with GoDaddy, Google Domains, and Amazon Route 53.\n\n## To set up custom domain access for Studio\n1. Sign in to the AWS Management Console and open AWS Amplify.\n2. Choose the app that you want to connect to a custom domain for Studio access.\n3. In the navigation pane, choose **App settings**, **Domain management**.\n4. On the **Domain management** page, choose **Add domain**.\n5. Under **Add domain**, for **Domain**, enter your root domain, and then choose **Configure domain**.\n6. At the bottom of the **Add domain** page, select the **Set up redirects for custom domain to point to Studio** checkbox. \n7. Update the DNS management settings for your domain with your DNS provider. Note that verification of domain ownership and DNS propagation for third-party domains can take up to 48 hours.\n\nAfter your app is successfully connected to your custom domain, you can access Studio at your domain address with `/amplify/staging` appended. For example, if your app's domain is `https://example.com`, by default you can access Studio at `https://example.com/amplify/staging`. You can also customize the domain address with a custom redirect rule. \n\n## To add a redirect rule for Studio access\n1. Sign in to the AWS Management Console and open AWS Amplify.\n2. Choose the app that you want to add a redirect rule to for Studio access.\n3. In the navigation pane, choose **App settings**, **Amplify Studio settings**.\n4. The **Domain management** section displays the redirect rules for Studio.\n5. Choose **Manage**.\n6. Choose **Add redirect rule**, and then do the following:\n  * For **Source**, enter a custom redirect rule, for example `/amplify/studio`. \n  * For **Target**, select the backend environment to open Studio for, for example, `staging`.\n7. Choose **Save**.\n\nIn this example, if an app is hosted at `https://example.com`, Studio for the `staging` backend is available at `https://example.com/amplify/studio`.\n\n",
    "meta": {
      "title": "Custom domains",
      "description": "Access Amplify Studio on a custom domain",
      "subcategory": "Basics",
      "category": "Amplify Studio"
    },
    "filename": "/console/adminui/custom-domain"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "With Amplify Studio, team members with different job functions can collaborate on different aspects of a project deployed in Amplify. Studio developers can create accounts with scoped access to resources and invite team members to join via email. Team members with Full access can create and manage AWS resources, while team members with Manage only access can edit application content and users."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Studio manages user access using an Amazon Cognito User Pool in your account. If you visit Cognito from the AWS console you should see a User Pool named amplify_backend_manager_APPID. This User Pool is managed by Studio so please do not modify the settings for this resource. You can invite up to 50,000 monthly users to Studio without cost. In order to give the Full access and Manage only groups the necessary permissions, Studio creates 2 IAM roles, namely: USERPOOLID_Full-access, and USERPOOLID_Manage-only. An Amazon Cognito Identity Pool named, amplify_backend_manager_APPID  is also created to vend AWS credentials that are tied to the Full access and Manage only groups."
      },
      {
        "heading": null,
        "depth": null,
        "text": "To provide a passwordless login experience from AWS Amplify Console to Amplify Studio, Studio creates 4 Cognito Lambda triggers (associated with the above-mentioned User Pool), namely: amplify-login-create-auth-challenge-SHORT_CODE, amplify-login-custom-message-SHORT_CODE, amplify-login-define-auth-challenge-SHORT_CODE, and amplify-login-verify-auth-challenge-SHORT_CODE."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Follow these instructions to add and manage team members and their access to a project."
      },
      {
        "heading": "To invite team members to access a project",
        "depth": 2,
        "text": "Sign in to the AWS Management Console and open AWS Amplify."
      },
      {
        "heading": "To invite team members to access a project",
        "depth": 2,
        "text": "In the navigation pane, choose Amplify Studio settings."
      },
      {
        "heading": "To invite team members to access a project",
        "depth": 2,
        "text": "On the Amplify Studio settings page, in the Access control settings section, choose Add team members."
      },
      {
        "heading": "To invite team members to access a project",
        "depth": 2,
        "text": "For Email, enter the email address of the team member to invite."
      },
      {
        "heading": "To invite team members to access a project",
        "depth": 2,
        "text": "For Access level, choose the level of access to grant the team member."
      },
      {
        "heading": "To invite team members to access a project",
        "depth": 2,
        "text": "Full access allows the team member to create and manage AWS resources."
      },
      {
        "heading": "To invite team members to access a project",
        "depth": 2,
        "text": "Manage only access allows the team member to edit app content and users."
      },
      {
        "heading": "To invite team members to access a project",
        "depth": 2,
        "text": "To email the invitation, choose Send invite. The team member receives an email with temporary credentials and a link to access the project in Studio."
      },
      {
        "heading": "To invite team members to access a project",
        "depth": 2,
        "text": "Granting a user the Full Access level attaches the AdministratorAccess-Amplify IAM policy. This IAM policy is not scoped to a single application and grants the user access to all applications within the AWS account. See AWS managed policies for AWS Amplify for more details."
      },
      {
        "heading": "To edit team member access or delete a user",
        "depth": 2,
        "text": "Sign in to the AWS Management Console and open AWS Amplify."
      },
      {
        "heading": "To edit team member access or delete a user",
        "depth": 2,
        "text": "In the navigation pane, choose Amplify Studio settings."
      },
      {
        "heading": "To edit team member access or delete a user",
        "depth": 2,
        "text": "On the Amplify Studio settings page, in the Access control settings section, select the team member to edit or delete."
      },
      {
        "heading": "To edit team member access or delete a user",
        "depth": 2,
        "text": "Do one of the following:"
      },
      {
        "heading": "To edit team member access or delete a user",
        "depth": 2,
        "text": "Choose Edit. In the Edit team member(s) window, choose the Access level for the team member."
      },
      {
        "heading": "To edit team member access or delete a user",
        "depth": 2,
        "text": "Choose Delete. In the Delete users window, confirm the delete action."
      },
      {
        "heading": "To edit team member access or delete a user",
        "depth": 2,
        "text": "If a team member logs into Amplify Studio, their login token is valid for 60 minutes, unless explicitly logged out. When you change a team member's permission from full access to manage-only or when you delete a team member's access, the team member can continue accessing Amplify Studio with their previously granted permissions until their token expires."
      }
    ],
    "source": "export const meta = {\n  title: `Manage team access`,\n  description: `Manage team access to a project`,\n};\n\nWith Amplify Studio, team members with different job functions can collaborate on different aspects of a project deployed in Amplify. Studio developers can create accounts with scoped access to resources and invite team members to join via email. Team members with *Full access* can create and manage AWS resources, while team members with *Manage only* access can edit application content and users.\n\nStudio manages user access using an Amazon Cognito User Pool in your account. If you visit Cognito from the AWS console you should see a User Pool named *amplify_backend_manager_APPID*. This User Pool is managed by Studio so please do not modify the settings for this resource. You can invite up to 50,000 monthly users to Studio without cost. In order to give the *Full access* and *Manage only* groups the necessary permissions, Studio creates 2 IAM roles, namely: *USERPOOLID_Full-access*, and *USERPOOLID_Manage-only*. An Amazon Cognito Identity Pool named, *amplify_backend_manager_APPID*  is also created to vend AWS credentials that are tied to the *Full access* and *Manage only* groups.\n\nTo provide a passwordless login experience from AWS Amplify Console to Amplify Studio, Studio creates 4 Cognito Lambda triggers (*associated with the above-mentioned User Pool*), namely: *amplify-login-create-auth-challenge-SHORT_CODE*, *amplify-login-custom-message-SHORT_CODE*, *amplify-login-define-auth-challenge-SHORT_CODE*, and *amplify-login-verify-auth-challenge-SHORT_CODE*.\n\nFollow these instructions to add and manage team members and their access to a project.\n\n## To invite team members to access a project\n\n1. Sign in to the AWS Management Console and open AWS Amplify.\n2. In the navigation pane, choose **Amplify Studio settings**.\n3. On the **Amplify Studio settings** page, in the **Access control settings** section, choose **Add team members**.\n4. For **Email**, enter the email address of the team member to invite.\n5. For **Access level**, choose the level of access to grant the team member.\n  * **Full access** allows the team member to create and manage AWS resources.\n  * **Manage only** access allows the team member to edit app content and users.\n6. To email the invitation, choose **Send invite**. The team member receives an email with temporary credentials and a link to access the project in Studio.\n\n<Callout warning>\n\n  Granting a user the **Full Access** level attaches the **AdministratorAccess-Amplify** IAM policy. This IAM policy is not scoped to a single application and grants the user access to all applications within the AWS account. See [AWS managed policies for AWS Amplify](https://docs.aws.amazon.com/amplify/latest/userguide/security-iam-awsmanpol.html) for more details.\n\n</Callout>\n\n## To edit team member access or delete a user\n1. Sign in to the AWS Management Console and open AWS Amplify.\n2. In the navigation pane, choose **Amplify Studio settings**.\n3. On the **Amplify Studio settings** page, in the **Access control settings** section, select the team member to edit or delete.\n4. Do one of the following:\n  * Choose **Edit**. In the **Edit team member(s)** window, choose the **Access level** for the team member.\n  * Choose **Delete**. In the **Delete users** window, confirm the delete action.\n\n<Callout warning>\nIf a team member logs into Amplify Studio, their login token is valid for 60 minutes, unless explicitly logged out. When you change a team member's permission from *full access* to *manage-only* or when you delete a team member's access, the team member can continue accessing Amplify Studio with their previously granted permissions until their token expires.\n</Callout>\n",
    "meta": {
      "title": "Manage team access",
      "description": "Manage team access to a project",
      "subcategory": "Basics",
      "category": "Amplify Studio"
    },
    "filename": "/console/adminui/access-management"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Amplify Studio allows you to use all the Amplify CLI's features without the need to configure it with AWS Identity and Access Management (IAM). Changes made in Amplify Studio can be made available in the CLI by running the amplify pull command. Similarly, CLI changes to the data model or auth will be visible in Amplify Studio. For all other categories, Studio provides links to the relevant service consoles in AWS."
      },
      {
        "heading": null,
        "depth": null,
        "text": ""
      },
      {
        "heading": "To install the Amplify CLI",
        "depth": 2,
        "text": "Open a terminal window and install the CLI."
      },
      {
        "heading": "To install the Amplify CLI",
        "depth": 2,
        "text": "After the Amplify CLI finishes installing, you can configure the CLI so that you can use it without an AWS account."
      },
      {
        "heading": "Adding features with the Amplify CLI",
        "depth": 2,
        "text": "The Studio Set up menu lists cloud backend features such as functions, storage, and APIs that you can add to your app using the CLI. For each backend resource, Studio displays the CLI commands to run in your terminal window."
      },
      {
        "heading": "Adding features with the Amplify CLI",
        "depth": 2,
        "text": "In Studio, on the Set up menu, choose Storage or Functions."
      },
      {
        "heading": "Adding features with the Amplify CLI",
        "depth": 2,
        "text": "On the Storage page, under Pull your Amplify project, copy the following command and run it in your terminal window."
      },
      {
        "heading": "Adding features with the Amplify CLI",
        "depth": 2,
        "text": "After your backend environment has been successfully pulled from the cloud, copy the following command under Add storage capabilities and paste it in your terminal window:"
      },
      {
        "heading": "Adding features with the Amplify CLI",
        "depth": 2,
        "text": "Follow the prompts in the terminal window to configure storage with your desired settings."
      },
      {
        "heading": "Adding features with the Amplify CLI",
        "depth": 2,
        "text": "Run the following command in your terminal window to build your local backend resources and provision them in the cloud:"
      },
      {
        "heading": "Adding features with the Amplify CLI",
        "depth": 2,
        "text": "Return to the Studio Storage page. Confirm that a link to your new storage resource is available in the Deployed storage resources section."
      },
      {
        "heading": "Infrastructure-as-code",
        "depth": 2,
        "text": "All backends created in Amplify Studio and Amplify CLI are deployed using AWS CloudFormation. AWS CloudFormation allows you store your backend configuration as code in your repository. This has three major benefits:"
      },
      {
        "heading": "Infrastructure-as-code",
        "depth": 2,
        "text": "Ability to extend a project with capabilities offered by individual services (e.g. Cognito, DynamoDB) that are not available in Amplify."
      },
      {
        "heading": "Infrastructure-as-code",
        "depth": 2,
        "text": "Ability to easily replicate backend environments across AWS accounts and regions."
      },
      {
        "heading": "Infrastructure-as-code",
        "depth": 2,
        "text": "Ability to easily integrate with CI/CD pipelines such as the pipeline offered in the Amplify console."
      },
      {
        "heading": "Infrastructure-as-code",
        "depth": 2,
        "text": "All backend infrastructure-as-code definitions can be added to your project with the Amplify Command Line Interface (CLI)."
      }
    ],
    "source": "export const meta = {\n  title: `Extend with the Amplify CLI`,\n  description: `Install the CLI without npm and use the CLI without an AWS account`,\n};\n\nAmplify Studio allows you to use all the Amplify CLI's features without the need to configure it with AWS Identity and Access Management (IAM). Changes made in Amplify Studio can be made available in the CLI by running the `amplify pull` command. Similarly, CLI changes to the data model or auth will be visible in Amplify Studio. For all other categories, Studio provides links to the relevant service consoles in AWS.\n\n![autologin](/images/console/cli-autologin.gif)\n\n## To install the Amplify CLI\n1. Open a terminal window and install the CLI.\n\nimport all0 from \"/src/fragments/cli-install-block.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nAfter the Amplify CLI finishes installing, you can configure the CLI so that you can use it without an AWS account.\n\n## To configure the Amplify CLI for use without an AWS account\n\nimport all1 from \"/src/fragments/pull-cli-studio.mdx\";\n\n<Fragments fragments={{all: all1}} />\n\n## Adding features with the Amplify CLI\n\nThe Studio **Set up** menu lists cloud backend features such as functions, storage, and APIs that you can add to your app using the CLI. For each backend resource, Studio displays the CLI commands to run in your terminal window. \n\n1. In Studio, on the **Set up** menu, choose **Storage** or **Functions**.\n2. On the **Storage** page, under **Pull your Amplify project**, copy the following command and run it in your terminal window. \n3. After your backend environment has been successfully pulled from the cloud, copy the following command under **Add storage capabilities** and paste it in your terminal window:\n```bash\namplify add storage\n```\n4. Follow the prompts in the terminal window to configure storage with your desired settings.\n5. Run the following command in your terminal window to build your local backend resources and provision them in the cloud:\n```bash\namplify push\n```\n6. Return to the Studio **Storage** page. Confirm that a link to your new storage resource is available in the **Deployed storage resources** section.\n\n## Infrastructure-as-code\n\nAll backends created in Amplify Studio and Amplify CLI are deployed using AWS CloudFormation. AWS CloudFormation allows you store your backend configuration as code in your repository. This has three major benefits:\n\n1. Ability to extend a project with capabilities offered by individual services (e.g. Cognito, DynamoDB) that are not available in Amplify.\n2. Ability to easily replicate backend environments across AWS accounts and regions. \n3. Ability to easily integrate with CI/CD pipelines such as the pipeline offered in the Amplify console. \n\nAll backend infrastructure-as-code definitions can be added to your project with the Amplify Command Line Interface (CLI).",
    "meta": {
      "title": "Extend with the Amplify CLI",
      "description": "Install the CLI without npm and use the CLI without an AWS account",
      "subcategory": "Basics",
      "category": "Amplify Studio"
    },
    "filename": "/console/adminui/extend-cli"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "AWS Amplify Studio is a visual development environment for building full-stack web and mobile apps. To learn more, see the Amplify Studio introduction."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify Studio is available in the following regions: Amplify Studio service endpoints."
      },
      {
        "heading": null,
        "depth": null,
        "text": "You can get started with or without an AWS account. Without an AWS account, you can begin modeling data for your backend and testing it locally. If you choose to create an AWS account and deploy your backend in the AWS Amplify console, an expanded set of features becomes available for configuring your backend environment."
      },
      {
        "heading": "Get started without an AWS account",
        "depth": 2,
        "text": "If you are new to AWS, you don't need an AWS account to get started. You can still model and test your data before deploying to the cloud. After building your data model, you must connect an AWS account to deploy your backend environment to Amplify using Amplify Studio. The sandbox interface lets you perform the following tasks:"
      },
      {
        "heading": "Get started without an AWS account",
        "depth": 2,
        "text": "Set up your data model. For instructions on creating models and setting relationships, see Data modeling in Amplify Studio."
      },
      {
        "heading": "Get started without an AWS account",
        "depth": 2,
        "text": "Test your new data model locally."
      },
      {
        "heading": "Get started without an AWS account",
        "depth": 2,
        "text": "Deploy your backend to the cloud. This requires an AWS account."
      },
      {
        "heading": "Get started without an AWS account",
        "depth": 2,
        "text": "Launch Sandbox\nGet started without an AWS account"
      },
      {
        "heading": "Get started with your AWS account",
        "depth": 2,
        "text": "If you already have an AWS account and you want to skip the sandbox experience, deploy Amplify Studio to start using all Amplify features, including DataStore, user authentication and authorization, and file storage. After you deploy a backend in Amplify, you can launch Amplify Studio from your Amplify app. Your entire team can use Studio to add new features, update app data, and manage users and groups."
      },
      {
        "heading": "Get started with your AWS account",
        "depth": 2,
        "text": "Log in to AWS console\nGet started in the AWS Amplify console"
      },
      {
        "heading": "To get started with a new Amplify app",
        "depth": 3,
        "text": "Sign in to the AWS Management Console and open AWS Amplify. Choose Create app backend."
      },
      {
        "heading": "To get started with a new Amplify app",
        "depth": 3,
        "text": "Enter a name for your app and choose Confirm deployment. This deploys a default staging backend environment."
      },
      {
        "heading": "To get started with a new Amplify app",
        "depth": 3,
        "text": "On the application information page, choose the Backend environments tab."
      },
      {
        "heading": "To get started with a new Amplify app",
        "depth": 3,
        "text": "Choose Launch Studio. This automatically logs you in to Amplify Studio."
      },
      {
        "heading": "To get started with a new Amplify app",
        "depth": 3,
        "text": "If you already have an existing backend environment, you can enable Amplify Studio from the console."
      },
      {
        "heading": "To get started from an existing Amplify app",
        "depth": 3,
        "text": "Sign in to the AWS Management Console and open AWS Amplify. Or, enter amplify console from the Amplify Command Line Interface (CLI)."
      },
      {
        "heading": "To get started from an existing Amplify app",
        "depth": 3,
        "text": "In the navigation pane, choose Amplify Studio settings."
      },
      {
        "heading": "To get started from an existing Amplify app",
        "depth": 3,
        "text": "Turn on Enable Amplify Studio."
      },
      {
        "heading": "To get started from an existing Amplify app",
        "depth": 3,
        "text": "In the Backend environments section, choose Launch Studio.  This automatically logs you in to Amplify Studio where you can use all the Studio capabilities."
      },
      {
        "heading": "Next steps",
        "depth": 2,
        "text": "You are ready to start creating and managing your application's backend in Amplify Studio. Recommended next steps:"
      },
      {
        "heading": "Next steps",
        "depth": 2,
        "text": "Build a data model"
      },
      {
        "heading": "Next steps",
        "depth": 2,
        "text": "Create UI components in Figma"
      }
    ],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `Getting started with Amplify Studio`,\n};\n\nAWS Amplify Studio is a visual development environment for building full-stack web and mobile apps. To learn more, see the [Amplify Studio introduction](/console/).\n\nAmplify Studio is available in the following regions: [Amplify Studio service endpoints](https://docs.aws.amazon.com/general/latest/gr/amplify.html#amplifyadmin_region).\n\nYou can get started with or without an AWS account. Without an AWS account, you can begin modeling data for your backend and testing it locally. If you choose to create an AWS account and deploy your backend in the AWS Amplify console, an expanded set of features becomes available for configuring your backend environment.\n\n## Get started without an AWS account \n\nIf you are new to AWS, you don't need an AWS account to get started. You can still model and test your data before deploying to the cloud. After building your data model, you must connect an AWS account to deploy your backend environment to Amplify using Amplify Studio. The sandbox interface lets you perform the following tasks:\n * Set up your data model. For instructions on creating models and setting relationships, see [Data modeling in Amplify Studio](/console/data/data-model#Data-modeling-in-the-Admin-UI).\n * Test your new data model locally.\n * Deploy your backend to the cloud. This requires an AWS account.\n\n<Card\n  external\n  href=\"https://sandbox.amplifyapp.com/\"\n  containertag=\"amplify-external-link\"\n>\n  <CardGraphic alt=\"Amplify Studio logo\" src=\"/images/console/adminui.svg\" />\n  <CardDetail>\n    <h4>Launch Sandbox</h4>\n    <p>Get started without an AWS account</p>\n  </CardDetail>\n</Card>\n\n## Get started with your AWS account\n\nIf you already have an AWS account and you want to skip the sandbox experience, deploy Amplify Studio to start using all Amplify features, including DataStore, user authentication and authorization, and file storage. After you deploy a backend in Amplify, you can launch Amplify Studio from your Amplify app. Your entire team can use Studio to add new features, update app data, and manage users and groups.\n\n<Card\n    external\n    href=\"https://console.aws.amazon.com/amplify/home?#/deploy-backend\"\n    containertag=\"amplify-external-link\"\n  >\n    <CardGraphic alt=\"Amplify logo\" src=\"/assets/logo-dark.svg\" />\n    <CardDetail>\n      <h4>Log in to AWS console</h4>\n      <p>Get started in the AWS Amplify console</p>\n    </CardDetail>\n  </Card>\n\n### To get started with a new Amplify app\n1. Sign in to the AWS Management Console and open AWS Amplify. Choose **Create app backend**.\n2. Enter a name for your app and choose **Confirm deployment**. This deploys a default **staging** backend environment.\n3. On the application information page, choose the **Backend environments** tab.\n4. Choose **Launch Studio**. This automatically logs you in to Amplify Studio.\n\nIf you already have an existing backend environment, you can enable Amplify Studio from the console.\n\n### To get started from an existing Amplify app\n\n1. Sign in to the AWS Management Console and open AWS Amplify. Or, enter `amplify console` from the Amplify Command Line Interface (CLI).\n2. In the navigation pane, choose **Amplify Studio settings**.\n3. Turn on **Enable Amplify Studio**. \n4. In the **Backend environments** section, choose **Launch Studio**.  This automatically logs you in to Amplify Studio where you can use all the Studio capabilities.\n\n## Next steps\n\nYou are ready to start creating and managing your application's backend in Amplify Studio. Recommended next steps:\n  * [Build a data model](/console/data/data-model)\n  * [Create UI components in Figma](/console/uibuilder/figmatocode/)\n  \n  \n \n\n",
    "meta": {
      "title": "Getting started",
      "description": "Getting started with Amplify Studio",
      "subcategory": "Basics",
      "category": "Amplify Studio"
    },
    "filename": "/console/adminui/start"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `ToDo App`,\n  description: `Getting Started with Amplify Framework - Try Amplify framework on a ToDo sample app`,\n};\n\nimport android1 from \"/src/fragments/start/sample-apps/android/todo-app.mdx\";\n\n<Fragments fragments={{android: android1}} />\n",
    "meta": {
      "title": "ToDo App - Android",
      "description": "Getting Started with Amplify Framework - Try Amplify framework on a ToDo sample app - Android",
      "subcategory": "Sample Apps",
      "category": "Getting started"
    },
    "filename": "/start/sample-apps/todo-app/q/integration/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Next steps`,\n  description: `Getting Started with Amplify Framework - Next steps`,\n};\n\nimport angular0 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{angular: angular0}} />\n\nimport js1 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{js: js1}} />\n\nimport vue2 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{vue: vue2}} />\n\nimport next3 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{next: next3}} />\n\nimport react4 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{react: react4}} />\n\nimport react_native5 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native5}} />\n\nimport ionic6 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{ionic: ionic6}} />\n\nimport angular7 from \"/src/fragments/start/getting-started/angular/nextsteps.mdx\";\n\n<Fragments fragments={{angular: angular7}} />\n\nimport js8 from \"/src/fragments/start/getting-started/vanillajs/nextsteps.mdx\";\n\n<Fragments fragments={{js: js8}} />\n\nimport vue9 from \"/src/fragments/start/getting-started/vue/nextsteps.mdx\";\n\n<Fragments fragments={{vue: vue9}} />\n\nimport next10 from \"/src/fragments/start/getting-started/react/nextsteps.mdx\";\n\n<Fragments fragments={{next: next10}} />\n\nimport react11 from \"/src/fragments/start/getting-started/react/nextsteps.mdx\";\n\n<Fragments fragments={{react: react11}} />\n\nimport react_native12 from \"/src/fragments/start/getting-started/reactnative/nextsteps.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native12}} />\n\nimport ionic13 from \"/src/fragments/start/getting-started/ionic/nextsteps.mdx\";\n\n<Fragments fragments={{ionic: ionic13}} />\n\nimport ios14 from \"/src/fragments/start/getting-started/ios/nextsteps.mdx\";\n\n<Fragments fragments={{ios: ios14}} />\n\nimport android15 from \"/src/fragments/start/getting-started/android/nextsteps.mdx\";\n\n<Fragments fragments={{android: android15}} />\n\nimport flutter16 from \"/src/fragments/start/getting-started/flutter/nextsteps.mdx\";\n\n<Fragments fragments={{flutter: flutter16}} />\n",
    "meta": {
      "title": "Next steps - Flutter",
      "description": "Getting Started with Amplify Framework - Next steps - Flutter",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/nextsteps/q/integration/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Next steps`,\n  description: `Getting Started with Amplify Framework - Next steps`,\n};\n\nimport angular0 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{angular: angular0}} />\n\nimport js1 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{js: js1}} />\n\nimport vue2 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{vue: vue2}} />\n\nimport next3 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{next: next3}} />\n\nimport react4 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{react: react4}} />\n\nimport react_native5 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native5}} />\n\nimport ionic6 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{ionic: ionic6}} />\n\nimport angular7 from \"/src/fragments/start/getting-started/angular/nextsteps.mdx\";\n\n<Fragments fragments={{angular: angular7}} />\n\nimport js8 from \"/src/fragments/start/getting-started/vanillajs/nextsteps.mdx\";\n\n<Fragments fragments={{js: js8}} />\n\nimport vue9 from \"/src/fragments/start/getting-started/vue/nextsteps.mdx\";\n\n<Fragments fragments={{vue: vue9}} />\n\nimport next10 from \"/src/fragments/start/getting-started/react/nextsteps.mdx\";\n\n<Fragments fragments={{next: next10}} />\n\nimport react11 from \"/src/fragments/start/getting-started/react/nextsteps.mdx\";\n\n<Fragments fragments={{react: react11}} />\n\nimport react_native12 from \"/src/fragments/start/getting-started/reactnative/nextsteps.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native12}} />\n\nimport ionic13 from \"/src/fragments/start/getting-started/ionic/nextsteps.mdx\";\n\n<Fragments fragments={{ionic: ionic13}} />\n\nimport ios14 from \"/src/fragments/start/getting-started/ios/nextsteps.mdx\";\n\n<Fragments fragments={{ios: ios14}} />\n\nimport android15 from \"/src/fragments/start/getting-started/android/nextsteps.mdx\";\n\n<Fragments fragments={{android: android15}} />\n\nimport flutter16 from \"/src/fragments/start/getting-started/flutter/nextsteps.mdx\";\n\n<Fragments fragments={{flutter: flutter16}} />\n",
    "meta": {
      "title": "Next steps - Ionic",
      "description": "Getting Started with Amplify Framework - Next steps - Ionic",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/nextsteps/q/integration/ionic"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Next steps`,\n  description: `Getting Started with Amplify Framework - Next steps`,\n};\n\nimport angular0 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{angular: angular0}} />\n\nimport js1 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{js: js1}} />\n\nimport vue2 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{vue: vue2}} />\n\nimport next3 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{next: next3}} />\n\nimport react4 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{react: react4}} />\n\nimport react_native5 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native5}} />\n\nimport ionic6 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{ionic: ionic6}} />\n\nimport angular7 from \"/src/fragments/start/getting-started/angular/nextsteps.mdx\";\n\n<Fragments fragments={{angular: angular7}} />\n\nimport js8 from \"/src/fragments/start/getting-started/vanillajs/nextsteps.mdx\";\n\n<Fragments fragments={{js: js8}} />\n\nimport vue9 from \"/src/fragments/start/getting-started/vue/nextsteps.mdx\";\n\n<Fragments fragments={{vue: vue9}} />\n\nimport next10 from \"/src/fragments/start/getting-started/react/nextsteps.mdx\";\n\n<Fragments fragments={{next: next10}} />\n\nimport react11 from \"/src/fragments/start/getting-started/react/nextsteps.mdx\";\n\n<Fragments fragments={{react: react11}} />\n\nimport react_native12 from \"/src/fragments/start/getting-started/reactnative/nextsteps.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native12}} />\n\nimport ionic13 from \"/src/fragments/start/getting-started/ionic/nextsteps.mdx\";\n\n<Fragments fragments={{ionic: ionic13}} />\n\nimport ios14 from \"/src/fragments/start/getting-started/ios/nextsteps.mdx\";\n\n<Fragments fragments={{ios: ios14}} />\n\nimport android15 from \"/src/fragments/start/getting-started/android/nextsteps.mdx\";\n\n<Fragments fragments={{android: android15}} />\n\nimport flutter16 from \"/src/fragments/start/getting-started/flutter/nextsteps.mdx\";\n\n<Fragments fragments={{flutter: flutter16}} />\n",
    "meta": {
      "title": "Next steps - iOS",
      "description": "Getting Started with Amplify Framework - Next steps - iOS",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/nextsteps/q/integration/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Next steps`,\n  description: `Getting Started with Amplify Framework - Next steps`,\n};\n\nimport angular0 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{angular: angular0}} />\n\nimport js1 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{js: js1}} />\n\nimport vue2 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{vue: vue2}} />\n\nimport next3 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{next: next3}} />\n\nimport react4 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{react: react4}} />\n\nimport react_native5 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native5}} />\n\nimport ionic6 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{ionic: ionic6}} />\n\nimport angular7 from \"/src/fragments/start/getting-started/angular/nextsteps.mdx\";\n\n<Fragments fragments={{angular: angular7}} />\n\nimport js8 from \"/src/fragments/start/getting-started/vanillajs/nextsteps.mdx\";\n\n<Fragments fragments={{js: js8}} />\n\nimport vue9 from \"/src/fragments/start/getting-started/vue/nextsteps.mdx\";\n\n<Fragments fragments={{vue: vue9}} />\n\nimport next10 from \"/src/fragments/start/getting-started/react/nextsteps.mdx\";\n\n<Fragments fragments={{next: next10}} />\n\nimport react11 from \"/src/fragments/start/getting-started/react/nextsteps.mdx\";\n\n<Fragments fragments={{react: react11}} />\n\nimport react_native12 from \"/src/fragments/start/getting-started/reactnative/nextsteps.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native12}} />\n\nimport ionic13 from \"/src/fragments/start/getting-started/ionic/nextsteps.mdx\";\n\n<Fragments fragments={{ionic: ionic13}} />\n\nimport ios14 from \"/src/fragments/start/getting-started/ios/nextsteps.mdx\";\n\n<Fragments fragments={{ios: ios14}} />\n\nimport android15 from \"/src/fragments/start/getting-started/android/nextsteps.mdx\";\n\n<Fragments fragments={{android: android15}} />\n\nimport flutter16 from \"/src/fragments/start/getting-started/flutter/nextsteps.mdx\";\n\n<Fragments fragments={{flutter: flutter16}} />\n",
    "meta": {
      "title": "Next steps - Android",
      "description": "Getting Started with Amplify Framework - Next steps - Android",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/nextsteps/q/integration/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Next steps`,\n  description: `Getting Started with Amplify Framework - Next steps`,\n};\n\nimport angular0 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{angular: angular0}} />\n\nimport js1 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{js: js1}} />\n\nimport vue2 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{vue: vue2}} />\n\nimport next3 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{next: next3}} />\n\nimport react4 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{react: react4}} />\n\nimport react_native5 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native5}} />\n\nimport ionic6 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{ionic: ionic6}} />\n\nimport angular7 from \"/src/fragments/start/getting-started/angular/nextsteps.mdx\";\n\n<Fragments fragments={{angular: angular7}} />\n\nimport js8 from \"/src/fragments/start/getting-started/vanillajs/nextsteps.mdx\";\n\n<Fragments fragments={{js: js8}} />\n\nimport vue9 from \"/src/fragments/start/getting-started/vue/nextsteps.mdx\";\n\n<Fragments fragments={{vue: vue9}} />\n\nimport next10 from \"/src/fragments/start/getting-started/react/nextsteps.mdx\";\n\n<Fragments fragments={{next: next10}} />\n\nimport react11 from \"/src/fragments/start/getting-started/react/nextsteps.mdx\";\n\n<Fragments fragments={{react: react11}} />\n\nimport react_native12 from \"/src/fragments/start/getting-started/reactnative/nextsteps.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native12}} />\n\nimport ionic13 from \"/src/fragments/start/getting-started/ionic/nextsteps.mdx\";\n\n<Fragments fragments={{ionic: ionic13}} />\n\nimport ios14 from \"/src/fragments/start/getting-started/ios/nextsteps.mdx\";\n\n<Fragments fragments={{ios: ios14}} />\n\nimport android15 from \"/src/fragments/start/getting-started/android/nextsteps.mdx\";\n\n<Fragments fragments={{android: android15}} />\n\nimport flutter16 from \"/src/fragments/start/getting-started/flutter/nextsteps.mdx\";\n\n<Fragments fragments={{flutter: flutter16}} />\n",
    "meta": {
      "title": "Next steps - Next.js",
      "description": "Getting Started with Amplify Framework - Next steps - Next.js",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/nextsteps/q/integration/next"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Next steps`,\n  description: `Getting Started with Amplify Framework - Next steps`,\n};\n\nimport angular0 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{angular: angular0}} />\n\nimport js1 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{js: js1}} />\n\nimport vue2 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{vue: vue2}} />\n\nimport next3 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{next: next3}} />\n\nimport react4 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{react: react4}} />\n\nimport react_native5 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native5}} />\n\nimport ionic6 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{ionic: ionic6}} />\n\nimport angular7 from \"/src/fragments/start/getting-started/angular/nextsteps.mdx\";\n\n<Fragments fragments={{angular: angular7}} />\n\nimport js8 from \"/src/fragments/start/getting-started/vanillajs/nextsteps.mdx\";\n\n<Fragments fragments={{js: js8}} />\n\nimport vue9 from \"/src/fragments/start/getting-started/vue/nextsteps.mdx\";\n\n<Fragments fragments={{vue: vue9}} />\n\nimport next10 from \"/src/fragments/start/getting-started/react/nextsteps.mdx\";\n\n<Fragments fragments={{next: next10}} />\n\nimport react11 from \"/src/fragments/start/getting-started/react/nextsteps.mdx\";\n\n<Fragments fragments={{react: react11}} />\n\nimport react_native12 from \"/src/fragments/start/getting-started/reactnative/nextsteps.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native12}} />\n\nimport ionic13 from \"/src/fragments/start/getting-started/ionic/nextsteps.mdx\";\n\n<Fragments fragments={{ionic: ionic13}} />\n\nimport ios14 from \"/src/fragments/start/getting-started/ios/nextsteps.mdx\";\n\n<Fragments fragments={{ios: ios14}} />\n\nimport android15 from \"/src/fragments/start/getting-started/android/nextsteps.mdx\";\n\n<Fragments fragments={{android: android15}} />\n\nimport flutter16 from \"/src/fragments/start/getting-started/flutter/nextsteps.mdx\";\n\n<Fragments fragments={{flutter: flutter16}} />\n",
    "meta": {
      "title": "Next steps - Vue",
      "description": "Getting Started with Amplify Framework - Next steps - Vue",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/nextsteps/q/integration/vue"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Next steps`,\n  description: `Getting Started with Amplify Framework - Next steps`,\n};\n\nimport angular0 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{angular: angular0}} />\n\nimport js1 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{js: js1}} />\n\nimport vue2 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{vue: vue2}} />\n\nimport next3 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{next: next3}} />\n\nimport react4 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{react: react4}} />\n\nimport react_native5 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native5}} />\n\nimport ionic6 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{ionic: ionic6}} />\n\nimport angular7 from \"/src/fragments/start/getting-started/angular/nextsteps.mdx\";\n\n<Fragments fragments={{angular: angular7}} />\n\nimport js8 from \"/src/fragments/start/getting-started/vanillajs/nextsteps.mdx\";\n\n<Fragments fragments={{js: js8}} />\n\nimport vue9 from \"/src/fragments/start/getting-started/vue/nextsteps.mdx\";\n\n<Fragments fragments={{vue: vue9}} />\n\nimport next10 from \"/src/fragments/start/getting-started/react/nextsteps.mdx\";\n\n<Fragments fragments={{next: next10}} />\n\nimport react11 from \"/src/fragments/start/getting-started/react/nextsteps.mdx\";\n\n<Fragments fragments={{react: react11}} />\n\nimport react_native12 from \"/src/fragments/start/getting-started/reactnative/nextsteps.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native12}} />\n\nimport ionic13 from \"/src/fragments/start/getting-started/ionic/nextsteps.mdx\";\n\n<Fragments fragments={{ionic: ionic13}} />\n\nimport ios14 from \"/src/fragments/start/getting-started/ios/nextsteps.mdx\";\n\n<Fragments fragments={{ios: ios14}} />\n\nimport android15 from \"/src/fragments/start/getting-started/android/nextsteps.mdx\";\n\n<Fragments fragments={{android: android15}} />\n\nimport flutter16 from \"/src/fragments/start/getting-started/flutter/nextsteps.mdx\";\n\n<Fragments fragments={{flutter: flutter16}} />\n",
    "meta": {
      "title": "Next steps - Angular",
      "description": "Getting Started with Amplify Framework - Next steps - Angular",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/nextsteps/q/integration/angular"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Next steps`,\n  description: `Getting Started with Amplify Framework - Next steps`,\n};\n\nimport angular0 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{angular: angular0}} />\n\nimport js1 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{js: js1}} />\n\nimport vue2 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{vue: vue2}} />\n\nimport next3 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{next: next3}} />\n\nimport react4 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{react: react4}} />\n\nimport react_native5 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native5}} />\n\nimport ionic6 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{ionic: ionic6}} />\n\nimport angular7 from \"/src/fragments/start/getting-started/angular/nextsteps.mdx\";\n\n<Fragments fragments={{angular: angular7}} />\n\nimport js8 from \"/src/fragments/start/getting-started/vanillajs/nextsteps.mdx\";\n\n<Fragments fragments={{js: js8}} />\n\nimport vue9 from \"/src/fragments/start/getting-started/vue/nextsteps.mdx\";\n\n<Fragments fragments={{vue: vue9}} />\n\nimport next10 from \"/src/fragments/start/getting-started/react/nextsteps.mdx\";\n\n<Fragments fragments={{next: next10}} />\n\nimport react11 from \"/src/fragments/start/getting-started/react/nextsteps.mdx\";\n\n<Fragments fragments={{react: react11}} />\n\nimport react_native12 from \"/src/fragments/start/getting-started/reactnative/nextsteps.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native12}} />\n\nimport ionic13 from \"/src/fragments/start/getting-started/ionic/nextsteps.mdx\";\n\n<Fragments fragments={{ionic: ionic13}} />\n\nimport ios14 from \"/src/fragments/start/getting-started/ios/nextsteps.mdx\";\n\n<Fragments fragments={{ios: ios14}} />\n\nimport android15 from \"/src/fragments/start/getting-started/android/nextsteps.mdx\";\n\n<Fragments fragments={{android: android15}} />\n\nimport flutter16 from \"/src/fragments/start/getting-started/flutter/nextsteps.mdx\";\n\n<Fragments fragments={{flutter: flutter16}} />\n",
    "meta": {
      "title": "Next steps - React Native",
      "description": "Getting Started with Amplify Framework - Next steps - React Native",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/nextsteps/q/integration/react-native"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Next steps`,\n  description: `Getting Started with Amplify Framework - Next steps`,\n};\n\nimport angular0 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{angular: angular0}} />\n\nimport js1 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{js: js1}} />\n\nimport vue2 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{vue: vue2}} />\n\nimport next3 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{next: next3}} />\n\nimport react4 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{react: react4}} />\n\nimport react_native5 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native5}} />\n\nimport ionic6 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{ionic: ionic6}} />\n\nimport angular7 from \"/src/fragments/start/getting-started/angular/nextsteps.mdx\";\n\n<Fragments fragments={{angular: angular7}} />\n\nimport js8 from \"/src/fragments/start/getting-started/vanillajs/nextsteps.mdx\";\n\n<Fragments fragments={{js: js8}} />\n\nimport vue9 from \"/src/fragments/start/getting-started/vue/nextsteps.mdx\";\n\n<Fragments fragments={{vue: vue9}} />\n\nimport next10 from \"/src/fragments/start/getting-started/react/nextsteps.mdx\";\n\n<Fragments fragments={{next: next10}} />\n\nimport react11 from \"/src/fragments/start/getting-started/react/nextsteps.mdx\";\n\n<Fragments fragments={{react: react11}} />\n\nimport react_native12 from \"/src/fragments/start/getting-started/reactnative/nextsteps.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native12}} />\n\nimport ionic13 from \"/src/fragments/start/getting-started/ionic/nextsteps.mdx\";\n\n<Fragments fragments={{ionic: ionic13}} />\n\nimport ios14 from \"/src/fragments/start/getting-started/ios/nextsteps.mdx\";\n\n<Fragments fragments={{ios: ios14}} />\n\nimport android15 from \"/src/fragments/start/getting-started/android/nextsteps.mdx\";\n\n<Fragments fragments={{android: android15}} />\n\nimport flutter16 from \"/src/fragments/start/getting-started/flutter/nextsteps.mdx\";\n\n<Fragments fragments={{flutter: flutter16}} />\n",
    "meta": {
      "title": "Next steps - React",
      "description": "Getting Started with Amplify Framework - Next steps - React",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/nextsteps/q/integration/react"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Next steps`,\n  description: `Getting Started with Amplify Framework - Next steps`,\n};\n\nimport angular0 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{angular: angular0}} />\n\nimport js1 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{js: js1}} />\n\nimport vue2 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{vue: vue2}} />\n\nimport next3 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{next: next3}} />\n\nimport react4 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{react: react4}} />\n\nimport react_native5 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native5}} />\n\nimport ionic6 from \"/src/fragments/start/getting-started/common/nextsteps-header.mdx\";\n\n<Fragments fragments={{ionic: ionic6}} />\n\nimport angular7 from \"/src/fragments/start/getting-started/angular/nextsteps.mdx\";\n\n<Fragments fragments={{angular: angular7}} />\n\nimport js8 from \"/src/fragments/start/getting-started/vanillajs/nextsteps.mdx\";\n\n<Fragments fragments={{js: js8}} />\n\nimport vue9 from \"/src/fragments/start/getting-started/vue/nextsteps.mdx\";\n\n<Fragments fragments={{vue: vue9}} />\n\nimport next10 from \"/src/fragments/start/getting-started/react/nextsteps.mdx\";\n\n<Fragments fragments={{next: next10}} />\n\nimport react11 from \"/src/fragments/start/getting-started/react/nextsteps.mdx\";\n\n<Fragments fragments={{react: react11}} />\n\nimport react_native12 from \"/src/fragments/start/getting-started/reactnative/nextsteps.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native12}} />\n\nimport ionic13 from \"/src/fragments/start/getting-started/ionic/nextsteps.mdx\";\n\n<Fragments fragments={{ionic: ionic13}} />\n\nimport ios14 from \"/src/fragments/start/getting-started/ios/nextsteps.mdx\";\n\n<Fragments fragments={{ios: ios14}} />\n\nimport android15 from \"/src/fragments/start/getting-started/android/nextsteps.mdx\";\n\n<Fragments fragments={{android: android15}} />\n\nimport flutter16 from \"/src/fragments/start/getting-started/flutter/nextsteps.mdx\";\n\n<Fragments fragments={{flutter: flutter16}} />\n",
    "meta": {
      "title": "Next steps - JavaScript",
      "description": "Getting Started with Amplify Framework - Next steps - JavaScript",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/nextsteps/q/integration/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Deploy and host app`,\n  description: `Getting Started with Amplify Framework - how to host & deploy your web app`,\n  filterKey: `integration`\n};\n\nimport next0 from '/src/fragments/start/getting-started/next/hosting.mdx';\n\n<Fragments fragments={{ next: next0 }} />\n\nimport react1 from '/src/fragments/start/getting-started/vanillajs/hosting.mdx';\n\n<Fragments fragments={{ react: react1 }} />\n\nimport angular2 from '/src/fragments/start/getting-started/vanillajs/hosting.mdx';\n\n<Fragments fragments={{ angular: angular2 }} />\n\nimport ionic3 from '/src/fragments/start/getting-started/ionic/hosting.mdx';\n\n<Fragments fragments={{ ionic: ionic3 }} />\n\nimport js4 from '/src/fragments/start/getting-started/vanillajs/hosting.mdx';\n\n<Fragments fragments={{ js: js4 }} />\n\nimport vue5 from '/src/fragments/start/getting-started/vanillajs/hosting.mdx';\n\n<Fragments fragments={{ vue: vue5 }} />\n",
    "meta": {
      "title": "Deploy and host app - Ionic",
      "description": "Getting Started with Amplify Framework - how to host & deploy your web app - Ionic",
      "filterKey": "integration",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/hosting/q/integration/ionic"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Deploy and host app`,\n  description: `Getting Started with Amplify Framework - how to host & deploy your web app`,\n  filterKey: `integration`\n};\n\nimport next0 from '/src/fragments/start/getting-started/next/hosting.mdx';\n\n<Fragments fragments={{ next: next0 }} />\n\nimport react1 from '/src/fragments/start/getting-started/vanillajs/hosting.mdx';\n\n<Fragments fragments={{ react: react1 }} />\n\nimport angular2 from '/src/fragments/start/getting-started/vanillajs/hosting.mdx';\n\n<Fragments fragments={{ angular: angular2 }} />\n\nimport ionic3 from '/src/fragments/start/getting-started/ionic/hosting.mdx';\n\n<Fragments fragments={{ ionic: ionic3 }} />\n\nimport js4 from '/src/fragments/start/getting-started/vanillajs/hosting.mdx';\n\n<Fragments fragments={{ js: js4 }} />\n\nimport vue5 from '/src/fragments/start/getting-started/vanillajs/hosting.mdx';\n\n<Fragments fragments={{ vue: vue5 }} />\n",
    "meta": {
      "title": "Deploy and host app - Next.js",
      "description": "Getting Started with Amplify Framework - how to host & deploy your web app - Next.js",
      "filterKey": "integration",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/hosting/q/integration/next"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Deploy and host app`,\n  description: `Getting Started with Amplify Framework - how to host & deploy your web app`,\n  filterKey: `integration`\n};\n\nimport next0 from '/src/fragments/start/getting-started/next/hosting.mdx';\n\n<Fragments fragments={{ next: next0 }} />\n\nimport react1 from '/src/fragments/start/getting-started/vanillajs/hosting.mdx';\n\n<Fragments fragments={{ react: react1 }} />\n\nimport angular2 from '/src/fragments/start/getting-started/vanillajs/hosting.mdx';\n\n<Fragments fragments={{ angular: angular2 }} />\n\nimport ionic3 from '/src/fragments/start/getting-started/ionic/hosting.mdx';\n\n<Fragments fragments={{ ionic: ionic3 }} />\n\nimport js4 from '/src/fragments/start/getting-started/vanillajs/hosting.mdx';\n\n<Fragments fragments={{ js: js4 }} />\n\nimport vue5 from '/src/fragments/start/getting-started/vanillajs/hosting.mdx';\n\n<Fragments fragments={{ vue: vue5 }} />\n",
    "meta": {
      "title": "Deploy and host app - Vue",
      "description": "Getting Started with Amplify Framework - how to host & deploy your web app - Vue",
      "filterKey": "integration",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/hosting/q/integration/vue"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Deploy and host app`,\n  description: `Getting Started with Amplify Framework - how to host & deploy your web app`,\n  filterKey: `integration`\n};\n\nimport next0 from '/src/fragments/start/getting-started/next/hosting.mdx';\n\n<Fragments fragments={{ next: next0 }} />\n\nimport react1 from '/src/fragments/start/getting-started/vanillajs/hosting.mdx';\n\n<Fragments fragments={{ react: react1 }} />\n\nimport angular2 from '/src/fragments/start/getting-started/vanillajs/hosting.mdx';\n\n<Fragments fragments={{ angular: angular2 }} />\n\nimport ionic3 from '/src/fragments/start/getting-started/ionic/hosting.mdx';\n\n<Fragments fragments={{ ionic: ionic3 }} />\n\nimport js4 from '/src/fragments/start/getting-started/vanillajs/hosting.mdx';\n\n<Fragments fragments={{ js: js4 }} />\n\nimport vue5 from '/src/fragments/start/getting-started/vanillajs/hosting.mdx';\n\n<Fragments fragments={{ vue: vue5 }} />\n",
    "meta": {
      "title": "Deploy and host app - Angular",
      "description": "Getting Started with Amplify Framework - how to host & deploy your web app - Angular",
      "filterKey": "integration",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/hosting/q/integration/angular"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Deploy and host app`,\n  description: `Getting Started with Amplify Framework - how to host & deploy your web app`,\n  filterKey: `integration`\n};\n\nimport next0 from '/src/fragments/start/getting-started/next/hosting.mdx';\n\n<Fragments fragments={{ next: next0 }} />\n\nimport react1 from '/src/fragments/start/getting-started/vanillajs/hosting.mdx';\n\n<Fragments fragments={{ react: react1 }} />\n\nimport angular2 from '/src/fragments/start/getting-started/vanillajs/hosting.mdx';\n\n<Fragments fragments={{ angular: angular2 }} />\n\nimport ionic3 from '/src/fragments/start/getting-started/ionic/hosting.mdx';\n\n<Fragments fragments={{ ionic: ionic3 }} />\n\nimport js4 from '/src/fragments/start/getting-started/vanillajs/hosting.mdx';\n\n<Fragments fragments={{ js: js4 }} />\n\nimport vue5 from '/src/fragments/start/getting-started/vanillajs/hosting.mdx';\n\n<Fragments fragments={{ vue: vue5 }} />\n",
    "meta": {
      "title": "Deploy and host app - React",
      "description": "Getting Started with Amplify Framework - how to host & deploy your web app - React",
      "filterKey": "integration",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/hosting/q/integration/react"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Deploy and host app`,\n  description: `Getting Started with Amplify Framework - how to host & deploy your web app`,\n  filterKey: `integration`\n};\n\nimport next0 from '/src/fragments/start/getting-started/next/hosting.mdx';\n\n<Fragments fragments={{ next: next0 }} />\n\nimport react1 from '/src/fragments/start/getting-started/vanillajs/hosting.mdx';\n\n<Fragments fragments={{ react: react1 }} />\n\nimport angular2 from '/src/fragments/start/getting-started/vanillajs/hosting.mdx';\n\n<Fragments fragments={{ angular: angular2 }} />\n\nimport ionic3 from '/src/fragments/start/getting-started/ionic/hosting.mdx';\n\n<Fragments fragments={{ ionic: ionic3 }} />\n\nimport js4 from '/src/fragments/start/getting-started/vanillajs/hosting.mdx';\n\n<Fragments fragments={{ js: js4 }} />\n\nimport vue5 from '/src/fragments/start/getting-started/vanillajs/hosting.mdx';\n\n<Fragments fragments={{ vue: vue5 }} />\n",
    "meta": {
      "title": "Deploy and host app - JavaScript",
      "description": "Getting Started with Amplify Framework - how to host & deploy your web app - JavaScript",
      "filterKey": "integration",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/hosting/q/integration/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Add authentication`,\n  description: `Getting Started with Amplify Framework - how to add auth to your app`\n};\n\nimport react0 from '/src/fragments/start/getting-started/react/auth.mdx';\n\n<Fragments fragments={{ react: react0 }} />\n\nimport angular1 from '/src/fragments/start/getting-started/angular/auth.mdx';\n\n<Fragments fragments={{ angular: angular1 }} />\n\nimport vue2 from '/src/fragments/start/getting-started/vue/auth.mdx';\n\n<Fragments fragments={{ vue: vue2 }} />\n\nimport ionic3 from '/src/fragments/start/getting-started/angular/auth.mdx';\n\n<Fragments fragments={{ ionic: ionic3 }} />\n",
    "meta": {
      "title": "Add authentication - Ionic",
      "description": "Getting Started with Amplify Framework - how to add auth to your app - Ionic",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/auth/q/integration/ionic"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Add authentication`,\n  description: `Getting Started with Amplify Framework - how to add auth to your app`\n};\n\nimport react0 from '/src/fragments/start/getting-started/react/auth.mdx';\n\n<Fragments fragments={{ react: react0 }} />\n\nimport angular1 from '/src/fragments/start/getting-started/angular/auth.mdx';\n\n<Fragments fragments={{ angular: angular1 }} />\n\nimport vue2 from '/src/fragments/start/getting-started/vue/auth.mdx';\n\n<Fragments fragments={{ vue: vue2 }} />\n\nimport ionic3 from '/src/fragments/start/getting-started/angular/auth.mdx';\n\n<Fragments fragments={{ ionic: ionic3 }} />\n",
    "meta": {
      "title": "Add authentication - Vue",
      "description": "Getting Started with Amplify Framework - how to add auth to your app - Vue",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/auth/q/integration/vue"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Add authentication`,\n  description: `Getting Started with Amplify Framework - how to add auth to your app`\n};\n\nimport react0 from '/src/fragments/start/getting-started/react/auth.mdx';\n\n<Fragments fragments={{ react: react0 }} />\n\nimport angular1 from '/src/fragments/start/getting-started/angular/auth.mdx';\n\n<Fragments fragments={{ angular: angular1 }} />\n\nimport vue2 from '/src/fragments/start/getting-started/vue/auth.mdx';\n\n<Fragments fragments={{ vue: vue2 }} />\n\nimport ionic3 from '/src/fragments/start/getting-started/angular/auth.mdx';\n\n<Fragments fragments={{ ionic: ionic3 }} />\n",
    "meta": {
      "title": "Add authentication - Angular",
      "description": "Getting Started with Amplify Framework - how to add auth to your app - Angular",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/auth/q/integration/angular"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Add authentication`,\n  description: `Getting Started with Amplify Framework - how to add auth to your app`\n};\n\nimport react0 from '/src/fragments/start/getting-started/react/auth.mdx';\n\n<Fragments fragments={{ react: react0 }} />\n\nimport angular1 from '/src/fragments/start/getting-started/angular/auth.mdx';\n\n<Fragments fragments={{ angular: angular1 }} />\n\nimport vue2 from '/src/fragments/start/getting-started/vue/auth.mdx';\n\n<Fragments fragments={{ vue: vue2 }} />\n\nimport ionic3 from '/src/fragments/start/getting-started/angular/auth.mdx';\n\n<Fragments fragments={{ ionic: ionic3 }} />\n",
    "meta": {
      "title": "Add authentication - React",
      "description": "Getting Started with Amplify Framework - how to add auth to your app - React",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/auth/q/integration/react"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Connect API and database to the app`,\n  description: `Getting Started with Amplify Framework - how to model your data using Amplify`,\n  filterKey: `integration`,\n};\n\nimport next0 from \"/src/fragments/start/getting-started/next/api.mdx\";\n\n<Fragments fragments={{next: next0}} />\n\nimport react1 from \"/src/fragments/start/getting-started/react/api.mdx\";\n\n<Fragments fragments={{react: react1}} />\n\nimport angular2 from \"/src/fragments/start/getting-started/angular/data-model.mdx\";\n\n<Fragments fragments={{angular: angular2}} />\n\nimport ionic3 from \"/src/fragments/start/getting-started/ionic/data-model.mdx\";\n\n<Fragments fragments={{ionic: ionic3}} />\n\nimport js4 from \"/src/fragments/start/getting-started/vanillajs/data-model.mdx\";\n\n<Fragments fragments={{js: js4}} />\n\nimport vue5 from \"/src/fragments/start/getting-started/vue/data-model.mdx\";\n\n<Fragments fragments={{vue: vue5}} />\n\nimport next6 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{next: next6}} />\n\nimport react7 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{react: react7}} />\n\nimport angular8 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{angular: angular8}} />\n\nimport ionic9 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{ionic: ionic9}} />\n\nimport js10 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{js: js10}} />\n\nimport vue11 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{vue: vue11}} />\n\n",
    "meta": {
      "title": "Connect API and database to the app - Ionic",
      "description": "Getting Started with Amplify Framework - how to model your data using Amplify - Ionic",
      "filterKey": "integration",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/data-model/q/integration/ionic"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Connect API and database to the app`,\n  description: `Getting Started with Amplify Framework - how to model your data using Amplify`,\n  filterKey: `integration`,\n};\n\nimport next0 from \"/src/fragments/start/getting-started/next/api.mdx\";\n\n<Fragments fragments={{next: next0}} />\n\nimport react1 from \"/src/fragments/start/getting-started/react/api.mdx\";\n\n<Fragments fragments={{react: react1}} />\n\nimport angular2 from \"/src/fragments/start/getting-started/angular/data-model.mdx\";\n\n<Fragments fragments={{angular: angular2}} />\n\nimport ionic3 from \"/src/fragments/start/getting-started/ionic/data-model.mdx\";\n\n<Fragments fragments={{ionic: ionic3}} />\n\nimport js4 from \"/src/fragments/start/getting-started/vanillajs/data-model.mdx\";\n\n<Fragments fragments={{js: js4}} />\n\nimport vue5 from \"/src/fragments/start/getting-started/vue/data-model.mdx\";\n\n<Fragments fragments={{vue: vue5}} />\n\nimport next6 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{next: next6}} />\n\nimport react7 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{react: react7}} />\n\nimport angular8 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{angular: angular8}} />\n\nimport ionic9 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{ionic: ionic9}} />\n\nimport js10 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{js: js10}} />\n\nimport vue11 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{vue: vue11}} />\n\n",
    "meta": {
      "title": "Connect API and database to the app - Next.js",
      "description": "Getting Started with Amplify Framework - how to model your data using Amplify - Next.js",
      "filterKey": "integration",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/data-model/q/integration/next"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Connect API and database to the app`,\n  description: `Getting Started with Amplify Framework - how to model your data using Amplify`,\n  filterKey: `integration`,\n};\n\nimport next0 from \"/src/fragments/start/getting-started/next/api.mdx\";\n\n<Fragments fragments={{next: next0}} />\n\nimport react1 from \"/src/fragments/start/getting-started/react/api.mdx\";\n\n<Fragments fragments={{react: react1}} />\n\nimport angular2 from \"/src/fragments/start/getting-started/angular/data-model.mdx\";\n\n<Fragments fragments={{angular: angular2}} />\n\nimport ionic3 from \"/src/fragments/start/getting-started/ionic/data-model.mdx\";\n\n<Fragments fragments={{ionic: ionic3}} />\n\nimport js4 from \"/src/fragments/start/getting-started/vanillajs/data-model.mdx\";\n\n<Fragments fragments={{js: js4}} />\n\nimport vue5 from \"/src/fragments/start/getting-started/vue/data-model.mdx\";\n\n<Fragments fragments={{vue: vue5}} />\n\nimport next6 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{next: next6}} />\n\nimport react7 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{react: react7}} />\n\nimport angular8 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{angular: angular8}} />\n\nimport ionic9 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{ionic: ionic9}} />\n\nimport js10 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{js: js10}} />\n\nimport vue11 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{vue: vue11}} />\n\n",
    "meta": {
      "title": "Connect API and database to the app - Vue",
      "description": "Getting Started with Amplify Framework - how to model your data using Amplify - Vue",
      "filterKey": "integration",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/data-model/q/integration/vue"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Connect API and database to the app`,\n  description: `Getting Started with Amplify Framework - how to model your data using Amplify`,\n  filterKey: `integration`,\n};\n\nimport next0 from \"/src/fragments/start/getting-started/next/api.mdx\";\n\n<Fragments fragments={{next: next0}} />\n\nimport react1 from \"/src/fragments/start/getting-started/react/api.mdx\";\n\n<Fragments fragments={{react: react1}} />\n\nimport angular2 from \"/src/fragments/start/getting-started/angular/data-model.mdx\";\n\n<Fragments fragments={{angular: angular2}} />\n\nimport ionic3 from \"/src/fragments/start/getting-started/ionic/data-model.mdx\";\n\n<Fragments fragments={{ionic: ionic3}} />\n\nimport js4 from \"/src/fragments/start/getting-started/vanillajs/data-model.mdx\";\n\n<Fragments fragments={{js: js4}} />\n\nimport vue5 from \"/src/fragments/start/getting-started/vue/data-model.mdx\";\n\n<Fragments fragments={{vue: vue5}} />\n\nimport next6 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{next: next6}} />\n\nimport react7 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{react: react7}} />\n\nimport angular8 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{angular: angular8}} />\n\nimport ionic9 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{ionic: ionic9}} />\n\nimport js10 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{js: js10}} />\n\nimport vue11 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{vue: vue11}} />\n\n",
    "meta": {
      "title": "Connect API and database to the app - Angular",
      "description": "Getting Started with Amplify Framework - how to model your data using Amplify - Angular",
      "filterKey": "integration",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/data-model/q/integration/angular"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Connect API and database to the app`,\n  description: `Getting Started with Amplify Framework - how to model your data using Amplify`,\n  filterKey: `integration`,\n};\n\nimport next0 from \"/src/fragments/start/getting-started/next/api.mdx\";\n\n<Fragments fragments={{next: next0}} />\n\nimport react1 from \"/src/fragments/start/getting-started/react/api.mdx\";\n\n<Fragments fragments={{react: react1}} />\n\nimport angular2 from \"/src/fragments/start/getting-started/angular/data-model.mdx\";\n\n<Fragments fragments={{angular: angular2}} />\n\nimport ionic3 from \"/src/fragments/start/getting-started/ionic/data-model.mdx\";\n\n<Fragments fragments={{ionic: ionic3}} />\n\nimport js4 from \"/src/fragments/start/getting-started/vanillajs/data-model.mdx\";\n\n<Fragments fragments={{js: js4}} />\n\nimport vue5 from \"/src/fragments/start/getting-started/vue/data-model.mdx\";\n\n<Fragments fragments={{vue: vue5}} />\n\nimport next6 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{next: next6}} />\n\nimport react7 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{react: react7}} />\n\nimport angular8 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{angular: angular8}} />\n\nimport ionic9 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{ionic: ionic9}} />\n\nimport js10 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{js: js10}} />\n\nimport vue11 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{vue: vue11}} />\n\n",
    "meta": {
      "title": "Connect API and database to the app - React",
      "description": "Getting Started with Amplify Framework - how to model your data using Amplify - React",
      "filterKey": "integration",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/data-model/q/integration/react"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Connect API and database to the app`,\n  description: `Getting Started with Amplify Framework - how to model your data using Amplify`,\n  filterKey: `integration`,\n};\n\nimport next0 from \"/src/fragments/start/getting-started/next/api.mdx\";\n\n<Fragments fragments={{next: next0}} />\n\nimport react1 from \"/src/fragments/start/getting-started/react/api.mdx\";\n\n<Fragments fragments={{react: react1}} />\n\nimport angular2 from \"/src/fragments/start/getting-started/angular/data-model.mdx\";\n\n<Fragments fragments={{angular: angular2}} />\n\nimport ionic3 from \"/src/fragments/start/getting-started/ionic/data-model.mdx\";\n\n<Fragments fragments={{ionic: ionic3}} />\n\nimport js4 from \"/src/fragments/start/getting-started/vanillajs/data-model.mdx\";\n\n<Fragments fragments={{js: js4}} />\n\nimport vue5 from \"/src/fragments/start/getting-started/vue/data-model.mdx\";\n\n<Fragments fragments={{vue: vue5}} />\n\nimport next6 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{next: next6}} />\n\nimport react7 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{react: react7}} />\n\nimport angular8 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{angular: angular8}} />\n\nimport ionic9 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{ionic: ionic9}} />\n\nimport js10 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{js: js10}} />\n\nimport vue11 from \"/src/fragments/start/getting-started/common/data-model-footer.mdx\";\n\n<Fragments fragments={{vue: vue11}} />\n\n",
    "meta": {
      "title": "Connect API and database to the app - JavaScript",
      "description": "Getting Started with Amplify Framework - how to model your data using Amplify - JavaScript",
      "filterKey": "integration",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/data-model/q/integration/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Connect to the cloud`,\n  description: `Getting Started with Amplify Libraries - how to add API and database to your app.`,\n  filterKey: `integration`,\n};\n\nimport ios0 from \"/src/fragments/start/getting-started/ios/add-api.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/start/getting-started/android/add-api.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/start/getting-started/flutter/add-api.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport react_native3 from \"/src/fragments/start/getting-started/reactnative/add-api.mdx\";\n\n<Fragments fragments={{\"react-native\": react_native3}} />\n\n",
    "meta": {
      "title": "Connect to the cloud - React Native",
      "description": "Getting Started with Amplify Libraries - how to add API and database to your app. - React Native",
      "filterKey": "integration",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/add-api/q/integration/react-native"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Connect to the cloud`,\n  description: `Getting Started with Amplify Libraries - how to add API and database to your app.`,\n  filterKey: `integration`,\n};\n\nimport ios0 from \"/src/fragments/start/getting-started/ios/add-api.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/start/getting-started/android/add-api.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/start/getting-started/flutter/add-api.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport react_native3 from \"/src/fragments/start/getting-started/reactnative/add-api.mdx\";\n\n<Fragments fragments={{\"react-native\": react_native3}} />\n\n",
    "meta": {
      "title": "Connect to the cloud - Flutter",
      "description": "Getting Started with Amplify Libraries - how to add API and database to your app. - Flutter",
      "filterKey": "integration",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/add-api/q/integration/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Connect to the cloud`,\n  description: `Getting Started with Amplify Libraries - how to add API and database to your app.`,\n  filterKey: `integration`,\n};\n\nimport ios0 from \"/src/fragments/start/getting-started/ios/add-api.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/start/getting-started/android/add-api.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/start/getting-started/flutter/add-api.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport react_native3 from \"/src/fragments/start/getting-started/reactnative/add-api.mdx\";\n\n<Fragments fragments={{\"react-native\": react_native3}} />\n\n",
    "meta": {
      "title": "Connect to the cloud - iOS",
      "description": "Getting Started with Amplify Libraries - how to add API and database to your app. - iOS",
      "filterKey": "integration",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/add-api/q/integration/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Connect to the cloud`,\n  description: `Getting Started with Amplify Libraries - how to add API and database to your app.`,\n  filterKey: `integration`,\n};\n\nimport ios0 from \"/src/fragments/start/getting-started/ios/add-api.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/start/getting-started/android/add-api.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/start/getting-started/flutter/add-api.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport react_native3 from \"/src/fragments/start/getting-started/reactnative/add-api.mdx\";\n\n<Fragments fragments={{\"react-native\": react_native3}} />\n\n",
    "meta": {
      "title": "Connect to the cloud - Android",
      "description": "Getting Started with Amplify Libraries - how to add API and database to your app. - Android",
      "filterKey": "integration",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/add-api/q/integration/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Integrate in your app`,\n  description: `Getting Started with Amplify Libraries - How to integrate Amplify into your app`,\n  filterKey: `integration`,\n};\n\nimport ios0 from \"/src/fragments/start/getting-started/ios/integrate.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/start/getting-started/android/integrate.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/start/getting-started/flutter/integrate.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport react_native3 from \"/src/fragments/start/getting-started/reactnative/integrate.mdx\";\n\n<Fragments fragments={{\"react-native\": react_native3}} />",
    "meta": {
      "title": "Integrate your app - React Native",
      "description": "Getting Started with Amplify Libraries - How to integrate Amplify into your app - React Native",
      "filterKey": "integration",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/integrate/q/integration/react-native"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Integrate in your app`,\n  description: `Getting Started with Amplify Libraries - How to integrate Amplify into your app`,\n  filterKey: `integration`,\n};\n\nimport ios0 from \"/src/fragments/start/getting-started/ios/integrate.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/start/getting-started/android/integrate.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/start/getting-started/flutter/integrate.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport react_native3 from \"/src/fragments/start/getting-started/reactnative/integrate.mdx\";\n\n<Fragments fragments={{\"react-native\": react_native3}} />",
    "meta": {
      "title": "Integrate your app - Flutter",
      "description": "Getting Started with Amplify Libraries - How to integrate Amplify into your app - Flutter",
      "filterKey": "integration",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/integrate/q/integration/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Integrate in your app`,\n  description: `Getting Started with Amplify Libraries - How to integrate Amplify into your app`,\n  filterKey: `integration`,\n};\n\nimport ios0 from \"/src/fragments/start/getting-started/ios/integrate.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/start/getting-started/android/integrate.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/start/getting-started/flutter/integrate.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport react_native3 from \"/src/fragments/start/getting-started/reactnative/integrate.mdx\";\n\n<Fragments fragments={{\"react-native\": react_native3}} />",
    "meta": {
      "title": "Integrate your app - iOS",
      "description": "Getting Started with Amplify Libraries - How to integrate Amplify into your app - iOS",
      "filterKey": "integration",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/integrate/q/integration/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Integrate in your app`,\n  description: `Getting Started with Amplify Libraries - How to integrate Amplify into your app`,\n  filterKey: `integration`,\n};\n\nimport ios0 from \"/src/fragments/start/getting-started/ios/integrate.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/start/getting-started/android/integrate.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/start/getting-started/flutter/integrate.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport react_native3 from \"/src/fragments/start/getting-started/reactnative/integrate.mdx\";\n\n<Fragments fragments={{\"react-native\": react_native3}} />",
    "meta": {
      "title": "Integrate your app - Android",
      "description": "Getting Started with Amplify Libraries - How to integrate Amplify into your app - Android",
      "filterKey": "integration",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/integrate/q/integration/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Generate model files`,\n  description: `Getting Started with Amplify Libraries - Generate model files`,\n  filterKey: `integration`,\n};\n\nimport ios0 from \"/src/fragments/start/getting-started/ios/generate-model.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/start/getting-started/android/generate-model.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/start/getting-started/flutter/generate-model.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport react_native3 from \"/src/fragments/start/getting-started/reactnative/generate-model.mdx\";\n\n<Fragments fragments={{\"react-native\": react_native3}} />",
    "meta": {
      "title": "Generate model files - React Native",
      "description": "Getting Started with Amplify Libraries - Generate model files - React Native",
      "filterKey": "integration",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/generate-model/q/integration/react-native"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Generate model files`,\n  description: `Getting Started with Amplify Libraries - Generate model files`,\n  filterKey: `integration`,\n};\n\nimport ios0 from \"/src/fragments/start/getting-started/ios/generate-model.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/start/getting-started/android/generate-model.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/start/getting-started/flutter/generate-model.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport react_native3 from \"/src/fragments/start/getting-started/reactnative/generate-model.mdx\";\n\n<Fragments fragments={{\"react-native\": react_native3}} />",
    "meta": {
      "title": "Generate model files - Flutter",
      "description": "Getting Started with Amplify Libraries - Generate model files - Flutter",
      "filterKey": "integration",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/generate-model/q/integration/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Generate model files`,\n  description: `Getting Started with Amplify Libraries - Generate model files`,\n  filterKey: `integration`,\n};\n\nimport ios0 from \"/src/fragments/start/getting-started/ios/generate-model.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/start/getting-started/android/generate-model.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/start/getting-started/flutter/generate-model.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport react_native3 from \"/src/fragments/start/getting-started/reactnative/generate-model.mdx\";\n\n<Fragments fragments={{\"react-native\": react_native3}} />",
    "meta": {
      "title": "Generate model files - iOS",
      "description": "Getting Started with Amplify Libraries - Generate model files - iOS",
      "filterKey": "integration",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/generate-model/q/integration/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Generate model files`,\n  description: `Getting Started with Amplify Libraries - Generate model files`,\n  filterKey: `integration`,\n};\n\nimport ios0 from \"/src/fragments/start/getting-started/ios/generate-model.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/start/getting-started/android/generate-model.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/start/getting-started/flutter/generate-model.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport react_native3 from \"/src/fragments/start/getting-started/reactnative/generate-model.mdx\";\n\n<Fragments fragments={{\"react-native\": react_native3}} />",
    "meta": {
      "title": "Generate model files - Android",
      "description": "Getting Started with Amplify Libraries - Generate model files - Android",
      "filterKey": "integration",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/generate-model/q/integration/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Set up fullstack project`,\n  description: `Getting Started with Amplify Framework - Setup a fullstack project`,\n};\n\nimport next0 from \"/src/fragments/start/getting-started/next/setup.mdx\";\n\n<Fragments fragments={{next: next0}} />\n\nimport react1 from \"/src/fragments/start/getting-started/react/setup.mdx\";\n\n<Fragments fragments={{react: react1}} />\n\nimport react_native2 from \"/src/fragments/start/getting-started/reactnative/setup.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native2}} />\n\nimport angular3 from \"/src/fragments/start/getting-started/angular/setup.mdx\";\n\n<Fragments fragments={{angular: angular3}} />\n\nimport ionic4 from \"/src/fragments/start/getting-started/ionic/setup.mdx\";\n\n<Fragments fragments={{ionic: ionic4}} />\n\nimport js5 from \"/src/fragments/start/getting-started/vanillajs/setup.mdx\";\n\n<Fragments fragments={{js: js5}} />\n\nimport vue6 from \"/src/fragments/start/getting-started/vue/setup.mdx\";\n\n<Fragments fragments={{vue: vue6}} />\n\nimport ios7 from \"/src/fragments/start/getting-started/ios/setup.mdx\";\n\n<Fragments fragments={{ios: ios7}} />\n\nimport android8 from \"/src/fragments/start/getting-started/android/setup.mdx\";\n\n<Fragments fragments={{android: android8}} />\n\nimport flutter9 from \"/src/fragments/start/getting-started/flutter/setup.mdx\";\n\n<Fragments fragments={{flutter: flutter9}} />",
    "meta": {
      "title": "Set up fullstack project - Flutter",
      "description": "Getting Started with Amplify Framework - Setup a fullstack project - Flutter",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/setup/q/integration/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Set up fullstack project`,\n  description: `Getting Started with Amplify Framework - Setup a fullstack project`,\n};\n\nimport next0 from \"/src/fragments/start/getting-started/next/setup.mdx\";\n\n<Fragments fragments={{next: next0}} />\n\nimport react1 from \"/src/fragments/start/getting-started/react/setup.mdx\";\n\n<Fragments fragments={{react: react1}} />\n\nimport react_native2 from \"/src/fragments/start/getting-started/reactnative/setup.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native2}} />\n\nimport angular3 from \"/src/fragments/start/getting-started/angular/setup.mdx\";\n\n<Fragments fragments={{angular: angular3}} />\n\nimport ionic4 from \"/src/fragments/start/getting-started/ionic/setup.mdx\";\n\n<Fragments fragments={{ionic: ionic4}} />\n\nimport js5 from \"/src/fragments/start/getting-started/vanillajs/setup.mdx\";\n\n<Fragments fragments={{js: js5}} />\n\nimport vue6 from \"/src/fragments/start/getting-started/vue/setup.mdx\";\n\n<Fragments fragments={{vue: vue6}} />\n\nimport ios7 from \"/src/fragments/start/getting-started/ios/setup.mdx\";\n\n<Fragments fragments={{ios: ios7}} />\n\nimport android8 from \"/src/fragments/start/getting-started/android/setup.mdx\";\n\n<Fragments fragments={{android: android8}} />\n\nimport flutter9 from \"/src/fragments/start/getting-started/flutter/setup.mdx\";\n\n<Fragments fragments={{flutter: flutter9}} />",
    "meta": {
      "title": "Set up fullstack project - Ionic",
      "description": "Getting Started with Amplify Framework - Setup a fullstack project - Ionic",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/setup/q/integration/ionic"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Set up fullstack project`,\n  description: `Getting Started with Amplify Framework - Setup a fullstack project`,\n};\n\nimport next0 from \"/src/fragments/start/getting-started/next/setup.mdx\";\n\n<Fragments fragments={{next: next0}} />\n\nimport react1 from \"/src/fragments/start/getting-started/react/setup.mdx\";\n\n<Fragments fragments={{react: react1}} />\n\nimport react_native2 from \"/src/fragments/start/getting-started/reactnative/setup.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native2}} />\n\nimport angular3 from \"/src/fragments/start/getting-started/angular/setup.mdx\";\n\n<Fragments fragments={{angular: angular3}} />\n\nimport ionic4 from \"/src/fragments/start/getting-started/ionic/setup.mdx\";\n\n<Fragments fragments={{ionic: ionic4}} />\n\nimport js5 from \"/src/fragments/start/getting-started/vanillajs/setup.mdx\";\n\n<Fragments fragments={{js: js5}} />\n\nimport vue6 from \"/src/fragments/start/getting-started/vue/setup.mdx\";\n\n<Fragments fragments={{vue: vue6}} />\n\nimport ios7 from \"/src/fragments/start/getting-started/ios/setup.mdx\";\n\n<Fragments fragments={{ios: ios7}} />\n\nimport android8 from \"/src/fragments/start/getting-started/android/setup.mdx\";\n\n<Fragments fragments={{android: android8}} />\n\nimport flutter9 from \"/src/fragments/start/getting-started/flutter/setup.mdx\";\n\n<Fragments fragments={{flutter: flutter9}} />",
    "meta": {
      "title": "Set up fullstack project - iOS",
      "description": "Getting Started with Amplify Framework - Setup a fullstack project - iOS",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/setup/q/integration/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Set up fullstack project`,\n  description: `Getting Started with Amplify Framework - Setup a fullstack project`,\n};\n\nimport next0 from \"/src/fragments/start/getting-started/next/setup.mdx\";\n\n<Fragments fragments={{next: next0}} />\n\nimport react1 from \"/src/fragments/start/getting-started/react/setup.mdx\";\n\n<Fragments fragments={{react: react1}} />\n\nimport react_native2 from \"/src/fragments/start/getting-started/reactnative/setup.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native2}} />\n\nimport angular3 from \"/src/fragments/start/getting-started/angular/setup.mdx\";\n\n<Fragments fragments={{angular: angular3}} />\n\nimport ionic4 from \"/src/fragments/start/getting-started/ionic/setup.mdx\";\n\n<Fragments fragments={{ionic: ionic4}} />\n\nimport js5 from \"/src/fragments/start/getting-started/vanillajs/setup.mdx\";\n\n<Fragments fragments={{js: js5}} />\n\nimport vue6 from \"/src/fragments/start/getting-started/vue/setup.mdx\";\n\n<Fragments fragments={{vue: vue6}} />\n\nimport ios7 from \"/src/fragments/start/getting-started/ios/setup.mdx\";\n\n<Fragments fragments={{ios: ios7}} />\n\nimport android8 from \"/src/fragments/start/getting-started/android/setup.mdx\";\n\n<Fragments fragments={{android: android8}} />\n\nimport flutter9 from \"/src/fragments/start/getting-started/flutter/setup.mdx\";\n\n<Fragments fragments={{flutter: flutter9}} />",
    "meta": {
      "title": "Set up fullstack project - Android",
      "description": "Getting Started with Amplify Framework - Setup a fullstack project - Android",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/setup/q/integration/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Set up fullstack project`,\n  description: `Getting Started with Amplify Framework - Setup a fullstack project`,\n};\n\nimport next0 from \"/src/fragments/start/getting-started/next/setup.mdx\";\n\n<Fragments fragments={{next: next0}} />\n\nimport react1 from \"/src/fragments/start/getting-started/react/setup.mdx\";\n\n<Fragments fragments={{react: react1}} />\n\nimport react_native2 from \"/src/fragments/start/getting-started/reactnative/setup.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native2}} />\n\nimport angular3 from \"/src/fragments/start/getting-started/angular/setup.mdx\";\n\n<Fragments fragments={{angular: angular3}} />\n\nimport ionic4 from \"/src/fragments/start/getting-started/ionic/setup.mdx\";\n\n<Fragments fragments={{ionic: ionic4}} />\n\nimport js5 from \"/src/fragments/start/getting-started/vanillajs/setup.mdx\";\n\n<Fragments fragments={{js: js5}} />\n\nimport vue6 from \"/src/fragments/start/getting-started/vue/setup.mdx\";\n\n<Fragments fragments={{vue: vue6}} />\n\nimport ios7 from \"/src/fragments/start/getting-started/ios/setup.mdx\";\n\n<Fragments fragments={{ios: ios7}} />\n\nimport android8 from \"/src/fragments/start/getting-started/android/setup.mdx\";\n\n<Fragments fragments={{android: android8}} />\n\nimport flutter9 from \"/src/fragments/start/getting-started/flutter/setup.mdx\";\n\n<Fragments fragments={{flutter: flutter9}} />",
    "meta": {
      "title": "Set up fullstack project - Next.js",
      "description": "Getting Started with Amplify Framework - Setup a fullstack project - Next.js",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/setup/q/integration/next"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Set up fullstack project`,\n  description: `Getting Started with Amplify Framework - Setup a fullstack project`,\n};\n\nimport next0 from \"/src/fragments/start/getting-started/next/setup.mdx\";\n\n<Fragments fragments={{next: next0}} />\n\nimport react1 from \"/src/fragments/start/getting-started/react/setup.mdx\";\n\n<Fragments fragments={{react: react1}} />\n\nimport react_native2 from \"/src/fragments/start/getting-started/reactnative/setup.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native2}} />\n\nimport angular3 from \"/src/fragments/start/getting-started/angular/setup.mdx\";\n\n<Fragments fragments={{angular: angular3}} />\n\nimport ionic4 from \"/src/fragments/start/getting-started/ionic/setup.mdx\";\n\n<Fragments fragments={{ionic: ionic4}} />\n\nimport js5 from \"/src/fragments/start/getting-started/vanillajs/setup.mdx\";\n\n<Fragments fragments={{js: js5}} />\n\nimport vue6 from \"/src/fragments/start/getting-started/vue/setup.mdx\";\n\n<Fragments fragments={{vue: vue6}} />\n\nimport ios7 from \"/src/fragments/start/getting-started/ios/setup.mdx\";\n\n<Fragments fragments={{ios: ios7}} />\n\nimport android8 from \"/src/fragments/start/getting-started/android/setup.mdx\";\n\n<Fragments fragments={{android: android8}} />\n\nimport flutter9 from \"/src/fragments/start/getting-started/flutter/setup.mdx\";\n\n<Fragments fragments={{flutter: flutter9}} />",
    "meta": {
      "title": "Set up fullstack project - Vue",
      "description": "Getting Started with Amplify Framework - Setup a fullstack project - Vue",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/setup/q/integration/vue"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Set up fullstack project`,\n  description: `Getting Started with Amplify Framework - Setup a fullstack project`,\n};\n\nimport next0 from \"/src/fragments/start/getting-started/next/setup.mdx\";\n\n<Fragments fragments={{next: next0}} />\n\nimport react1 from \"/src/fragments/start/getting-started/react/setup.mdx\";\n\n<Fragments fragments={{react: react1}} />\n\nimport react_native2 from \"/src/fragments/start/getting-started/reactnative/setup.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native2}} />\n\nimport angular3 from \"/src/fragments/start/getting-started/angular/setup.mdx\";\n\n<Fragments fragments={{angular: angular3}} />\n\nimport ionic4 from \"/src/fragments/start/getting-started/ionic/setup.mdx\";\n\n<Fragments fragments={{ionic: ionic4}} />\n\nimport js5 from \"/src/fragments/start/getting-started/vanillajs/setup.mdx\";\n\n<Fragments fragments={{js: js5}} />\n\nimport vue6 from \"/src/fragments/start/getting-started/vue/setup.mdx\";\n\n<Fragments fragments={{vue: vue6}} />\n\nimport ios7 from \"/src/fragments/start/getting-started/ios/setup.mdx\";\n\n<Fragments fragments={{ios: ios7}} />\n\nimport android8 from \"/src/fragments/start/getting-started/android/setup.mdx\";\n\n<Fragments fragments={{android: android8}} />\n\nimport flutter9 from \"/src/fragments/start/getting-started/flutter/setup.mdx\";\n\n<Fragments fragments={{flutter: flutter9}} />",
    "meta": {
      "title": "Set up fullstack project - Angular",
      "description": "Getting Started with Amplify Framework - Setup a fullstack project - Angular",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/setup/q/integration/angular"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Set up fullstack project`,\n  description: `Getting Started with Amplify Framework - Setup a fullstack project`,\n};\n\nimport next0 from \"/src/fragments/start/getting-started/next/setup.mdx\";\n\n<Fragments fragments={{next: next0}} />\n\nimport react1 from \"/src/fragments/start/getting-started/react/setup.mdx\";\n\n<Fragments fragments={{react: react1}} />\n\nimport react_native2 from \"/src/fragments/start/getting-started/reactnative/setup.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native2}} />\n\nimport angular3 from \"/src/fragments/start/getting-started/angular/setup.mdx\";\n\n<Fragments fragments={{angular: angular3}} />\n\nimport ionic4 from \"/src/fragments/start/getting-started/ionic/setup.mdx\";\n\n<Fragments fragments={{ionic: ionic4}} />\n\nimport js5 from \"/src/fragments/start/getting-started/vanillajs/setup.mdx\";\n\n<Fragments fragments={{js: js5}} />\n\nimport vue6 from \"/src/fragments/start/getting-started/vue/setup.mdx\";\n\n<Fragments fragments={{vue: vue6}} />\n\nimport ios7 from \"/src/fragments/start/getting-started/ios/setup.mdx\";\n\n<Fragments fragments={{ios: ios7}} />\n\nimport android8 from \"/src/fragments/start/getting-started/android/setup.mdx\";\n\n<Fragments fragments={{android: android8}} />\n\nimport flutter9 from \"/src/fragments/start/getting-started/flutter/setup.mdx\";\n\n<Fragments fragments={{flutter: flutter9}} />",
    "meta": {
      "title": "Set up fullstack project - React Native",
      "description": "Getting Started with Amplify Framework - Setup a fullstack project - React Native",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/setup/q/integration/react-native"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Set up fullstack project`,\n  description: `Getting Started with Amplify Framework - Setup a fullstack project`,\n};\n\nimport next0 from \"/src/fragments/start/getting-started/next/setup.mdx\";\n\n<Fragments fragments={{next: next0}} />\n\nimport react1 from \"/src/fragments/start/getting-started/react/setup.mdx\";\n\n<Fragments fragments={{react: react1}} />\n\nimport react_native2 from \"/src/fragments/start/getting-started/reactnative/setup.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native2}} />\n\nimport angular3 from \"/src/fragments/start/getting-started/angular/setup.mdx\";\n\n<Fragments fragments={{angular: angular3}} />\n\nimport ionic4 from \"/src/fragments/start/getting-started/ionic/setup.mdx\";\n\n<Fragments fragments={{ionic: ionic4}} />\n\nimport js5 from \"/src/fragments/start/getting-started/vanillajs/setup.mdx\";\n\n<Fragments fragments={{js: js5}} />\n\nimport vue6 from \"/src/fragments/start/getting-started/vue/setup.mdx\";\n\n<Fragments fragments={{vue: vue6}} />\n\nimport ios7 from \"/src/fragments/start/getting-started/ios/setup.mdx\";\n\n<Fragments fragments={{ios: ios7}} />\n\nimport android8 from \"/src/fragments/start/getting-started/android/setup.mdx\";\n\n<Fragments fragments={{android: android8}} />\n\nimport flutter9 from \"/src/fragments/start/getting-started/flutter/setup.mdx\";\n\n<Fragments fragments={{flutter: flutter9}} />",
    "meta": {
      "title": "Set up fullstack project - React",
      "description": "Getting Started with Amplify Framework - Setup a fullstack project - React",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/setup/q/integration/react"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Set up fullstack project`,\n  description: `Getting Started with Amplify Framework - Setup a fullstack project`,\n};\n\nimport next0 from \"/src/fragments/start/getting-started/next/setup.mdx\";\n\n<Fragments fragments={{next: next0}} />\n\nimport react1 from \"/src/fragments/start/getting-started/react/setup.mdx\";\n\n<Fragments fragments={{react: react1}} />\n\nimport react_native2 from \"/src/fragments/start/getting-started/reactnative/setup.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native2}} />\n\nimport angular3 from \"/src/fragments/start/getting-started/angular/setup.mdx\";\n\n<Fragments fragments={{angular: angular3}} />\n\nimport ionic4 from \"/src/fragments/start/getting-started/ionic/setup.mdx\";\n\n<Fragments fragments={{ionic: ionic4}} />\n\nimport js5 from \"/src/fragments/start/getting-started/vanillajs/setup.mdx\";\n\n<Fragments fragments={{js: js5}} />\n\nimport vue6 from \"/src/fragments/start/getting-started/vue/setup.mdx\";\n\n<Fragments fragments={{vue: vue6}} />\n\nimport ios7 from \"/src/fragments/start/getting-started/ios/setup.mdx\";\n\n<Fragments fragments={{ios: ios7}} />\n\nimport android8 from \"/src/fragments/start/getting-started/android/setup.mdx\";\n\n<Fragments fragments={{android: android8}} />\n\nimport flutter9 from \"/src/fragments/start/getting-started/flutter/setup.mdx\";\n\n<Fragments fragments={{flutter: flutter9}} />",
    "meta": {
      "title": "Set up fullstack project - JavaScript",
      "description": "Getting Started with Amplify Framework - Setup a fullstack project - JavaScript",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/setup/q/integration/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Prerequisites`,\n  description: `Getting Started with Amplify Framework - Prerequisites`,\n  filterKey: `integration`,\n};\n\nimport js0 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport react1 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{react: react1}} />\n\nimport angular2 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{angular: angular2}} />\n\nimport vue3 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{vue: vue3}} />\n\nimport next4 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{next: next4}} />\n\nimport android5 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{android: android5}} />\n\nimport ios6 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{ios: ios6}} />\n\nimport react_native7 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native7}} />\n\nimport ionic8 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{ionic: ionic8}} />\n\nimport flutter9 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{flutter: flutter9}} />\n",
    "meta": {
      "title": "Prerequisites - Flutter",
      "description": "Getting Started with Amplify Framework - Prerequisites - Flutter",
      "filterKey": "integration",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/installation/q/integration/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Prerequisites`,\n  description: `Getting Started with Amplify Framework - Prerequisites`,\n  filterKey: `integration`,\n};\n\nimport js0 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport react1 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{react: react1}} />\n\nimport angular2 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{angular: angular2}} />\n\nimport vue3 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{vue: vue3}} />\n\nimport next4 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{next: next4}} />\n\nimport android5 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{android: android5}} />\n\nimport ios6 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{ios: ios6}} />\n\nimport react_native7 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native7}} />\n\nimport ionic8 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{ionic: ionic8}} />\n\nimport flutter9 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{flutter: flutter9}} />\n",
    "meta": {
      "title": "Prerequisites - Ionic",
      "description": "Getting Started with Amplify Framework - Prerequisites - Ionic",
      "filterKey": "integration",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/installation/q/integration/ionic"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Prerequisites`,\n  description: `Getting Started with Amplify Framework - Prerequisites`,\n  filterKey: `integration`,\n};\n\nimport js0 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport react1 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{react: react1}} />\n\nimport angular2 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{angular: angular2}} />\n\nimport vue3 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{vue: vue3}} />\n\nimport next4 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{next: next4}} />\n\nimport android5 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{android: android5}} />\n\nimport ios6 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{ios: ios6}} />\n\nimport react_native7 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native7}} />\n\nimport ionic8 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{ionic: ionic8}} />\n\nimport flutter9 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{flutter: flutter9}} />\n",
    "meta": {
      "title": "Prerequisites - iOS",
      "description": "Getting Started with Amplify Framework - Prerequisites - iOS",
      "filterKey": "integration",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/installation/q/integration/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Prerequisites`,\n  description: `Getting Started with Amplify Framework - Prerequisites`,\n  filterKey: `integration`,\n};\n\nimport js0 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport react1 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{react: react1}} />\n\nimport angular2 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{angular: angular2}} />\n\nimport vue3 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{vue: vue3}} />\n\nimport next4 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{next: next4}} />\n\nimport android5 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{android: android5}} />\n\nimport ios6 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{ios: ios6}} />\n\nimport react_native7 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native7}} />\n\nimport ionic8 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{ionic: ionic8}} />\n\nimport flutter9 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{flutter: flutter9}} />\n",
    "meta": {
      "title": "Prerequisites - Android",
      "description": "Getting Started with Amplify Framework - Prerequisites - Android",
      "filterKey": "integration",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/installation/q/integration/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Prerequisites`,\n  description: `Getting Started with Amplify Framework - Prerequisites`,\n  filterKey: `integration`,\n};\n\nimport js0 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport react1 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{react: react1}} />\n\nimport angular2 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{angular: angular2}} />\n\nimport vue3 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{vue: vue3}} />\n\nimport next4 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{next: next4}} />\n\nimport android5 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{android: android5}} />\n\nimport ios6 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{ios: ios6}} />\n\nimport react_native7 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native7}} />\n\nimport ionic8 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{ionic: ionic8}} />\n\nimport flutter9 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{flutter: flutter9}} />\n",
    "meta": {
      "title": "Prerequisites - Next.js",
      "description": "Getting Started with Amplify Framework - Prerequisites - Next.js",
      "filterKey": "integration",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/installation/q/integration/next"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Prerequisites`,\n  description: `Getting Started with Amplify Framework - Prerequisites`,\n  filterKey: `integration`,\n};\n\nimport js0 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport react1 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{react: react1}} />\n\nimport angular2 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{angular: angular2}} />\n\nimport vue3 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{vue: vue3}} />\n\nimport next4 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{next: next4}} />\n\nimport android5 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{android: android5}} />\n\nimport ios6 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{ios: ios6}} />\n\nimport react_native7 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native7}} />\n\nimport ionic8 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{ionic: ionic8}} />\n\nimport flutter9 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{flutter: flutter9}} />\n",
    "meta": {
      "title": "Prerequisites - Vue",
      "description": "Getting Started with Amplify Framework - Prerequisites - Vue",
      "filterKey": "integration",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/installation/q/integration/vue"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Prerequisites`,\n  description: `Getting Started with Amplify Framework - Prerequisites`,\n  filterKey: `integration`,\n};\n\nimport js0 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport react1 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{react: react1}} />\n\nimport angular2 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{angular: angular2}} />\n\nimport vue3 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{vue: vue3}} />\n\nimport next4 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{next: next4}} />\n\nimport android5 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{android: android5}} />\n\nimport ios6 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{ios: ios6}} />\n\nimport react_native7 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native7}} />\n\nimport ionic8 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{ionic: ionic8}} />\n\nimport flutter9 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{flutter: flutter9}} />\n",
    "meta": {
      "title": "Prerequisites - Angular",
      "description": "Getting Started with Amplify Framework - Prerequisites - Angular",
      "filterKey": "integration",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/installation/q/integration/angular"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Prerequisites`,\n  description: `Getting Started with Amplify Framework - Prerequisites`,\n  filterKey: `integration`,\n};\n\nimport js0 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport react1 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{react: react1}} />\n\nimport angular2 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{angular: angular2}} />\n\nimport vue3 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{vue: vue3}} />\n\nimport next4 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{next: next4}} />\n\nimport android5 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{android: android5}} />\n\nimport ios6 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{ios: ios6}} />\n\nimport react_native7 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native7}} />\n\nimport ionic8 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{ionic: ionic8}} />\n\nimport flutter9 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{flutter: flutter9}} />\n",
    "meta": {
      "title": "Prerequisites - React Native",
      "description": "Getting Started with Amplify Framework - Prerequisites - React Native",
      "filterKey": "integration",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/installation/q/integration/react-native"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Prerequisites`,\n  description: `Getting Started with Amplify Framework - Prerequisites`,\n  filterKey: `integration`,\n};\n\nimport js0 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport react1 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{react: react1}} />\n\nimport angular2 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{angular: angular2}} />\n\nimport vue3 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{vue: vue3}} />\n\nimport next4 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{next: next4}} />\n\nimport android5 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{android: android5}} />\n\nimport ios6 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{ios: ios6}} />\n\nimport react_native7 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native7}} />\n\nimport ionic8 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{ionic: ionic8}} />\n\nimport flutter9 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{flutter: flutter9}} />\n",
    "meta": {
      "title": "Prerequisites - React",
      "description": "Getting Started with Amplify Framework - Prerequisites - React",
      "filterKey": "integration",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/installation/q/integration/react"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Prerequisites`,\n  description: `Getting Started with Amplify Framework - Prerequisites`,\n  filterKey: `integration`,\n};\n\nimport js0 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport react1 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{react: react1}} />\n\nimport angular2 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{angular: angular2}} />\n\nimport vue3 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{vue: vue3}} />\n\nimport next4 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{next: next4}} />\n\nimport android5 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{android: android5}} />\n\nimport ios6 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{ios: ios6}} />\n\nimport react_native7 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native7}} />\n\nimport ionic8 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{ionic: ionic8}} />\n\nimport flutter9 from \"/src/fragments/start/getting-started/common/prereq.mdx\";\n\n<Fragments fragments={{flutter: flutter9}} />\n",
    "meta": {
      "title": "Prerequisites - JavaScript",
      "description": "Getting Started with Amplify Framework - Prerequisites - JavaScript",
      "filterKey": "integration",
      "subcategory": "Tutorial",
      "category": "Getting started"
    },
    "filename": "/start/getting-started/installation/q/integration/js"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "The open-source Amplify Framework provides the following products to build fullstack iOS, Android, Flutter, Web, and React Native apps:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify CLI - Configure all the services needed to power your backend through a simple command line interface."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify Libraries - Use case-centric client libraries to integrate your app code with a backend using declarative interfaces."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify UI Components - UI libraries for React, React Native, Angular, Ionic, Vue and Flutter."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The Amplify Hosting is an AWS service that provides a git-based workflow for continuous deployment & hosting of fullstack web apps. Cloud resources created by the Amplify CLI are also visible in the Amplify Console."
      },
      {
        "heading": null,
        "depth": null,
        "text": "NEW! Use Amplify Studio to get started with Amplify. Get started"
      }
    ],
    "source": "export const meta = {\n  title: \"Getting started\",\n  description: \"Getting Started with Amplify Framework\",\n  disableTOC: \"true\",\n  filterKey: \"integration\",\n};\n\nThe open-source Amplify Framework provides the following products to build fullstack iOS, Android, Flutter, Web, and React Native apps:\n\n- **Amplify [CLI](/cli)** - Configure all the services needed to power your backend through a simple command line interface.\n- **Amplify [Libraries](/lib)** - Use case-centric client libraries to integrate your app code with a backend using declarative interfaces.\n- **Amplify [UI Components](/ui)** - UI libraries for React, React Native, Angular, Ionic, Vue and Flutter.\n\nThe **Amplify [Hosting](https://aws.amazon.com/amplify/hosting/)** is an AWS service that provides a git-based workflow for continuous deployment & hosting of fullstack web apps. Cloud resources created by the Amplify CLI are also visible in the Amplify Console.\n\nimport ios0 from '/src/fragments/start/getting-started/ios/build.mdx';\n\n<Fragments fragments={{ ios: ios0 }} />\n\nimport android1 from '/src/fragments/start/getting-started/android/build.mdx';\n\n<Fragments fragments={{ android: android1 }} />\n\nimport flutter2 from '/src/fragments/start/getting-started/flutter/build.mdx';\n\n<Fragments fragments={{ flutter: flutter2 }} />\n\nimport js3 from '/src/fragments/start/getting-started/vanillajs/build.mdx';\n\n<Fragments fragments={{ js: js3 }} />\n\nimport next4 from '/src/fragments/start/getting-started/next/build.mdx';\n\n<Fragments fragments={{ next: next4 }} />\n\nimport react5 from '/src/fragments/start/getting-started/react/build.mdx';\n\n<Fragments fragments={{ react: react5 }} />\n\nimport react_native6 from '/src/fragments/start/getting-started/reactnative/build.mdx';\n\n<Fragments fragments={{ 'react-native': react_native6 }} />\n\nimport angular7 from '/src/fragments/start/getting-started/angular/build.mdx';\n\n<Fragments fragments={{ angular: angular7 }} />\n\nimport ionic8 from '/src/fragments/start/getting-started/ionic/build.mdx';\n\n<Fragments fragments={{ ionic: ionic8 }} />\n\nimport vue9 from '/src/fragments/start/getting-started/vue/build.mdx';\n\n<Fragments fragments={{ vue: vue9 }} />\n\nimport ios10 from '/src/fragments/start/getting-started/ios/build-footer.mdx';\n\n<Fragments fragments={{ ios: ios10 }} />\n\nimport android11 from '/src/fragments/start/getting-started/android/build-footer.mdx';\n\n<Fragments fragments={{ android: android11 }} />\n\nimport flutter12 from '/src/fragments/start/getting-started/flutter/build-footer.mdx';\n\n<Fragments fragments={{ flutter: flutter12 }} />\n\nimport js13 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ js: js13 }} />\n\nimport next14 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ next: next14 }} />\n\nimport react15 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ react: react15 }} />\n\nimport react_native16 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ 'react-native': react_native16 }} />\n\nimport angular17 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ angular: angular17 }} />\n\nimport ionic18 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ ionic: ionic18 }} />\n\nimport vue19 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ vue: vue19 }} />\n\n**NEW!** Use Amplify Studio to get started with Amplify. [Get started](https://sandbox.amplifyapp.com/getting-started)\n",
    "meta": {
      "title": "Getting started - Flutter",
      "description": "Getting Started with Amplify Framework - Flutter",
      "disableTOC": "true",
      "filterKey": "integration",
      "category": "Getting started"
    },
    "filename": "/start/q/integration/flutter"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "The open-source Amplify Framework provides the following products to build fullstack iOS, Android, Flutter, Web, and React Native apps:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify CLI - Configure all the services needed to power your backend through a simple command line interface."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify Libraries - Use case-centric client libraries to integrate your app code with a backend using declarative interfaces."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify UI Components - UI libraries for React, React Native, Angular, Ionic, Vue and Flutter."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The Amplify Hosting is an AWS service that provides a git-based workflow for continuous deployment & hosting of fullstack web apps. Cloud resources created by the Amplify CLI are also visible in the Amplify Console."
      },
      {
        "heading": null,
        "depth": null,
        "text": "NEW! Use Amplify Studio to get started with Amplify. Get started"
      }
    ],
    "source": "export const meta = {\n  title: \"Getting started\",\n  description: \"Getting Started with Amplify Framework\",\n  disableTOC: \"true\",\n  filterKey: \"integration\",\n};\n\nThe open-source Amplify Framework provides the following products to build fullstack iOS, Android, Flutter, Web, and React Native apps:\n\n- **Amplify [CLI](/cli)** - Configure all the services needed to power your backend through a simple command line interface.\n- **Amplify [Libraries](/lib)** - Use case-centric client libraries to integrate your app code with a backend using declarative interfaces.\n- **Amplify [UI Components](/ui)** - UI libraries for React, React Native, Angular, Ionic, Vue and Flutter.\n\nThe **Amplify [Hosting](https://aws.amazon.com/amplify/hosting/)** is an AWS service that provides a git-based workflow for continuous deployment & hosting of fullstack web apps. Cloud resources created by the Amplify CLI are also visible in the Amplify Console.\n\nimport ios0 from '/src/fragments/start/getting-started/ios/build.mdx';\n\n<Fragments fragments={{ ios: ios0 }} />\n\nimport android1 from '/src/fragments/start/getting-started/android/build.mdx';\n\n<Fragments fragments={{ android: android1 }} />\n\nimport flutter2 from '/src/fragments/start/getting-started/flutter/build.mdx';\n\n<Fragments fragments={{ flutter: flutter2 }} />\n\nimport js3 from '/src/fragments/start/getting-started/vanillajs/build.mdx';\n\n<Fragments fragments={{ js: js3 }} />\n\nimport next4 from '/src/fragments/start/getting-started/next/build.mdx';\n\n<Fragments fragments={{ next: next4 }} />\n\nimport react5 from '/src/fragments/start/getting-started/react/build.mdx';\n\n<Fragments fragments={{ react: react5 }} />\n\nimport react_native6 from '/src/fragments/start/getting-started/reactnative/build.mdx';\n\n<Fragments fragments={{ 'react-native': react_native6 }} />\n\nimport angular7 from '/src/fragments/start/getting-started/angular/build.mdx';\n\n<Fragments fragments={{ angular: angular7 }} />\n\nimport ionic8 from '/src/fragments/start/getting-started/ionic/build.mdx';\n\n<Fragments fragments={{ ionic: ionic8 }} />\n\nimport vue9 from '/src/fragments/start/getting-started/vue/build.mdx';\n\n<Fragments fragments={{ vue: vue9 }} />\n\nimport ios10 from '/src/fragments/start/getting-started/ios/build-footer.mdx';\n\n<Fragments fragments={{ ios: ios10 }} />\n\nimport android11 from '/src/fragments/start/getting-started/android/build-footer.mdx';\n\n<Fragments fragments={{ android: android11 }} />\n\nimport flutter12 from '/src/fragments/start/getting-started/flutter/build-footer.mdx';\n\n<Fragments fragments={{ flutter: flutter12 }} />\n\nimport js13 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ js: js13 }} />\n\nimport next14 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ next: next14 }} />\n\nimport react15 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ react: react15 }} />\n\nimport react_native16 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ 'react-native': react_native16 }} />\n\nimport angular17 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ angular: angular17 }} />\n\nimport ionic18 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ ionic: ionic18 }} />\n\nimport vue19 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ vue: vue19 }} />\n\n**NEW!** Use Amplify Studio to get started with Amplify. [Get started](https://sandbox.amplifyapp.com/getting-started)\n",
    "meta": {
      "title": "Getting started - Ionic",
      "description": "Getting Started with Amplify Framework - Ionic",
      "disableTOC": "true",
      "filterKey": "integration",
      "category": "Getting started"
    },
    "filename": "/start/q/integration/ionic"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "The open-source Amplify Framework provides the following products to build fullstack iOS, Android, Flutter, Web, and React Native apps:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify CLI - Configure all the services needed to power your backend through a simple command line interface."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify Libraries - Use case-centric client libraries to integrate your app code with a backend using declarative interfaces."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify UI Components - UI libraries for React, React Native, Angular, Ionic, Vue and Flutter."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The Amplify Hosting is an AWS service that provides a git-based workflow for continuous deployment & hosting of fullstack web apps. Cloud resources created by the Amplify CLI are also visible in the Amplify Console."
      },
      {
        "heading": null,
        "depth": null,
        "text": "NEW! Use Amplify Studio to get started with Amplify. Get started"
      }
    ],
    "source": "export const meta = {\n  title: \"Getting started\",\n  description: \"Getting Started with Amplify Framework\",\n  disableTOC: \"true\",\n  filterKey: \"integration\",\n};\n\nThe open-source Amplify Framework provides the following products to build fullstack iOS, Android, Flutter, Web, and React Native apps:\n\n- **Amplify [CLI](/cli)** - Configure all the services needed to power your backend through a simple command line interface.\n- **Amplify [Libraries](/lib)** - Use case-centric client libraries to integrate your app code with a backend using declarative interfaces.\n- **Amplify [UI Components](/ui)** - UI libraries for React, React Native, Angular, Ionic, Vue and Flutter.\n\nThe **Amplify [Hosting](https://aws.amazon.com/amplify/hosting/)** is an AWS service that provides a git-based workflow for continuous deployment & hosting of fullstack web apps. Cloud resources created by the Amplify CLI are also visible in the Amplify Console.\n\nimport ios0 from '/src/fragments/start/getting-started/ios/build.mdx';\n\n<Fragments fragments={{ ios: ios0 }} />\n\nimport android1 from '/src/fragments/start/getting-started/android/build.mdx';\n\n<Fragments fragments={{ android: android1 }} />\n\nimport flutter2 from '/src/fragments/start/getting-started/flutter/build.mdx';\n\n<Fragments fragments={{ flutter: flutter2 }} />\n\nimport js3 from '/src/fragments/start/getting-started/vanillajs/build.mdx';\n\n<Fragments fragments={{ js: js3 }} />\n\nimport next4 from '/src/fragments/start/getting-started/next/build.mdx';\n\n<Fragments fragments={{ next: next4 }} />\n\nimport react5 from '/src/fragments/start/getting-started/react/build.mdx';\n\n<Fragments fragments={{ react: react5 }} />\n\nimport react_native6 from '/src/fragments/start/getting-started/reactnative/build.mdx';\n\n<Fragments fragments={{ 'react-native': react_native6 }} />\n\nimport angular7 from '/src/fragments/start/getting-started/angular/build.mdx';\n\n<Fragments fragments={{ angular: angular7 }} />\n\nimport ionic8 from '/src/fragments/start/getting-started/ionic/build.mdx';\n\n<Fragments fragments={{ ionic: ionic8 }} />\n\nimport vue9 from '/src/fragments/start/getting-started/vue/build.mdx';\n\n<Fragments fragments={{ vue: vue9 }} />\n\nimport ios10 from '/src/fragments/start/getting-started/ios/build-footer.mdx';\n\n<Fragments fragments={{ ios: ios10 }} />\n\nimport android11 from '/src/fragments/start/getting-started/android/build-footer.mdx';\n\n<Fragments fragments={{ android: android11 }} />\n\nimport flutter12 from '/src/fragments/start/getting-started/flutter/build-footer.mdx';\n\n<Fragments fragments={{ flutter: flutter12 }} />\n\nimport js13 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ js: js13 }} />\n\nimport next14 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ next: next14 }} />\n\nimport react15 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ react: react15 }} />\n\nimport react_native16 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ 'react-native': react_native16 }} />\n\nimport angular17 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ angular: angular17 }} />\n\nimport ionic18 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ ionic: ionic18 }} />\n\nimport vue19 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ vue: vue19 }} />\n\n**NEW!** Use Amplify Studio to get started with Amplify. [Get started](https://sandbox.amplifyapp.com/getting-started)\n",
    "meta": {
      "title": "Getting started - iOS",
      "description": "Getting Started with Amplify Framework - iOS",
      "disableTOC": "true",
      "filterKey": "integration",
      "category": "Getting started"
    },
    "filename": "/start/q/integration/ios"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "The open-source Amplify Framework provides the following products to build fullstack iOS, Android, Flutter, Web, and React Native apps:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify CLI - Configure all the services needed to power your backend through a simple command line interface."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify Libraries - Use case-centric client libraries to integrate your app code with a backend using declarative interfaces."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify UI Components - UI libraries for React, React Native, Angular, Ionic, Vue and Flutter."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The Amplify Hosting is an AWS service that provides a git-based workflow for continuous deployment & hosting of fullstack web apps. Cloud resources created by the Amplify CLI are also visible in the Amplify Console."
      },
      {
        "heading": null,
        "depth": null,
        "text": "NEW! Use Amplify Studio to get started with Amplify. Get started"
      }
    ],
    "source": "export const meta = {\n  title: \"Getting started\",\n  description: \"Getting Started with Amplify Framework\",\n  disableTOC: \"true\",\n  filterKey: \"integration\",\n};\n\nThe open-source Amplify Framework provides the following products to build fullstack iOS, Android, Flutter, Web, and React Native apps:\n\n- **Amplify [CLI](/cli)** - Configure all the services needed to power your backend through a simple command line interface.\n- **Amplify [Libraries](/lib)** - Use case-centric client libraries to integrate your app code with a backend using declarative interfaces.\n- **Amplify [UI Components](/ui)** - UI libraries for React, React Native, Angular, Ionic, Vue and Flutter.\n\nThe **Amplify [Hosting](https://aws.amazon.com/amplify/hosting/)** is an AWS service that provides a git-based workflow for continuous deployment & hosting of fullstack web apps. Cloud resources created by the Amplify CLI are also visible in the Amplify Console.\n\nimport ios0 from '/src/fragments/start/getting-started/ios/build.mdx';\n\n<Fragments fragments={{ ios: ios0 }} />\n\nimport android1 from '/src/fragments/start/getting-started/android/build.mdx';\n\n<Fragments fragments={{ android: android1 }} />\n\nimport flutter2 from '/src/fragments/start/getting-started/flutter/build.mdx';\n\n<Fragments fragments={{ flutter: flutter2 }} />\n\nimport js3 from '/src/fragments/start/getting-started/vanillajs/build.mdx';\n\n<Fragments fragments={{ js: js3 }} />\n\nimport next4 from '/src/fragments/start/getting-started/next/build.mdx';\n\n<Fragments fragments={{ next: next4 }} />\n\nimport react5 from '/src/fragments/start/getting-started/react/build.mdx';\n\n<Fragments fragments={{ react: react5 }} />\n\nimport react_native6 from '/src/fragments/start/getting-started/reactnative/build.mdx';\n\n<Fragments fragments={{ 'react-native': react_native6 }} />\n\nimport angular7 from '/src/fragments/start/getting-started/angular/build.mdx';\n\n<Fragments fragments={{ angular: angular7 }} />\n\nimport ionic8 from '/src/fragments/start/getting-started/ionic/build.mdx';\n\n<Fragments fragments={{ ionic: ionic8 }} />\n\nimport vue9 from '/src/fragments/start/getting-started/vue/build.mdx';\n\n<Fragments fragments={{ vue: vue9 }} />\n\nimport ios10 from '/src/fragments/start/getting-started/ios/build-footer.mdx';\n\n<Fragments fragments={{ ios: ios10 }} />\n\nimport android11 from '/src/fragments/start/getting-started/android/build-footer.mdx';\n\n<Fragments fragments={{ android: android11 }} />\n\nimport flutter12 from '/src/fragments/start/getting-started/flutter/build-footer.mdx';\n\n<Fragments fragments={{ flutter: flutter12 }} />\n\nimport js13 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ js: js13 }} />\n\nimport next14 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ next: next14 }} />\n\nimport react15 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ react: react15 }} />\n\nimport react_native16 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ 'react-native': react_native16 }} />\n\nimport angular17 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ angular: angular17 }} />\n\nimport ionic18 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ ionic: ionic18 }} />\n\nimport vue19 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ vue: vue19 }} />\n\n**NEW!** Use Amplify Studio to get started with Amplify. [Get started](https://sandbox.amplifyapp.com/getting-started)\n",
    "meta": {
      "title": "Getting started - Android",
      "description": "Getting Started with Amplify Framework - Android",
      "disableTOC": "true",
      "filterKey": "integration",
      "category": "Getting started"
    },
    "filename": "/start/q/integration/android"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "The open-source Amplify Framework provides the following products to build fullstack iOS, Android, Flutter, Web, and React Native apps:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify CLI - Configure all the services needed to power your backend through a simple command line interface."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify Libraries - Use case-centric client libraries to integrate your app code with a backend using declarative interfaces."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify UI Components - UI libraries for React, React Native, Angular, Ionic, Vue and Flutter."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The Amplify Hosting is an AWS service that provides a git-based workflow for continuous deployment & hosting of fullstack web apps. Cloud resources created by the Amplify CLI are also visible in the Amplify Console."
      },
      {
        "heading": null,
        "depth": null,
        "text": "NEW! Use Amplify Studio to get started with Amplify. Get started"
      }
    ],
    "source": "export const meta = {\n  title: \"Getting started\",\n  description: \"Getting Started with Amplify Framework\",\n  disableTOC: \"true\",\n  filterKey: \"integration\",\n};\n\nThe open-source Amplify Framework provides the following products to build fullstack iOS, Android, Flutter, Web, and React Native apps:\n\n- **Amplify [CLI](/cli)** - Configure all the services needed to power your backend through a simple command line interface.\n- **Amplify [Libraries](/lib)** - Use case-centric client libraries to integrate your app code with a backend using declarative interfaces.\n- **Amplify [UI Components](/ui)** - UI libraries for React, React Native, Angular, Ionic, Vue and Flutter.\n\nThe **Amplify [Hosting](https://aws.amazon.com/amplify/hosting/)** is an AWS service that provides a git-based workflow for continuous deployment & hosting of fullstack web apps. Cloud resources created by the Amplify CLI are also visible in the Amplify Console.\n\nimport ios0 from '/src/fragments/start/getting-started/ios/build.mdx';\n\n<Fragments fragments={{ ios: ios0 }} />\n\nimport android1 from '/src/fragments/start/getting-started/android/build.mdx';\n\n<Fragments fragments={{ android: android1 }} />\n\nimport flutter2 from '/src/fragments/start/getting-started/flutter/build.mdx';\n\n<Fragments fragments={{ flutter: flutter2 }} />\n\nimport js3 from '/src/fragments/start/getting-started/vanillajs/build.mdx';\n\n<Fragments fragments={{ js: js3 }} />\n\nimport next4 from '/src/fragments/start/getting-started/next/build.mdx';\n\n<Fragments fragments={{ next: next4 }} />\n\nimport react5 from '/src/fragments/start/getting-started/react/build.mdx';\n\n<Fragments fragments={{ react: react5 }} />\n\nimport react_native6 from '/src/fragments/start/getting-started/reactnative/build.mdx';\n\n<Fragments fragments={{ 'react-native': react_native6 }} />\n\nimport angular7 from '/src/fragments/start/getting-started/angular/build.mdx';\n\n<Fragments fragments={{ angular: angular7 }} />\n\nimport ionic8 from '/src/fragments/start/getting-started/ionic/build.mdx';\n\n<Fragments fragments={{ ionic: ionic8 }} />\n\nimport vue9 from '/src/fragments/start/getting-started/vue/build.mdx';\n\n<Fragments fragments={{ vue: vue9 }} />\n\nimport ios10 from '/src/fragments/start/getting-started/ios/build-footer.mdx';\n\n<Fragments fragments={{ ios: ios10 }} />\n\nimport android11 from '/src/fragments/start/getting-started/android/build-footer.mdx';\n\n<Fragments fragments={{ android: android11 }} />\n\nimport flutter12 from '/src/fragments/start/getting-started/flutter/build-footer.mdx';\n\n<Fragments fragments={{ flutter: flutter12 }} />\n\nimport js13 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ js: js13 }} />\n\nimport next14 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ next: next14 }} />\n\nimport react15 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ react: react15 }} />\n\nimport react_native16 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ 'react-native': react_native16 }} />\n\nimport angular17 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ angular: angular17 }} />\n\nimport ionic18 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ ionic: ionic18 }} />\n\nimport vue19 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ vue: vue19 }} />\n\n**NEW!** Use Amplify Studio to get started with Amplify. [Get started](https://sandbox.amplifyapp.com/getting-started)\n",
    "meta": {
      "title": "Getting started - Next.js",
      "description": "Getting Started with Amplify Framework - Next.js",
      "disableTOC": "true",
      "filterKey": "integration",
      "category": "Getting started"
    },
    "filename": "/start/q/integration/next"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "The open-source Amplify Framework provides the following products to build fullstack iOS, Android, Flutter, Web, and React Native apps:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify CLI - Configure all the services needed to power your backend through a simple command line interface."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify Libraries - Use case-centric client libraries to integrate your app code with a backend using declarative interfaces."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify UI Components - UI libraries for React, React Native, Angular, Ionic, Vue and Flutter."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The Amplify Hosting is an AWS service that provides a git-based workflow for continuous deployment & hosting of fullstack web apps. Cloud resources created by the Amplify CLI are also visible in the Amplify Console."
      },
      {
        "heading": null,
        "depth": null,
        "text": "NEW! Use Amplify Studio to get started with Amplify. Get started"
      }
    ],
    "source": "export const meta = {\n  title: \"Getting started\",\n  description: \"Getting Started with Amplify Framework\",\n  disableTOC: \"true\",\n  filterKey: \"integration\",\n};\n\nThe open-source Amplify Framework provides the following products to build fullstack iOS, Android, Flutter, Web, and React Native apps:\n\n- **Amplify [CLI](/cli)** - Configure all the services needed to power your backend through a simple command line interface.\n- **Amplify [Libraries](/lib)** - Use case-centric client libraries to integrate your app code with a backend using declarative interfaces.\n- **Amplify [UI Components](/ui)** - UI libraries for React, React Native, Angular, Ionic, Vue and Flutter.\n\nThe **Amplify [Hosting](https://aws.amazon.com/amplify/hosting/)** is an AWS service that provides a git-based workflow for continuous deployment & hosting of fullstack web apps. Cloud resources created by the Amplify CLI are also visible in the Amplify Console.\n\nimport ios0 from '/src/fragments/start/getting-started/ios/build.mdx';\n\n<Fragments fragments={{ ios: ios0 }} />\n\nimport android1 from '/src/fragments/start/getting-started/android/build.mdx';\n\n<Fragments fragments={{ android: android1 }} />\n\nimport flutter2 from '/src/fragments/start/getting-started/flutter/build.mdx';\n\n<Fragments fragments={{ flutter: flutter2 }} />\n\nimport js3 from '/src/fragments/start/getting-started/vanillajs/build.mdx';\n\n<Fragments fragments={{ js: js3 }} />\n\nimport next4 from '/src/fragments/start/getting-started/next/build.mdx';\n\n<Fragments fragments={{ next: next4 }} />\n\nimport react5 from '/src/fragments/start/getting-started/react/build.mdx';\n\n<Fragments fragments={{ react: react5 }} />\n\nimport react_native6 from '/src/fragments/start/getting-started/reactnative/build.mdx';\n\n<Fragments fragments={{ 'react-native': react_native6 }} />\n\nimport angular7 from '/src/fragments/start/getting-started/angular/build.mdx';\n\n<Fragments fragments={{ angular: angular7 }} />\n\nimport ionic8 from '/src/fragments/start/getting-started/ionic/build.mdx';\n\n<Fragments fragments={{ ionic: ionic8 }} />\n\nimport vue9 from '/src/fragments/start/getting-started/vue/build.mdx';\n\n<Fragments fragments={{ vue: vue9 }} />\n\nimport ios10 from '/src/fragments/start/getting-started/ios/build-footer.mdx';\n\n<Fragments fragments={{ ios: ios10 }} />\n\nimport android11 from '/src/fragments/start/getting-started/android/build-footer.mdx';\n\n<Fragments fragments={{ android: android11 }} />\n\nimport flutter12 from '/src/fragments/start/getting-started/flutter/build-footer.mdx';\n\n<Fragments fragments={{ flutter: flutter12 }} />\n\nimport js13 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ js: js13 }} />\n\nimport next14 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ next: next14 }} />\n\nimport react15 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ react: react15 }} />\n\nimport react_native16 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ 'react-native': react_native16 }} />\n\nimport angular17 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ angular: angular17 }} />\n\nimport ionic18 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ ionic: ionic18 }} />\n\nimport vue19 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ vue: vue19 }} />\n\n**NEW!** Use Amplify Studio to get started with Amplify. [Get started](https://sandbox.amplifyapp.com/getting-started)\n",
    "meta": {
      "title": "Getting started - Vue",
      "description": "Getting Started with Amplify Framework - Vue",
      "disableTOC": "true",
      "filterKey": "integration",
      "category": "Getting started"
    },
    "filename": "/start/q/integration/vue"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "The open-source Amplify Framework provides the following products to build fullstack iOS, Android, Flutter, Web, and React Native apps:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify CLI - Configure all the services needed to power your backend through a simple command line interface."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify Libraries - Use case-centric client libraries to integrate your app code with a backend using declarative interfaces."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify UI Components - UI libraries for React, React Native, Angular, Ionic, Vue and Flutter."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The Amplify Hosting is an AWS service that provides a git-based workflow for continuous deployment & hosting of fullstack web apps. Cloud resources created by the Amplify CLI are also visible in the Amplify Console."
      },
      {
        "heading": null,
        "depth": null,
        "text": "NEW! Use Amplify Studio to get started with Amplify. Get started"
      }
    ],
    "source": "export const meta = {\n  title: \"Getting started\",\n  description: \"Getting Started with Amplify Framework\",\n  disableTOC: \"true\",\n  filterKey: \"integration\",\n};\n\nThe open-source Amplify Framework provides the following products to build fullstack iOS, Android, Flutter, Web, and React Native apps:\n\n- **Amplify [CLI](/cli)** - Configure all the services needed to power your backend through a simple command line interface.\n- **Amplify [Libraries](/lib)** - Use case-centric client libraries to integrate your app code with a backend using declarative interfaces.\n- **Amplify [UI Components](/ui)** - UI libraries for React, React Native, Angular, Ionic, Vue and Flutter.\n\nThe **Amplify [Hosting](https://aws.amazon.com/amplify/hosting/)** is an AWS service that provides a git-based workflow for continuous deployment & hosting of fullstack web apps. Cloud resources created by the Amplify CLI are also visible in the Amplify Console.\n\nimport ios0 from '/src/fragments/start/getting-started/ios/build.mdx';\n\n<Fragments fragments={{ ios: ios0 }} />\n\nimport android1 from '/src/fragments/start/getting-started/android/build.mdx';\n\n<Fragments fragments={{ android: android1 }} />\n\nimport flutter2 from '/src/fragments/start/getting-started/flutter/build.mdx';\n\n<Fragments fragments={{ flutter: flutter2 }} />\n\nimport js3 from '/src/fragments/start/getting-started/vanillajs/build.mdx';\n\n<Fragments fragments={{ js: js3 }} />\n\nimport next4 from '/src/fragments/start/getting-started/next/build.mdx';\n\n<Fragments fragments={{ next: next4 }} />\n\nimport react5 from '/src/fragments/start/getting-started/react/build.mdx';\n\n<Fragments fragments={{ react: react5 }} />\n\nimport react_native6 from '/src/fragments/start/getting-started/reactnative/build.mdx';\n\n<Fragments fragments={{ 'react-native': react_native6 }} />\n\nimport angular7 from '/src/fragments/start/getting-started/angular/build.mdx';\n\n<Fragments fragments={{ angular: angular7 }} />\n\nimport ionic8 from '/src/fragments/start/getting-started/ionic/build.mdx';\n\n<Fragments fragments={{ ionic: ionic8 }} />\n\nimport vue9 from '/src/fragments/start/getting-started/vue/build.mdx';\n\n<Fragments fragments={{ vue: vue9 }} />\n\nimport ios10 from '/src/fragments/start/getting-started/ios/build-footer.mdx';\n\n<Fragments fragments={{ ios: ios10 }} />\n\nimport android11 from '/src/fragments/start/getting-started/android/build-footer.mdx';\n\n<Fragments fragments={{ android: android11 }} />\n\nimport flutter12 from '/src/fragments/start/getting-started/flutter/build-footer.mdx';\n\n<Fragments fragments={{ flutter: flutter12 }} />\n\nimport js13 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ js: js13 }} />\n\nimport next14 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ next: next14 }} />\n\nimport react15 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ react: react15 }} />\n\nimport react_native16 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ 'react-native': react_native16 }} />\n\nimport angular17 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ angular: angular17 }} />\n\nimport ionic18 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ ionic: ionic18 }} />\n\nimport vue19 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ vue: vue19 }} />\n\n**NEW!** Use Amplify Studio to get started with Amplify. [Get started](https://sandbox.amplifyapp.com/getting-started)\n",
    "meta": {
      "title": "Getting started - Angular",
      "description": "Getting Started with Amplify Framework - Angular",
      "disableTOC": "true",
      "filterKey": "integration",
      "category": "Getting started"
    },
    "filename": "/start/q/integration/angular"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "The open-source Amplify Framework provides the following products to build fullstack iOS, Android, Flutter, Web, and React Native apps:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify CLI - Configure all the services needed to power your backend through a simple command line interface."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify Libraries - Use case-centric client libraries to integrate your app code with a backend using declarative interfaces."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify UI Components - UI libraries for React, React Native, Angular, Ionic, Vue and Flutter."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The Amplify Hosting is an AWS service that provides a git-based workflow for continuous deployment & hosting of fullstack web apps. Cloud resources created by the Amplify CLI are also visible in the Amplify Console."
      },
      {
        "heading": null,
        "depth": null,
        "text": "NEW! Use Amplify Studio to get started with Amplify. Get started"
      }
    ],
    "source": "export const meta = {\n  title: \"Getting started\",\n  description: \"Getting Started with Amplify Framework\",\n  disableTOC: \"true\",\n  filterKey: \"integration\",\n};\n\nThe open-source Amplify Framework provides the following products to build fullstack iOS, Android, Flutter, Web, and React Native apps:\n\n- **Amplify [CLI](/cli)** - Configure all the services needed to power your backend through a simple command line interface.\n- **Amplify [Libraries](/lib)** - Use case-centric client libraries to integrate your app code with a backend using declarative interfaces.\n- **Amplify [UI Components](/ui)** - UI libraries for React, React Native, Angular, Ionic, Vue and Flutter.\n\nThe **Amplify [Hosting](https://aws.amazon.com/amplify/hosting/)** is an AWS service that provides a git-based workflow for continuous deployment & hosting of fullstack web apps. Cloud resources created by the Amplify CLI are also visible in the Amplify Console.\n\nimport ios0 from '/src/fragments/start/getting-started/ios/build.mdx';\n\n<Fragments fragments={{ ios: ios0 }} />\n\nimport android1 from '/src/fragments/start/getting-started/android/build.mdx';\n\n<Fragments fragments={{ android: android1 }} />\n\nimport flutter2 from '/src/fragments/start/getting-started/flutter/build.mdx';\n\n<Fragments fragments={{ flutter: flutter2 }} />\n\nimport js3 from '/src/fragments/start/getting-started/vanillajs/build.mdx';\n\n<Fragments fragments={{ js: js3 }} />\n\nimport next4 from '/src/fragments/start/getting-started/next/build.mdx';\n\n<Fragments fragments={{ next: next4 }} />\n\nimport react5 from '/src/fragments/start/getting-started/react/build.mdx';\n\n<Fragments fragments={{ react: react5 }} />\n\nimport react_native6 from '/src/fragments/start/getting-started/reactnative/build.mdx';\n\n<Fragments fragments={{ 'react-native': react_native6 }} />\n\nimport angular7 from '/src/fragments/start/getting-started/angular/build.mdx';\n\n<Fragments fragments={{ angular: angular7 }} />\n\nimport ionic8 from '/src/fragments/start/getting-started/ionic/build.mdx';\n\n<Fragments fragments={{ ionic: ionic8 }} />\n\nimport vue9 from '/src/fragments/start/getting-started/vue/build.mdx';\n\n<Fragments fragments={{ vue: vue9 }} />\n\nimport ios10 from '/src/fragments/start/getting-started/ios/build-footer.mdx';\n\n<Fragments fragments={{ ios: ios10 }} />\n\nimport android11 from '/src/fragments/start/getting-started/android/build-footer.mdx';\n\n<Fragments fragments={{ android: android11 }} />\n\nimport flutter12 from '/src/fragments/start/getting-started/flutter/build-footer.mdx';\n\n<Fragments fragments={{ flutter: flutter12 }} />\n\nimport js13 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ js: js13 }} />\n\nimport next14 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ next: next14 }} />\n\nimport react15 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ react: react15 }} />\n\nimport react_native16 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ 'react-native': react_native16 }} />\n\nimport angular17 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ angular: angular17 }} />\n\nimport ionic18 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ ionic: ionic18 }} />\n\nimport vue19 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ vue: vue19 }} />\n\n**NEW!** Use Amplify Studio to get started with Amplify. [Get started](https://sandbox.amplifyapp.com/getting-started)\n",
    "meta": {
      "title": "Getting started - React Native",
      "description": "Getting Started with Amplify Framework - React Native",
      "disableTOC": "true",
      "filterKey": "integration",
      "category": "Getting started"
    },
    "filename": "/start/q/integration/react-native"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "The open-source Amplify Framework provides the following products to build fullstack iOS, Android, Flutter, Web, and React Native apps:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify CLI - Configure all the services needed to power your backend through a simple command line interface."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify Libraries - Use case-centric client libraries to integrate your app code with a backend using declarative interfaces."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify UI Components - UI libraries for React, React Native, Angular, Ionic, Vue and Flutter."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The Amplify Hosting is an AWS service that provides a git-based workflow for continuous deployment & hosting of fullstack web apps. Cloud resources created by the Amplify CLI are also visible in the Amplify Console."
      },
      {
        "heading": null,
        "depth": null,
        "text": "NEW! Use Amplify Studio to get started with Amplify. Get started"
      }
    ],
    "source": "export const meta = {\n  title: \"Getting started\",\n  description: \"Getting Started with Amplify Framework\",\n  disableTOC: \"true\",\n  filterKey: \"integration\",\n};\n\nThe open-source Amplify Framework provides the following products to build fullstack iOS, Android, Flutter, Web, and React Native apps:\n\n- **Amplify [CLI](/cli)** - Configure all the services needed to power your backend through a simple command line interface.\n- **Amplify [Libraries](/lib)** - Use case-centric client libraries to integrate your app code with a backend using declarative interfaces.\n- **Amplify [UI Components](/ui)** - UI libraries for React, React Native, Angular, Ionic, Vue and Flutter.\n\nThe **Amplify [Hosting](https://aws.amazon.com/amplify/hosting/)** is an AWS service that provides a git-based workflow for continuous deployment & hosting of fullstack web apps. Cloud resources created by the Amplify CLI are also visible in the Amplify Console.\n\nimport ios0 from '/src/fragments/start/getting-started/ios/build.mdx';\n\n<Fragments fragments={{ ios: ios0 }} />\n\nimport android1 from '/src/fragments/start/getting-started/android/build.mdx';\n\n<Fragments fragments={{ android: android1 }} />\n\nimport flutter2 from '/src/fragments/start/getting-started/flutter/build.mdx';\n\n<Fragments fragments={{ flutter: flutter2 }} />\n\nimport js3 from '/src/fragments/start/getting-started/vanillajs/build.mdx';\n\n<Fragments fragments={{ js: js3 }} />\n\nimport next4 from '/src/fragments/start/getting-started/next/build.mdx';\n\n<Fragments fragments={{ next: next4 }} />\n\nimport react5 from '/src/fragments/start/getting-started/react/build.mdx';\n\n<Fragments fragments={{ react: react5 }} />\n\nimport react_native6 from '/src/fragments/start/getting-started/reactnative/build.mdx';\n\n<Fragments fragments={{ 'react-native': react_native6 }} />\n\nimport angular7 from '/src/fragments/start/getting-started/angular/build.mdx';\n\n<Fragments fragments={{ angular: angular7 }} />\n\nimport ionic8 from '/src/fragments/start/getting-started/ionic/build.mdx';\n\n<Fragments fragments={{ ionic: ionic8 }} />\n\nimport vue9 from '/src/fragments/start/getting-started/vue/build.mdx';\n\n<Fragments fragments={{ vue: vue9 }} />\n\nimport ios10 from '/src/fragments/start/getting-started/ios/build-footer.mdx';\n\n<Fragments fragments={{ ios: ios10 }} />\n\nimport android11 from '/src/fragments/start/getting-started/android/build-footer.mdx';\n\n<Fragments fragments={{ android: android11 }} />\n\nimport flutter12 from '/src/fragments/start/getting-started/flutter/build-footer.mdx';\n\n<Fragments fragments={{ flutter: flutter12 }} />\n\nimport js13 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ js: js13 }} />\n\nimport next14 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ next: next14 }} />\n\nimport react15 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ react: react15 }} />\n\nimport react_native16 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ 'react-native': react_native16 }} />\n\nimport angular17 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ angular: angular17 }} />\n\nimport ionic18 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ ionic: ionic18 }} />\n\nimport vue19 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ vue: vue19 }} />\n\n**NEW!** Use Amplify Studio to get started with Amplify. [Get started](https://sandbox.amplifyapp.com/getting-started)\n",
    "meta": {
      "title": "Getting started - React",
      "description": "Getting Started with Amplify Framework - React",
      "disableTOC": "true",
      "filterKey": "integration",
      "category": "Getting started"
    },
    "filename": "/start/q/integration/react"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "The open-source Amplify Framework provides the following products to build fullstack iOS, Android, Flutter, Web, and React Native apps:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify CLI - Configure all the services needed to power your backend through a simple command line interface."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify Libraries - Use case-centric client libraries to integrate your app code with a backend using declarative interfaces."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify UI Components - UI libraries for React, React Native, Angular, Ionic, Vue and Flutter."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The Amplify Hosting is an AWS service that provides a git-based workflow for continuous deployment & hosting of fullstack web apps. Cloud resources created by the Amplify CLI are also visible in the Amplify Console."
      },
      {
        "heading": null,
        "depth": null,
        "text": "NEW! Use Amplify Studio to get started with Amplify. Get started"
      }
    ],
    "source": "export const meta = {\n  title: \"Getting started\",\n  description: \"Getting Started with Amplify Framework\",\n  disableTOC: \"true\",\n  filterKey: \"integration\",\n};\n\nThe open-source Amplify Framework provides the following products to build fullstack iOS, Android, Flutter, Web, and React Native apps:\n\n- **Amplify [CLI](/cli)** - Configure all the services needed to power your backend through a simple command line interface.\n- **Amplify [Libraries](/lib)** - Use case-centric client libraries to integrate your app code with a backend using declarative interfaces.\n- **Amplify [UI Components](/ui)** - UI libraries for React, React Native, Angular, Ionic, Vue and Flutter.\n\nThe **Amplify [Hosting](https://aws.amazon.com/amplify/hosting/)** is an AWS service that provides a git-based workflow for continuous deployment & hosting of fullstack web apps. Cloud resources created by the Amplify CLI are also visible in the Amplify Console.\n\nimport ios0 from '/src/fragments/start/getting-started/ios/build.mdx';\n\n<Fragments fragments={{ ios: ios0 }} />\n\nimport android1 from '/src/fragments/start/getting-started/android/build.mdx';\n\n<Fragments fragments={{ android: android1 }} />\n\nimport flutter2 from '/src/fragments/start/getting-started/flutter/build.mdx';\n\n<Fragments fragments={{ flutter: flutter2 }} />\n\nimport js3 from '/src/fragments/start/getting-started/vanillajs/build.mdx';\n\n<Fragments fragments={{ js: js3 }} />\n\nimport next4 from '/src/fragments/start/getting-started/next/build.mdx';\n\n<Fragments fragments={{ next: next4 }} />\n\nimport react5 from '/src/fragments/start/getting-started/react/build.mdx';\n\n<Fragments fragments={{ react: react5 }} />\n\nimport react_native6 from '/src/fragments/start/getting-started/reactnative/build.mdx';\n\n<Fragments fragments={{ 'react-native': react_native6 }} />\n\nimport angular7 from '/src/fragments/start/getting-started/angular/build.mdx';\n\n<Fragments fragments={{ angular: angular7 }} />\n\nimport ionic8 from '/src/fragments/start/getting-started/ionic/build.mdx';\n\n<Fragments fragments={{ ionic: ionic8 }} />\n\nimport vue9 from '/src/fragments/start/getting-started/vue/build.mdx';\n\n<Fragments fragments={{ vue: vue9 }} />\n\nimport ios10 from '/src/fragments/start/getting-started/ios/build-footer.mdx';\n\n<Fragments fragments={{ ios: ios10 }} />\n\nimport android11 from '/src/fragments/start/getting-started/android/build-footer.mdx';\n\n<Fragments fragments={{ android: android11 }} />\n\nimport flutter12 from '/src/fragments/start/getting-started/flutter/build-footer.mdx';\n\n<Fragments fragments={{ flutter: flutter12 }} />\n\nimport js13 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ js: js13 }} />\n\nimport next14 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ next: next14 }} />\n\nimport react15 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ react: react15 }} />\n\nimport react_native16 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ 'react-native': react_native16 }} />\n\nimport angular17 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ angular: angular17 }} />\n\nimport ionic18 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ ionic: ionic18 }} />\n\nimport vue19 from '/src/fragments/start/getting-started/common/build-footer.mdx';\n\n<Fragments fragments={{ vue: vue19 }} />\n\n**NEW!** Use Amplify Studio to get started with Amplify. [Get started](https://sandbox.amplifyapp.com/getting-started)\n",
    "meta": {
      "title": "Getting started - JavaScript",
      "description": "Getting Started with Amplify Framework - JavaScript",
      "disableTOC": "true",
      "filterKey": "integration",
      "category": "Getting started"
    },
    "filename": "/start/q/integration/js"
  },
  {
    "searchableText": [
      {
        "heading": "Task App",
        "depth": 2,
        "text": "Note: To use the @auth directive, the API must be configured to use Amazon Cognito user pools."
      },
      {
        "heading": "Common Patterns for the API Category",
        "depth": 2,
        "text": "The Amplify CLI exposes the GraphQL Transform libraries to help create APIs with common\npatterns and best practices baked in but it also provides number of escape hatches for\nthose situations where you might need a bit more control. Here are a few common use cases\nyou might find useful."
      },
      {
        "heading": "Filter Subscriptions by model fields and/or relations",
        "depth": 3,
        "text": "In multi-tenant scenarios, subscribed clients may not always want to receive every change for a model type. These are useful features for limiting the objects that are returned by a client subscription. It is crucial to remember that subscriptions can only filter by what fields are returned from the mutation query. Keep in mind, these two methods can be used together to create truly robust filtering options."
      },
      {
        "heading": "Filter Subscriptions by model fields and/or relations",
        "depth": 3,
        "text": "Consider this simple schema for our examples:"
      },
      {
        "heading": "Filter Subscriptions by model fields and/or relations",
        "depth": 3,
        "text": "Filtering by type fields"
      },
      {
        "heading": "Filter Subscriptions by model fields and/or relations",
        "depth": 3,
        "text": "This is the simpler method of filtering subscriptions, as it requires one less change to the model than filtering on relations."
      },
      {
        "heading": "Filter Subscriptions by model fields and/or relations",
        "depth": 3,
        "text": "Add the subscriptions argument on the @model directive, telling Amplify to not generate subscriptions for your Comment type."
      },
      {
        "heading": "Filter Subscriptions by model fields and/or relations",
        "depth": 3,
        "text": "Run amplify push at this point, as running it after adding the Subscription type will throw an error, claiming you cannot have two Subscription definitions in your schema."
      },
      {
        "heading": "Filter Subscriptions by model fields and/or relations",
        "depth": 3,
        "text": "After the push, you will need to add the Subscription type to your schema, including whichever scalar Comment fields you wish to use for filtering (content in this case):"
      },
      {
        "heading": "Filter Subscriptions by model fields and/or relations",
        "depth": 3,
        "text": "Filtering by related (@connection designated) type"
      },
      {
        "heading": "Filter Subscriptions by model fields and/or relations",
        "depth": 3,
        "text": "This is useful when you need to filter by what Todo objects the Comments are connected to. You will need to augment your schema slightly to enable this."
      },
      {
        "heading": "Filter Subscriptions by model fields and/or relations",
        "depth": 3,
        "text": "Add the subscriptions argument on the @model directive, telling Amplify to not generate subscriptions for your Comment type. Also, just as importantly, we will be utilizing an auto-generated column from DynamoDB by adding commentTodoId to our Comment model:"
      },
      {
        "heading": "Filter Subscriptions by model fields and/or relations",
        "depth": 3,
        "text": "You should run amplify push at this point, as running it after adding the Subscription type will throw an error, claiming you cannot have two Subscription definitions in your schema."
      },
      {
        "heading": "Filter Subscriptions by model fields and/or relations",
        "depth": 3,
        "text": "After the push, you will need to add the Subscription type to your schema, including the commentTodoId as an optional argument:"
      },
      {
        "heading": "Filter Subscriptions by model fields and/or relations",
        "depth": 3,
        "text": "The next time you run amplify push or amplify api gql-compile, your subscriptions will allow an id and/or commentTodoId argument on a Comment subscription. As long as your mutation on the Comment type returns the specified argument field from its query, AppSync filters which subscription events will be pushed to your subscribed client."
      }
    ],
    "source": "export const meta = {\n  title: `Examples`,\n  description: `Refer to these examples to learn about various sample application's GraphQL schemas.`,\n};\n\n<MigrationAlert isLegacy url={\"/cli/graphql/examples-and-solutions\"}/>\n\n## Simple Todo\n\n```graphql\ntype Todo @model {\n  id: ID!\n  name: String!\n  description: String\n}\n```\n\n## Blog\n\n```graphql\ntype Blog @model {\n  id: ID!\n  name: String!\n  posts: [Post] @connection(name: \"BlogPosts\")\n}\ntype Post @model {\n  id: ID!\n  title: String!\n  blog: Blog @connection(name: \"BlogPosts\")\n  comments: [Comment] @connection(name: \"PostComments\")\n}\ntype Comment @model {\n  id: ID!\n  content: String\n  post: Post @connection(name: \"PostComments\")\n}\n```\n\n### Blog Queries\n\n```graphql\n# Create a blog. Remember the returned id.\n# Provide the returned id as the \"blogId\" variable.\nmutation CreateBlog {\n  createBlog(input: {\n    name: \"My New Blog!\"\n  }) {\n    id\n    name\n  }\n}\n\n# Create a post and associate it with the blog via the \"postBlogId\" input field.\n# Provide the returned id as the \"postId\" variable.\nmutation CreatePost($blogId:ID!) {\n  createPost(input:{title:\"My Post!\", postBlogId: $blogId}) {\n    id\n    title\n    blog {\n      id\n      name\n    }\n  }\n}\n\n# Create a comment and associate it with the post via the \"commentPostId\" input field.\nmutation CreateComment($postId:ID!) {\n  createComment(input:{content:\"A comment!\", commentPostId:$postId}) {\n    id\n    content\n    post {\n      id\n      title\n      blog {\n        id\n        name\n      }\n    }\n  }\n}\n\n# Get a blog, its posts, and its posts comments.\nquery GetBlog($blogId:ID!) {\n  getBlog(id:$blogId) {\n    id\n    name\n    posts(filter: {\n      title: {\n        eq: \"My Post!\"\n      }\n    }) {\n      items {\n        id\n        title\n        comments {\n          items {\n            id\n            content\n          }\n        }\n      }\n    }\n  }\n}\n\n# List all blogs, their posts, and their posts comments.\nquery ListBlogs {\n  listBlogs { # Try adding: listBlog(filter: { name: { eq: \"My New Blog!\" } })\n    items {\n      id\n      name\n      posts { # or try adding: posts(filter: { title: { eq: \"My Post!\" } })\n        items {\n          id\n          title\n          comments { # and so on ...\n            items {\n              id\n              content\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n## Task App\n\n**Note: To use the @auth directive, the API must be configured to use Amazon Cognito user pools.**\n\n```graphql\ntype Task\n  @model\n  @auth(rules: [\n    {allow: groups, groups: [\"Managers\"], mutations: [create, update, delete], queries: null},\n    {allow: groups, groups: [\"Employees\"], mutations: null, queries: [get, list]}\n  ]) {\n  id: ID!\n  title: String!\n  description: String\n  status: String\n}\ntype PrivateNote\n  @model\n  @auth(rules: [{allow: owner}]) {\n  id: ID!\n  content: String!\n}\n```\n\n### Task Queries\n\n```graphql\n# Create a task. Only allowed if a manager.\nmutation CreateTask {\n  createTask(input:{\n    title:\"A task\",\n    description:\"A task description\",\n    status: \"pending\"\n  }) {\n    id\n    title\n    description\n  }\n}\n\n# Get a task. Allowed if an employee.\nquery GetTask($taskId:ID!) {\n  getTask(id:$taskId) {\n    id\n    title\n    description\n  }\n}\n\n# Automatically inject the username as owner attribute.\nmutation CreatePrivateNote {\n  createPrivateNote(input:{content:\"A private note of user 1\"}) {\n    id\n    content\n  }\n}\n\n# Unauthorized error if not owner.\nquery GetPrivateNote($privateNoteId:ID!) {\n  getPrivateNote(id:$privateNoteId) {\n    id\n    content\n  }\n}\n\n# Return only my own private notes.\nquery ListPrivateNote {\n  listPrivateNote {\n    items {\n      id\n      content\n    }\n  }\n}\n```\n\n## Conflict Detection\n\n```graphql\ntype Note @model @versioned {\n  id: ID!\n  content: String!\n  version: Int! # You can leave this out. Validation fails if this is not a int like type (Int/BigInt) and is always coerced to non-null.\n}\n```\n\n### Conflict Detection Queries\n\n```graphql\nmutation Create {\n  createNote(input:{\n    content:\"A note\"\n  }) {\n    id\n    content\n    version\n  }\n}\n\nmutation Update($noteId: ID!) {\n  updateNote(input:{\n    id: $noteId,\n    content:\"A second version\",\n    expectedVersion: 1\n  }) {\n    id\n    content\n    version\n  }\n}\n\nmutation Delete($noteId: ID!) {\n  deleteNote(input:{\n    id: $noteId,\n    expectedVersion: 2\n  }) {\n    id\n    content\n    version\n  }\n}\n```\n\n## Common Patterns for the API Category\n\nThe Amplify CLI exposes the GraphQL Transform libraries to help create APIs with common\npatterns and best practices baked in but it also provides number of escape hatches for\nthose situations where you might need a bit more control. Here are a few common use cases\nyou might find useful.\n\n### Filter Subscriptions by model fields and/or relations\n\nIn multi-tenant scenarios, subscribed clients may not always want to receive every change for a model type. These are useful features for limiting the objects that are returned by a client subscription. It is crucial to remember that subscriptions can only filter by what fields are returned from the mutation query. Keep in mind, these two methods can be used together to create truly robust filtering options.\n\nConsider this simple schema for our examples:\n\n```graphql\ntype Todo @model {\n  id: ID!\n  name: String!\n  description: String\n  comments: [Comment] @connection(name: \"TodoComments\")\n}\ntype Comment @model {\n  id: ID!\n  content: String\n  todo: Todo @connection(name: \"TodoComments\")\n}\n```\n\n**Filtering by type fields**\n\nThis is the simpler method of filtering subscriptions, as it requires one less change to the model than filtering on relations.\n\n1. Add the subscriptions argument on the *@model* directive, telling Amplify to *not* generate subscriptions for your Comment type.\n\n```graphql\ntype Comment @model(subscriptions: null) {\n  id: ID!\n  content: String\n  todo: Todo @connection(name: \"TodoComments\")\n}\n```\n\n2. Run `amplify push` at this point, as running it after adding the Subscription type will throw an error, claiming you cannot have two Subscription definitions in your schema.\n\n3. After the push, you will need to add the Subscription type to your schema, including whichever scalar Comment fields you wish to use for filtering (content in this case):\n\n```graphql\ntype Subscription {\n  onCreateComment(content: String): Comment @aws_subscribe(mutations: [\"createComment\"])\n  onUpdateComment(id: ID, content: String): Comment @aws_subscribe(mutations: [\"updateComment\"])\n  onDeleteComment(id: ID, content: String): Comment @aws_subscribe(mutations: [\"deleteComment\"])\n}\n```\n\n**Filtering by related (*@connection* designated) type**\n\nThis is useful when you need to filter by what Todo objects the Comments are connected to. You will need to augment your schema slightly to enable this.\n\n1. Add the subscriptions argument on the *@model* directive, telling Amplify to *not* generate subscriptions for your Comment type. Also, just as importantly, we will be utilizing an auto-generated column from DynamoDB by adding `commentTodoId` to our Comment model:\n\n```graphql\ntype Comment @model(subscriptions: null) {\n  id: ID!\n  content: String\n  todo: Todo @connection(name: \"TodoComments\")\n  commentTodoId: String # This references the commentTodoId field in DynamoDB\n}\n```\n\n2. You should run `amplify push` at this point, as running it after adding the Subscription type will throw an error, claiming you cannot have two Subscription definitions in your schema.\n\n3. After the push, you will need to add the Subscription type to your schema, including the `commentTodoId` as an optional argument:\n\n```graphql\ntype Subscription {\n  onCreateComment(commentTodoId: String): Comment @aws_subscribe(mutations: [\"createComment\"])\n  onUpdateComment(id: ID, commentTodoId: String): Comment @aws_subscribe(mutations: [\"updateComment\"])\n  onDeleteComment(id: ID, commentTodoId: String): Comment @aws_subscribe(mutations: [\"deleteComment\"])\n}\n```\n\nThe next time you run `amplify push` or `amplify api gql-compile`, your subscriptions will allow an `id` and/or `commentTodoId` argument on a Comment subscription. As long as your mutation on the Comment type returns the specified argument field from its query, AppSync filters which subscription events will be pushed to your subscribed client.\n",
    "meta": {
      "title": "Examples",
      "description": "Refer to these examples to learn about various sample application's GraphQL schemas.",
      "subcategory": "API (GraphQL)",
      "category": "Amplify CLI (Legacy)"
    },
    "filename": "/cli-legacy/graphql-transformer/examples"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Much of the behavior of the GraphQL Transform logic is configured by passing arguments to the directives in the GraphQL SDL definition. However, certain other things are configured by passing parameters to the CloudFormation template itself. This provides escape hatches without leaking too many implementation details into the SDL definition. You can pass values to these parameters by adding them to the parameters.json file in the API directory of your amplify project."
      },
      {
        "heading": "AppSyncApiName",
        "depth": 2,
        "text": "Override the name of the generated AppSync API"
      },
      {
        "heading": "CreateAPIKey",
        "depth": 2,
        "text": "CreateAPIKey takes value of either 1 or 0."
      },
      {
        "heading": "CreateAPIKey",
        "depth": 2,
        "text": "It gives you the mechanism to rotate the API Key, in scenarios such as to handle API Key expiration."
      },
      {
        "heading": "CreateAPIKey",
        "depth": 2,
        "text": "Follow these two steps when you need to rotate an API Key"
      },
      {
        "heading": "CreateAPIKey",
        "depth": 2,
        "text": "Delete the existing API key by setting CreateAPIKey to 0 in the amplify/backend/api/<apiName>/parameters.json file and execute amplify push."
      },
      {
        "heading": "CreateAPIKey",
        "depth": 2,
        "text": "Create a new API key by setting CreateAPIKey to 1 in the amplify/backend/api/<apiName>/parameters.json file and execute amplify push."
      },
      {
        "heading": "CreateAPIKey",
        "depth": 2,
        "text": "Delete the existing API Key"
      },
      {
        "heading": "CreateAPIKey",
        "depth": 2,
        "text": "Create new API Key"
      },
      {
        "heading": "APIKeyExpirationEpoch",
        "depth": 2,
        "text": "Resets the API Key to expire 1 week after the next amplify push"
      },
      {
        "heading": "APIKeyExpirationEpoch",
        "depth": 2,
        "text": "Do not create an API key"
      },
      {
        "heading": "APIKeyExpirationEpoch",
        "depth": 2,
        "text": "Set a custom API key expiration date"
      },
      {
        "heading": "APIKeyExpirationEpoch",
        "depth": 2,
        "text": "The value specified is the expiration date in seconds since Epoch"
      },
      {
        "heading": "DynamoDBBillingMode",
        "depth": 2,
        "text": "Set the DynamoDB billing mode for the API. One of \"PROVISIONED\" or \"PAY_PER_REQUEST\"."
      },
      {
        "heading": "DynamoDBModelTableReadIOPS",
        "depth": 2,
        "text": "Override the default read IOPS provisioned for each @model table"
      },
      {
        "heading": "DynamoDBModelTableReadIOPS",
        "depth": 2,
        "text": "Only valid if the \"DynamoDBBillingMode\" is set to \"PROVISIONED\""
      },
      {
        "heading": "DynamoDBModelTableWriteIOPS",
        "depth": 2,
        "text": "Override the default write IOPS provisioned for each @model table"
      },
      {
        "heading": "DynamoDBModelTableWriteIOPS",
        "depth": 2,
        "text": "Only valid if the \"DynamoDBBillingMode\" is set to \"PROVISIONED\""
      },
      {
        "heading": "DynamoDBEnablePointInTimeRecovery",
        "depth": 2,
        "text": "Enable/disable DynamoDB Point-in-time-Recovery for all model tables"
      },
      {
        "heading": "DynamoDBEnablePointInTimeRecovery",
        "depth": 2,
        "text": "For more information, see https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/PointInTimeRecovery.html"
      },
      {
        "heading": "ElasticSearchStreamingFunctionName",
        "depth": 2,
        "text": "Override the name of the AWS Lambda searchable streaming function"
      },
      {
        "heading": "ElasticSearchInstanceCount",
        "depth": 2,
        "text": "Override the number of instances launched into the OpenSearch domain created by @searchable"
      },
      {
        "heading": "ElasticSearchInstanceType",
        "depth": 2,
        "text": "Override the type of instance launched into the OpenSearch domain created by @searchable"
      },
      {
        "heading": "ElasticSearchEBSVolumeGB",
        "depth": 2,
        "text": "Override the amount of disk space allocated to each instance in the OpenSearch domain created by @searchable"
      },
      {
        "heading": "ElasticSearchEBSVolumeGB",
        "depth": 2,
        "text": "Note: To use the @auth directive, the API must be configured to use Amazon Cognito user pools."
      }
    ],
    "source": "export const meta = {\n  title: `Configurable Parameters`,\n  description: `Additional configurable parameters for GraphQL Transform can be passed to the CloudFormation template itself. This provides escape hatches without leaking too many implementation details into the SDL definition`,\n};\n\n<MigrationAlert isLegacy url={\"/cli/graphql/override\"}/>\n\nMuch of the behavior of the GraphQL Transform logic is configured by passing arguments to the directives in the GraphQL SDL definition. However, certain other things are configured by passing parameters to the CloudFormation template itself. This provides escape hatches without leaking too many implementation details into the SDL definition. You can pass values to these parameters by adding them to the `parameters.json` file in the API directory of your amplify project.\n\n## AppSyncApiName\n\n**Override the name of the generated AppSync API**\n\n```json\n{\n  \"AppSyncApiName\": \"AppSyncAPI\"\n}\n```\n\n## CreateAPIKey\n\n`CreateAPIKey` takes value of either `1` or `0`.\n\nIt gives you the mechanism to rotate the API Key, in scenarios such as to handle API Key expiration.\n\nFollow these two steps when you need to rotate an API Key\n\n- Delete the existing API key by setting `CreateAPIKey` to `0` in the `amplify/backend/api/<apiName>/parameters.json` file and execute `amplify push`.\n- Create a new API key by setting `CreateAPIKey` to `1` in the `amplify/backend/api/<apiName>/parameters.json` file and execute `amplify push`.\n\n**Delete the existing API Key**\n\n```json\n{\n  \"CreateAPIKey\": 0\n}\n```\n\n**Create new API Key**\n\n```json\n{\n  \"CreateAPIKey\": 1\n}\n```\n\n## APIKeyExpirationEpoch\n\n**Resets the API Key to expire 1 week after the next `amplify push`**\n\n```json\n{\n  \"APIKeyExpirationEpoch\": 0\n}\n```\n\n**Do not create an API key**\n\n```json\n{\n  \"APIKeyExpirationEpoch\": -1\n}\n```\n\n**Set a custom API key expiration date**\n\n```json\n{\n  \"APIKeyExpirationEpoch\": 1544745428\n}\n```\n\n> The value specified is the expiration date in seconds since Epoch\n\n## DynamoDBBillingMode\n\n**Set the DynamoDB billing mode for the API. One of \"PROVISIONED\" or \"PAY_PER_REQUEST\".**\n\n```json\n{\n  \"DynamoDBBillingMode\": \"PAY_PER_REQUEST\"\n}\n```\n\n## DynamoDBModelTableReadIOPS\n\n**Override the default read IOPS provisioned for each @model table**\n\n**Only valid if the \"DynamoDBBillingMode\" is set to \"PROVISIONED\"**\n\n```json\n{\n  \"DynamoDBModelTableReadIOPS\": 5\n}\n```\n\n## DynamoDBModelTableWriteIOPS\n\n**Override the default write IOPS provisioned for each @model table**\n\n**Only valid if the \"DynamoDBBillingMode\" is set to \"PROVISIONED\"**\n\n```json\n{\n  \"DynamoDBModelTableWriteIOPS\": 5\n}\n```\n\n## DynamoDBEnablePointInTimeRecovery\n\n**Enable/disable DynamoDB Point-in-time-Recovery for all model tables**\n\nFor more information, see https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/PointInTimeRecovery.html\n\n```json\n{\n  \"DynamoDBEnablePointInTimeRecovery\": true\n}\n```\n\n## ElasticSearchStreamingFunctionName\n\n**Override the name of the AWS Lambda searchable streaming function**\n\n```json\n{\n  \"ElasticSearchStreamingFunctionName\": \"CustomFunctionName\"\n}\n```\n\n## ElasticSearchInstanceCount\n\n**Override the number of instances launched into the OpenSearch domain created by @searchable**\n\n```json\n{\n  \"ElasticSearchInstanceCount\": 1\n}\n```\n\n## ElasticSearchInstanceType\n\n**Override the type of instance launched into the OpenSearch domain created by @searchable**\n\n```json\n{\n  \"ElasticSearchInstanceType\": \"t2.small.elasticsearch\"\n}\n```\n\n## ElasticSearchEBSVolumeGB\n\n**Override the amount of disk space allocated to each instance in the OpenSearch domain created by @searchable**\n\n```json\n{\n  \"ElasticSearchEBSVolumeGB\": 10\n}\n```\n\n**Note: To use the @auth directive, the API must be configured to use Amazon Cognito user pools.**\n\n```graphql\ntype Task\n  @model\n  @auth(rules: [\n    {allow: groups, groups: [\"Managers\"], operations: [create, update, delete]},\n    {allow: groups, groups: [\"Employees\"], operations: [read, list]}\n  ]) {\n  id: ID!\n  title: String!\n  description: String\n  status: String\n}\ntype PrivateNote\n  @model\n  @auth(rules: [{allow: owner}]) {\n  id: ID!\n  content: String!\n}\n```\n",
    "meta": {
      "title": "Configurable Parameters",
      "description": "Additional configurable parameters for GraphQL Transform can be passed to the CloudFormation template itself. This provides escape hatches without leaking too many implementation details into the SDL definition",
      "subcategory": "API (GraphQL)",
      "category": "Amplify CLI (Legacy)"
    },
    "filename": "/cli-legacy/graphql-transformer/config-params"
  },
  {
    "searchableText": [
      {
        "heading": "Overwriting Resolvers",
        "depth": 2,
        "text": "Let's say you have a simple schema.graphql..."
      },
      {
        "heading": "Overwriting Resolvers",
        "depth": 2,
        "text": "and you want to change the behavior of request mapping template for the Query.getTodo resolver that will be generated when the project compiles. To do this you would create a file named Query.getTodo.req.vtl in the resolvers directory of your API project. The next time you run amplify push or amplify api gql-compile, your resolver template will be used instead of the auto-generated template. You may similarly create a Query.getTodo.res.vtl file to change the behavior of the resolver's response mapping template."
      },
      {
        "heading": "Custom Resolvers",
        "depth": 2,
        "text": "You can add custom Query, Mutation and Subscription when the generated ones do not cover your use case."
      },
      {
        "heading": "Custom Resolvers",
        "depth": 2,
        "text": "Add the required Query, Mutation or Subscription type to your schema."
      },
      {
        "heading": "Custom Resolvers",
        "depth": 2,
        "text": "Create resolvers for newly created Query, Mutation or Subscription by creating request and response template in <project-root>/amplify/backend/api/<api-name>/resolvers folder. Graphql Transformer follows <TypeName>.<FieldName>.<req/res>.vtl as convention to name the resolvers. So if you're adding a custom query name myCustomQuery the resolvers would be name Query.myCustomQuery.req.vtl and Query.myCustomQuery.res.vtl."
      },
      {
        "heading": "Custom Resolvers",
        "depth": 2,
        "text": "Add resolvers resource by creating a custom stack inside <project-root>/amplify/backend/api/<api-name>/stacks directory of your API."
      },
      {
        "heading": "Custom Resolvers",
        "depth": 2,
        "text": "To add the custom fields, add the following to your schema:"
      },
      {
        "heading": "Custom Resolvers",
        "depth": 2,
        "text": "The GraphQL Transformer by default creates a file called CustomResources.json inside <project-root>/amplify/backend/api/<api-name>/stacks, which can be used to add the custom resolvers for newly added Query, Mutation or Subscription. The custom stack gets the following arguments passed to it, allowing you to get details about API:"
      },
      {
        "heading": "Custom Resolvers",
        "depth": 2,
        "text": "| Parameter                          | Type   | Possible values                    | Description                                                                                                                                                                       |\n| :--------------------------------- | :----- | ---------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| AppSyncApiId                       | String |                                    | The id of the AppSync API associated with this project                                                                                                                            |\n| AppSyncApiName                     | String |                                    | The name of the AppSync API                                                                                                                                                       |\n| env                                | String |                                    | Environment name                                                                                                                                                                  |\n| S3DeploymentBucket                 | String |                                    | The S3 bucket containing all deployment assets for the project                                                                                                                    |\n| S3DeploymentRootKey                | String |                                    | An S3 key relative to the S3DeploymentBucket that points to the root of the deployment directory.                                                                                 |\n| DynamoDBEnableServerSideEncryption | String | true or false                  | Enable server side encryption powered by KMS.                                                                                                                                     |\n| AuthCognitoUserPoolId              | String |                                    | The id of an existing User Pool to connect                                                                                                                                        |\n| DynamoDBModelTableReadIOPS         | Number |                                    | The number of read IOPS the table should support.                                                                                                                                 |\n| DynamoDBModelTableWriteIOPS        | Number |                                    | The number of write IOPS the table should support                                                                                                                                 |\n| DynamoDBBillingMode                | String | PAY_PER_REQUEST or PROVISIONED | Configure @model types to create DynamoDB tables with PAY_PER_REQUEST or PROVISIONED billing modes                                                                                |\n| DynamoDBEnablePointInTimeRecovery  | String | true or false                  | Whether to enable Point in Time Recovery on the table                                                                                                                             |\n| APIKeyExpirationEpoch              | Number |                                    | he epoch time in seconds when the API Key should expire                                                                                                                           |\n| CreateAPIKey                       | Number | 0 or 1                         | The boolean value to control if an API Key will be created or not. The value of the property is automatically set by the CLI. If the value is set to 0 no API Key will be created |"
      },
      {
        "heading": "Custom Resolvers",
        "depth": 2,
        "text": "Any additional values added Custom Stacks will be exposed as parameter in the root stack, and value can be set by adding the value for it in <project-root>/amplify/backend/api/<api-name>/parameters.json file."
      },
      {
        "heading": "Custom Resolvers",
        "depth": 2,
        "text": "To add a custom resolver, add the following in the resource section of CustomResource.json"
      },
      {
        "heading": "Custom Resolvers",
        "depth": 2,
        "text": "The request and response template should be placed inside <project-root>/amplify/backend/api/<api-name>/resolvers folder. Resolver templates are written in the Apache Velocity Template Language, commonly referred to as VTL. Query.myCustomQuery.req.vtl is a request mapping template, which receives an incoming AppSync request and transforms it into a JSON document that is subsequently passed to the GraphQL resolver. Similarly, Query.myCustomQuery.res.vtl is a response mapping template. These templates receive the GraphQL resolver's response and transform the data before returning it to the user."
      },
      {
        "heading": "Custom Resolvers",
        "depth": 2,
        "text": "Several example VTL files are discussed later in this documentation. For more detailed information on VTL, including how it can be used in the context of GraphQL resolvers, see the official AppSync Resolver Mapping Template Reference."
      },
      {
        "heading": "Add a custom resolver that targets a DynamoDB table from @model",
        "depth": 3,
        "text": "This is useful if you want to write a more specific query against a DynamoDB table that was created by @model. For example, assume you had this schema with two @model types and a pair of @connection directives."
      },
      {
        "heading": "Add a custom resolver that targets a DynamoDB table from @model",
        "depth": 3,
        "text": "This schema will generate resolvers for Query.getTodo, Query.listTodos, Query.getComment, and Query.listComments at the top level as well as for Todo.comments, and Comment.todo to implement the @connection. Under the hood, the transform will create a global secondary index on the Comment table in DynamoDB but it will not generate a top level query field that queries the GSI because you can fetch the comments for a given todo object via the Query.getTodo.comments query path. If you want to fetch all comments for a todo object via a top level query field i.e. Query.commentsForTodo then do the following:"
      },
      {
        "heading": "Add a custom resolver that targets a DynamoDB table from @model",
        "depth": 3,
        "text": "Add the desired field to your schema.graphql."
      },
      {
        "heading": "Add a custom resolver that targets a DynamoDB table from @model",
        "depth": 3,
        "text": "Add a resolver resource to a stack in the stacks/ directory. The DataSourceName is auto-generated. In most cases, it'll look like {MODEL_NAME}Table. To confirm the data source name, you can verify it from within the AppSync Console (amplify console api) and clicking on the Data Sources tab."
      },
      {
        "heading": "Add a custom resolver that targets a DynamoDB table from @model",
        "depth": 3,
        "text": "Write the resolver templates."
      },
      {
        "heading": "Add a custom resolver that targets an AWS Lambda function",
        "depth": 3,
        "text": "Velocity is useful as a fast, secure environment to run arbitrary code but when it comes to writing complex business logic you can just as easily call out to an AWS lambda function. Here is how:"
      },
      {
        "heading": "Add a custom resolver that targets an AWS Lambda function",
        "depth": 3,
        "text": "First create a function by running amplify add function. The rest of the example assumes you created a function named \"echofunction\" via the amplify add function command. If you already have a function then you may skip this step."
      },
      {
        "heading": "Add a custom resolver that targets an AWS Lambda function",
        "depth": 3,
        "text": "Add a field to your schema.graphql that will invoke the AWS Lambda function."
      },
      {
        "heading": "Add a custom resolver that targets an AWS Lambda function",
        "depth": 3,
        "text": "Add the function as an AppSync data source in the stack's Resources block."
      },
      {
        "heading": "Add a custom resolver that targets an AWS Lambda function",
        "depth": 3,
        "text": "Create an AWS IAM role that allows AppSync to invoke the lambda function on your behalf to the stack's Resources block."
      },
      {
        "heading": "Add a custom resolver that targets an AWS Lambda function",
        "depth": 3,
        "text": "Create an AppSync resolver in the stack's Resources block."
      },
      {
        "heading": "Add a custom resolver that targets an AWS Lambda function",
        "depth": 3,
        "text": "Create the resolver templates in the project's resolvers directory."
      },
      {
        "heading": "Add a custom resolver that targets an AWS Lambda function",
        "depth": 3,
        "text": "resolvers/Query.echo.req.vtl"
      },
      {
        "heading": "Add a custom resolver that targets an AWS Lambda function",
        "depth": 3,
        "text": "resolvers/Query.echo.res.vtl"
      },
      {
        "heading": "Add a custom resolver that targets an AWS Lambda function",
        "depth": 3,
        "text": "After running amplify push open the AppSync console with amplify api console and test your API with this simple query:"
      },
      {
        "heading": "Add a custom geolocation search resolver that targets an OpenSearch domain created by @searchable",
        "depth": 3,
        "text": "To add a geolocation search capabilities to an API add the @searchable directive to an @model type."
      },
      {
        "heading": "Add a custom geolocation search resolver that targets an OpenSearch domain created by @searchable",
        "depth": 3,
        "text": "The next time you run amplify push, an Amazon OpenSearch domain will be created and configured such that data automatically streams from DynamoDB into OpenSearch. The @searchable directive on the Todo type will generate a Query.searchTodos query field and resolver but it is not uncommon to want more specific search capabilities. You can write a custom search resolver by following these steps:"
      },
      {
        "heading": "Add a custom geolocation search resolver that targets an OpenSearch domain created by @searchable",
        "depth": 3,
        "text": "Add the relevant location and search fields to the schema."
      },
      {
        "heading": "Add a custom geolocation search resolver that targets an OpenSearch domain created by @searchable",
        "depth": 3,
        "text": "Create the resolver record in the stack's Resources block."
      },
      {
        "heading": "Add a custom geolocation search resolver that targets an OpenSearch domain created by @searchable",
        "depth": 3,
        "text": "Write the resolver templates."
      },
      {
        "heading": "Add a custom geolocation search resolver that targets an OpenSearch domain created by @searchable",
        "depth": 3,
        "text": "Run amplify push"
      },
      {
        "heading": "Add a custom geolocation search resolver that targets an OpenSearch domain created by @searchable",
        "depth": 3,
        "text": "Amazon OpenSearch domains can take a while to deploy. Take this time to read up on OpenSearch to see what capabilities you are about to unlock."
      },
      {
        "heading": "Add a custom geolocation search resolver that targets an OpenSearch domain created by @searchable",
        "depth": 3,
        "text": "Getting Started with OpenSearch"
      },
      {
        "heading": "Add a custom geolocation search resolver that targets an OpenSearch domain created by @searchable",
        "depth": 3,
        "text": "After the update is complete but before creating any objects, update your OpenSearch index mapping."
      },
      {
        "heading": "Add a custom geolocation search resolver that targets an OpenSearch domain created by @searchable",
        "depth": 3,
        "text": "An index mapping tells OpenSearch how it should treat the data that you are trying to store. By default, if we create an object with field \"location\": { \"lat\": 40, \"lon\": -40 }, OpenSearch will treat that data as an object type when in reality we want it to be treated as a geo_point. You use the mapping APIs to tell OpenSearch how to do this."
      },
      {
        "heading": "Add a custom geolocation search resolver that targets an OpenSearch domain created by @searchable",
        "depth": 3,
        "text": "Make sure you tell OpenSearch that your location field is a geo_point before creating objects in the index because otherwise you will need delete the index and try again. Go to the Amazon OpenSearch Console and find the OpenSearch domain that contains this environment's GraphQL API ID. Click on it and open the OpenSearch Dashboard link. To get the OpenSearch Dashboard to show up you need to install a browser extension such as AWS Agent and configure it with your AWS profile's public key and secret so the browser can sign your requests to the OpenSearch Dashboard for security reasons. Once you have the OpenSearch Dashboard open, click the \"Dev Tools\" tab on the left and run the commands below using the in browser console."
      },
      {
        "heading": "Add a custom geolocation search resolver that targets an OpenSearch domain created by @searchable",
        "depth": 3,
        "text": "Use your API to create objects and immediately search them."
      },
      {
        "heading": "Add a custom geolocation search resolver that targets an OpenSearch domain created by @searchable",
        "depth": 3,
        "text": "After updating the OpenSearch index mapping, open the AWS AppSync console with amplify api console and try out these queries."
      },
      {
        "heading": "Add a custom geolocation search resolver that targets an OpenSearch domain created by @searchable",
        "depth": 3,
        "text": "When you run Mutation.createTodo, the data will automatically be streamed via AWS Lambda into OpenSearch such that it nearly immediately available via Query.nearbyTodos."
      }
    ],
    "source": "export const meta = {\n  title: `Overwrite & customize resolvers`,\n  description: `GraphQL resolvers connect the fields in a type’s schema to a data source. Resolvers are the mechanism by which requests are fulfilled. Learn how to overwrite or add custom resolvers with Amplify.`,\n};\n\n<MigrationAlert isLegacy url={\"/cli/graphql/custom-business-logic\"}/>\n\n## Overwriting Resolvers\n\nLet's say you have a simple *schema.graphql*...\n\n```graphql\ntype Todo @model {\n  id: ID!\n  name: String!\n  description: String\n}\n```\n\nand you want to change the behavior of request mapping template for the *Query.getTodo* resolver that will be generated when the project compiles. To do this you would create a file named `Query.getTodo.req.vtl` in the *resolvers* directory of your API project. The next time you run `amplify push` or `amplify api gql-compile`, your resolver template will be used instead of the auto-generated template. You may similarly create a `Query.getTodo.res.vtl` file to change the behavior of the resolver's response mapping template.\n\n## Custom Resolvers\n\nYou can add custom `Query`, `Mutation` and `Subscription` when the generated ones do not cover your use case.\n1. Add the required `Query`, `Mutation` or `Subscription` type to your schema.\n2. Create resolvers for newly created `Query`, `Mutation` or `Subscription` by creating request and response template in `<project-root>/amplify/backend/api/<api-name>/resolvers` folder. Graphql Transformer follows `<TypeName>.<FieldName>.<req/res>.vtl` as convention to name the resolvers. So if you're adding a custom query name `myCustomQuery` the resolvers would be name `Query.myCustomQuery.req.vtl` and `Query.myCustomQuery.res.vtl`.\n3. Add resolvers resource by creating a custom stack inside `<project-root>/amplify/backend/api/<api-name>/stacks` directory of your API.\n\nTo add the custom fields, add the following to your schema:\n\n```graphql\n  # <project-root>amplify/backend/api/<api-name>/schema.graphql\n\n  type Query {\n    # Add all the custom queries here\n  }\n\n  type Mutation {\n    # Add all the custom mutations here\n  }\n\n  type Subscription {\n    # Add all the custom subscription here\n  }\n\n```\n\nThe GraphQL Transformer by default creates a file called `CustomResources.json` inside `<project-root>/amplify/backend/api/<api-name>/stacks`, which can be used to add the custom resolvers for newly added `Query`, `Mutation` or `Subscription`. The custom stack gets the following arguments passed to it, allowing you to get details about API:\n\n<div class=\"table-wrapper\" markdown=\"block\">\n\n| Parameter                          | Type   | Possible values                    | Description                                                                                                                                                                       |\n| :--------------------------------- | :----- | ---------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| AppSyncApiId                       | String |                                    | The id of the AppSync API associated with this project                                                                                                                            |\n| AppSyncApiName                     | String |                                    | The name of the AppSync API                                                                                                                                                       |\n| env                                | String |                                    | Environment name                                                                                                                                                                  |\n| S3DeploymentBucket                 | String |                                    | The S3 bucket containing all deployment assets for the project                                                                                                                    |\n| S3DeploymentRootKey                | String |                                    | An S3 key relative to the S3DeploymentBucket that points to the root of the deployment directory.                                                                                 |\n| DynamoDBEnableServerSideEncryption | String | `true` or `false`                  | Enable server side encryption powered by KMS.                                                                                                                                     |\n| AuthCognitoUserPoolId              | String |                                    | The id of an existing User Pool to connect                                                                                                                                        |\n| DynamoDBModelTableReadIOPS         | Number |                                    | The number of read IOPS the table should support.                                                                                                                                 |\n| DynamoDBModelTableWriteIOPS        | Number |                                    | The number of write IOPS the table should support                                                                                                                                 |\n| DynamoDBBillingMode                | String | `PAY_PER_REQUEST` or `PROVISIONED` | Configure @model types to create DynamoDB tables with PAY_PER_REQUEST or PROVISIONED billing modes                                                                                |\n| DynamoDBEnablePointInTimeRecovery  | String | `true` or `false`                  | Whether to enable Point in Time Recovery on the table                                                                                                                             |\n| APIKeyExpirationEpoch              | Number |                                    | he epoch time in seconds when the API Key should expire                                                                                                                           |\n| CreateAPIKey                       | Number | `0` or `1`                         | The boolean value to control if an API Key will be created or not. The value of the property is automatically set by the CLI. If the value is set to 0 no API Key will be created |\n\n</div>\n\nAny additional values added Custom Stacks will be exposed as parameter in the root stack, and value can be set by adding the value for it in `<project-root>/amplify/backend/api/<api-name>/parameters.json` file.\n\nTo add a custom resolver, add the following in the resource section of `CustomResource.json`\n\n```json\n{\n    \"Resources\": {\n        \"CustomQuery1\": {\n            \"Type\": \"AWS::AppSync::Resolver\",\n            \"Properties\": {\n                \"ApiId\": {\n                    \"Ref\": \"AppSyncApiId\"\n                },\n                \"DataSourceName\": \"CommentTable\",\n                \"TypeName\": \"Query\",\n                \"FieldName\": \"myCustomQuery\",\n                \"RequestMappingTemplateS3Location\": {\n                    \"Fn::Sub\": [\n                        \"s3://${S3DeploymentBucket}/${S3DeploymentRootKey}/resolvers/Query.myCustomQuery.req.vtl\",\n                        {\n                            \"S3DeploymentBucket\": {\n                                \"Ref\": \"S3DeploymentBucket\"\n                            },\n                            \"S3DeploymentRootKey\": {\n                                \"Ref\": \"S3DeploymentRootKey\"\n                            }\n                        }\n                    ]\n                },\n                \"ResponseMappingTemplateS3Location\": {\n                    \"Fn::Sub\": [\n                        \"s3://${S3DeploymentBucket}/${S3DeploymentRootKey}/resolvers/Query.myCustomQuery.res.vtl\",\n                        {\n                            \"S3DeploymentBucket\": {\n                                \"Ref\": \"S3DeploymentBucket\"\n                            },\n                            \"S3DeploymentRootKey\": {\n                                \"Ref\": \"S3DeploymentRootKey\"\n                            }\n                        }\n                    ]\n                }\n            }\n        }\n    }\n}\n```\n\nThe request and response template should be placed inside `<project-root>/amplify/backend/api/<api-name>/resolvers` folder. Resolver templates are written in the [Apache Velocity Template Language](https://velocity.apache.org/engine/1.7/user-guide.html), commonly referred to as VTL. `Query.myCustomQuery.req.vtl` is a request mapping template, which receives an incoming AppSync request and transforms it into a JSON document that is subsequently passed to the GraphQL resolver. Similarly, `Query.myCustomQuery.res.vtl` is a response mapping template. These templates receive the GraphQL resolver's response and transform the data before returning it to the user.\n\nSeveral example VTL files are discussed later in this documentation. For more detailed information on VTL, including how it can be used in the context of GraphQL resolvers, see the official [AppSync Resolver Mapping Template Reference](https://docs.aws.amazon.com/appsync/latest/devguide/resolver-mapping-template-reference.html).\n\n### Add a custom resolver that targets a DynamoDB table from @model\n\nThis is useful if you want to write a more specific query against a DynamoDB table that was created by *@model*. For example, assume you had this schema with two *@model* types and a pair of *@connection* directives.\n\n```graphql\ntype Todo @model {\n  id: ID!\n  name: String!\n  description: String\n  comments: [Comment] @connection(name: \"TodoComments\")\n}\ntype Comment @model {\n  id: ID!\n  content: String\n  todo: Todo @connection(name: \"TodoComments\")\n}\n```\n\nThis schema will generate resolvers for *Query.getTodo*, *Query.listTodos*, *Query.getComment*, and *Query.listComments* at the top level as well as for *Todo.comments*, and *Comment.todo* to implement the *@connection*. Under the hood, the transform will create a global secondary index on the Comment table in DynamoDB but it will not generate a top level query field that queries the GSI because you can fetch the comments for a given todo object via the *Query.getTodo.comments* query path. If you want to fetch all comments for a todo object via a top level query field i.e. *Query.commentsForTodo* then do the following:\n\n- Add the desired field to your *schema.graphql*.\n\n```graphql\n# ... Todo and Comment types from above\n\ntype CommentConnection {\n  items: [Comment]\n  nextToken: String\n}\ntype Query {\n  commentsForTodo(todoId: ID!, limit: Int, nextToken: String): CommentConnection\n}\n```\n\n- Add a resolver resource to a stack in the *stacks/* directory. The `DataSourceName` is auto-generated. In most cases, it'll look like `{MODEL_NAME}Table`. To confirm the data source name, you can verify it from within the **AppSync Console** (`amplify console api`) and clicking on the **Data Sources** tab.\n\n```json\n{\n  // ... The rest of the template\n  \"Resources\": {\n    \"QueryCommentsForTodoResolver\": {\n      \"Type\": \"AWS::AppSync::Resolver\",\n      \"Properties\": {\n        \"ApiId\": {\n          \"Ref\": \"AppSyncApiId\"\n        },\n        \"DataSourceName\": \"CommentTable\",\n        \"TypeName\": \"Query\",\n        \"FieldName\": \"commentsForTodo\",\n        \"RequestMappingTemplateS3Location\": {\n          \"Fn::Sub\": [\n            \"s3://${S3DeploymentBucket}/${S3DeploymentRootKey}/resolvers/Query.commentsForTodo.req.vtl\",\n            {\n              \"S3DeploymentBucket\": {\n                \"Ref\": \"S3DeploymentBucket\"\n              },\n              \"S3DeploymentRootKey\": {\n                \"Ref\": \"S3DeploymentRootKey\"\n              }\n            }\n          ]\n        },\n        \"ResponseMappingTemplateS3Location\": {\n          \"Fn::Sub\": [\n            \"s3://${S3DeploymentBucket}/${S3DeploymentRootKey}/resolvers/Query.commentsForTodo.res.vtl\",\n            {\n              \"S3DeploymentBucket\": {\n                \"Ref\": \"S3DeploymentBucket\"\n              },\n              \"S3DeploymentRootKey\": {\n                \"Ref\": \"S3DeploymentRootKey\"\n              }\n            }\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n- Write the resolver templates.\n\n```text\n## Query.commentsForTodo.req.vtl **\n\n#set( $limit = $util.defaultIfNull($context.args.limit, 10) )\n{\n  \"version\": \"2017-02-28\",\n  \"operation\": \"Query\",\n  \"query\": {\n    \"expression\": \"#connectionAttribute = :connectionAttribute\",\n    \"expressionNames\": {\n        \"#connectionAttribute\": \"commentTodoId\"\n    },\n    \"expressionValues\": {\n        \":connectionAttribute\": {\n            \"S\": \"$context.args.todoId\"\n        }\n    }\n  },\n  \"scanIndexForward\": true,\n  \"limit\": $limit,\n  \"nextToken\": #if( $context.args.nextToken ) \"$context.args.nextToken\" #else null #end,\n  \"index\": \"gsi-TodoComments\"\n}\n```\n\n```text\n## Query.commentsForTodo.res.vtl **\n\n$util.toJson($ctx.result)\n```\n\n### Add a custom resolver that targets an AWS Lambda function\n\nVelocity is useful as a fast, secure environment to run arbitrary code but when it comes to writing complex business logic you can just as easily call out to an AWS lambda function. Here is how:\n\n- First create a function by running `amplify add function`. The rest of the example assumes you created a function named \"echofunction\" via the `amplify add function` command. If you already have a function then you may skip this step.\n\n- Add a field to your schema.graphql that will invoke the AWS Lambda function.\n\n```graphql\ntype Query {\n  echo(msg: String): String\n}\n```\n\n- Add the function as an AppSync data source in the stack's *Resources* block.\n\n```json\n\"EchoLambdaDataSource\": {\n  \"Type\": \"AWS::AppSync::DataSource\",\n  \"Properties\": {\n    \"ApiId\": {\n      \"Ref\": \"AppSyncApiId\"\n    },\n    \"Name\": \"EchoFunction\",\n    \"Type\": \"AWS_LAMBDA\",\n    \"ServiceRoleArn\": {\n      \"Fn::GetAtt\": [\n        \"EchoLambdaDataSourceRole\",\n        \"Arn\"\n      ]\n    },\n    \"LambdaConfig\": {\n      \"LambdaFunctionArn\": {\n        \"Fn::Sub\": [\n          \"arn:aws:lambda:${AWS::Region}:${AWS::AccountId}:function:echofunction-${env}\",\n          { \"env\": { \"Ref\": \"env\" } }\n        ]\n      }\n    }\n  }\n}\n```\n\n- Create an AWS IAM role that allows AppSync to invoke the lambda function on your behalf to the stack's *Resources* block.\n\n```json\n\"EchoLambdaDataSourceRole\": {\n  \"Type\": \"AWS::IAM::Role\",\n  \"Properties\": {\n    \"RoleName\": {\n      \"Fn::Sub\": [\n        \"EchoLambdaDataSourceRole-${env}\",\n        { \"env\": { \"Ref\": \"env\" } }\n      ]\n    },\n    \"AssumeRolePolicyDocument\": {\n      \"Version\": \"2012-10-17\",\n      \"Statement\": [\n        {\n          \"Effect\": \"Allow\",\n          \"Principal\": {\n            \"Service\": \"appsync.amazonaws.com\"\n          },\n          \"Action\": \"sts:AssumeRole\"\n        }\n      ]\n    },\n    \"Policies\": [\n      {\n        \"PolicyName\": \"InvokeLambdaFunction\",\n        \"PolicyDocument\": {\n          \"Version\": \"2012-10-17\",\n          \"Statement\": [\n            {\n              \"Effect\": \"Allow\",\n              \"Action\": [\n                \"lambda:invokeFunction\"\n              ],\n              \"Resource\": [\n                {\n                  \"Fn::Sub\": [\n                    \"arn:aws:lambda:${AWS::Region}:${AWS::AccountId}:function:echofunction-${env}\",\n                    { \"env\": { \"Ref\": \"env\" } }\n                  ]\n                }\n              ]\n            }\n          ]\n        }\n      }\n    ]\n  }\n}\n```\n\n- Create an AppSync resolver in the stack's *Resources* block.\n\n```json\n\"QueryEchoResolver\": {\n  \"Type\": \"AWS::AppSync::Resolver\",\n  \"Properties\": {\n    \"ApiId\": {\n      \"Ref\": \"AppSyncApiId\"\n    },\n    \"DataSourceName\": {\n      \"Fn::GetAtt\": [\n        \"EchoLambdaDataSource\",\n        \"Name\"\n      ]\n    },\n    \"TypeName\": \"Query\",\n    \"FieldName\": \"echo\",\n    \"RequestMappingTemplateS3Location\": {\n      \"Fn::Sub\": [\n        \"s3://${S3DeploymentBucket}/${S3DeploymentRootKey}/resolvers/Query.echo.req.vtl\",\n        {\n          \"S3DeploymentBucket\": {\n            \"Ref\": \"S3DeploymentBucket\"\n          },\n          \"S3DeploymentRootKey\": {\n            \"Ref\": \"S3DeploymentRootKey\"\n          }\n        }\n      ]\n    },\n    \"ResponseMappingTemplateS3Location\": {\n      \"Fn::Sub\": [\n        \"s3://${S3DeploymentBucket}/${S3DeploymentRootKey}/resolvers/Query.echo.res.vtl\",\n        {\n          \"S3DeploymentBucket\": {\n            \"Ref\": \"S3DeploymentBucket\"\n          },\n          \"S3DeploymentRootKey\": {\n            \"Ref\": \"S3DeploymentRootKey\"\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\n- Create the resolver templates in the project's *resolvers* directory.\n\n**resolvers/Query.echo.req.vtl**\n\n```text\n{\n  \"version\": \"2017-02-28\",\n  \"operation\": \"Invoke\",\n  \"payload\": {\n    \"type\": \"Query\",\n    \"field\": \"echo\",\n    \"arguments\": $utils.toJson($context.arguments),\n    \"identity\": $utils.toJson($context.identity),\n    \"source\": $utils.toJson($context.source)\n  }\n}\n```\n\n**resolvers/Query.echo.res.vtl**\n\n```\n$util.toJson($ctx.result)\n```\n\nAfter running `amplify push` open the AppSync console with `amplify api console` and test your API with this simple query:\n\n```graphql\nquery {\n  echo(msg:\"Hello, world!\")\n}\n```\n\n### Add a custom geolocation search resolver that targets an OpenSearch domain created by @searchable\n\nTo add a geolocation search capabilities to an API add the *@searchable* directive to an *@model* type.\n\n```graphql\ntype Todo @model @searchable {\n  id: ID!\n  name: String!\n  description: String\n  comments: [Comment] @connection(name: \"TodoComments\")\n}\n```\n\nThe next time you run `amplify push`, an Amazon OpenSearch domain will be created and configured such that data automatically streams from DynamoDB into OpenSearch. The *@searchable* directive on the Todo type will generate a *Query.searchTodos* query field and resolver but it is not uncommon to want more specific search capabilities. You can write a custom search resolver by following these steps:\n\n- Add the relevant location and search fields to the schema.\n\n```graphql\ntype Comment @model {\n  id: ID!\n  content: String\n  todo: Todo @connection(name: \"TodoComments\")\n}\ntype Location {\n  lat: Float\n  lon: Float\n}\ntype Todo @model @searchable {\n  id: ID!\n  name: String!\n  description: String\n  comments: [Comment] @connection(name: \"TodoComments\")\n  location: Location\n}\ntype TodoConnection {\n  items: [Todo]\n  nextToken: String\n}\ninput LocationInput {\n  lat: Float\n  lon: Float\n}\ntype Query {\n  nearbyTodos(location: LocationInput!, km: Int): TodoConnection\n}\n```\n\n- Create the resolver record in the stack's *Resources* block.\n\n```json\n\"QueryNearbyTodos\": {\n  \"Type\": \"AWS::AppSync::Resolver\",\n  \"Properties\": {\n    \"ApiId\": {\n      \"Ref\": \"AppSyncApiId\"\n    },\n    \"DataSourceName\": \"ElasticSearchDomain\",\n    \"TypeName\": \"Query\",\n    \"FieldName\": \"nearbyTodos\",\n    \"RequestMappingTemplateS3Location\": {\n      \"Fn::Sub\": [\n        \"s3://${S3DeploymentBucket}/${S3DeploymentRootKey}/resolvers/Query.nearbyTodos.req.vtl\",\n        {\n          \"S3DeploymentBucket\": {\n            \"Ref\": \"S3DeploymentBucket\"\n          },\n          \"S3DeploymentRootKey\": {\n            \"Ref\": \"S3DeploymentRootKey\"\n          }\n        }\n      ]\n    },\n    \"ResponseMappingTemplateS3Location\": {\n      \"Fn::Sub\": [\n        \"s3://${S3DeploymentBucket}/${S3DeploymentRootKey}/resolvers/Query.nearbyTodos.res.vtl\",\n        {\n          \"S3DeploymentBucket\": {\n            \"Ref\": \"S3DeploymentBucket\"\n          },\n          \"S3DeploymentRootKey\": {\n            \"Ref\": \"S3DeploymentRootKey\"\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\n- Write the resolver templates.\n\n```\n## Query.nearbyTodos.req.vtl\n## Objects of type Todo will be stored in the /todo index\n\n#set( $indexPath = \"/todo/doc/_search\" )\n#set( $distance = $util.defaultIfNull($ctx.args.km, 200) )\n{\n  \"version\": \"2017-02-28\",\n  \"operation\": \"GET\",\n  \"path\": \"$indexPath.toLowerCase()\",\n  \"params\": {\n    \"body\": {\n      \"query\": {\n        \"bool\": {\n          \"must\": {\n            \"match_all\": {}\n          },\n          \"filter\": {\n            \"geo_distance\": {\n              \"distance\": \"${distance}km\",\n              \"location\": $util.toJson($ctx.args.location)\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n```\n## Query.nearbyTodos.res.vtl\n\n#set( $items = [] )\n#foreach( $entry in $context.result.hits.hits )\n  #if( !$foreach.hasNext )\n    #set( $nextToken = \"$entry.sort.get(0)\" )\n  #end\n  $util.qr($items.add($entry.get(\"_source\")))\n#end\n$util.toJson({\n  \"items\": $items,\n  \"total\": $ctx.result.hits.total,\n  \"nextToken\": $nextToken\n})\n```\n\n- Run `amplify push`\n\nAmazon OpenSearch domains can take a while to deploy. Take this time to read up on OpenSearch to see what capabilities you are about to unlock.\n\n[Getting Started with OpenSearch](https://opensearch.org/docs/opensearch/index/)\n\n- After the update is complete but before creating any objects, update your OpenSearch index mapping.\n\nAn index mapping tells OpenSearch how it should treat the data that you are trying to store. By default, if we create an object with field `\"location\": { \"lat\": 40, \"lon\": -40 }`, OpenSearch will treat that data as an *object* type when in reality we want it to be treated as a *geo_point*. You use the mapping APIs to tell OpenSearch how to do this.\n\nMake sure you tell OpenSearch that your location field is a *geo_point* before creating objects in the index because otherwise you will need delete the index and try again. Go to the [Amazon OpenSearch Console](https://console.aws.amazon.com/es/home) and find the OpenSearch domain that contains this environment's GraphQL API ID. Click on it and open the OpenSearch Dashboard link. To get the OpenSearch Dashboard to show up you need to install a browser extension such as [AWS Agent](https://addons.mozilla.org/en-US/firefox/addon/aws-agent/) and configure it with your AWS profile's public key and secret so the browser can sign your requests to the OpenSearch Dashboard for security reasons. Once you have the OpenSearch Dashboard open, click the \"Dev Tools\" tab on the left and run the commands below using the in browser console.\n\n```text\n# Create the /todo index if it does not exist\nPUT /todo\n\n# Tell OpenSearch that the location field is a geo_point\nPUT /todo/_mapping/doc\n{\n  \"properties\": {\n    \"location\": {\n      \"type\": \"geo_point\"\n    }\n  }\n}\n```\n\n- Use your API to create objects and immediately search them.\n\nAfter updating the OpenSearch index mapping, open the AWS AppSync console with `amplify api console` and try out these queries.\n\n```graphql\nmutation CreateTodo {\n  createTodo(input:{\n    name: \"Todo 1\",\n    description: \"The first thing to do\",\n    location: {\n      lat:43.476446,\n      lon:-110.767786\n    }\n  }) {\n    id\n    name\n    location {\n      lat\n      lon\n    }\n    description\n  }\n}\n\nquery NearbyTodos {\n  nearbyTodos(location: {\n    lat: 43.476546,\n    lon: -110.768786\n  }, km: 200) {\n    items {\n      id\n      name\n      location {\n        lat\n        lon\n      }\n    }\n  }\n}\n```\n\nWhen you run *Mutation.createTodo*, the data will automatically be streamed via AWS Lambda into OpenSearch such that it nearly immediately available via *Query.nearbyTodos*.\n",
    "meta": {
      "title": "Overwrite & customize resolvers",
      "description": "GraphQL resolvers connect the fields in a type’s schema to a data source. Resolvers are the mechanism by which requests are fulfilled. Learn how to overwrite or add custom resolvers with Amplify.",
      "subcategory": "API (GraphQL)",
      "category": "Amplify CLI (Legacy)"
    },
    "filename": "/cli-legacy/graphql-transformer/resolvers"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Codegen helps you generate native code for iOS and Android, as well as the generation of types for Flow and TypeScript. It can also generate GraphQL statements (queries, mutations, and subscriptions) so that you don't have to hand code them."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Codegen add workflow triggers automatically when an AppSync API is pushed to the cloud. You will be prompted if you want to configure codegen when an AppSync API is created and if you opt-in for codegen, subsequent pushes prompt you if they want to update the generated code after changes get pushed to the cloud."
      },
      {
        "heading": null,
        "depth": null,
        "text": "When a project is configured to generate code with codegen, it stores all the configuration .graphqlconfig.yml file in the root folder of your project. When generating types, codegen uses GraphQL statements as input. It will generate only the types that are being used in the GraphQL statements."
      },
      {
        "heading": "Statement depth",
        "depth": 2,
        "text": "In the below schema there are connections between Comment -> Post -> Blog -> Post -> Comments. When generating statements codegen has a default limit of 2 for depth traversal. But if you need to go deeper than 2 levels you can change the maxDepth parameter either when setting up your codegen or by passing  --maxDepth parameter to codegen"
      },
      {
        "heading": "amplify add codegen",
        "depth": 3,
        "text": "The amplify add codegen allows you to add AppSync API created using the AWS console. If you have your API is in a different region then that of your current region, the command asks you to choose the region. If you are adding codegen outside of an initialized amplify project, provide your introspection schema named schema.json in the same directory that you make the add codegen call from.\nNote: If you use the --apiId flag to add an externally created AppSync API, such as one created in the AWS console, you will not be able to manage this API from the Amplify CLI with commands such as amplify api update when performing schema updates. You cannot add an external AppSync API when outside of an initialized project."
      },
      {
        "heading": "amplify configure codegen",
        "depth": 3,
        "text": "The amplify configure codegen command allows you to update the codegen configuration after it is added to your project. When outside of an initialized project, you can use this to update your project configuration as well as the codegen configuration."
      },
      {
        "heading": "amplify codegen statements",
        "depth": 4,
        "text": "The amplify codegen statements command  generates GraphQL statements(queries, mutation and subscription) based on your GraphQL schema. This command downloads introspection schema every time it is run, but it can be forced to use previously downloaded introspection schema by passing --nodownload flag."
      },
      {
        "heading": "amplify codegen types",
        "depth": 4,
        "text": "The amplify codegen types [--nodownload] command generates GraphQL types for Flow and typescript and Swift class in an iOS project. This command downloads introspection schema every time it is run, but it can be forced to use previously downloaded introspection schema by passing --nodownload flag."
      },
      {
        "heading": "amplify codegen",
        "depth": 4,
        "text": "The amplify codegen [--nodownload] generates GraphQL statements and types. This command downloads introspection schema every time it is run but it can be forced to use previously downloaded introspection schema by passing --nodownload flag. If you are running codegen outside of an initialized amplify project, the introspection schema named schema.json must be in the same directory that you run amplify codegen from. This command will not download the introspection schema when outside of an amplify project - it will only use the introspection schema provided."
      },
      {
        "heading": "Workflows",
        "depth": 2,
        "text": "The design of codegen functionality provides mechanisms to run at different points in your app development lifecycle, including when you create or update an API as well as independently when you want to just update the data fetching requirements of your app but leave your API alone. It additionally allows you to work in a team where the schema is updated or managed by another person. Finally, you can also include the codegen in your build process so that it runs automatically (such as from in Xcode)."
      },
      {
        "heading": "Workflows",
        "depth": 2,
        "text": "Flow 1: Create API then automatically generate code"
      },
      {
        "heading": "Workflows",
        "depth": 2,
        "text": "You’ll see questions as before, but now it will also automatically ask you if you want to generate GraphQL statements and do codegen. It will also respect the ./app/src/main directory for Android projects. After the AppSync deployment finishes the Swift file will be automatically generated (Android you’ll need to kick off a Gradle Build step) and you can begin using in your app immediately."
      },
      {
        "heading": "Workflows",
        "depth": 2,
        "text": "Flow 2: Modify GraphQL schema, push, then automatically generate code"
      },
      {
        "heading": "Workflows",
        "depth": 2,
        "text": "During development, you might wish to update your GraphQL schema and generated code as part of an iterative dev/test cycle. Modify & save your schema in amplify/backend/api/<apiname>/schema.graphql then run:"
      },
      {
        "heading": "Workflows",
        "depth": 2,
        "text": "Each time you will be prompted to update the code in your API and also ask you if you want to run codegen again as well, including regeneration of the GraphQL statements from the new schema."
      },
      {
        "heading": "Workflows",
        "depth": 2,
        "text": "Flow 3: No API changes, just update GraphQL statements & generate code"
      },
      {
        "heading": "Workflows",
        "depth": 2,
        "text": "One of the benefits of GraphQL is the client can define it's data fetching requirements independently of the API. Amplify codegen supports this by allowing you to modify the selection set (e.g. add/remove fields inside the curly braces) for the GraphQL statements and running type generation again. This gives you fine-grained control over the network requests that your application is making. Modify your GraphQL statements (default in the ./graphql folder unless you changed it) then save the files and run:"
      },
      {
        "heading": "Workflows",
        "depth": 2,
        "text": "A new updated Swift file will be created (or run Gradle Build on Android for the same). You can then use the updates in your application code."
      },
      {
        "heading": "Workflows",
        "depth": 2,
        "text": "Flow 4: Shared schema, modified elsewhere (e.g. console or team workflows)"
      },
      {
        "heading": "Workflows",
        "depth": 2,
        "text": "Suppose you are working in a team and the schema is updated either from the AWS AppSync console or on another system. Your types are now out of date because your GraphQL statement was generated off an outdated schema. The easiest way to resolve this is to regenerate your GraphQL statements, update them if necessary, and then generate your types again. Modify the schema in the console or on a separate system, then run:"
      },
      {
        "heading": "Workflows",
        "depth": 2,
        "text": "You should have newly generated GraphQL statements and Swift code that matches the schema updates. If you ran the second command your types will be updated as well. Alternatively, if you run amplify codegen alone it will perform both of these actions."
      },
      {
        "heading": "Workflows",
        "depth": 2,
        "text": "Flow 5: Introspection Schema outside of an initialized project"
      },
      {
        "heading": "Workflows",
        "depth": 2,
        "text": "If you would like to generate statements and types without initializing an amplify project, you can do so by providing your introspection schema named schema.json in your project directory and adding codegen from the same directory. To download your introspection schema from an AppSync api, in the AppSync console go to the schema editor and under \"Export schema\" choose schema.json."
      },
      {
        "heading": "Workflows",
        "depth": 2,
        "text": "Once codegen has been added you can update your introspection schema, then generate statements and types again without re-entering your project information."
      },
      {
        "heading": "Workflows",
        "depth": 2,
        "text": "You can update your project and codegen configuration if required."
      },
      {
        "heading": "iOS usage",
        "depth": 2,
        "text": "This section will walk through the steps needed to take an iOS project written in Swift and add Amplify to it along with a GraphQL API using AWS AppSync. If you are a first time user, we recommend starting with a new Xcode project and a single View Controller."
      },
      {
        "heading": "Setup",
        "depth": 3,
        "text": "After completing the Amplify Getting Started navigate in your terminal to an Xcode project directory and run the following:"
      },
      {
        "heading": "Setup",
        "depth": 3,
        "text": "The add api flow above will ask you some questions, like if you already have an annotated GraphQL schema. If this is your first time using the CLI select No and let it guide you through the default project \"Single object with fields (e.g., “Todo” with ID, name, description)\" as it will be used in the code generation examples below. Later on, you can always change it."
      },
      {
        "heading": "Setup",
        "depth": 3,
        "text": "Since you added an API the amplify push process will automatically prompt you to enter the codegen process and walk through the configuration options. Accept the defaults and it will create a file named API.swift in your root directory (unless you choose to name it differently) as well as a directory called graphql with your documents. You also will have an awsconfiguration.json file that the AppSync client will use for initialization."
      },
      {
        "heading": "Setup",
        "depth": 3,
        "text": "Next, modify your Podfile with a dependency of the AWS AppSync SDK:"
      },
      {
        "heading": "Setup",
        "depth": 3,
        "text": "Run pod install from your terminal and open up the *.xcworkspace Xcode project. Add the API.swift and awsconfiguration.json files to your project (File->Add Files to ..->Add) and then build your project ensuring there are no issues."
      },
      {
        "heading": "Initialize the AppSync client",
        "depth": 3,
        "text": "Inside your application delegate is the best place to initialize the AppSync client. The AWSAppSyncServiceConfig represents the configuration information present in awsconfiguration.json file. By default, the information under the Default section will be used. You will need to create an AWSAppSyncClientConfiguration and AWSAppSyncClient like below:"
      },
      {
        "heading": "Initialize the AppSync client",
        "depth": 3,
        "text": "Next, in your application code where you wish to use the AppSync client, such in a Todos class which is bound to your View Controller, you need to reference this in the viewDidLoad() lifecycle method:"
      },
      {
        "heading": "Queries",
        "depth": 3,
        "text": "Now that the backend is configured, you can run a GraphQL query. The syntax is appSyncClient?.fetch(query: <NAME>Query() {(result, error)}) where <NAME> comes from the GraphQL statements that amplify codegen types created. For example, if you have a ListTodos query your code will look like the following:"
      },
      {
        "heading": "Queries",
        "depth": 3,
        "text": "Optionally, you can set a cache policy on the query like so:"
      },
      {
        "heading": "Queries",
        "depth": 3,
        "text": "returnCacheDataAndFetch will pull results from the local cache first before retrieving data over the network. This gives a snappy UX as well as offline support."
      },
      {
        "heading": "Mutations",
        "depth": 3,
        "text": "For adding data now you will need to run a GraphQL mutation. The syntax appSyncClient?.perform(mutation: <NAME>Mutation() {(result, error)}) where <NAME> comes from the GraphQL statements that amplify codegen types created. However, most GraphQL schemas organize mutations with an input type for maintainability, which is what the Amplify CLI does as well. Therefore you'll pass this as a parameter called input as in the example below:"
      },
      {
        "heading": "Subscriptions",
        "depth": 3,
        "text": "Finally it's time to setup a subscription to realtime data. The syntax appSyncClient?.subscribe(subscription: <NAME>Subscription() {(result, transaction, error)}) where <NAME> comes from the GraphQL statements that amplify codegen types created."
      },
      {
        "heading": "Subscriptions",
        "depth": 3,
        "text": "Subscriptions can also take input types like mutations, in which case they will be subscribing to particular events based on the input. Learn more about Subscription arguments in AppSync here."
      },
      {
        "heading": "Complete Sample",
        "depth": 3,
        "text": "AppDelegate.swift"
      },
      {
        "heading": "Complete Sample",
        "depth": 3,
        "text": "ViewController.swift"
      },
      {
        "heading": "Android usage",
        "depth": 2,
        "text": "This section will walk through the steps needed to take an Android Studio project written in Java and add Amplify to it along with a GraphQL API using AWS AppSync. If you are a first time user, we recommend starting with a new Android Studio project and a single Activity class."
      },
      {
        "heading": "Setup",
        "depth": 3,
        "text": "After completing the Amplify Getting Started navigate in your terminal to an Android Studio project directory and run the following:"
      },
      {
        "heading": "Setup",
        "depth": 3,
        "text": "The add api flow above will ask you some questions, like if you already have an annotated GraphQL schema. If this is your first time using the CLI select No and let it guide you through the default project \"Single object with fields (e.g., “Todo” with ID, name, description)\" as it will be used in the code generation examples below. Later on, you can always change it."
      },
      {
        "heading": "Setup",
        "depth": 3,
        "text": "Since you added an API the amplify push process will automatically enter the codegen process and prompt you for configuration. Accept the defaults and it will create a file named awsconfiguration.json in the ./app/src/main/res/raw  directory that the AppSync client will use for initialization. To finish off the build process there are Gradle and permission updates needed."
      },
      {
        "heading": "Setup",
        "depth": 3,
        "text": "First, in the project's build.gradle, add the following dependency in the build script:"
      },
      {
        "heading": "Setup",
        "depth": 3,
        "text": "Next, in the app's build.gradle add in a plugin of apply plugin: 'com.amazonaws.appsync' and a dependency of implementation 'com.amazonaws:aws-android-sdk-appsync:2.6.+'. For example:"
      },
      {
        "heading": "Setup",
        "depth": 3,
        "text": "Finally, update your AndroidManifest.xml with updates to <uses-permissions>for network calls and offline state. Also add a <service> entry under <application> for MqttService for subscriptions:"
      },
      {
        "heading": "Setup",
        "depth": 3,
        "text": "Build your project ensuring there are no issues."
      },
      {
        "heading": "Initialize the AppSync client",
        "depth": 3,
        "text": "Inside your application code, such as the onCreate() lifecycle method of your activity class, you can initialize the AppSync client using an instance of AWSConfiguration() in the AWSAppSyncClient builder. This reads configuration information present in the awsconfiguration.json file. By default, the information under the Default section will be used."
      },
      {
        "heading": "Queries",
        "depth": 3,
        "text": "Now that the backend is configured, you can run a GraphQL query. The syntax of the callback is GraphQLCall.Callback<{NAME>Query.Data> where {NAME} comes from the GraphQL statements that amplify codegen types created. You will invoke this from an instance of the AppSync client with a similar syntax of .query(<NAME>Query.builder().build()). For example, if you have a ListTodos query your code will look like the following:"
      },
      {
        "heading": "Queries",
        "depth": 3,
        "text": "You can optionally change the cache policy on AppSyncResponseFetchers but we recommend leaving CACHE_AND_NETWORK as it will pull results from the local cache first before retrieving data over the network. This gives a snappy UX as well as offline support."
      },
      {
        "heading": "Mutations",
        "depth": 3,
        "text": "For adding data now you will need to run a GraphQL mutation. The syntax of the callback is GraphQLCall.Callback<{NAME}Mutation.Data> where {NAME} comes from the GraphQL statements that amplify codegen types created. However, most GraphQL schemas organize mutations with an input type for maintainability, which is what the Amplify CLI does as well. Therefore you'll pass this as a parameter called input created with a second builder. You will invoke this from an instance of the AppSync client with a similar syntax of .mutate({NAME}Mutation.builder().input({Name}Input).build()) like so:"
      },
      {
        "heading": "Subscriptions",
        "depth": 3,
        "text": "Finally, it's time to set up a subscription to real-time data. The callback is just AppSyncSubscriptionCall.Callback and you invoke it with a client .subscribe() call and pass in a builder with the syntax of {NAME}Subscription.builder() where {NAME} comes from the GraphQL statements that amplify codegen types created. Note that the Amplify GraphQL transformer has a common nomenclature of putting the word On in front of a subscription like the below example:"
      },
      {
        "heading": "Subscriptions",
        "depth": 3,
        "text": "Subscriptions can also take input types like mutations, in which case they will be subscribing to particular events based on the input. Learn more about Subscription arguments in AppSync here."
      },
      {
        "heading": "Sample",
        "depth": 3,
        "text": "MainActivity.java"
      }
    ],
    "source": "export const meta = {\n  title: `Client code generation`,\n  description: `Amplify's codegen capabilities generates native code for iOS and Android, as well as the generation of types for Flow and TypeScript. It can also generate GraphQL statements(queries, mutations, and subscriptions).`,\n};\n\n<MigrationAlert isLegacy url={\"/cli/graphql/client-code-generation/\"}/>\n\nCodegen helps you generate native code for iOS and Android, as well as the generation of types for Flow and TypeScript. It can also generate GraphQL statements (queries, mutations, and subscriptions) so that you don't have to hand code them.\n\nCodegen `add` workflow triggers automatically when an AppSync API is pushed to the cloud. You will be prompted if you want to configure codegen when an AppSync API is created and if you opt-in for codegen, subsequent pushes prompt you if they want to update the generated code after changes get pushed to the cloud.\n\nWhen a project is configured to generate code with codegen, it stores all the configuration `.graphqlconfig.yml` file in the root folder of your project. When generating types, codegen uses GraphQL statements as input. It will generate only the types that are being used in the GraphQL statements.\n\n## Statement depth\n\nIn the below schema there are connections between `Comment` -> `Post` -> `Blog` -> `Post` -> `Comments`. When generating statements codegen has a default limit of 2 for depth traversal. But if you need to go deeper than 2 levels you can change the `maxDepth` parameter either when setting up your codegen or by passing  `--maxDepth` parameter to `codegen`\n\n```graphql\ntype Blog @model {\n  id: ID!\n  name: String!\n  posts: [Post] @connection(name: \"BlogPosts\")\n}\ntype Post @model {\n  id: ID!\n  title: String!\n  blog: Blog @connection(name: \"BlogPosts\")\n  comments: [Comment] @connection(name: \"PostComments\")\n}\ntype Comment @model {\n  id: ID!\n  content: String\n  post: Post @connection(name: \"PostComments\")\n}\n```\n\n```graphql\nquery GetComment($id: ID!) {\n  getComment(id: $id) { # depth level 1\n    id\n    content\n    post { # depth level 2\n      id\n      title\n      blog { # depth level 3\n        id\n        name\n        posts { # depth level 4\n          items { # depth level 5\n            id\n            title\n          }\n          nextToken\n        }\n      }\n      comments { # depth level 3\n        items { # depth level 4\n          id\n          content\n          post { # depth level 5\n            id\n            title\n          }\n        }\n        nextToken\n      }\n    }\n  }\n}\n```\n\n### General Usage\n\n### amplify add codegen\n\n```bash\namplify add codegen\n```\n\nThe `amplify add codegen` allows you to add AppSync API created using the AWS console. If you have your API is in a different region then that of your current region, the command asks you to choose the region. If you are adding codegen outside of an initialized amplify project, provide your introspection schema named `schema.json` in the same directory that you make the add codegen call from.\n__Note__: If you use the --apiId flag to add an externally created AppSync API, such as one created in the AWS console, you will not be able to manage this API from the Amplify CLI with commands such as amplify api update when performing schema updates. You cannot add an external AppSync API when outside of an initialized project.\n\n### amplify configure codegen\n\n```bash\namplify configure codegen\n```\n\nThe `amplify configure codegen` command allows you to update the codegen configuration after it is added to your project. When outside of an initialized project, you can use this to update your project configuration as well as the codegen configuration.\n\n#### amplify codegen statements\n\n```bash\namplify codegen statements [--nodownload] [--maxDepth <int>]\n```\n\nThe `amplify codegen statements` command  generates GraphQL statements(queries, mutation and subscription) based on your GraphQL schema. This command downloads introspection schema every time it is run, but it can be forced to use previously downloaded introspection schema by passing `--nodownload` flag.\n\n#### amplify codegen types\n\n```bash\namplify codegen types\n```\n\nThe `amplify codegen types [--nodownload]` command generates GraphQL `types` for Flow and typescript and Swift class in an iOS project. This command downloads introspection schema every time it is run, but it can be forced to use previously downloaded introspection schema by passing `--nodownload` flag.\n\n#### amplify codegen\n\n```bash\namplify codegen [--maxDepth <int>]\n```\n\nThe `amplify codegen [--nodownload]` generates GraphQL `statements` and `types`. This command downloads introspection schema every time it is run but it can be forced to use previously downloaded introspection schema by passing `--nodownload` flag. If you are running codegen outside of an initialized amplify project, the introspection schema named `schema.json` must be in the same directory that you run amplify codegen from. This command will not download the introspection schema when outside of an amplify project - it will only use the introspection schema provided.\n\n## Workflows\n\nThe design of codegen functionality provides mechanisms to run at different points in your app development lifecycle, including when you create or update an API as well as independently when you want to just update the data fetching requirements of your app but leave your API alone. It additionally allows you to work in a team where the schema is updated or managed by another person. Finally, you can also include the codegen in your build process so that it runs automatically (such as from in Xcode).\n\n**Flow 1: Create API then automatically generate code**\n\n```bash\namplify init\namplify add api (select GraphQL)\namplify push\n```\n\nYou’ll see questions as before, but now it will also automatically ask you if you want to generate GraphQL statements and do codegen. It will also respect the `./app/src/main` directory for Android projects. After the AppSync deployment finishes the Swift file will be automatically generated (Android you’ll need to kick off a [Gradle Build step](#androiduse)) and you can begin using in your app immediately.\n\n**Flow 2: Modify GraphQL schema, push, then automatically generate code**\n\nDuring development, you might wish to update your GraphQL schema and generated code as part of an iterative dev/test cycle. Modify & save your schema in `amplify/backend/api/<apiname>/schema.graphql` then run:\n\n```bash\namplify push\n```\n\nEach time you will be prompted to update the code in your API and also ask you if you want to run codegen again as well, including regeneration of the GraphQL statements from the new schema.\n\n**Flow 3: No API changes, just update GraphQL statements & generate code**\n\nOne of the benefits of GraphQL is the client can define it's data fetching requirements independently of the API. Amplify codegen supports this by allowing you to modify the selection set (e.g. add/remove fields inside the curly braces) for the GraphQL statements and running type generation again. This gives you fine-grained control over the network requests that your application is making. Modify your GraphQL statements (default in the `./graphql` folder unless you changed it) then save the files and run:\n\n```bash\namplify codegen types\n```\n\nA new updated Swift file will be created (or run Gradle Build on Android for the same). You can then use the updates in your application code.\n\n**Flow 4: Shared schema, modified elsewhere (e.g. console or team workflows)**\n\nSuppose you are working in a team and the schema is updated either from the AWS AppSync console or on another system. Your types are now out of date because your GraphQL statement was generated off an outdated schema. The easiest way to resolve this is to regenerate your GraphQL statements, update them if necessary, and then generate your types again. Modify the schema in the console or on a separate system, then run:\n\n```bash\namplify codegen statements\namplify codegen types\n```\n\nYou should have newly generated GraphQL statements and Swift code that matches the schema updates. If you ran the second command your types will be updated as well. Alternatively, if you run `amplify codegen` alone it will perform both of these actions.\n\n**Flow 5: Introspection Schema outside of an initialized project**\n\nIf you would like to generate statements and types without initializing an amplify project, you can do so by providing your introspection schema named `schema.json` in your project directory and adding codegen from the same directory. To download your introspection schema from an AppSync api, in the AppSync console go to the schema editor and under \"Export schema\" choose `schema.json`.\n\n```bash\namplify add codegen\n```\n\nOnce codegen has been added you can update your introspection schema, then generate statements and types again without re-entering your project information.\n\n```bash\namplify codegen\n```\n\nYou can update your project and codegen configuration if required.\n\n```bash\namplify configure codegen\namplify codegen\n```\n\n## iOS usage\n\nThis section will walk through the steps needed to take an iOS project written in Swift and add Amplify to it along with a GraphQL API using AWS AppSync. If you are a first time user, we recommend starting with a new Xcode project and a single View Controller.\n\n### Setup\n\nAfter completing the [Amplify Getting Started](/start) navigate in your terminal to an Xcode project directory and run the following:\n\n```bash\namplify init       ## Select iOS as your platform\namplify add api    ## Select GraphQL, API key, \"Single object with fields Todo application\"\namplify push       ## Sets up backend and prompts you for codegen, accept the defaults\n```\n\nThe `add api` flow above will ask you some questions, like if you already have an annotated GraphQL schema. If this is your first time using the CLI select **No** and let it guide you through the default project **\"Single object with fields (e.g., “Todo” with ID, name, description)\"** as it will be used in the code generation examples below. Later on, you can always change it.\n\nSince you added an API the `amplify push` process will automatically prompt you to enter the codegen process and walk through the configuration options. Accept the defaults and it will create a file named `API.swift` in your root directory (unless you choose to name it differently) as well as a directory called `graphql` with your documents. You also will have an `awsconfiguration.json` file that the AppSync client will use for initialization.\n\nNext, modify your **Podfile** with a dependency of the AWS AppSync SDK:\n\n```ruby\ntarget 'PostsApp' do\n  use_frameworks!\n  pod 'AWSAppSync'\nend\n```\n\nRun `pod install` from your terminal and open up the `*.xcworkspace` Xcode project. Add the `API.swift` and `awsconfiguration.json` files to your project (_File->Add Files to ..->Add_) and then build your project ensuring there are no issues.\n\n### Initialize the AppSync client\n\nInside your application delegate is the best place to initialize the AppSync client. The `AWSAppSyncServiceConfig` represents the configuration information present in awsconfiguration.json file. By default, the information under the `Default` section will be used. You will need to create an `AWSAppSyncClientConfiguration` and `AWSAppSyncClient` like below:\n\n```swift\nimport AWSAppSync\n\n@UIApplicationMain\nclass AppDelegate: UIResponder, UIApplicationDelegate {\n\n    var appSyncClient: AWSAppSyncClient?\n\n    func application(_ application: UIApplication, didFinishLaunchingWithOptions launchOptions: [UIApplication.LaunchOptionsKey: Any]?) -> Bool {\n\n        do {\n            // You can choose your database location if you wish, or use the default\n            let cacheConfiguration = try AWSAppSyncCacheConfiguration()\n\n            // AppSync configuration & client initialization\n            let appSyncConfig = try AWSAppSyncClientConfiguration(appSyncServiceConfig: AWSAppSyncServiceConfig(), cacheConfiguration: cacheConfiguration)\n            appSyncClient = try AWSAppSyncClient(appSyncConfig: appSyncConfig)\n        } catch {\n            print(\"Error initializing appsync client. \\(error)\")\n        }\n        // other methods\n        return true\n  }\n```\n\nNext, in your application code where you wish to use the AppSync client, such in a `Todos` class which is bound to your View Controller, you need to reference this in the `viewDidLoad()` lifecycle method:\n\n```swift\nimport AWSAppSync\n\nclass Todos: UIViewController{\n  //Reference AppSync client\n  var appSyncClient: AWSAppSyncClient?\n\n  override func viewDidLoad() {\n      super.viewDidLoad()\n      //Reference AppSync client from App Delegate\n      let appDelegate = UIApplication.shared.delegate as! AppDelegate\n      appSyncClient = appDelegate.appSyncClient\n  }\n}\n```\n\n### Queries\n\nNow that the backend is configured, you can run a GraphQL query. The syntax is `appSyncClient?.fetch(query: <NAME>Query() {(result, error)})` where `<NAME>` comes from the GraphQL statements that `amplify codegen types` created. For example, if you have a `ListTodos` query your code will look like the following:\n\n```swift\n//Run a query\nappSyncClient?.fetch(query: ListTodosQuery())  { (result, error) in\n  if error != nil {\n    print(error?.localizedDescription ?? \"\")\n      return\n  }\n    result?.data?.listTodos?.items!.forEach { print(($0?.name)! + \" \" + ($0?.description)!) }\n}\n```\n\nOptionally, you can set a cache policy on the query like so:\n\n```swift\nappSyncClient?.fetch(query: ListTodosQuery(), cachePolicy: .returnCacheDataAndFetch)  { (result, error) in\n```\n\n`returnCacheDataAndFetch` will pull results from the local cache first before retrieving data over the network. This gives a snappy UX as well as offline support.\n\n### Mutations\n\nFor adding data now you will need to run a GraphQL mutation. The syntax `appSyncClient?.perform(mutation: <NAME>Mutation() {(result, error)})` where `<NAME>` comes from the GraphQL statements that `amplify codegen types` created. However, most GraphQL schemas organize mutations with an `input` type for maintainability, which is what the Amplify CLI does as well. Therefore you'll pass this as a parameter called `input` as in the example below:\n\n```swift\nlet mutationInput = CreateTodoInput(name: \"Use AppSync\", description:\"Realtime and Offline\")\n\nappSyncClient?.perform(mutation: CreateTodoMutation(input: mutationInput)) { (result, error) in\n  if let error = error as? AWSAppSyncClientError {\n    print(\"Error occurred: \\(error.localizedDescription )\")\n  }\n  if let resultError = result?.errors {\n    print(\"Error saving the item on server: \\(resultError)\")\n    return\n  }\n}\n```\n\n### Subscriptions\n\nFinally it's time to setup a subscription to realtime data. The syntax `appSyncClient?.subscribe(subscription: <NAME>Subscription() {(result, transaction, error)})` where `<NAME>` comes from the GraphQL statements that `amplify codegen types` created.\n\n```swift\n// Subscription notifications will only be delivered as long as this is retained\nvar subscriptionWatcher: Cancellable?\n\n//In your app code\ndo {\n  subscriptionWatcher = try appSyncClient?.subscribe(subscription: OnCreateTodoSubscription(), resultHandler: { (result, transaction, error) in\n    if let result = result {\n      print(result.data!.onCreateTodo!.name + \" \" + result.data!.onCreateTodo!.description!)\n    } else if let error = error {\n      print(error.localizedDescription)\n    }\n  })\n} catch {\n  print(\"Error starting subscription.\")\n}\n```\n\nSubscriptions can also take `input` types like mutations, in which case they will be subscribing to particular events based on the input. Learn more about Subscription arguments in AppSync [here](https://docs.aws.amazon.com/appsync/latest/devguide/real-time-data.html).\n\n### Complete Sample\n\n**AppDelegate.swift**\n\n```swift\nimport UIKit\nimport AWSAppSync\n\n@UIApplicationMain\nclass AppDelegate: UIResponder, UIApplicationDelegate {\n\n    var window: UIWindow?\n    var appSyncClient: AWSAppSyncClient?\n\n    func application(_ application: UIApplication, didFinishLaunchingWithOptions launchOptions: [UIApplication.LaunchOptionsKey: Any]?) -> Bool {\n        do {\n            // You can choose your database location if you wish, or use the default\n            let cacheConfiguration = try AWSAppSyncCacheConfiguration()\n\n            // AppSync configuration & client initialization\n            let appSyncConfig = try AWSAppSyncClientConfiguration(appSyncServiceConfig: AWSAppSyncServiceConfig(), cacheConfiguration: cacheConfiguration)\n            appSyncClient = try AWSAppSyncClient(appSyncConfig: appSyncConfig)\n        } catch {\n            print(\"Error initializing appsync client. \\(error)\")\n        }\n        return true\n    }\n}\n```\n\n**ViewController.swift**\n\n```swift\nimport UIKit\nimport AWSAppSync\n\nclass ViewController: UIViewController {\n\n    var appSyncClient: AWSAppSyncClient?\n\n    // Subscription notifications will only be delivered as long as this is retained\n    var subscriptionWatcher: Cancellable?\n\n    override func viewDidLoad() {\n        super.viewDidLoad()\n        let appDelegate = UIApplication.shared.delegate as! AppDelegate\n        appSyncClient = appDelegate.appSyncClient\n\n        // Note: each of these are asynchronous calls. Attempting to query the results of `runMutation` immediately\n        // after calling it probably won't work--instead, invoke the query in the mutation's result handler\n        runMutation()\n        runQuery()\n        subscribe()\n    }\n\n    func subscribe() {\n        do {\n            subscriptionWatcher = try appSyncClient?.subscribe(subscription: OnCreateTodoSubscription()) {\n                // The subscription watcher's result block retains a strong reference to the result handler block.\n                // Make sure to capture `self` weakly if you use it\n                // [weak self]\n                (result, transaction, error) in\n                if let result = result {\n                    print(result.data!.onCreateTodo!.name + \" \" + result.data!.onCreateTodo!.description!)\n                    // Update the UI, as in:\n                    //    self?.doSomethingInTheUIWithSubscriptionResults(result)\n                    // By default, `subscribe` will invoke its subscription callbacks on the main queue, so there\n                    // is no need to dispatch to the main queue.\n                } else if let error = error {\n                    print(error.localizedDescription)\n                }\n            }\n        } catch {\n            print(\"Error starting subscription.\")\n        }\n    }\n\n    func runMutation(){\n        let mutationInput = CreateTodoInput(name: \"Use AppSync\", description:\"Realtime and Offline\")\n        appSyncClient?.perform(mutation: CreateTodoMutation(input: mutationInput)) { (result, error) in\n            if let error = error as? AWSAppSyncClientError {\n                print(\"Error occurred: \\(error.localizedDescription )\")\n            }\n            if let resultError = result?.errors {\n                print(\"Error saving the item on server: \\(resultError)\")\n                return\n            }\n            // The server and the local cache are now updated with the results of the mutation\n        }\n    }\n\n    func runQuery(){\n        appSyncClient?.fetch(query: ListTodosQuery()) {(result, error) in\n            if error != nil {\n                print(error?.localizedDescription ?? \"\")\n                return\n            }\n            result?.data?.listTodos?.items!.forEach { print(($0?.name)! + \" \" + ($0?.description)!) }\n        }\n    }\n}\n```\n\n## Android usage\n\nThis section will walk through the steps needed to take an Android Studio project written in Java and add Amplify to it along with a GraphQL API using AWS AppSync. If you are a first time user, we recommend starting with a new Android Studio project and a single Activity class.\n\n### Setup\n\nAfter completing the [Amplify Getting Started](/start) navigate in your terminal to an Android Studio project directory and run the following:\n\n```bash\namplify init       ## Select iOS as your platform\namplify add api    ## Select GraphQL, API key, \"Single object with fields Todo application\"\namplify push       ## Sets up backend and prompts you for codegen, accept the defaults\n```\n\nThe `add api` flow above will ask you some questions, like if you already have an annotated GraphQL schema. If this is your first time using the CLI select **No** and let it guide you through the default project **\"Single object with fields (e.g., “Todo” with ID, name, description)\"** as it will be used in the code generation examples below. Later on, you can always change it.\n\nSince you added an API the `amplify push` process will automatically enter the codegen process and prompt you for configuration. Accept the defaults and it will create a file named `awsconfiguration.json` in the `./app/src/main/res/raw`  directory that the AppSync client will use for initialization. To finish off the build process there are Gradle and permission updates needed.\n\nFirst, in the project's `build.gradle`, add the following dependency in the build script:\n\n```gradle\nclasspath 'com.amazonaws:aws-android-sdk-appsync-gradle-plugin:2.6.+'\n```\n\nNext, in the app's `build.gradle` add in a plugin of `apply plugin: 'com.amazonaws.appsync'` and a dependency of `implementation 'com.amazonaws:aws-android-sdk-appsync:2.6.+'`. For example:\n\n```gradle\napply plugin: 'com.android.application'\napply plugin: 'com.amazonaws.appsync'\nandroid {\n    // Typical items\n}\ndependencies {\n    // Typical dependencies\n    implementation 'com.amazonaws:aws-android-sdk-appsync:2.6.+'\n    implementation 'org.eclipse.paho:org.eclipse.paho.client.mqttv3:1.2.0'\n    implementation 'org.eclipse.paho:org.eclipse.paho.android.service:1.1.1'\n}\n```\n\nFinally, update your `AndroidManifest.xml` with updates to `<uses-permissions>`for network calls and offline state. Also add a `<service>` entry under `<application>` for `MqttService` for subscriptions:\n\n```xml\n<uses-permission android:name=\"android.permission.INTERNET\"/>\n<uses-permission android:name=\"android.permission.ACCESS_NETWORK_STATE\"/>\n<uses-permission android:name=\"android.permission.WAKE_LOCK\" />\n<uses-permission android:name=\"android.permission.READ_PHONE_STATE\" />\n<uses-permission android:name=\"android.permission.WRITE_EXTERNAL_STORAGE\"/>\n<uses-permission android:name=\"android.permission.READ_EXTERNAL_STORAGE\"/>\n\n        <!--other code-->\n\n    <application\n        android:allowBackup=\"true\"\n        android:icon=\"@mipmap/ic_launcher\"\n        android:label=\"@string/app_name\"\n        android:roundIcon=\"@mipmap/ic_launcher_round\"\n        android:supportsRtl=\"true\"\n        android:theme=\"@style/AppTheme\">\n\n        <service android:name=\"org.eclipse.paho.android.service.MqttService\" />\n\n        <!--other code-->\n    </application>\n```\n\nBuild your project ensuring there are no issues.\n\n### Initialize the AppSync client\n\nInside your application code, such as the `onCreate()` lifecycle method of your activity class, you can initialize the AppSync client using an instance of `AWSConfiguration()` in the `AWSAppSyncClient` builder. This reads configuration information present in the `awsconfiguration.json` file. By default, the information under the Default section will be used.\n\n```java\n    private AWSAppSyncClient mAWSAppSyncClient;\n\n    @Override\n    protected void onCreate(Bundle savedInstanceState) {\n        super.onCreate(savedInstanceState);\n        setContentView(R.layout.activity_main);\n        mAWSAppSyncClient = AWSAppSyncClient.builder()\n                .context(getApplicationContext())\n                .awsConfiguration(new AWSConfiguration(getApplicationContext()))\n                .build();\n    }\n```\n\n### Queries\n\nNow that the backend is configured, you can run a GraphQL query. The syntax of the callback is `GraphQLCall.Callback<{NAME>Query.Data>` where `{NAME}` comes from the GraphQL statements that `amplify codegen types` created. You will invoke this from an instance of the AppSync client with a similar syntax of `.query(<NAME>Query.builder().build())`. For example, if you have a `ListTodos` query your code will look like the following:\n\n```java\n    public void query(){\n        mAWSAppSyncClient.query(ListTodosQuery.builder().build())\n                .responseFetcher(AppSyncResponseFetchers.CACHE_AND_NETWORK)\n                .enqueue(todosCallback);\n    }\n\n    private GraphQLCall.Callback<ListTodosQuery.Data> todosCallback = new GraphQLCall.Callback<ListTodosQuery.Data>() {\n        @Override\n        public void onResponse(@Nonnull Response<ListTodosQuery.Data> response) {\n            Log.i(\"Results\", response.data().listTodos().items().toString());\n        }\n\n        @Override\n        public void onFailure(@Nonnull ApolloException e) {\n            Log.e(\"ERROR\", e.toString());\n        }\n    };\n```\n\nYou can optionally change the cache policy on `AppSyncResponseFetchers` but we recommend leaving `CACHE_AND_NETWORK` as it will pull results from the local cache first before retrieving data over the network. This gives a snappy UX as well as offline support.\n\n### Mutations\n\nFor adding data now you will need to run a GraphQL mutation. The syntax of the callback is `GraphQLCall.Callback<{NAME}Mutation.Data>` where `{NAME}` comes from the GraphQL statements that `amplify codegen types` created. However, most GraphQL schemas organize mutations with an `input` type for maintainability, which is what the Amplify CLI does as well. Therefore you'll pass this as a parameter called `input` created with a second builder. You will invoke this from an instance of the AppSync client with a similar syntax of `.mutate({NAME}Mutation.builder().input({Name}Input).build())` like so:\n\n```java\npublic void mutation(){\n    CreateTodoInput createTodoInput = CreateTodoInput.builder().\n        name(\"Use AppSync\").\n        description(\"Realtime and Offline\").\n        build();\n\n    mAWSAppSyncClient.mutate(CreateTodoMutation.builder().input(createTodoInput).build())\n        .enqueue(mutationCallback);\n}\n\nprivate GraphQLCall.Callback<CreateTodoMutation.Data> mutationCallback = new GraphQLCall.Callback<CreateTodoMutation.Data>() {\n    @Override\n    public void onResponse(@Nonnull Response<CreateTodoMutation.Data> response) {\n        Log.i(\"Results\", \"Added Todo\");\n    }\n\n    @Override\n    public void onFailure(@Nonnull ApolloException e) {\n        Log.e(\"Error\", e.toString());\n    }\n};\n```\n\n### Subscriptions\n\nFinally, it's time to set up a subscription to real-time data. The callback is just `AppSyncSubscriptionCall.Callback` and you invoke it with a client `.subscribe()` call and pass in a builder with the syntax of `{NAME}Subscription.builder()` where `{NAME}` comes from the GraphQL statements that `amplify codegen types` created. Note that the Amplify GraphQL transformer has a common nomenclature of putting the word `On` in front of a subscription like the below example:\n\n```java\nprivate AppSyncSubscriptionCall subscriptionWatcher;\n\n    private void subscribe(){\n        OnCreateTodoSubscription subscription = OnCreateTodoSubscription.builder().build();\n        subscriptionWatcher = mAWSAppSyncClient.subscribe(subscription);\n        subscriptionWatcher.execute(subCallback);\n    }\n\n    private AppSyncSubscriptionCall.Callback subCallback = new AppSyncSubscriptionCall.Callback() {\n        @Override\n        public void onResponse(@Nonnull Response response) {\n            Log.i(\"Response\", response.data().toString());\n        }\n\n        @Override\n        public void onFailure(@Nonnull ApolloException e) {\n            Log.e(\"Error\", e.toString());\n        }\n\n        @Override\n        public void onCompleted() {\n            Log.i(\"Completed\", \"Subscription completed\");\n        }\n    };\n\n```\n\nSubscriptions can also take `input` types like mutations, in which case they will be subscribing to particular events based on the input. Learn more about Subscription arguments in AppSync [here](https://docs.aws.amazon.com/appsync/latest/devguide/real-time-data.html).\n\n### Sample\n\n**MainActivity.java**\n\n```java\nimport android.util.Log;\nimport com.amazonaws.mobile.config.AWSConfiguration;\nimport com.amazonaws.mobileconnectors.appsync.AWSAppSyncClient;\nimport com.amazonaws.mobileconnectors.appsync.AppSyncSubscriptionCall;\nimport com.amazonaws.mobileconnectors.appsync.fetcher.AppSyncResponseFetchers;\nimport com.apollographql.apollo.GraphQLCall;\nimport com.apollographql.apollo.api.Response;\nimport com.apollographql.apollo.exception.ApolloException;\nimport javax.annotation.Nonnull;\nimport amazonaws.demo.todo.CreateTodoMutation;\nimport amazonaws.demo.todo.ListTodosQuery;\nimport amazonaws.demo.todo.OnCreateTodoSubscription;\nimport amazonaws.demo.todo.type.CreateTodoInput;\n\npublic class MainActivity extends AppCompatActivity {\n\n    private AWSAppSyncClient mAWSAppSyncClient;\n    private AppSyncSubscriptionCall subscriptionWatcher;\n\n    @Override\n    protected void onCreate(Bundle savedInstanceState) {\n        super.onCreate(savedInstanceState);\n        setContentView(R.layout.activity_main);\n        mAWSAppSyncClient = AWSAppSyncClient.builder()\n                .context(getApplicationContext())\n                .awsConfiguration(new AWSConfiguration(getApplicationContext()))\n                .build();\n        query();\n        mutation();\n        subscribe();\n    }\n\n    private void subscribe(){\n        OnCreateTodoSubscription subscription = OnCreateTodoSubscription.builder().build();\n        subscriptionWatcher = mAWSAppSyncClient.subscribe(subscription);\n        subscriptionWatcher.execute(subCallback);\n    }\n\n    private AppSyncSubscriptionCall.Callback subCallback = new AppSyncSubscriptionCall.Callback() {\n        @Override\n        public void onResponse(@Nonnull Response response) {\n            Log.i(\"Response\", response.data().toString());\n        }\n\n        @Override\n        public void onFailure(@Nonnull ApolloException e) {\n            Log.e(\"Error\", e.toString());\n        }\n\n        @Override\n        public void onCompleted() {\n            Log.i(\"Completed\", \"Subscription completed\");\n        }\n    };\n\n    public void query(){\n        mAWSAppSyncClient.query(ListTodosQuery.builder().build())\n                .responseFetcher(AppSyncResponseFetchers.CACHE_AND_NETWORK)\n                .enqueue(todosCallback);\n    }\n\n    private GraphQLCall.Callback<ListTodosQuery.Data> todosCallback = new GraphQLCall.Callback<ListTodosQuery.Data>() {\n        @Override\n        public void onResponse(@Nonnull Response<ListTodosQuery.Data> response) {\n            Log.i(\"Results\", response.data().listTodos().items().toString());\n        }\n\n        @Override\n        public void onFailure(@Nonnull ApolloException e) {\n            Log.e(\"ERROR\", e.toString());\n        }\n    };\n\n    public void mutation(){\n\n        CreateTodoInput createTodoInput = CreateTodoInput.builder().\n                name(\"Use AppSync\").\n                description(\"Realtime and Offline\").\n                build();\n\n        mAWSAppSyncClient.mutate(CreateTodoMutation.builder().input(createTodoInput).build())\n                .enqueue(mutationCallback);\n\n    }\n\n    private GraphQLCall.Callback<CreateTodoMutation.Data> mutationCallback = new GraphQLCall.Callback<CreateTodoMutation.Data>() {\n        @Override\n        public void onResponse(@Nonnull Response<CreateTodoMutation.Data> response) {\n            Log.i(\"Results\", \"Added Todo\");\n        }\n\n        @Override\n        public void onFailure(@Nonnull ApolloException e) {\n            Log.e(\"Error\", e.toString());\n        }\n    };\n}\n```\n\n",
    "meta": {
      "title": "Client code generation",
      "description": "Amplify's codegen capabilities generates native code for iOS and Android, as well as the generation of types for Flow and TypeScript. It can also generate GraphQL statements(queries, mutations, and subscriptions).",
      "subcategory": "API (GraphQL)",
      "category": "Amplify CLI (Legacy)"
    },
    "filename": "/cli-legacy/graphql-transformer/codegen"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "The Amplify CLI currently supports importing serverless Amazon Aurora MySQL 5.6 databases running in the us-east-1 region. The following instruction show how to create an Amazon Aurora Serverless database, import this database as a GraphQL data source and test it."
      },
      {
        "heading": null,
        "depth": null,
        "text": "First, if you do not have an Amplify project with a GraphQL API create one using these simple commands."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Go to the AWS RDS console and click \"Create database\"."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Select \"Standard Create\" for the database creation method"
      },
      {
        "heading": null,
        "depth": null,
        "text": ""
      },
      {
        "heading": null,
        "depth": null,
        "text": "For Engine Options keep the following options"
      },
      {
        "heading": null,
        "depth": null,
        "text": ""
      },
      {
        "heading": null,
        "depth": null,
        "text": "Select \"Serverless\" in Database Features"
      },
      {
        "heading": null,
        "depth": null,
        "text": ""
      },
      {
        "heading": null,
        "depth": null,
        "text": "In Settings fill in the following information"
      },
      {
        "heading": null,
        "depth": null,
        "text": ""
      },
      {
        "heading": null,
        "depth": null,
        "text": "Select the Capacity Settings as shown below"
      },
      {
        "heading": null,
        "depth": null,
        "text": ""
      },
      {
        "heading": null,
        "depth": null,
        "text": "Expand the \"Additional connectivity configuration\" and enable \"Data API\" and \"Create New\" if you do not have a VPC security group configured"
      },
      {
        "heading": null,
        "depth": null,
        "text": ""
      },
      {
        "heading": null,
        "depth": null,
        "text": "Expand \"Additional Configuration\" and fill in \"Initial Database Name\" as MarketPlace"
      },
      {
        "heading": null,
        "depth": null,
        "text": ""
      },
      {
        "heading": null,
        "depth": null,
        "text": "Click Create Database. Once created, click Query Editor on the side menu to open a connection prompt. To connect, select the cluster and fill in the credentials configured earlier."
      },
      {
        "heading": null,
        "depth": null,
        "text": ""
      },
      {
        "heading": null,
        "depth": null,
        "text": "After connecting, create a database and some tables."
      },
      {
        "heading": null,
        "depth": null,
        "text": ""
      },
      {
        "heading": null,
        "depth": null,
        "text": "Return to your command line and run amplify api add-graphql-datasource from the root of your amplify project."
      },
      {
        "heading": null,
        "depth": null,
        "text": ""
      },
      {
        "heading": null,
        "depth": null,
        "text": "Push your project to AWS with amplify push."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Run amplify push to push your project to AWS. You can then open the AppSync console with amplify api console, to try interacting with your RDS database via your GraphQL API."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Interact with your SQL database from GraphQL"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Your API is now configured to work with your serverless Amazon Aurora MySQL database. Try running a mutation to create a customer from the AppSync Console and then query it from the RDS Console to double check."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Create a customer:"
      },
      {
        "heading": null,
        "depth": null,
        "text": ""
      },
      {
        "heading": null,
        "depth": null,
        "text": "Then open the RDS console and run a simple select statement to see the new customer:"
      },
      {
        "heading": null,
        "depth": null,
        "text": ""
      },
      {
        "heading": "How does this work?",
        "depth": 3,
        "text": "The add-graphql-datasource will add a custom stack to your project that provides a basic set of functionality for working with an existing data source. You can find the new stack in the stacks/ directory, a set of new resolvers in the resolvers/ directory, and will also find a few additions to your schema.graphql. You may edit details in the custom stack and/or resolver files without worry. You may run add-graphql-datasource again to update your project with changes in the database but be careful as these will overwrite any existing templates in the stacks/ or resolvers/ directories. When using multiple environment with the Amplify CLI, you will be asked to configure the data source once per environment."
      }
    ],
    "source": "export const meta = {\n  title: `Relational Databases`,\n  description: `The Amplify CLI currently supports importing serverless Amazon Aurora MySQL 5.6 databases running in the us-east-1 region. Learn how to create an Amazon Aurora Serverless database, import this database as a GraphQL data source and test it.`\n};\n\n<MigrationAlert isLegacy url={'/cli/graphql/data-modeling'} />\n\nThe Amplify CLI currently supports importing serverless Amazon Aurora MySQL 5.6 databases running in the us-east-1 region. The following instruction show how to create an Amazon Aurora Serverless database, import this database as a GraphQL data source and test it.\n\n**First, if you do not have an Amplify project with a GraphQL API create one using these simple commands.**\n\n```bash\namplify init\namplify add api\n```\n\n**Go to the AWS RDS console and click \"Create database\".**\n\n**Select \"Standard Create\" for the database creation method**\n\n![Database Creation](/images/database-creation.png)\n\n**For Engine Options keep the following options**\n\n![Engine Option](/images/database-engine-option.png)\n\n**Select \"Serverless\" in Database Features**\n\n![Database Features](/images/database-features.png)\n\n**In Settings fill in the following information**\n\n![Database Settings](/images/database-setting.png)\n\n**Select the Capacity Settings as shown below**\n\n![Database Capacity](/images/database-capacity.png)\n\n**Expand the \"Additional connectivity configuration\" and enable \"Data API\" and \"Create New\" if you do not have a VPC security group configured**\n\n![Database Connectivity](/images/database-connectivity.png)\n\n**Expand \"Additional Configuration\" and fill in \"Initial Database Name\" as MarketPlace**\n\n![Database Additional Configuration](/images/database-additional-configuration.png)\n\n**Click _Create Database_. Once created, click _Query Editor_ on the side menu to open a connection prompt. To connect, select the cluster and fill in the credentials configured earlier.**\n\n![Database Connect ](/images/connect-to-database.png)\n\n**After connecting, create a database and some tables.**\n\n![Database details](/images/query-editor.png)\n\n```sql\nUSE MarketPlace;\nCREATE TABLE Customers (\n  id int(11) NOT NULL PRIMARY KEY,\n  name varchar(50) NOT NULL,\n  phone varchar(50) NOT NULL,\n  email varchar(50) NOT NULL\n);\nCREATE TABLE Orders (\n  id int(11) NOT NULL PRIMARY KEY,\n  customerId int(11) NOT NULL,\n  orderDate datetime DEFAULT CURRENT_TIMESTAMP,\n  KEY `customerId` (`customerId`),\n  CONSTRAINT `customer_orders_ibfk_1` FOREIGN KEY (`customerId`) REFERENCES `Customers` (`id`)\n);\n```\n\n**Return to your command line and run `amplify api add-graphql-datasource` from the root of your amplify project.**\n\n![Add GraphQL Data Source](/images/add-graphql-datasource.png)\n\n**Push your project to AWS with `amplify push`.**\n\nRun `amplify push` to push your project to AWS. You can then open the AppSync console with `amplify api console`, to try interacting with your RDS database via your GraphQL API.\n\n**Interact with your SQL database from GraphQL**\n\nYour API is now configured to work with your serverless Amazon Aurora MySQL database. Try running a mutation to create a customer from the [AppSync Console](https://console.aws.amazon.com/appsync/home) and then query it from the [RDS Console](https://console.aws.amazon.com/rds/home) to double check.\n\nCreate a customer:\n\n```graphql\nmutation CreateCustomer {\n  createCustomers(\n    createCustomersInput: {\n      id: 1\n      name: \"Hello\"\n      phone: \"111-222-3333\"\n      email: \"customer1@mydomain.com\"\n    }\n  ) {\n    id\n    name\n    phone\n    email\n  }\n}\n```\n\n![GraphQL Results](/images/graphql-results.png)\n\nThen open the RDS console and run a simple select statement to see the new customer:\n\n```sql\nUSE MarketPlace;\nSELECT * FROM Customers;\n```\n\n![SQL Results](/images/sql-results.png)\n\n### How does this work?\n\nThe `add-graphql-datasource` will add a custom stack to your project that provides a basic set of functionality for working with an existing data source. You can find the new stack in the `stacks/` directory, a set of new resolvers in the `resolvers/` directory, and will also find a few additions to your `schema.graphql`. You may edit details in the custom stack and/or resolver files without worry. You may run `add-graphql-datasource` again to update your project with changes in the database but be careful as these will overwrite any existing templates in the `stacks/` or `resolvers/` directories. When using multiple environment with the Amplify CLI, you will be asked to configure the data source once per environment.\n",
    "meta": {
      "title": "Relational Databases",
      "description": "The Amplify CLI currently supports importing serverless Amazon Aurora MySQL 5.6 databases running in the us-east-1 region. Learn how to create an Amazon Aurora Serverless database, import this database as a GraphQL data source and test it.",
      "subcategory": "API (GraphQL)",
      "category": "Amplify CLI (Legacy)"
    },
    "filename": "/cli-legacy/graphql-transformer/relational"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "The GraphQL Transform, Amplify CLI, and Amplify Library make it simple to add complex object support with Amazon S3 to an application."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Note: Complex objects are not supported by DataStore-enabled GraphQL APIs."
      },
      {
        "heading": "Basics",
        "depth": 3,
        "text": "At a minimum the steps to add S3 Object support are as follows:"
      },
      {
        "heading": "Basics",
        "depth": 3,
        "text": "Create a Amazon S3 bucket to hold files via amplify add storage."
      },
      {
        "heading": "Basics",
        "depth": 3,
        "text": "Create a user pool in Amazon Cognito User Pools via amplify add auth."
      },
      {
        "heading": "Basics",
        "depth": 3,
        "text": "Create a GraphQL API via amplify add api and add the following type definition:"
      },
      {
        "heading": "Basics",
        "depth": 3,
        "text": "Reference the S3Object type from some @model type:"
      },
      {
        "heading": "Basics",
        "depth": 3,
        "text": "The GraphQL Transform handles creating the relevant input types and will store pointers to S3 objects in Amazon DynamoDB. The AppSync SDKs and Amplify library handle uploading the files to S3 transparently."
      },
      {
        "heading": "Basics",
        "depth": 3,
        "text": "Run a mutation with S3 objects from your client app:"
      }
    ],
    "source": "export const meta = {\n  title: `GraphQL transform and Storage`,\n  description: `The GraphQL Transform, Amplify CLI, and Amplify Library make it simple to add complex object support with Amazon S3 to an application.`\n};\n\nThe GraphQL Transform, Amplify CLI, and Amplify Library make it simple to add complex object support with Amazon S3 to an application.\n\n<Callout warning>\n\n  Note: Complex objects are not supported by DataStore-enabled GraphQL APIs.\n  \n</Callout>\n\n### Basics\n\nAt a minimum the steps to add S3 Object support are as follows:\n\n**Create a Amazon S3 bucket to hold files via `amplify add storage`.**\n\n**Create a user pool in Amazon Cognito User Pools via `amplify add auth`.**\n\n**Create a GraphQL API via `amplify add api` and add the following type definition:**\n\n```graphql\ntype S3Object {\n  bucket: String!\n  region: String!\n  key: String!\n}\n```\n\n**Reference the S3Object type from some `@model` type:**\n\n```graphql\ntype Picture @model @auth(rules: [{ allow: owner }]) {\n  id: ID!\n  name: String\n  owner: String\n\n  # Reference the S3Object type from a field.\n  file: S3Object\n}\n```\n\nThe GraphQL Transform handles creating the relevant input types and will store pointers to S3 objects in Amazon DynamoDB. The AppSync SDKs and Amplify library handle uploading the files to S3 transparently.\n\n**Run a mutation with S3 objects from your client app:**\n\n```graphql\nmutation($input: CreatePictureInput!) {\n  createPicture(input: $input) {\n    id\n    name\n    visibility\n    owner\n    createdAt\n    file {\n      region\n      bucket\n      key\n    }\n  }\n}\n```\n",
    "meta": {
      "title": "GraphQL transform and Storage",
      "description": "The GraphQL Transform, Amplify CLI, and Amplify Library make it simple to add complex object support with Amazon S3 to an application.",
      "subcategory": "API (GraphQL)",
      "category": "Amplify CLI (Legacy)"
    },
    "filename": "/cli-legacy/graphql-transformer/storage"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In the DynamoDB documentation for modeling relational data in a NoSQL database, there is an in depth example of 17 access patterns from the First Steps for Modeling Relational Data in DynamoDB page."
      },
      {
        "heading": null,
        "depth": null,
        "text": "| | Most common/import access patterns in our organization|\n|---|--------------|\n|1| Look up employee details by employee ID|\n|2| Query employee details by employee name|\n|3| Find an employee's phone number(s)|\n|4| Find a customer's phone number(s)|\n|5| Get orders for a given customer within a given date range|\n|6| Show all open orders within a given date range across all customers|\n|7| See all employees recently hired|\n|8| Find all employees working in a given warehouse|\n|9| Get all items on order for a given product|\n|10| Get current inventories for a given product at all warehouses|\n|11| Get customers by account representative|\n|12| Get orders by account representative and date|\n|13| Get all items on order for a given product|\n|14| Get all employees with a given job title|\n|15| Get inventory by product and warehouse|\n|16| Get total product inventory|\n|17| Get account representatives ranked by order total and sales period|"
      },
      {
        "heading": null,
        "depth": null,
        "text": "In this example, you will learn how to support these data access patterns using GraphQL, AWS Amplify, and the GraphQL Transform library. This example has the following types:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Warehouse"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Product"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Inventory"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Employee"
      },
      {
        "heading": null,
        "depth": null,
        "text": "AccountRepresentative"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Customer"
      },
      {
        "heading": null,
        "depth": null,
        "text": "The following schema introduces the required keys and connections so that we can support these access patterns:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Now that we have the schema created, let's create the items in the database that we will be operating against:"
      },
      {
        "heading": "1. Look up employee details by employee ID",
        "depth": 2,
        "text": "This can simply be done by querying the employee model with an employee ID, no @key or @connection is needed to make this work."
      },
      {
        "heading": "2. Query employee details by employee name",
        "depth": 2,
        "text": "The @key byName on the Employee type makes this access-pattern feasible because under the covers an index is created and a query is used to match against the name field. We can use this query:"
      },
      {
        "heading": "3. Find an Employee’s phone number",
        "depth": 2,
        "text": "Either one of the previous queries would work to find an employee’s phone number as long as one has their ID or name."
      },
      {
        "heading": "4. Find a customer’s phone number",
        "depth": 2,
        "text": "A similar query to those given above but on the Customer model would give you a customer’s phone number."
      },
      {
        "heading": "5. Get orders for a given customer within a given date range",
        "depth": 2,
        "text": "There is a one-to-many relation that lets all the orders of a customer be queried."
      },
      {
        "heading": "5. Get orders for a given customer within a given date range",
        "depth": 2,
        "text": "This relationship is created by having the @key name byCustomerByDate on the Order model that is queried by the connection on the orders field of the Customer model."
      },
      {
        "heading": "5. Get orders for a given customer within a given date range",
        "depth": 2,
        "text": "A sort key with the date is used. What this means is that the GraphQL resolver can use predicates like Between to efficiently search the date range rather than scanning all records in the database and then filtering them out."
      },
      {
        "heading": "5. Get orders for a given customer within a given date range",
        "depth": 2,
        "text": "The query one would need to get the orders to a customer within a date range would be:"
      },
      {
        "heading": "6. Show all open orders within a given date range across all customers",
        "depth": 2,
        "text": "The @key byCustomerByStatusByDate enables you to run a query that would work for this access pattern."
      },
      {
        "heading": "6. Show all open orders within a given date range across all customers",
        "depth": 2,
        "text": "In this example, a composite sort key (combination of two or more keys) with the status and date is used. What this means is that the unique identifier of a record in the database is created by concatenating these two fields (status and date) together, and then the GraphQL resolver can use predicates like Between or Contains to efficiently search the unique identifier for matches rather than scanning all records in the database and then filtering them out."
      },
      {
        "heading": "7. See all employees hired recently",
        "depth": 2,
        "text": "Having @key(name: \"newHire\", fields: [\"newHire\", \"id\"]) on the Employee model allows one to query by whether an employee has been hired recently."
      },
      {
        "heading": "7. See all employees hired recently",
        "depth": 2,
        "text": "We can also query and have the results returned by start date by using the employeesNewHireByStartDate query:"
      },
      {
        "heading": "8. Find all employees working in a given warehouse",
        "depth": 2,
        "text": "This needs a one to many relationship from warehouses to employees. As can be seen from the @connection in the Warehouse model, this connection uses the byWarehouse key on the Employee model. The relevant query would look like this:"
      },
      {
        "heading": "9. Get all items on order for a given product",
        "depth": 2,
        "text": "This access-pattern would use a one-to-many relation from products to orders. With this query we can get all orders of a given product:"
      },
      {
        "heading": "10. Get current inventories for a product at all warehouses",
        "depth": 2,
        "text": "The query needed to get the inventories of a product in all warehouses would be:"
      },
      {
        "heading": "11. Get customers by account representative",
        "depth": 2,
        "text": "This uses a one-to-many connection between account representatives and customers:"
      },
      {
        "heading": "11. Get customers by account representative",
        "depth": 2,
        "text": "The query needed would look like this:"
      },
      {
        "heading": "12. Get orders by account representative and date",
        "depth": 2,
        "text": "As can be seen in the AccountRepresentative model this connection uses the byRepresentativebyDate field on the Order model to create the connection needed. The query needed would look like this:"
      },
      {
        "heading": "13. Get all items on order for a given product",
        "depth": 2,
        "text": "This is the same as number 9."
      },
      {
        "heading": "14. Get all employees with a given job title",
        "depth": 2,
        "text": "Using the byTitle @key makes this access pattern quite easy."
      },
      {
        "heading": "15. Get inventory by product by warehouse",
        "depth": 2,
        "text": "Here having the inventories be held in a separate model is particularly useful since this model can have its own partition key and sort key such that the inventories themselves can be queried as is needed for this access-pattern."
      },
      {
        "heading": "15. Get inventory by product by warehouse",
        "depth": 2,
        "text": "A query on this model would look like this:"
      },
      {
        "heading": "15. Get inventory by product by warehouse",
        "depth": 2,
        "text": "We can also get all inventory from an individual warehouse by using the itemsByWarehouseID query created by the byWarehouseID key:"
      },
      {
        "heading": "16. Get total product inventory",
        "depth": 2,
        "text": "How this would be done depends on the use case. If one just wants a list of all inventories in all warehouses, one could just run a list inventories on the Inventory model:"
      },
      {
        "heading": "17. Get sales representatives ranked by order total and sales period",
        "depth": 2,
        "text": "The sales period is either a date range or maybe even a month or week. Therefore we can set the sales period as a string and query using the combination of salesPeriod and orderTotal. We can also set the sortDirection in order to get the return values from largest to smallest:"
      }
    ],
    "source": "export const meta = {\n  title: `Data access patterns`,\n  description: `Learn how to support these 17 common database access patterns using GraphQL, AWS Amplify, and the GraphQL Transform library`,\n};\n\n<MigrationAlert isLegacy url={\"/cli/graphql/examples-and-solutions\"}/>\n\nIn the [DynamoDB documentation for modeling relational data in a NoSQL database](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-modeling-nosql.html), there is an in depth example of 17 access patterns from the [First Steps for Modeling Relational Data in DynamoDB](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-modeling-nosql.html) page.\n\n| | Most common/import access patterns in our organization|\n|---|--------------|\n|1| Look up employee details by employee ID|\n|2| Query employee details by employee name|\n|3| Find an employee's phone number(s)|\n|4| Find a customer's phone number(s)|\n|5| Get orders for a given customer within a given date range|\n|6| Show all open orders within a given date range across all customers|\n|7| See all employees recently hired|\n|8| Find all employees working in a given warehouse|\n|9| Get all items on order for a given product|\n|10| Get current inventories for a given product at all warehouses|\n|11| Get customers by account representative|\n|12| Get orders by account representative and date|\n|13| Get all items on order for a given product|\n|14| Get all employees with a given job title|\n|15| Get inventory by product and warehouse|\n|16| Get total product inventory|\n|17| Get account representatives ranked by order total and sales period|\n\nIn this example, you will learn how to support these data access patterns using GraphQL, AWS Amplify, and the GraphQL Transform library. This example has the following types:\n\n- Warehouse\n- Product\n- Inventory\n- Employee\n- AccountRepresentative\n- Customer\n\nThe [following schema](https://gist.github.com/dabit3/e0af16db09b6e206292d1c5cfc0d0a07) introduces the required keys and connections so that we can support these access patterns:\n\n```graphql\ntype Order @model\n  @key(name: \"byCustomerByStatusByDate\", fields: [\"customerID\", \"status\", \"date\"])\n  @key(name: \"byCustomerByDate\", fields: [\"customerID\", \"date\"])\n  @key(name: \"byRepresentativebyDate\", fields: [\"accountRepresentativeID\", \"date\"])\n  @key(name: \"byProduct\", fields: [\"productID\", \"id\"]) {\n  id: ID!\n  customerID: ID!\n  accountRepresentativeID: ID!\n  productID: ID!\n  status: String!\n  amount: Int!\n  date: String!\n}\n\ntype Customer @model\n  @key(name: \"byRepresentative\", fields: [\"accountRepresentativeID\", \"id\"]) {\n  id: ID!\n  name: String!\n  phoneNumber: String\n  accountRepresentativeID: ID!\n  ordersByDate: [Order] @connection(keyName: \"byCustomerByDate\", fields: [\"id\"])\n  ordersByStatusDate: [Order] @connection(keyName: \"byCustomerByStatusByDate\", fields: [\"id\"])\n}\n\ntype Employee @model\n  @key(name: \"newHire\", fields: [\"newHire\", \"id\"], queryField: \"employeesNewHire\")\n  @key(name: \"newHireByStartDate\", fields: [\"newHire\", \"startDate\"], queryField: \"employeesNewHireByStartDate\")\n  @key(name: \"byName\", fields: [\"name\", \"id\"], queryField: \"employeeByName\")\n  @key(name: \"byTitle\", fields: [\"jobTitle\", \"id\"], queryField: \"employeesByJobTitle\")\n  @key(name: \"byWarehouse\", fields: [\"warehouseID\", \"id\"]) {\n  id: ID!\n  name: String!\n  startDate: String!\n  phoneNumber: String!\n  warehouseID: ID!\n  jobTitle: String!\n  newHire: String! # We have to use String type, because Boolean types cannot be sort keys\n}\n\ntype Warehouse @model {\n  id: ID!\n  employees: [Employee] @connection(keyName: \"byWarehouse\", fields: [\"id\"])\n}\n\ntype AccountRepresentative @model\n  @key(name: \"bySalesPeriodByOrderTotal\", fields: [\"salesPeriod\", \"orderTotal\"], queryField: \"repsByPeriodAndTotal\") {\n  id: ID!\n  customers: [Customer] @connection(keyName: \"byRepresentative\", fields: [\"id\"])\n  orders: [Order] @connection(keyName: \"byRepresentativebyDate\", fields: [\"id\"])\n  orderTotal: Int\n  salesPeriod: String\n}\n\ntype Inventory @model\n  @key(name: \"byWarehouseID\", fields: [\"warehouseID\"], queryField: \"itemsByWarehouseID\")\n  @key(fields: [\"productID\", \"warehouseID\"]) {\n  productID: ID!\n  warehouseID: ID!\n  inventoryAmount: Int!\n}\n\ntype Product @model {\n  id: ID!\n  name: String!\n  orders: [Order] @connection(keyName: \"byProduct\", fields: [\"id\"])\n  inventories: [Inventory] @connection(fields: [\"id\"])\n}\n```\n\nNow that we have the schema created, let's create the items in the database that we will be operating against:\n\n```graphql\n# first\nmutation createWarehouse {\n  createWarehouse(input: {id: \"1\"}) {\n    id\n  }\n}\n\n# second\nmutation createEmployee {\n  createEmployee(input: {\n    id: \"amanda\"\n    name: \"Amanda\",\n    startDate: \"2018-05-22\",\n    phoneNumber: \"6015555555\",\n    warehouseID: \"1\",\n    jobTitle: \"Manager\",\n    newHire: \"true\"}\n  ) {\n    id\n    jobTitle\n    name\n    newHire\n    phoneNumber\n    startDate\n    warehouseID\n  }\n}\n\n# third\nmutation createAccountRepresentative {\n  createAccountRepresentative(input: {\n    id: \"dabit\"\n    orderTotal: 400000\n    salesPeriod: \"January 2019\"\n  }) {\n    id\n    orderTotal\n    salesPeriod\n  }\n}\n\n# fourth\nmutation createCustomer {\n  createCustomer(input: {\n    id: \"jennifer_thomas\"\n    accountRepresentativeID: \"dabit\"\n    name: \"Jennifer Thomas\"\n    phoneNumber: \"+16015555555\"\n  }) {\n    id\n    name\n    accountRepresentativeID\n    phoneNumber\n  }\n}\n\n# fifth\nmutation createProduct {\n  createProduct(input: {\n    id: \"yeezyboost\"\n    name: \"Yeezy Boost\"\n  }) {\n    id\n    name\n  }\n}\n\n# sixth\nmutation createInventory {\n  createInventory(input: {\n    productID: \"yeezyboost\"\n    warehouseID: \"1\"\n    inventoryAmount: 300\n  }) {\n    productID\n    inventoryAmount\n    warehouseID\n  }\n}\n\n# seventh\nmutation createOrder {\n  createOrder(input: {\n    amount: 300\n    date: \"2018-07-12\"\n    status: \"pending\"\n    accountRepresentativeID: \"dabit\"\n    customerID: \"jennifer_thomas\"\n    productID: \"yeezyboost\"\n  }) {\n    id\n    customerID\n    accountRepresentativeID\n    amount\n    date\n    customerID\n    productID\n  }\n}\n```\n\n## 1. Look up employee details by employee ID\n\nThis can simply be done by querying the employee model with an employee ID, no `@key` or `@connection` is needed to make this work.\n\n```graphql\nquery getEmployee($id: ID!) {\n  getEmployee(id: $id) {\n    id\n    name\n    phoneNumber\n    startDate\n    jobTitle\n  }\n}\n```\n\n## 2. Query employee details by employee name\n\nThe `@key` `byName` on the `Employee` type makes this access-pattern feasible because under the covers an index is created and a query is used to match against the name field. We can use this query:\n\n```graphql\nquery employeeByName($name: String!) {\n  employeeByName(name: $name) {\n    items {\n      id\n      name\n      phoneNumber\n      startDate\n      jobTitle\n    }\n  }\n}\n```\n\n## 3. Find an Employee’s phone number\n\nEither one of the previous queries would work to find an employee’s phone number as long as one has their ID or name.\n\n## 4. Find a customer’s phone number\n\nA similar query to those given above but on the Customer model would give you a customer’s phone number.\n\n```graphql\nquery getCustomer($customerID: ID!) {\n  getCustomer(id: $customerID) {\n    phoneNumber\n  }\n}\n```\n\n## 5. Get orders for a given customer within a given date range\n\nThere is a one-to-many relation that lets all the orders of a customer be queried.\n\nThis relationship is created by having the `@key` name `byCustomerByDate` on the Order model that is queried by the connection on the orders field of the Customer model.\n\nA sort key with the date is used. What this means is that the GraphQL resolver can use predicates like `Between` to efficiently search the date range rather than scanning all records in the database and then filtering them out.\n\nThe query one would need to get the orders to a customer within a date range would be:\n\n```graphql\nquery getCustomerWithOrdersByDate($customerID: ID!) {\n  getCustomer(id: $customerID) {\n    ordersByDate(date: {\n      between: [ \"2018-01-22\", \"2020-10-11\" ]\n    }) {\n      items {\n        id\n        amount\n        productID\n      }\n    }\n  }\n}\n```\n\n## 6. Show all open orders within a given date range across all customers\n\nThe `@key` `byCustomerByStatusByDate` enables you to run a query that would work for this access pattern.\n\nIn this example, a composite sort key (combination of two or more keys) with the `status` and `date` is used. What this means is that the unique identifier of a record in the database is created by concatenating these two fields (status and date) together, and then the GraphQL resolver can use predicates like `Between` or `Contains` to efficiently search the unique identifier for matches rather than scanning all records in the database and then filtering them out.\n\n```graphql\nquery getCustomerWithOrdersByStatusDate($customerID: ID!) {\n  getCustomer(id: $customerID) {\n    ordersByStatusDate (statusDate: {\n      between: [\n        { status: \"pending\" date:  \"2018-01-22\" },\n        { status: \"pending\", date: \"2020-10-11\"}\n      ]}) {\n        items {\n            id\n            amount\n            date\n        }\n    }\n  }\n}\n```\n\n## 7. See all employees hired recently\n\nHaving `@key(name: \"newHire\", fields: [\"newHire\", \"id\"])` on the `Employee` model allows one to query by whether an employee has been hired recently.\n\n```graphql\nquery employeesNewHire {\n  employeesNewHire(newHire: \"true\") {\n    items {\n      id\n      name\n      phoneNumber\n      startDate\n      jobTitle\n    }\n  }\n}\n```\n\nWe can also query and have the results returned by start date by using the `employeesNewHireByStartDate` query:\n\n```graphql\nquery employeesNewHireByDate {\n  employeesNewHireByStartDate(newHire: \"true\") {\n    items {\n      id\n      name\n      phoneNumber\n      startDate\n      jobTitle\n    }\n  }\n}\n```\n\n## 8. Find all employees working in a given warehouse\n\nThis needs a one to many relationship from warehouses to employees. As can be seen from the @connection in the `Warehouse` model, this connection uses the `byWarehouse` key on the `Employee` model. The relevant query would look like this:\n\n```graphql\nquery getWarehouse($warehouseID: ID!) {\n  getWarehouse(id: $warehouseID) {\n    id\n    employees{\n      items {\n        id\n        name\n        startDate\n        phoneNumber\n        jobTitle\n      }\n    }\n  }\n}\n```\n\n## 9. Get all items on order for a given product\n\nThis access-pattern would use a one-to-many relation from products to orders. With this query we can get all orders of a given product:\n\n```graphql\nquery getProductOrders($productID: ID!) {\n  getProduct(id: $productID) {\n    id\n    orders {\n      items {\n        id\n        status\n        amount\n        date\n      }\n    }\n  }\n}\n```\n\n## 10. Get current inventories for a product at all warehouses\n\nThe query needed to get the inventories of a product in all warehouses would be:\n\n```graphql\nquery getProductInventoryInfo($productID: ID!) {\n  getProduct(id: $productID) {\n    id\n    inventories {\n      items {\n        warehouseID\n        inventoryAmount\n      }\n    }\n  }\n}\n```\n\n## 11. Get customers by account representative\n\nThis uses a one-to-many connection between account representatives and customers:\n\nThe query needed would look like this:\n\n```graphql\nquery getCustomersForAccountRepresentative($representativeId: ID!) {\n  getAccountRepresentative(id: $representativeId) {\n    customers {\n      items {\n        id\n        name\n        phoneNumber\n      }\n    }\n  }\n}\n```\n\n## 12. Get orders by account representative and date\n\nAs can be seen in the AccountRepresentative model this connection uses the `byRepresentativebyDate` field on the `Order` model to create the connection needed. The query needed would look like this:\n\n```graphql\nquery getOrdersForAccountRepresentative($representativeId: ID!) {\n  getAccountRepresentative(id: $representativeId) {\n    id\n    orders(date: {\n      between: [\n         \"2010-01-22\", \"2020-10-11\"\n      ]\n    }) {\n        items {\n          id\n          status\n          amount\n          date\n        }\n    }\n  }\n}\n```\n\n## 13. Get all items on order for a given product\n\nThis is the same as number 9.\n\n## 14. Get all employees with a given job title\n\nUsing the `byTitle` `@key` makes this access pattern quite easy.\n\n```graphql\nquery employeesByJobTitle {\n  employeesByJobTitle(jobTitle: \"Manager\") {\n    items {\n      id\n      name\n      phoneNumber\n      jobTitle\n    }\n  }\n}\n```\n\n## 15. Get inventory by product by warehouse\n\nHere having the inventories be held in a separate model is particularly useful since this model can have its own partition key and sort key such that the inventories themselves can be queried as is needed for this access-pattern.\n\nA query on this model would look like this:\n\n```graphql\nquery inventoryByProductAndWarehouse($productID: ID!, $warehouseID: ID!) {\n  getInventory(productID: $productID, warehouseID: $warehouseID) {\n    productID\n    warehouseID\n    inventoryAmount\n  }\n}\n\n```\n\nWe can also get all inventory from an individual warehouse by using the `itemsByWarehouseID` query created by the `byWarehouseID` key:\n\n```graphql\nquery byWarehouseId($warehouseID: ID!) {\n  itemsByWarehouseID(warehouseID: $warehouseID) {\n    items {\n      inventoryAmount\n      productID\n    }\n  }\n}\n```\n\n## 16. Get total product inventory\n\nHow this would be done depends on the use case. If one just wants a list of all inventories in all warehouses, one could just run a list inventories on the Inventory model:\n\n```graphql\nquery listInventorys {\n  listInventorys {\n    items {\n      productID\n      warehouseID\n      inventoryAmount\n    }\n  }\n}\n```\n\n## 17. Get sales representatives ranked by order total and sales period\n\nThe sales period is either a date range or maybe even a month or week. Therefore we can set the sales period as a string and query using the combination of `salesPeriod` and `orderTotal`. We can also set the `sortDirection` in order to get the return values from largest to smallest:\n\n```graphql\nquery repsByPeriodAndTotal {\n  repsByPeriodAndTotal(\n    sortDirection: DESC,\n    salesPeriod: \"January 2019\",\n    orderTotal: {\n      ge: 1000\n    }) {\n    items {\n      id\n      orderTotal\n    }\n  }\n}\n```\n",
    "meta": {
      "title": "Data access patterns",
      "description": "Learn how to support these 17 common database access patterns using GraphQL, AWS Amplify, and the GraphQL Transform library",
      "subcategory": "API (GraphQL)",
      "category": "Amplify CLI (Legacy)"
    },
    "filename": "/cli-legacy/graphql-transformer/dataaccess"
  },
  {
    "searchableText": [
      {
        "heading": "@versioned",
        "depth": 2,
        "text": "The @versioned directive adds object versioning and conflict resolution to a type. Do not use this directive when leveraging DataStore as the conflict detection and resolution features are automatically handled inside AppSync and are incompatible with the @versioned directive."
      },
      {
        "heading": "@versioned",
        "depth": 2,
        "text": "Note that @versioned is only supported in client code (statement and types) generated via AppSync codegen.\n@versioned is not supported by models generated via amplify codegen models.\nUse Amplify DataStore instead of @versioned to provide offline app data access with built-in conflict-resolution."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Add @versioned to a type that is also annotate with @model to enable object versioning and conflict detection for a type."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Creating a Post automatically sets the version to 1"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Updating a Post requires passing the \"expectedVersion\" which is the object's last saved version"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Note: When updating an object, the version number will automatically increment."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Deleting a Post requires passing the \"expectedVersion\" which is the object's last saved version"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Update and delete operations will fail if the expectedVersion does not match the version\nstored in DynamoDB. You may change the default name of the version field on the type as well as the name\nof the input field via the versionField and versionInput arguments on the @versioned directive."
      },
      {
        "heading": "Generates",
        "depth": 3,
        "text": "The @versioned directive manipulates resolver mapping templates and will store a version field in versioned objects."
      }
    ],
    "source": "export const meta = {\n  title: `Versioning and conflict resolution`,\n  description: `The @versioned directive adds object versioning and conflict resolution to a type.`,\n};\n\n## @versioned\n\nThe `@versioned` directive adds object versioning and conflict resolution to a type. Do not use this directive when leveraging DataStore as the conflict detection and resolution features are automatically handled inside AppSync and are incompatible with the `@versioned` directive.\n\n<Callout>\n\nNote that **@versioned** is only supported in client code (statement and types) generated via AppSync [codegen](/cli/graphql-transformer/codegen).\n**@versioned** is not supported by models generated via `amplify codegen models`.\nUse [Amplify DataStore](/lib/datastore/getting-started) instead of **@versioned** to provide offline app data access with built-in conflict-resolution.\n\n</Callout>\n\n### Definition\n\n```graphql\ndirective @versioned(versionField: String = \"version\", versionInput: String = \"expectedVersion\") on OBJECT\n```\n\n### Usage\n\nAdd `@versioned` to a type that is also annotate with `@model` to enable object versioning and conflict detection for a type.\n\n```graphql\ntype Post @model @versioned {\n  id: ID!\n  title: String!\n  version: Int!   # <- If not provided, it is added for you.\n}\n```\n\n**Creating a Post automatically sets the version to 1**\n\n```graphql\nmutation Create {\n  createPost(input:{\n    title:\"Conflict detection in the cloud!\"\n  }) {\n    id\n    title\n    version  # will be 1\n  }\n}\n```\n\n**Updating a Post requires passing the \"expectedVersion\" which is the object's last saved version**\n\n> Note: When updating an object, the version number will automatically increment.\n\n```graphql\nmutation Update($postId: ID!) {\n  updatePost(\n    input:{\n      id: $postId,\n      title: \"Conflict detection in the cloud is great!\",\n      expectedVersion: 1\n    }\n  ) {\n    id\n    title\n    version # will be 2\n  }\n}\n```\n\n**Deleting a Post requires passing the \"expectedVersion\" which is the object's last saved version**\n\n```graphql\nmutation Delete($postId: ID!) {\n  deletePost(\n    input: {\n      id: $postId,\n      expectedVersion: 2\n    }\n  ) {\n    id\n    title\n    version\n  }\n}\n```\n\nUpdate and delete operations will fail if the **expectedVersion** does not match the version\nstored in DynamoDB. You may change the default name of the version field on the type as well as the name\nof the input field via the **versionField** and **versionInput** arguments on the `@versioned` directive.\n\n### Generates\n\nThe `@versioned` directive manipulates resolver mapping templates and will store a `version` field in versioned objects.\n",
    "meta": {
      "title": "Versioning and conflict resolution",
      "description": "The @versioned directive adds object versioning and conflict resolution to a type.",
      "subcategory": "API (GraphQL)",
      "category": "Amplify CLI (Legacy)"
    },
    "filename": "/cli-legacy/graphql-transformer/versioned"
  },
  {
    "searchableText": [
      {
        "heading": "@searchable",
        "depth": 2,
        "text": "The @searchable directive handles streaming the data of an @model object type to the Amazon OpenSearch Service and configures search resolvers that search that information."
      },
      {
        "heading": "@searchable",
        "depth": 2,
        "text": "Migration warning: You might observe duplicate records on search operations, if you deployed your GraphQL schema using CLI version older than 4.14.1 and have thereafter updated your schema & deployed the changes with a CLI version between 4.14.1 - 4.16.1.\nPlease use this Python script to remove the duplicate records from your OpenSearch cluster. This script indexes data from your DynamoDB Table to your OpenSearch Cluster. View an example of how to call the script with the following parameters here."
      },
      {
        "heading": "@searchable",
        "depth": 2,
        "text": "Billing warning: @searchable incurs an additional cost depending on instance size. For more information refer to the Amazon OpenSearch service pricing."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Given the following schema an index is created for Post, if there are more types with @searchable the directive will create an index for it, and those posts in Amazon DynamoDB are automatically streamed to the post index in Amazon OpenSearch via AWS Lambda and connect a searchQueryField resolver."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "You may then create objects in DynamoDB that will be automatically streamed to lambda\nusing the normal createPost mutation."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "And then search for posts using a match query:"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "There are multiple SearchableTypes generated in the schema, based on the datatype of the fields you specify in the Post type."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "The filter parameter in the search query has a searchable type field that corresponds to the field listed in the Post type. For example, the title field of the filter object, has the following properties (containing the operators that are applicable to the string type):"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "eq - which uses the OpenSearch keyword type to match for the exact term."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "ne - this is the inverse operation of eq."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "matchPhrase - searches using OpenSearch's Match Phrase Query to filter the documents in the search query."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "matchPhrasePrefix - This uses OpenSearch's Match Phrase Prefix Query to filter the documents in the search query."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "multiMatch - Corresponds to the OpenSearch Multi Match Query."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "exists - Corresponds to the OpenSearch Exists Query."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "wildcard - Corresponds to the OpenSearch Wildcard Query."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "regexp - Corresponds to the OpenSearch Regexp Query."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "The sort parameter can be used to specify the order of the search results, can be ascending (asc) or descending (desc), if not specified ascending order is used."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "The limit parameter controls the number of search results returned. If not specified the default value is 100."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "For example, you can filter using the wildcard expression to search for posts using the following wildcard query:"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "The above query returns all documents whose title begins with S and ends with OpenSearch!."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Moreover you can use the filter parameter to pass a nested and/or/not condition. By default, every operation in the filter properties is AND ed. You can use the or or not properties in the filter parameter of the search query to override this behavior. Each of these operators (and, or, not properties in the filter object) accepts an array of searchable types which are in turn joined by the corresponding operator. For example, consider the following search query:"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Assuming you used the createPost mutation to create new posts with title, createdAt and updatedAt values, the above search query will return you a list of all Posts, whose title starts with S and have createdAt or updatedAt value as 08/20/2018."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Here is a complete list of searchable operations per GraphQL type supported as of today:"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "| GraphQL Type        | Searchable Operation           |\n|-------------:|:-------------|\n| String      | ne, eq, match, matchPhrase, matchPhrasePrefix, multiMatch, exists, wildcard, regexp |\n| Int     | ne, gt, lt, gte, lte, eq, range      |\n| Float | ne, gt, lt, gte, lte, eq, range      |\n| Boolean | eq, ne      |"
      },
      {
        "heading": "Known limitations",
        "depth": 3,
        "text": "@searchable is not compatible with DataStore but you can use it with the API category."
      },
      {
        "heading": "Known limitations",
        "depth": 3,
        "text": "@searchable is not compatible with Amazon ElasticSearch t2.micro instance as it only works with ElasticSearch version 1.5 and 2.3 and Amplify CLI only supports instances with ElasticSearch version >= 6.x."
      },
      {
        "heading": "Known limitations",
        "depth": 3,
        "text": "@searchable is not compatible with the @connection directive"
      },
      {
        "heading": "Known limitations",
        "depth": 3,
        "text": "Support for adding the @searchable directive does not yet provide automatic indexing for any existing data to OpenSearch. View the feature request here."
      },
      {
        "heading": "Known limitations",
        "depth": 3,
        "text": "t2.small OpenSearch instance type is not recommended to be used in a production environment."
      },
      {
        "heading": "Configure environment OpenSearch instance type",
        "depth": 3,
        "text": "By default Amplify CLI will configure a t2.small instance type. This is great for getting started and prototyping BUT not recommended to be used in the production environment per the OpenSearch best practices.\nYou can configure the OpenSearch instance type per environment as follows:"
      },
      {
        "heading": "Configure environment OpenSearch instance type",
        "depth": 3,
        "text": "Run amplify env add to create a new environment (e.g. \"prod\")"
      },
      {
        "heading": "Configure environment OpenSearch instance type",
        "depth": 3,
        "text": "Edit the amplify/team-provider-info.json file and set ElasticSearchInstanceType to the instance type that works for your application"
      },
      {
        "heading": "Configure environment OpenSearch instance type",
        "depth": 3,
        "text": "Deploy your changes with amplify push"
      },
      {
        "heading": "Configure environment OpenSearch instance type",
        "depth": 3,
        "text": "Learn more about Amazon OpenSearch Service instance types here."
      },
      {
        "heading": "Backfill your OpenSearch index from your DynamoDB table",
        "depth": 3,
        "text": "The following Python script creates an event stream of your DynamoDB records and sends them to your OpenSearch Index. This will help you backfill your data should you choose to add @searchable to your @model types at a later time."
      },
      {
        "heading": "Backfill your OpenSearch index from your DynamoDB table",
        "depth": 3,
        "text": "Example of calling the script:"
      }
    ],
    "source": "export const meta = {\n  title: `Make your data searchable`,\n  description: `The @searchable directive handles streaming the data of an @model object type to the Amazon OpenSearch Service and configures search resolvers that search that information.`,\n};\n\n<MigrationAlert isLegacy url={\"/cli/graphql/search-and-result-aggregations\"}/>\n\n## @searchable\n\nThe `@searchable` directive handles streaming the data of an `@model` object type to the Amazon OpenSearch Service and configures search resolvers that search that information.\n\n> **Migration warning**: You might observe duplicate records on search operations, if you deployed your GraphQL schema using CLI version older than 4.14.1 and have thereafter updated your schema & deployed the changes with a CLI version between 4.14.1 - 4.16.1.\nPlease use this Python [script](https://github.com/aws-amplify/amplify-category-api/blob/main/packages/graphql-elasticsearch-transformer/scripts/ddb_to_es.py) to remove the duplicate records from your OpenSearch cluster. [This script](https://github.com/aws-amplify/amplify-category-api/blob/master/packages/graphql-elasticsearch-transformer/scripts/ddb_to_es.py) indexes data from your DynamoDB Table to your OpenSearch Cluster. View an example of how to call the script with the following parameters [here](https://aws-amplify.github.io/docs/cli-toolchain/graphql#example-of-calling-the-script).\n\n> **Billing warning**: `@searchable` incurs an additional cost depending on instance size. For more information refer to the [Amazon OpenSearch service pricing](https://aws.amazon.com/elasticsearch-service/pricing/).\n\n### Definition\n\n```graphql\n# Streams data from DynamoDB to OpenSearch and exposes search capabilities.\ndirective @searchable(queries: SearchableQueryMap) on OBJECT\ninput SearchableQueryMap { search: String }\n```\n\n### Usage\n\nGiven the following schema an index is created for Post, if there are more types with `@searchable` the directive will create an index for it, and those posts in Amazon DynamoDB are automatically streamed to the post index in Amazon OpenSearch via AWS Lambda and connect a searchQueryField resolver.\n\n```graphql\ntype Post @model @searchable {\n  id: ID!\n  title: String!\n  createdAt: String!\n  updatedAt: String!\n  upvotes: Int\n}\n```\n\nYou may then create objects in DynamoDB that will be automatically streamed to lambda\nusing the normal `createPost` mutation.\n\n```graphql\nmutation CreatePost {\n  createPost(input: { title: \"Stream me to OpenSearch!\" }) {\n    id\n    title\n    createdAt\n    updatedAt\n    upvotes\n  }\n}\n```\n\nAnd then search for posts using a `match` query:\n\n```graphql\nquery SearchPosts {\n  searchPosts(filter: { title: { match: \"Stream\" }}) {\n    items {\n      id\n      title\n    }\n  }\n}\n```\n\nThere are multiple `SearchableTypes` generated in the schema, based on the datatype of the fields you specify in the Post type.\n\nThe `filter` parameter in the search query has a searchable type field that corresponds to the field listed in the Post type. For example, the `title` field of the `filter` object, has the following properties (containing the operators that are applicable to the `string` type):\n\n- `eq` - which uses the OpenSearch keyword type to match for the exact term.\n- `ne` - this is the inverse operation of `eq`.\n- `matchPhrase` - searches using OpenSearch's [Match Phrase Query](https://opensearch.org/docs/opensearch/query-dsl/full-text/#match-phrase) to filter the documents in the search query.\n- `matchPhrasePrefix` - This uses OpenSearch's [Match Phrase Prefix Query](https://opensearch.org/docs/opensearch/query-dsl/full-text/#match-phrase-prefix) to filter the documents in the search query.\n- `multiMatch` - Corresponds to the OpenSearch [Multi Match Query](https://opensearch.org/docs/opensearch/query-dsl/full-text/#multi-match).\n- `exists` - Corresponds to the OpenSearch [Exists Query](https://opensearch.org/docs/opensearch/query-dsl/term/#exists).\n- `wildcard` - Corresponds to the OpenSearch [Wildcard Query](https://opensearch.org/docs/opensearch/query-dsl/term/#wildcards).\n- `regexp` - Corresponds to the OpenSearch [Regexp Query](https://opensearch.org/docs/opensearch/query-dsl/term/#regex).\n\nThe `sort` parameter can be used to specify the order of the search results, can be ascending (`asc`) or descending (`desc`), if not specified ascending order is used.\n\nThe `limit` parameter controls the number of search results returned. If not specified the default value is 100.\n\nFor example, you can filter using the wildcard expression to search for posts using the following `wildcard` query:\n\n```graphql\nquery SearchPosts {\n  searchPost(filter: { title: { wildcard: \"S*OpenSearch!\" }}) {\n    items {\n      id\n      title\n    }\n  }\n}\n```\n\nThe above query returns all documents whose `title` begins with `S` and ends with `OpenSearch!`.\n\nMoreover you can use the `filter` parameter to pass a nested `and`/`or`/`not` condition. By default, every operation in the filter properties is *AND* ed. You can use the `or` or `not` properties in the `filter` parameter of the search query to override this behavior. Each of these operators (`and`, `or`, `not` properties in the filter object) accepts an array of searchable types which are in turn joined by the corresponding operator. For example, consider the following search query:\n\n```graphql\nquery SearchPosts {\n  searchPost(filter: {\n    title: { wildcard: \"S*\" }\n    or: [\n      { createdAt: { eq: \"08/20/2018\" } },\n      { updatedAt: { eq: \"08/20/2018\" } }\n    ]\n  }) {\n    items {\n      id\n      title\n    }\n  }\n}\n```\n\nAssuming you used the `createPost` mutation to create new posts with `title`, `createdAt` and `updatedAt` values, the above search query will return you a list of all `Posts`, whose `title` starts with `S` _and_ have `createdAt` _or_ `updatedAt` value as `08/20/2018`.\n\nHere is a complete list of searchable operations per GraphQL type supported as of today:\n\n| GraphQL Type        | Searchable Operation           |\n|-------------:|:-------------|\n| String      | `ne`, `eq`, `match`, `matchPhrase`, `matchPhrasePrefix`, `multiMatch`, `exists`, `wildcard`, `regexp` |\n| Int     | `ne`, `gt`, `lt`, `gte`, `lte`, `eq`, `range`      |\n| Float | `ne`, `gt`, `lt`, `gte`, `lte`, `eq`, `range`      |\n| Boolean | `eq`, `ne`      |\n\n### Known limitations\n\n- `@searchable` is not compatible with DataStore but you can use it with the API category.\n- `@searchable` is not compatible with Amazon ElasticSearch t2.micro instance as it only works with ElasticSearch version 1.5 and 2.3 and Amplify CLI only supports instances with ElasticSearch version >= 6.x.\n- `@searchable` is not compatible with the @connection directive\n- Support for adding the `@searchable` directive does not yet provide automatic indexing for any existing data to OpenSearch. View the feature request [here](https://github.com/aws-amplify/amplify-cli/issues/98).\n- `t2.small` OpenSearch instance type is not recommended to be used in a production environment.\n\n### Configure environment OpenSearch instance type\n\nBy default Amplify CLI will configure a `t2.small` instance type. This is great for getting started and prototyping BUT not recommended to be used in the production environment per the OpenSearch [best practices](https://docs.aws.amazon.com/opensearch-service/latest/developerguide/bp.html).\nYou can configure the OpenSearch instance type per environment as follows:\n\n1. Run `amplify env add` to create a new environment (e.g. \"prod\")\n2. Edit the `amplify/team-provider-info.json` file and set `ElasticSearchInstanceType` to the instance type that works for your application\n```json\n  {\n    \"dev\": {\n      \"categories\": {\n        \"api\": {\n          \"<your-api-name>\" : {\n            \"ElasticSearchInstanceType\": \"t2.small.elasticsearch\"\n          }\n        }\n      }\n    },\n    \"prod\": {\n      \"categories\": {\n        \"api\": {\n          \"<your-api-name>\" : {\n            \"ElasticSearchInstanceType\": \"t2.medium.elasticsearch\"\n          }\n        }\n      }\n    }\n  }\n```\n3. Deploy your changes with `amplify push`\n\nLearn more about Amazon OpenSearch Service instance types [here](https://docs.aws.amazon.com/opensearch-service/latest/developerguide/supported-instance-types.html).\n\n### Backfill your OpenSearch index from your DynamoDB table\n\nThe following Python [script](https://github.com/aws-amplify/amplify-category-api/blob/main/packages/graphql-elasticsearch-transformer/scripts/ddb_to_es.py) creates an event stream of your DynamoDB records and sends them to your OpenSearch Index. This will help you backfill your data should you choose to add `@searchable` to your @model types at a later time.\n\n**Example of calling the script**:\n\n```bash\npython3 ddb_to_es.py \\\n  --rn 'us-west-2' \\ # Use the region in which your table and OpenSearch domain reside\n  --tn 'Post-XXXX-dev' \\ # Table name\n  --lf 'arn:aws:lambda:us-west-2:123456789xxx:function:DdbToEsFn-<api__id>-dev' \\ # Lambda function ARN, find the DdbToEsFn in your Lambda functions list, copy entire ARN\n  --esarn 'arn:aws:dynamodb:us-west-2:123456789xxx:table/Post-<api__id>-dev/stream/2019-20-03T00:00:00.350' # Event source ARN, copy the full DynamoDB table ARN\n```\n",
    "meta": {
      "title": "Make your data searchable",
      "description": "The @searchable directive handles streaming the data of an @model object type to the Amazon OpenSearch Service and configures search resolvers that search that information.",
      "subcategory": "API (GraphQL)",
      "category": "Amplify CLI (Legacy)"
    },
    "filename": "/cli-legacy/graphql-transformer/searchable"
  },
  {
    "searchableText": [
      {
        "heading": "@predictions",
        "depth": 2,
        "text": "The @predictions directive allows you to query an orchestration of AI/ML services such as Amazon Rekognition, Amazon Translate, and/or Amazon Polly."
      },
      {
        "heading": "@predictions",
        "depth": 2,
        "text": "Note: Support for adding the @predictions directive uses the s3 storage bucket which is configured via the CLI. At the moment this directive works only with objects located within public/."
      },
      {
        "heading": "Definition",
        "depth": 3,
        "text": "The supported actions in this directive are included in the definition."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Given the following schema a query operation is defined which will do the following with the provided image."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Identify text from the image"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Translate the text from that image"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Synthesize speech from the translated text."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "An example of that query will look like:"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "A code example of this using the JS Library:"
      },
      {
        "heading": "How it works",
        "depth": 3,
        "text": "From example schema above, @predictions will create resources to communicate with Amazon Rekognition, Translate and Polly.\nFor each action the following is created:"
      },
      {
        "heading": "How it works",
        "depth": 3,
        "text": "IAM Policy for each service (e.g. Amazon Rekognition detectText Policy)"
      },
      {
        "heading": "How it works",
        "depth": 3,
        "text": "An AppSync VTL function"
      },
      {
        "heading": "How it works",
        "depth": 3,
        "text": "An AppSync DataSource"
      },
      {
        "heading": "How it works",
        "depth": 3,
        "text": "Finally a resolver is created for speakTranslatedImageText which is a pipeline resolver composed of AppSync functions which are defined by the action list provided in the directive."
      },
      {
        "heading": "Actions",
        "depth": 3,
        "text": "Each of the actions described in the @predictions definition section can be used individually, as well as in a sequence. Sequence of actions supported today are as follows:"
      },
      {
        "heading": "Actions",
        "depth": 3,
        "text": "identifyText -> translateText -> convertTextToSpeech"
      },
      {
        "heading": "Actions",
        "depth": 3,
        "text": "identifyLabels -> translateText -> convertTextToSpeech"
      },
      {
        "heading": "Actions",
        "depth": 3,
        "text": "translateText -> convertTextToSpeech"
      },
      {
        "heading": "Action resources",
        "depth": 3,
        "text": "translateText Supported Language Codes"
      },
      {
        "heading": "Action resources",
        "depth": 3,
        "text": "convertTextToSpeech Supported Voice IDs"
      }
    ],
    "source": "export const meta = {\n  title: `Connect machine learning services`,\n  description: `The @predictions directive allows you to query an orchestration of AI/ML services such as Amazon Rekognition, Amazon Translate, and/or Amazon Polly.`,\n};\n\n<MigrationAlert isLegacy url={\"/cli/graphql/connect-to-machine-learning-services\"}/>\n\n## @predictions\n\nThe `@predictions` directive allows you to query an orchestration of AI/ML services such as Amazon Rekognition, Amazon Translate, and/or Amazon Polly.\n\n> Note: Support for adding the `@predictions` directive uses the s3 storage bucket which is configured via the CLI. At the moment this directive works only with objects located within `public/`.\n\n### Definition\n\nThe supported actions in this directive are included in the definition.\n\n```graphql\ndirective @predictions(actions: [PredictionsActions!]!) on FIELD_DEFINITION\nenum PredictionsActions {\n  identifyText # uses Amazon Rekognition to detect text\n  identifyLabels # uses Amazon Rekognition to detect labels\n  convertTextToSpeech # uses Amazon Polly in a lambda to output a presigned url to synthesized speech\n  translateText # uses Amazon Translate to translate text from source to target language\n}\n```\n\n### Usage\n\nGiven the following schema a query operation is defined which will do the following with the provided image.\n\n- Identify text from the image\n- Translate the text from that image\n- Synthesize speech from the translated text.\n\n```graphql\ntype Query {\n  speakTranslatedImageText: String @predictions(actions: [\n    identifyText\n    translateText\n    convertTextToSpeech\n  ])\n}\n```\n\nAn example of that query will look like:\n\n```graphql\nquery SpeakTranslatedImageText($input: SpeakTranslatedImageTextInput!) {\n  speakTranslatedImageText(input: {\n    identifyText: {\n      key: \"myimage.jpg\"\n    }\n    translateText: {\n      sourceLanguage: \"en\"\n      targetLanguage: \"es\"\n    }\n    convertTextToSpeech: {\n      voiceID: \"Conchita\"\n    }\n  })\n}\n```\n\nA code example of this using the JS Library:\n\n```js\nimport React, { useState } from 'react';\nimport { Amplify, Storage, API, graphqlOperation } from 'aws-amplify';\nimport awsconfig from './aws-exports';\nimport { speakTranslatedImageText } from './graphql/queries';\n\n/* Configure Exports */\nAmplify.configure(awsconfig);\n\nfunction SpeakTranslatedImage() {\n  const [ src, setSrc ] = useState(\"\");\n  const [ img, setImg ] = useState(\"\");\n\n  function putS3Image(event) {\n    const file = event.target.files[0];\n    Storage.put(file.name, file)\n    .then (async (result) => {\n      setSrc(await speakTranslatedImageTextOP(result.key))\n      setImg(await Storage.get(result.key));\n    })\n    .catch(err => console.log(err));\n  }\n\n  return (\n    <div className=\"Text\">\n      <div>\n        <h3>Upload Image</h3>\n        <input\n              type = \"file\" accept='image/jpeg'\n              onChange = {(event) => {\n                putS3Image(event)\n              }}\n          />\n        <br />\n        { img && <img src = {img}></img>}\n        { src &&\n          <div> <audio id=\"audioPlayback\" controls>\n              <source id=\"audioSource\" type=\"audio/mp3\" src = {src}/>\n          </audio> </div>\n        }\n      </div>\n    </div>\n  );\n}\n\nasync function speakTranslatedImageTextOP(key) {\n  const inputObj = {\n    translateText: {\n      sourceLanguage: \"en\", targetLanguage: \"es\" },\n    identifyText: { key },\n    convertTextToSpeech: { voiceID: \"Conchita\" }\n  };\n  const response = await API.graphql(\n    graphqlOperation(speakTranslatedImageText, { input: inputObj }));\n  return response.data.speakTranslatedImageText;\n}\nfunction App() {\n  return (\n    <div className=\"App\">\n        <h1>Speak Translated Image</h1>\n        < SpeakTranslatedImage />\n    </div>\n  );\n}\nexport default App;\n```\n\n### How it works\n\nFrom example schema above, `@predictions` will create resources to communicate with Amazon Rekognition, Translate and Polly.\nFor each action the following is created:\n\n- IAM Policy for each service (e.g. Amazon Rekognition `detectText` Policy)\n- An AppSync VTL function\n- An AppSync DataSource\n\nFinally a resolver is created for `speakTranslatedImageText` which is a pipeline resolver composed of AppSync functions which are defined by the action list provided in the directive.\n\n### Actions\n\nEach of the actions described in the @predictions definition section can be used individually, as well as in a sequence. Sequence of actions supported today are as follows:\n\n- `identifyText -> translateText -> convertTextToSpeech`\n- `identifyLabels -> translateText -> convertTextToSpeech`\n- `translateText -> convertTextToSpeech`\n\n### Action resources\n\n- [`translateText` Supported Language Codes](https://docs.aws.amazon.com/translate/latest/dg/what-is.html#what-is-languages)\n- [`convertTextToSpeech` Supported Voice IDs](https://docs.aws.amazon.com/polly/latest/dg/voicelist.html)\n",
    "meta": {
      "title": "Connect machine learning services",
      "description": "The @predictions directive allows you to query an orchestration of AI/ML services such as Amazon Rekognition, Amazon Translate, and/or Amazon Polly.",
      "subcategory": "API (GraphQL)",
      "category": "Amplify CLI (Legacy)"
    },
    "filename": "/cli-legacy/graphql-transformer/predictions"
  },
  {
    "searchableText": [
      {
        "heading": "@http",
        "depth": 2,
        "text": "The @http directive allows you to quickly configure HTTP resolvers within your AWS AppSync API."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "The @http directive allows you to quickly connect HTTP or HTTPS endpoint to an AppSync API by creating an AWS AppSync HTTP resolver. To connect to an endpoint, add the @http directive to a field in your schema.graphql file. The directive allows you to define URL path parameters, and specify a query string and/or specify a request body. For example, given the definition of a post type,"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Amplify generates the definition below that sends a request to the url when the listPosts query is used."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Request Headers"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "The @http directive generates resolvers that can handle xml and json responses. If an HTTP method is not defined, GET is used by default. You can specify a list of static headers to be passed with the HTTP requests to your backend in your directive definition."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Path Parameters"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "You can create dynamic paths by specifying parameters in the directive URL by using the special :<parameter> notation. Your set of parameters can then be specified in the params input object of the query. Note that path parameters are not added to the request body or query string. You can define multiple parameters."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Given the definition"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Amplify generates"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "You can fetch a specific post by enclosing the id in the params input object."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "which will send"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Query String"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "You can send a query string with your request by specifying variables for your query. The query string is supported with all request methods."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Given the definition"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Amplify generates"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "You can query for posts using the query input object"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "which sends the following request:"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Request Body"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "The @http directive also allows you to specify the body of a request, which is used for POST, PUT, and PATCH requests. To create a new post, you can define the following."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Amplify generates the addPost query field with the query and body input objects since this type of request also supports a query string. The generated resolver verifies that non-null arguments (e.g.: the title and description) are passed in at least one of the input objects; if not, an error is returned."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "You can add a post by using the body input object:"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "which will send"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Specifying the environment"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "The @http directive allows you to use ${env} to reference the current Amplify CLI environment."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "which, in the DEV environment, will send"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Specifying the region"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "The @http directive allows you to use ${aws_region} to reference the AWS region of your environment."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "which, in the us-east-1 region, will send"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Combining the different components"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "You can use a combination of parameters, query, body, headers, and environments in your @http directive definition."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Given the definition"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "you can update a post with"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "which, in the DEV environment, will send"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Advanced cases"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "In some cases, you may want to send a request based on existing field data. Take a scenario where you have a post and want to fetch comments associated with the post in a single query. Let's use the previous definition of Post and Comment."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "A post can be fetched at /posts/:id and a post's comments at /posts/:id/comments. You can fetch the comments based on the post id with the following updated definition. $ctx.source is a map that contains the resolution of the parent field (Post) and gives access to id."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "You can retrieve the comments of a specific post with the following query and selection set."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Assuming that getPost retrieves a post with the id POST_ID, the comments field is resolved by sending this request to the endpoint"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Note that there is no check to ensure that the reference variable (here the post ID) exists. When using this technique, it is recommended to make sure the referenced field is non-null."
      },
      {
        "heading": "Generates",
        "depth": 3,
        "text": "The @http transformer will create one HTTP datasource for each identified base URL. For example, if multiple HTTP resolvers are created that interact with the \"https://www.example.com\" endpoint, only a single datasource is created. Each directive generates one resolver. Depending on the definition, the appropriate body, params, and query input types are created. Note that @http transformer does not support calling other AWS services where Signature Version 4 signing process is required."
      }
    ],
    "source": "export const meta = {\n  title: `Configure HTTP resolvers`,\n  description: 'The `@http` directive allows you to quickly connect HTTP or HTTPS endpoint to an AppSync API by creating an AWS AppSync HTTP resolver.',\n};\n\n<MigrationAlert isLegacy url={\"/cli/graphql/custom-business-logic\"}/>\n\n## @http\n\nThe `@http` directive allows you to quickly configure HTTP resolvers within your AWS AppSync API.\n\n### Definition\n\n```graphql\ndirective @http(method: HttpMethod, url: String!, headers: [HttpHeader]) on FIELD_DEFINITION\nenum HttpMethod { PUT POST GET DELETE PATCH }\ninput HttpHeader {\n  key: String\n  value: String\n}\n```\n\n### Usage\n\nThe `@http` directive allows you to quickly connect HTTP or HTTPS endpoint to an AppSync API by creating an AWS AppSync HTTP resolver. To connect to an endpoint, add the `@http` directive to a field in your `schema.graphql` file. The directive allows you to define URL path parameters, and specify a query string and/or specify a request body. For example, given the definition of a post type,\n\n```graphql\ntype Post {\n  id: ID!\n  title: String\n  description: String\n  views: Int\n}\n\ntype Query {\n  listPosts: Post @http(url: \"https://www.example.com/posts\")\n}\n```\n\nAmplify generates the definition below that sends a request to the url when the `listPosts` query is used.\n\n```graphql\ntype Query {\n  listPosts: Post\n}\n```\n\n**Request Headers**\n\nThe `@http` directive generates resolvers that can handle xml and json responses. If an HTTP method is not defined, `GET` is used by default. You can specify a list of static headers to be passed with the HTTP requests to your backend in your directive definition.\n\n```graphql\ntype Query {\n  listPosts: Post\n    @http(\n      url: \"https://www.example.com/posts\"\n      headers: [{ key: \"X-Header\", value: \"X-Header-Value\" }]\n    )\n}\n```\n\n**Path Parameters**\n\nYou can create dynamic paths by specifying parameters in the directive URL by using the special `:<parameter>` notation. Your set of parameters can then be specified in the `params` input object of the query. Note that path parameters are not added to the request body or query string. You can define multiple parameters.\n\nGiven the definition\n\n```graphql\ntype Query {\n  getPost: Post @http(url: \"https://www.example.com/posts/:id\")\n}\n```\n\nAmplify generates\n\n```graphql\ntype Query {\n  getPost(params: QueryGetPostParamsInput!): Post\n}\n\ninput QueryGetPostParamsInput {\n  id: String!\n}\n```\n\nYou can fetch a specific post by enclosing the `id` in the `params` input object.\n\n```graphql\nquery post {\n  getPost(params: {id: \"POST_ID\"}) {\n    id\n    title\n  }\n}\n```\n\nwhich will send\n\n```text\nGET /posts/POST_ID\nHost: www.example.com\n```\n\n**Query String**\n\nYou can send a query string with your request by specifying variables for your query. The query string is supported with all request methods.\n\nGiven the definition\n\n```graphql\ntype Query {\n  listPosts(sort: String!, from: String!, limit: Int!): Post\n    @http(url: \"https://www.example.com/posts\")\n}\n```\n\nAmplify generates\n\n```graphql\ntype Query {\n  listPosts(query: QueryListPostsQueryInput!): Post\n}\n\ninput QueryListPostsQueryInput {\n  sort: String!\n  from: String!\n  limit: Int!\n}\n```\n\nYou can query for posts using the `query` input object\n\n```graphql\nquery posts{\n  listPosts(query: {sort: \"DESC\", from: \"last-week\", limit: 5}) {\n    id\n    title\n    description\n  }\n}\n```\n\nwhich sends the following request:\n\n```text\nGET /posts?sort=DESC&from=last-week&limit=5\nHost: www.example.com\n```\n\n**Request Body**\n\nThe `@http` directive also allows you to specify the body of a request, which is used for `POST`, `PUT`, and `PATCH` requests. To create a new post, you can define the following.\n\n```graphql\ntype Mutation {\n  addPost(title: String!, description: String!, views: Int): Post\n    @http(method: POST, url: \"https://www.example.com/post\")\n}\n```\n\nAmplify generates the `addPost` query field with the `query` and `body` input objects since this type of request also supports a query string. The generated resolver verifies that non-null arguments (e.g.: the `title` and `description`) are passed in at least one of the input objects; if not, an error is returned.\n\n```graphql\ntype Mutation {\n  addPost(query: QueryAddPostQueryInput, body: QueryAddPostBodyInput): Post\n}\n\ninput QueryAddPostQueryInput {\n  title: String\n  description: String\n  views: Int\n}\n\ninput QueryAddPostBodyInput {\n  title: String\n  description: String\n  views: Int\n}\n```\n\nYou can add a post by using the `body` input object:\n\n```graphql\nmutation add {\n  addPost(body: {title: \"new post\", description: \"fresh content\"}) {\n    id\n  }\n}\n```\n\nwhich will send\n\n```text\nPOST /post\nHost: www.example.com\n{\n  title: \"new post\"\n  description: \"fresh content\"\n}\n```\n\n**Specifying the environment**\n\nThe `@http` directive allows you to use `${env}` to reference the current Amplify CLI environment.\n\n```graphql\ntype Query {\n  listPosts: Post @http(\n    url: \"https://www.example.com/${env}/posts\"\n  )\n}\n```\n\nwhich, in the `DEV` environment, will send\n\n```text\nGET /DEV/posts\nHost: www.example.com\n```\n\n**Specifying the region**\n\nThe `@http` directive allows you to use `${aws_region}` to reference the AWS region of your environment.\n\n```graphql\ntype Query {\n listPosts: Post @http(\n  url: \"https://www.example.com/${aws_region}/posts\"\n )\n}\n```\n\nwhich, in the `us-east-1` region, will send\n\n```text\nGET /us-east-1/posts\nHost: www.example.com\n```\n\n**Combining the different components**\n\nYou can use a combination of parameters, query, body, headers, and environments in your `@http` directive definition.\n\nGiven the definition\n\n```graphql\ntype Post {\n  id: ID!\n  title: String\n  description: String\n  views: Int\n  comments: [Comment]\n}\n\ntype Comment {\n  id: ID!\n  content: String\n}\n\ntype Mutation {\n  updatePost(\n    title: String!\n    description: String!\n    views: Int\n    withComments: Boolean\n  ): Post\n    @http(\n      method: PUT\n      url: \"https://www.example.com/${env}/posts/:id\"\n      headers: [{ key: \"X-Header\", value: \"X-Header-Value\" }]\n    )\n}\n```\n\nyou can update a post with\n\n```graphql\nmutation update {\n  updatePost(\n    body: {title: \"new title\", description: \"updated description\", views: 100}\n    params: {id: \"EXISTING_ID\"}\n    query: {withComments: true}) {\n    id\n    title\n    description\n    comments {\n      id\n      content\n    }\n  }\n}\n```\n\nwhich, in the `DEV` environment, will send\n\n```text\nPUT /DEV/posts/EXISTING_ID?withComments=true\nHost: www.example.com\nX-Header: X-Header-Value\n{\n  title: \"new title\"\n  description: \"updated description\"\n  views: 100\n}\n```\n\n**Advanced cases**\n\nIn some cases, you may want to send a request based on existing field data. Take a scenario where you have a post and want to fetch comments associated with the post in a single query. Let's use the previous definition of `Post` and `Comment`.\n\n```graphql\ntype Post {\n  id: ID!\n  title: String\n  description: String\n  views: Int\n  comments: [Comment]\n}\n\ntype Comment {\n  id: ID!\n  content: String\n}\n```\n\nA post can be fetched at `/posts/:id` and a post's comments at `/posts/:id/comments`. You can fetch the comments based on the post id with the following updated definition. `$ctx.source` is a map that contains the resolution of the parent field (`Post`) and gives access to `id`.\n\n```graphql\ntype Post {\n  id: ID!\n  title: String\n  description: String\n  views: Int\n  comments: [Comment]\n    @http(url: \"https://www.example.com/posts/${ctx.source.id}/comments\")\n}\n\ntype Comment {\n  id: ID!\n  content: String\n}\n\ntype Query {\n  getPost: Post @http(url: \"https://www.example.com/posts/:id\")\n}\n```\n\nYou can retrieve the comments of a specific post with the following query and selection set.\n\n```graphql\nquery post {\n  getPost(params: {id: \"POST_ID\"}) {\n    id\n    title\n    description\n    comments {\n      id\n      content\n    }\n  }\n}\n```\n\nAssuming that `getPost` retrieves a post with the id `POST_ID`, the comments field is resolved by sending this request to the endpoint\n\n```text\nGET /posts/POST_ID/comments\nHost: www.example.com\n```\n\nNote that there is no check to ensure that the reference variable (here the post ID) exists. When using this technique, it is recommended to make sure the referenced field is non-null.\n\n### Generates\n\nThe `@http` transformer will create one HTTP datasource for each identified base URL. For example, if multiple HTTP resolvers are created that interact with the \"https://www.example.com\" endpoint, only a single datasource is created. Each directive generates one resolver. Depending on the definition, the appropriate `body`, `params`, and `query` input types are created. Note that `@http` transformer does not support calling other AWS services where Signature Version 4 signing process is required.\n",
    "meta": {
      "title": "Configure HTTP resolvers",
      "description": "The `@http` directive allows you to quickly connect HTTP or HTTPS endpoint to an AppSync API by creating an AWS AppSync HTTP resolver.",
      "subcategory": "API (GraphQL)",
      "category": "Amplify CLI (Legacy)"
    },
    "filename": "/cli-legacy/graphql-transformer/http"
  },
  {
    "searchableText": [
      {
        "heading": "@function",
        "depth": 2,
        "text": "The @function directive allows you to quickly & easily configure AWS Lambda resolvers within your AWS AppSync API."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "The @function directive allows you to quickly connect lambda resolvers to an AppSync API. You may deploy the AWS Lambda functions via the Amplify CLI, AWS Lambda console, or any other tool. To connect an AWS Lambda resolver, add the @function directive to a field in your schema.graphql."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Let's assume you have deployed an echo function with the following contents:"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "If you deployed your function using the function category"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "The Amplify CLI provides support for maintaining multiple environments out of the box. When you deploy a function via amplify add function, it will automatically add the environment suffix to your Lambda function name. For example if you create a function named echofunction using amplify add function in the dev environment, the deployed function will be named echofunction-dev. The @function directive allows you to use ${env} to reference the current Amplify CLI environment."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "If you deployed your function without amplify"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "If you deployed your API without amplify then you must provide the full Lambda function name. If you deployed the same function with the name echofunction then you would have:"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Example: Return custom data and run custom logic"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "You can use the @function directive to write custom business logic in an AWS Lambda function. To get started, use\namplify add function, the AWS Lambda console, or other tool to deploy an AWS Lambda function with the following contents."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "For example purposes assume the function is named GraphQLResolverFunction:"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Example: Get the logged in user from Amazon Cognito User Pools"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "When building applications, it is often useful to fetch information for the current user. You can use the @function directive to quickly add a resolver that uses AppSync identity information to fetch a user from Amazon Cognito User Pools. First make sure you have added Amazon Cognito User Pools enabled via amplify add auth and a GraphQL API via amplify add api to an amplify project. Once you have created the user pool, get the UserPoolId from amplify-meta.json in the backend/ directory of your amplify project. You will provide this value as an environment variable in a moment. Next, using the Amplify function category, AWS console, or some other tool, deploy an AWS Lambda function with the following contents."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "For example purposes assume the function is named GraphQLResolverFunction:"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "You can connect this function to your AppSync API deployed via Amplify using this schema:"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "This simple lambda function shows how you can write your own custom logic using a language of your choosing. Try enhancing the example with your own data and logic."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "When deploying the function, make sure your function has access to the auth resource. You can run the amplify update function command for the CLI to automatically supply an environment variable named AUTH_<RESOURCE_NAME>_USERPOOLID to the function and associate corresponding CRUD policies to the execution role of the function."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "After deploying our function, you can connect it to AppSync by defining some types and using the @function directive. Add this to your schema, to connect the\nQuery.echo and Query.me resolvers to our new function."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Next run amplify push and wait as your project finishes deploying. To test that everything is working as expected run amplify api console to open the GraphiQL editor for your API. You are going to need to open the Amazon Cognito User Pools console to create a user if you do not yet have any. Once you have created a user go back to the AppSync console's query page and click \"Login with User Pools\". You can find the ClientId in amplify-meta.json under the key AppClientIDWeb. Paste that value into the modal and login using your username and password. You can now run this query:"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "which will return user information related to the current user directly from your user pool."
      },
      {
        "heading": "Structure of the function event",
        "depth": 3,
        "text": "When writing lambda functions that are connected via the @function directive, you can expect the following structure for the AWS Lambda event object."
      },
      {
        "heading": "Structure of the function event",
        "depth": 3,
        "text": "| Key  | Description  |\n|---|---|\n| typeName  | The name of the parent object type of the field being resolver.  |\n| fieldName  | The name of the field being resolved.  |\n| arguments  | A map containing the arguments passed to the field being resolved.  |\n| identity  | A map containing identity information for the request. Contains a nested key 'claims' that will contains the JWT claims if they exist. |\n| source  | When resolving a nested field in a query, the source contains parent value at runtime. For example when resolving Post.comments, the source will be the Post object.  |\n| request   | The AppSync request object. Contains header information.  |\n| prev | When using pipeline resolvers, this contains the object returned by the previous function. You can return the previous value for auditing use cases. |"
      },
      {
        "heading": "Structure of the function event",
        "depth": 3,
        "text": "Your function should follow the lambda handler guidelines for your specific language. See the developer guides from the\nAWS Lambda documentation for your chosen language. If you choose to use structured types, your type should serialize\nthe AWS Lambda event object outlined above. For example, if using Golang, you should define a struct with the above fields."
      },
      {
        "heading": "Calling functions in different regions",
        "depth": 3,
        "text": "By default, you expect the function to be in the same region as the amplify project. If you need to call a function in a different (or static) region, you can provide the region argument."
      },
      {
        "heading": "Calling functions in different regions",
        "depth": 3,
        "text": "Calling functions in different AWS accounts is not supported via the @function directive but is supported by AWS AppSync."
      },
      {
        "heading": "Chaining functions",
        "depth": 3,
        "text": "The @function directive supports AWS AppSync pipeline resolvers. That means, you can chain together multiple functions such that they are invoked in series when your field's resolver is invoked. To create a pipeline resolver that calls out to multiple AWS Lambda functions in series, use multiple @function directives on the field."
      },
      {
        "heading": "Chaining functions",
        "depth": 3,
        "text": "In the example above when you run a mutation that calls the Mutation.doSomeWork field, the worker-function will be invoked first then the audit-function will be invoked with an event that contains the results of the worker-function under the event.prev.result key. The audit-function would need to return event.prev.result if you want the result of worker-function to be returned for the field. Under the hood, Amplify creates an AppSync::FunctionConfiguration for each unique instance of @function in a document and a pipeline resolver containing a pointer to a function for each @function on a given field."
      },
      {
        "heading": "Generates",
        "depth": 4,
        "text": "The @function directive generates these resources as necessary:"
      },
      {
        "heading": "Generates",
        "depth": 4,
        "text": "An AWS IAM role that has permission to invoke the function as well as a trust policy with AWS AppSync."
      },
      {
        "heading": "Generates",
        "depth": 4,
        "text": "An AWS AppSync data source that registers the new role and existing function with your AppSync API."
      },
      {
        "heading": "Generates",
        "depth": 4,
        "text": "An AWS AppSync pipeline function that prepares the lambda event and invokes the new data source."
      },
      {
        "heading": "Generates",
        "depth": 4,
        "text": "An AWS AppSync resolver that attaches to the GraphQL field and invokes the new pipeline functions."
      }
    ],
    "source": "export const meta = {\n  title: `Configure Lambda resolvers`,\n  description: `Quickly & easily configure AWS Lambda resolvers within your AWS AppSync API.`,\n};\n\n<MigrationAlert isLegacy url={\"/cli/graphql/custom-business-logic\"}/>\n\n## @function\n\nThe `@function` directive allows you to quickly & easily configure AWS Lambda resolvers within your AWS AppSync API.\n\n### Definition\n\n```graphql\ndirective @function(name: String!, region: String) on FIELD_DEFINITION\n```\n\n### Usage\n\nThe `@function` directive allows you to quickly connect lambda resolvers to an AppSync API. You may deploy the AWS Lambda functions via the Amplify CLI, AWS Lambda console, or any other tool. To connect an AWS Lambda resolver, add the `@function` directive to a field in your `schema.graphql`.\n\nLet's assume you have deployed an *echo* function with the following contents:\n\n```js\nexports.handler =  async function(event, context){\n  return event.arguments.msg;\n};\n```\n\n**If you deployed your function using the `function` category**\n\nThe Amplify CLI provides support for maintaining multiple environments out of the box. When you deploy a function via `amplify add function`, it will automatically add the environment suffix to your Lambda function name. For example if you create a function named **echofunction** using `amplify add function` in the **dev** environment, the deployed function will be named **echofunction-dev**. The `@function` directive allows you to use `${env}` to reference the current Amplify CLI environment.\n\n```graphql\ntype Query {\n  echo(msg: String): String @function(name: \"echofunction-${env}\")\n}\n```\n\n**If you deployed your function without amplify**\n\nIf you deployed your API without amplify then you must provide the full Lambda function name. If you deployed the same function with the name **echofunction** then you would have:\n\n```graphql\ntype Query {\n  echo(msg: String): String @function(name: \"echofunction\")\n}\n```\n\n**Example: Return custom data and run custom logic**\n\nYou can use the `@function` directive to write custom business logic in an AWS Lambda function. To get started, use\n`amplify add function`, the AWS Lambda console, or other tool to deploy an AWS Lambda function with the following contents.\n\nFor example purposes assume the function is named `GraphQLResolverFunction`:\n\n```js\nconst POSTS = [\n  { id: 1, title: \"AWS Lambda: How To Guide.\" },\n  { id: 2, title: \"AWS Amplify Launches @function and @key directives.\" },\n  { id: 3, title: \"Serverless 101\" }\n];\nconst COMMENTS = [\n  { postId: 1, content: \"Great guide!\" },\n  { postId: 1, content: \"Thanks for sharing!\" },\n  { postId: 2, content: \"Can't wait to try them out!\" }\n];\n\n// Get all posts. Write your own logic that reads from any data source.\nfunction getPosts() {\n  return POSTS;\n}\n\n// Get the comments for a single post.\nfunction getCommentsForPost(postId) {\n  return COMMENTS.filter(comment => comment.postId === postId);\n}\n\n/**\n * Using this as the entry point, you can use a single function to handle many resolvers.\n */\nconst resolvers = {\n  Query: {\n    posts: ctx => {\n      return getPosts();\n    },\n  },\n  Post: {\n    comments: ctx => {\n      return getCommentsForPost(ctx.source.id);\n    },\n  },\n}\n\n// event\n// {\n//   \"typeName\": \"Query\", /* Filled dynamically based on @function usage location */\n//   \"fieldName\": \"me\", /* Filled dynamically based on @function usage location */\n//   \"arguments\": { /* GraphQL field arguments via $ctx.arguments */ },\n//   \"identity\": { /* AppSync identity object via $ctx.identity */ },\n//   \"source\": { /* The object returned by the parent resolver. E.G. if resolving field 'Post.comments', the source is the Post object. */ },\n//   \"request\": { /* AppSync request object. Contains things like headers. */ },\n//   \"prev\": { /* If using the built-in pipeline resolver support, this contains the object returned by the previous function. */ },\n// }\nexports.handler = async (event) => {\n  const typeHandler = resolvers[event.typeName];\n  if (typeHandler) {\n    const resolver = typeHandler[event.fieldName];\n    if (resolver) {\n      return await resolver(event);\n    }\n  }\n  throw new Error(\"Resolver not found.\");\n};\n```\n\n**Example: Get the logged in user from Amazon Cognito User Pools**\n\nWhen building applications, it is often useful to fetch information for the current user. You can use the `@function` directive to quickly add a resolver that uses AppSync identity information to fetch a user from Amazon Cognito User Pools. First make sure you have added Amazon Cognito User Pools enabled via `amplify add auth` and a GraphQL API via `amplify add api` to an amplify project. Once you have created the user pool, get the **UserPoolId** from **amplify-meta.json** in the **backend/** directory of your amplify project. You will provide this value as an environment variable in a moment. Next, using the Amplify function category, AWS console, or some other tool, deploy an AWS Lambda function with the following contents.\n\nFor example purposes assume the function is named `GraphQLResolverFunction`:\n\n```js\n/* Amplify Params - DO NOT EDIT\nYou can access the following resource attributes as environment variables from your Lambda function\nvar environment = process.env.ENV\nvar region = process.env.REGION\nvar authMyResourceNameUserPoolId = process.env.AUTH_MYRESOURCENAME_USERPOOLID\n\nAmplify Params - DO NOT EDIT */\n\nconst { CognitoIdentityServiceProvider } = require('aws-sdk');\nconst cognitoIdentityServiceProvider = new CognitoIdentityServiceProvider();\n\n/**\n * Get user pool information from environment variables.\n */\nconst COGNITO_USERPOOL_ID = process.env.AUTH_MYRESOURCENAME_USERPOOLID;\nif (!COGNITO_USERPOOL_ID) {\n  throw new Error(`Function requires environment variable: 'COGNITO_USERPOOL_ID'`);\n}\nconst COGNITO_USERNAME_CLAIM_KEY = 'cognito:username';\n\n/**\n * Using this as the entry point, you can use a single function to handle many resolvers.\n */\nconst resolvers = {\n  Query: {\n    echo: ctx => {\n      return ctx.arguments.msg;\n    },\n    me: async ctx => {\n      var params = {\n        UserPoolId: COGNITO_USERPOOL_ID, /* required */\n        Username: ctx.identity.claims[COGNITO_USERNAME_CLAIM_KEY], /* required */\n      };\n      try {\n        // Read more: https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/CognitoIdentityServiceProvider.html#adminGetUser-property\n        return await cognitoIdentityServiceProvider.adminGetUser(params).promise();\n      } catch (e) {\n        throw new Error(`NOT FOUND`);\n      }\n    }\n  },\n}\n\n// event\n// {\n//   \"typeName\": \"Query\", /* Filled dynamically based on @function usage location */\n//   \"fieldName\": \"me\", /* Filled dynamically based on @function usage location */\n//   \"arguments\": { /* GraphQL field arguments via $ctx.arguments */ },\n//   \"identity\": { /* AppSync identity object via $ctx.identity */ },\n//   \"source\": { /* The object returned by the parent resolver. E.G. if resolving field 'Post.comments', the source is the Post object. */ },\n//   \"request\": { /* AppSync request object. Contains things like headers. */ },\n//   \"prev\": { /* If using the built-in pipeline resolver support, this contains the object returned by the previous function. */ },\n// }\nexports.handler = async (event) => {\n  const typeHandler = resolvers[event.typeName];\n  if (typeHandler) {\n    const resolver = typeHandler[event.fieldName];\n    if (resolver) {\n      return await resolver(event);\n    }\n  }\n  throw new Error(\"Resolver not found.\");\n};\n```\n\nYou can connect this function to your AppSync API deployed via Amplify using this schema:\n\n```graphql\ntype Query {\n  posts: [Post] @function(name: \"GraphQLResolverFunction\")\n}\ntype Post {\n  id: ID!\n  title: String!\n  comments: [Comment] @function(name: \"GraphQLResolverFunction\")\n}\ntype Comment {\n  postId: ID!\n  content: String\n}\n```\n\nThis simple lambda function shows how you can write your own custom logic using a language of your choosing. Try enhancing the example with your own data and logic.\n\n> When deploying the function, make sure your function has access to the auth resource. You can run the `amplify update function` command for the CLI to automatically supply an environment variable named `AUTH_<RESOURCE_NAME>_USERPOOLID` to the function and associate corresponding CRUD policies to the execution role of the function.\n\nAfter deploying our function, you can connect it to AppSync by defining some types and using the @function directive. Add this to your schema, to connect the\n`Query.echo` and `Query.me` resolvers to our new function.\n\n```graphql\ntype Query {\n  me: User @function(name: \"ResolverFunction\")\n  echo(msg: String): String @function(name: \"ResolverFunction\")\n}\n# These types derived from https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/CognitoIdentityServiceProvider.html#adminGetUser-property\ntype User {\n  Username: String!\n  UserAttributes: [Value]\n  UserCreateDate: String\n  UserLastModifiedDate: String\n  Enabled: Boolean\n  UserStatus: UserStatus\n  MFAOptions: [MFAOption]\n  PreferredMfaSetting: String\n  UserMFASettingList: String\n}\ntype Value {\n  Name: String!\n  Value: String\n}\ntype MFAOption {\n  DeliveryMedium: String\n  AttributeName: String\n}\nenum UserStatus {\n  UNCONFIRMED\n  CONFIRMED\n  ARCHIVED\n  COMPROMISED\n  UNKNOWN\n  RESET_REQUIRED\n  FORCE_CHANGE_PASSWORD\n}\n```\n\nNext run `amplify push` and wait as your project finishes deploying. To test that everything is working as expected run `amplify api console` to open the GraphiQL editor for your API. You are going to need to open the Amazon Cognito User Pools console to create a user if you do not yet have any. Once you have created a user go back to the AppSync console's query page and click \"Login with User Pools\". You can find the **ClientId** in **amplify-meta.json** under the key **AppClientIDWeb**. Paste that value into the modal and login using your username and password. You can now run this query:\n\n```graphql\nquery {\n  me {\n    Username\n    UserStatus\n    UserCreateDate\n    UserAttributes {\n      Name\n      Value\n    }\n    MFAOptions {\n      AttributeName\n      DeliveryMedium\n    }\n    Enabled\n    PreferredMfaSetting\n    UserMFASettingList\n    UserLastModifiedDate\n  }\n}\n```\n\nwhich will return user information related to the current user directly from your user pool.\n\n### Structure of the function event\n\nWhen writing lambda functions that are connected via the `@function` directive, you can expect the following structure for the AWS Lambda event object.\n\n| Key  | Description  |\n|---|---|\n| typeName  | The name of the parent object type of the field being resolver.  |\n| fieldName  | The name of the field being resolved.  |\n| arguments  | A map containing the arguments passed to the field being resolved.  |\n| identity  | A map containing identity information for the request. Contains a nested key 'claims' that will contains the JWT claims if they exist. |\n| source  | When resolving a nested field in a query, the source contains parent value at runtime. For example when resolving `Post.comments`, the source will be the Post object.  |\n| request   | The AppSync request object. Contains header information.  |\n| prev | When using pipeline resolvers, this contains the object returned by the previous function. You can return the previous value for auditing use cases. |\n\nYour function should follow the lambda handler guidelines for your specific language. See the developer guides from the\n[AWS Lambda](https://docs.aws.amazon.com/lambda/latest/dg/welcome.html) documentation for your chosen language. If you choose to use structured types, your type should serialize\nthe AWS Lambda event object outlined above. For example, if using Golang, you should define a struct with the above fields.\n\n### Calling functions in different regions\n\nBy default, you expect the function to be in the same region as the amplify project. If you need to call a function in a different (or static) region, you can provide the **region** argument.\n\n```graphql\ntype Query {\n  echo(msg: String): String @function(name: \"echofunction\", region: \"us-east-1\")\n}\n```\n\nCalling functions in different AWS accounts is not supported via the @function directive but is supported by AWS AppSync.\n\n### Chaining functions\n\nThe @function directive supports AWS AppSync pipeline resolvers. That means, you can chain together multiple functions such that they are invoked in series when your field's resolver is invoked. To create a pipeline resolver that calls out to multiple AWS Lambda functions in series, use multiple `@function` directives on the field.\n\n```graphql\ntype Mutation {\n  doSomeWork(msg: String): String @function(name: \"worker-function\") @function(name: \"audit-function\")\n}\n```\n\nIn the example above when you run a mutation that calls the `Mutation.doSomeWork` field, the **worker-function** will be invoked first then the **audit-function** will be invoked with an event that contains the results of the **worker-function** under the **event.prev.result** key. The **audit-function** would need to return **event.prev.result** if you want the result of **worker-function** to be returned for the field. Under the hood, Amplify creates an `AppSync::FunctionConfiguration` for each unique instance of `@function` in a document and a pipeline resolver containing a pointer to a function for each `@function` on a given field.\n\n#### Generates\n\nThe `@function` directive generates these resources as necessary:\n\n1. An AWS IAM role that has permission to invoke the function as well as a trust policy with AWS AppSync.\n2. An AWS AppSync data source that registers the new role and existing function with your AppSync API.\n3. An AWS AppSync pipeline function that prepares the lambda event and invokes the new data source.\n4. An AWS AppSync resolver that attaches to the GraphQL field and invokes the new pipeline functions.\n\n",
    "meta": {
      "title": "Configure Lambda resolvers",
      "description": "Quickly & easily configure AWS Lambda resolvers within your AWS AppSync API.",
      "subcategory": "API (GraphQL)",
      "category": "Amplify CLI (Legacy)"
    },
    "filename": "/cli-legacy/graphql-transformer/function"
  },
  {
    "searchableText": [
      {
        "heading": "@connection",
        "depth": 2,
        "text": "The @connection directive enables you to specify relationships between @model types. Currently, this supports one-to-one, one-to-many, and many-to-one relationships. You may implement many-to-many relationships using two one-to-many connections and a joining @model type. See the usage section for details."
      },
      {
        "heading": "@connection",
        "depth": 2,
        "text": "We also provide a fully working schema with 17 patterns related to relational designs."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Relationships between types are specified by annotating fields on an @model object type with the @connection directive."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "The fields argument can be provided and indicates which fields can be queried by to get connected objects. The keyName argument can optionally be used to specify the name of secondary index (an index that was set up using @key) that should be queried from the other type in the relationship."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "When specifying a keyName, the fields argument should be provided to indicate which field(s) will be used to get connected objects. If keyName is not provided, then @connection queries the target table's primary index."
      },
      {
        "heading": "Has one",
        "depth": 3,
        "text": "In the simplest case, you can define a one-to-one connection where a project has one team:"
      },
      {
        "heading": "Has one",
        "depth": 3,
        "text": "You can also define the field you would like to use for the connection by populating the first argument to the fields array and matching it to a field on the type:"
      },
      {
        "heading": "Has one",
        "depth": 3,
        "text": "In this case, the Project type has a teamID field added as an identifier for the team that the project belongs to. @connection can then get the connected Team object by querying the Team table with this teamID."
      },
      {
        "heading": "Has one",
        "depth": 3,
        "text": "After it's transformed, you can create projects and query the connected team as follows:"
      },
      {
        "heading": "Has one",
        "depth": 3,
        "text": "Note: The Project.team resolver is configured to work with the defined connection. This is done with a query on the Team table where teamID is passed in as an argument."
      },
      {
        "heading": "Has one",
        "depth": 3,
        "text": "A Has One @connection can only reference the primary index of a model (ie. it cannot specify a \"keyName\" as described below in the Has Many section)."
      },
      {
        "heading": "Has many",
        "depth": 3,
        "text": "The following schema defines a Post that can have many comments:"
      },
      {
        "heading": "Has many",
        "depth": 3,
        "text": "Note how a one-to-many connection needs an @key that allows comments to be queried by the postID and the connection uses this key to get all comments whose postID is the id of the post was called on.\nAfter it's transformed, you can create comments and query the connected Post as follows:"
      },
      {
        "heading": "Has many",
        "depth": 3,
        "text": "And you can query a Post with its comments as follows:"
      },
      {
        "heading": "Belongs to",
        "depth": 3,
        "text": "You can make a connection bi-directional by adding a many-to-one connection to types that already have a one-to-many connection. In this case you add a connection from Comment to Post since each comment belongs to a post:"
      },
      {
        "heading": "Belongs to",
        "depth": 3,
        "text": "After it's transformed, you can create comments with a post as follows:"
      },
      {
        "heading": "Belongs to",
        "depth": 3,
        "text": "And you can query a Comment with its Post, then all Comments of that Post by navigating the connection:"
      },
      {
        "heading": "Many-to-many connections",
        "depth": 3,
        "text": "You can implement many to many using two 1-M @connections, an @key, and a joining @model. For example:"
      },
      {
        "heading": "Many-to-many connections",
        "depth": 3,
        "text": "This case is a bidirectional many-to-many which is why two @key calls are needed on the PostEditor model.\nYou can first create a Post and a User, and then add a connection between them with by creating a PostEditor object as follows:"
      },
      {
        "heading": "Many-to-many connections",
        "depth": 3,
        "text": "Note that neither the User type nor the Post type have any identifiers of connected objects. The connection info is held entirely inside the PostEditor objects."
      },
      {
        "heading": "Many-to-many connections",
        "depth": 3,
        "text": "You can query a given user with their posts:"
      },
      {
        "heading": "Many-to-many connections",
        "depth": 3,
        "text": "Also you can query a given post with the editors of that post and can list the posts of those editors, all in a single query:"
      },
      {
        "heading": "Many-to-many connections",
        "depth": 3,
        "text": "Amplify Studio does not support custom naming. Changing the auto-generated name will break Amplify Studio."
      },
      {
        "heading": "Alternative definition",
        "depth": 4,
        "text": "The above definition is the recommended way to create relationships between model types in your API. This involves defining index structures using @key and connection resolvers using @connection. There is an older parameterization of @connection that creates indices and connection resolvers that is still functional for backwards compatibility reasons. It is recommended to use @key and the new @connection via the fields argument."
      },
      {
        "heading": "Alternative definition",
        "depth": 4,
        "text": "This parameterization is not compatible with @key. See the parameterization above to use @connection with indexes created by @key."
      },
      {
        "heading": "Limit",
        "depth": 3,
        "text": "The default number of nested objects is 100. You can override this behavior by setting the limit argument. For example:"
      },
      {
        "heading": "Generates",
        "depth": 3,
        "text": "In order to keep connection queries fast and efficient, the GraphQL transform manages global secondary indexes (GSIs) on the generated tables on your behalf when using @connection"
      },
      {
        "heading": "Generates",
        "depth": 3,
        "text": "Note: After you have pushed a @connection directive you should not try to\nchange it. If you try to change it, the DynamoDB\nUpdateTable operation will fail. Should you need to change a @connection, you should add a new\n@connection that implements the new access pattern, update your application\nto use the new @connection, and then delete the old @connection when it's no\nlonger needed."
      }
    ],
    "source": "export const meta = {\n  title: `Add relationships between types`,\n  description: `Define relationships with other types in your schema.`,\n};\n\n<MigrationAlert isLegacy url={\"/cli/graphql/data-modeling\"}/>\n\n## @connection\n\nThe `@connection` directive enables you to specify relationships between `@model` types. Currently, this supports one-to-one, one-to-many, and many-to-one relationships. You may implement many-to-many relationships using two one-to-many connections and a joining `@model` type. See the usage section for details.\n\n[We also provide a fully working schema with 17 patterns related to relational designs](/cli/graphql-transformer/dataaccess).\n\n### Definition\n\n```graphql\ndirective @connection(keyName: String, fields: [String!]) on FIELD_DEFINITION\n```\n\n### Usage\n\nRelationships between types are specified by annotating fields on an `@model` object type with the `@connection` directive.\n\nThe `fields` argument can be provided and indicates which fields can be queried by to get connected objects. The `keyName` argument can optionally be used to specify the name of secondary index (an index that was set up using `@key`) that should be queried from the other type in the relationship.\n\nWhen specifying a `keyName`, the `fields` argument should be provided to indicate which field(s) will be used to get connected objects. If `keyName` is not provided, then `@connection` queries the target table's primary index.\n\n### Has one\n\nIn the simplest case, you can define a one-to-one connection where a project has one team:\n\n```graphql\ntype Project @model {\n  id: ID!\n  name: String\n  team: Team @connection\n}\n\ntype Team @model {\n  id: ID!\n  name: String!\n}\n```\n\nYou can also define the field you would like to use for the connection by populating the first argument to the fields array and matching it to a field on the type:\n\n```graphql\ntype Project @model {\n  id: ID!\n  name: String\n  teamID: ID!\n  team: Team @connection(fields: [\"teamID\"])\n}\n\ntype Team @model {\n  id: ID!\n  name: String!\n}\n```\n\nIn this case, the Project type has a `teamID` field added as an identifier for the team that the project belongs to. `@connection` can then get the connected Team object by querying the Team table with this `teamID`.\n\nAfter it's transformed, you can create projects and query the connected team as follows:\n\n```graphql\nmutation CreateProject {\n  createProject(input: { name: \"New Project\", teamID: \"a-team-id\"}) {\n    id\n    name\n    team {\n      id\n      name\n    }\n  }\n}\n```\n\n> **Note:** The **Project.team** resolver is configured to work with the defined connection. This is done with a query on the Team table where `teamID` is passed in as an argument.\n\nA Has One @connection can only reference the primary index of a model (ie. it cannot specify a \"keyName\" as described below in the Has Many section).\n\n### Has many\n\nThe following schema defines a Post that can have many comments:\n\n```graphql\ntype Post @model {\n  id: ID!\n  title: String!\n  comments: [Comment] @connection(keyName: \"byPost\", fields: [\"id\"])\n}\n\ntype Comment @model\n  @key(name: \"byPost\", fields: [\"postID\", \"content\"]) {\n  id: ID!\n  postID: ID!\n  content: String!\n}\n```\n\nNote how a one-to-many connection needs an `@key` that allows comments to be queried by the postID and the connection uses this key to get all comments whose postID is the id of the post was called on.\nAfter it's transformed, you can create comments and query the connected Post as follows:\n\n```graphql\nmutation CreatePost {\n  createPost(input: { id: \"a-post-id\", title: \"Post Title\" } ) {\n    id\n    title\n  }\n}\n\nmutation CreateCommentOnPost {\n  createComment(input: { id: \"a-comment-id\", content: \"A comment\", postID: \"a-post-id\"}) {\n    id\n    content\n  }\n}\n```\n\nAnd you can query a Post with its comments as follows:\n\n```graphql\nquery getPost {\n  getPost(id: \"a-post-id\") {\n    id\n    title\n    comments {\n      items {\n        id\n        content\n      }\n    }\n  }\n}\n```\n\n### Belongs to\n\nYou can make a connection bi-directional by adding a many-to-one connection to types that already have a one-to-many connection. In this case you add a connection from Comment to Post since each comment belongs to a post:\n\n```graphql\ntype Post @model {\n  id: ID!\n  title: String!\n  comments: [Comment] @connection(keyName: \"byPost\", fields: [\"id\"])\n}\n\ntype Comment @model\n  @key(name: \"byPost\", fields: [\"postID\", \"content\"]) {\n  id: ID!\n  postID: ID!\n  content: String!\n  post: Post @connection(fields: [\"postID\"])\n}\n```\n\nAfter it's transformed, you can create comments with a post as follows:\n\n```graphql\nmutation CreatePost {\n  createPost(input: { id: \"a-post-id\", title: \"Post Title\" } ) {\n    id\n    title\n  }\n}\n\nmutation CreateCommentOnPost1 {\n  createComment(input: { id: \"a-comment-id-1\", content: \"A comment #1\", postID: \"a-post-id\"}) {\n    id\n    content\n  }\n}\n\nmutation CreateCommentOnPost2 {\n  createComment(input: { id: \"a-comment-id-2\", content: \"A comment #2\", postID: \"a-post-id\"}) {\n    id\n    content\n  }\n}\n```\n\nAnd you can query a Comment with its Post, then all Comments of that Post by navigating the connection:\n\n```graphql\nquery GetCommentWithPostAndComments {\n  getComment( id: \"a-comment-id-1\" ) {\n    id\n    content\n    post {\n      id\n      title\n      comments {\n        items {\n          id\n          content\n        }\n      }\n    }\n  }\n}\n```\n\n### Many-to-many connections\n\nYou can implement many to many using two 1-M @connections, an @key, and a joining @model. For example:\n\n```graphql\ntype Post @model {\n  id: ID!\n  title: String!\n  editors: [PostEditor] @connection(keyName: \"byPost\", fields: [\"id\"])\n}\n\n# Create a join model and disable queries as you don't need them\n# and can query through Post.editors and User.posts\ntype PostEditor\n  @model(queries: null)\n  @key(name: \"byPost\", fields: [\"postID\", \"editorID\"])\n  @key(name: \"byEditor\", fields: [\"editorID\", \"postID\"]) {\n  id: ID!\n  postID: ID!\n  editorID: ID!\n  post: Post! @connection(fields: [\"postID\"])\n  editor: User! @connection(fields: [\"editorID\"])\n}\n\ntype User @model {\n  id: ID!\n  username: String!\n  posts: [PostEditor] @connection(keyName: \"byEditor\", fields: [\"id\"])\n}\n```\n\nThis case is a bidirectional many-to-many which is why two `@key` calls are needed on the PostEditor model.\nYou can first create a Post and a User, and then add a connection between them with by creating a PostEditor object as follows:\n\n```graphql\nmutation CreateData {\n  p1: createPost(input: { id: \"P1\", title: \"Post 1\" }) {\n    id\n  }\n  p2: createPost(input: { id: \"P2\", title: \"Post 2\" }) {\n    id\n  }\n  u1: createUser(input: { id: \"U1\", username: \"user1\" }) {\n    id\n  }\n  u2: createUser(input: { id: \"U2\", username: \"user2\" }) {\n    id\n  }\n}\n\nmutation CreateLinks {\n  p1u1: createPostEditor(input: { id: \"P1U1\", postID: \"P1\", editorID: \"U1\" }) {\n    id\n  }\n  p1u2: createPostEditor(input: { id: \"P1U2\", postID: \"P1\", editorID: \"U2\" }) {\n    id\n  }\n  p2u1: createPostEditor(input: { id: \"P2U1\", postID: \"P2\", editorID: \"U1\" }) {\n    id\n  }\n}\n```\n\nNote that neither the User type nor the Post type have any identifiers of connected objects. The connection info is held entirely inside the PostEditor objects.\n\nYou can query a given user with their posts:\n\n```graphql\nquery GetUserWithPosts {\n  getUser(id: \"U1\") {\n    id\n    username\n    posts {\n      items {\n        post {\n          title\n        }\n      }\n    }\n  }\n}\n```\n\nAlso you can query a given post with the editors of that post and can list the posts of those editors, all in a single query:\n\n```graphql\nquery GetPostWithEditorsWithPosts {\n  getPost(id: \"P1\") {\n    id\n    title\n    editors {\n      items {\n        editor {\n          username\n          posts {\n            items {\n              post {\n                title\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n<Callout warning>\nAmplify Studio does not support custom naming. Changing the auto-generated name will break Amplify Studio.\n</Callout>\n\n#### Alternative definition\n\nThe above definition is the recommended way to create relationships between model types in your API. This involves defining index structures using `@key` and connection resolvers using `@connection`. There is an older parameterization of `@connection` that creates indices and connection resolvers that is still functional for backwards compatibility reasons. It is recommended to use `@key` and the new `@connection` via the fields argument.\n\n```graphql\ndirective @connection(name: String, keyField: String, sortField: String, limit: Int) on FIELD_DEFINITION\n```\n\nThis parameterization is not compatible with `@key`. See the parameterization above to use `@connection` with indexes created by @key.\n\n### Limit\n\nThe default number of nested objects is 100. You can override this behavior by setting the **limit** argument. For example:\n\n```graphql\ntype Post @model {\n  id: ID!\n  title: String!\n  comments: [Comment] @connection(limit: 50)\n}\n\ntype Comment @model {\n  id: ID!\n  content: String!\n}\n```\n\n### Generates\n\nIn order to keep connection queries fast and efficient, the GraphQL transform manages global secondary indexes (GSIs) on the generated tables on your behalf when using @connection\n\n> **Note:** After you have pushed a `@connection` directive you should not try to\nchange it. If you try to change it, the DynamoDB\nUpdateTable operation will fail. Should you need to change a `@connection`, you should add a new\n`@connection` that implements the new access pattern, update your application\nto use the new `@connection`, and then delete the old `@connection` when it's no\nlonger needed.\n",
    "meta": {
      "title": "Add relationships between types",
      "description": "Define relationships with other types in your schema.",
      "subcategory": "API (GraphQL)",
      "category": "Amplify CLI (Legacy)"
    },
    "filename": "/cli-legacy/graphql-transformer/connection"
  },
  {
    "searchableText": [
      {
        "heading": "@auth",
        "depth": 2,
        "text": "Authorization is required for applications to interact with your GraphQL API. API Keys are best used for public APIs (or parts of your schema which you wish to be public) or prototyping, and you must specify the expiration time before deploying. IAM authorization uses Signature Version 4 to make request with policies attached to Roles. OIDC tokens provided by Amazon Cognito User Pools or 3rd party OpenID Connect providers can also be used for authorization, and simply enabling this provides a simple access control requiring users to authenticate to be granted top level access to API actions. You can set finer grained access controls using @auth on your schema which leverages authorization metadata provided as part of these tokens or set on the database items themselves."
      },
      {
        "heading": "@auth",
        "depth": 2,
        "text": "@auth object types that are annotated with @auth are protected by a set of authorization rules giving you additional controls than the top level authorization on an API. You may use the @auth directive on object type definitions and field definitions in your project's schema."
      },
      {
        "heading": "@auth",
        "depth": 2,
        "text": "When using the @auth directive on object type definitions that are also annotated with\n@model, all resolvers that return objects of that type will be protected. When using the\n@auth directive on a field definition, a resolver will be added to the field that authorize access\nbased on attributes found in the parent type."
      },
      {
        "heading": "Definition",
        "depth": 3,
        "text": "Note: The operations argument was added to replace the 'queries' and 'mutations' arguments. The 'queries' and 'mutations' arguments will continue to work but it is encouraged to move to 'operations'. If both are provided, the 'operations' argument takes precedence over 'queries'."
      },
      {
        "heading": "Owner authorization",
        "depth": 3,
        "text": "By default, enabling owner authorization allows any signed in user to create records."
      },
      {
        "heading": "Owner authorization",
        "depth": 3,
        "text": "Owner authorization requires an authentication type of Amazon Cognito User Pools to be enabled in your app."
      },
      {
        "heading": "Owner authorization",
        "depth": 3,
        "text": "Owner authorization specifies whether a user can access or operate against an object. To do so, each object will get an ownerField field (by default owner will be added to the object if not specified) that stores ownership information and is verified in various ways during resolver execution."
      },
      {
        "heading": "Owner authorization",
        "depth": 3,
        "text": "You can use the operations argument to specify which operations are enabled as follows:"
      },
      {
        "heading": "Owner authorization",
        "depth": 3,
        "text": "read: Allow the user to perform queries (get and list operations) against the API."
      },
      {
        "heading": "Owner authorization",
        "depth": 3,
        "text": "create: Inject the logged in user's identity as the ownerField automatically."
      },
      {
        "heading": "Owner authorization",
        "depth": 3,
        "text": "update: Add conditional update that checks the stored ownerField is the same as the signed in user."
      },
      {
        "heading": "Owner authorization",
        "depth": 3,
        "text": "delete: Add conditional update that checks the stored ownerField is the same as the signed in user."
      },
      {
        "heading": "Owner authorization",
        "depth": 3,
        "text": "You must ensure that the create operations rule is specified explicitly or inferred from defaults to ensure that the owner's identity is stored with the record so it can be verified on subsequent requests."
      },
      {
        "heading": "Owner authorization",
        "depth": 3,
        "text": "When specifying operations as a part of the @auth rule, the operations not included in the list are not protected by default."
      },
      {
        "heading": "Owner authorization",
        "depth": 3,
        "text": "Let's take a look at a few examples:"
      },
      {
        "heading": "Owner authorization",
        "depth": 3,
        "text": "In this schema, only the owner of the object has the authorization to perform read (getTodo and listTodos), update (updateTodo), and delete (deleteTodo) operations on the owner created object. This prevents the object from being updated or deleted by users other than the creator of the object."
      },
      {
        "heading": "Owner authorization",
        "depth": 3,
        "text": "Here's a table outlining which users are permitted to execute which operations. owner refers to the user who created the object, other refers to all other authenticated users."
      },
      {
        "heading": "Owner authorization",
        "depth": 3,
        "text": "|       | getTodo | listTodos | createTodo | updateTodo | deleteTodo |\n|:------|:-------:|:---------:|:----------:|:----------:|:----------:|\n| owner |    ✅   |     ✅    |     ✅     |      ✅   |     ✅     |\n| other |    ❌   |     ❌    |     ✅     |      ❌   |     ❌     |"
      },
      {
        "heading": "Owner authorization",
        "depth": 3,
        "text": "Next, let's say that you wanted to modify the schema to allow only the owner of the object to be able to update or delete, but allow any authenticated user to read the objects."
      },
      {
        "heading": "Owner authorization",
        "depth": 3,
        "text": "In this schema, only the owner of the object has the authorization to perform update (updateTodo) and delete (deleteTodo) operations on the owner created object, but anyone can read them (getTodo, listTodos). This prevents the object from being updated or deleted by users other than the creator of the object while allowing all authenticated users of the app to read them."
      },
      {
        "heading": "Owner authorization",
        "depth": 3,
        "text": "Here's a table outlining which users are permitted to execute which operations. owner refers to the user who created the object, other refers to all other authenticated users."
      },
      {
        "heading": "Owner authorization",
        "depth": 3,
        "text": "|       | getTodo | listTodos | createTodo | updateTodo | deleteTodo |\n|:------|:-------:|:---------:|:----------:|:----------:|:----------:|\n| owner |    ✅   |     ✅    |     ✅     |      ✅   |     ✅     |\n| other |    ✅   |     ✅    |     ✅     |      ❌   |     ❌     |"
      },
      {
        "heading": "Owner authorization",
        "depth": 3,
        "text": "Next, let's say that you wanted to modify the schema to allow only the owner of the object to be able to delete, but allow anyone to create, read, and update."
      },
      {
        "heading": "Owner authorization",
        "depth": 3,
        "text": "In this schema, only the owner of the object has the authorization to perform delete operations on the owner created object, but anyone can read or update them. This is because read and update aren't specified as owner-only actions, so all users are able to perform them. Since delete is specified as an owner only action, only the object's creator can delete the object."
      },
      {
        "heading": "Owner authorization",
        "depth": 3,
        "text": "Here's a table outlining which users are permitted to execute which operations. owner refers to the user who created the object, other refers to all other authenticated users."
      },
      {
        "heading": "Owner authorization",
        "depth": 3,
        "text": "|       | getTodo | listTodos | createTodo | updateTodo | deleteTodo |\n|:------|:-------:|:---------:|:----------:|:----------:|:----------:|\n| owner |    ✅   |     ✅    |     ✅     |      ✅   |     ✅     |\n| other |    ✅   |     ✅    |     ✅     |      ✅   |     ❌     |"
      },
      {
        "heading": "Multiple authorization rules",
        "depth": 3,
        "text": "You may also apply multiple ownership rules on a single @model type."
      },
      {
        "heading": "Multiple authorization rules",
        "depth": 3,
        "text": "For example, imagine you have a type Draft that stores unfinished posts for a blog. You might want to allow the Draft's owner to create, update, delete, and read Draft objects. However, you might also want the Draft's editors to be able to update and read Draft objects."
      },
      {
        "heading": "Multiple authorization rules",
        "depth": 3,
        "text": "To allow for this use case you could use the following type definition:"
      },
      {
        "heading": "Ownership with create mutations",
        "depth": 3,
        "text": "The ownership authorization rule will automatically fill ownership fields unless\ntold explicitly not to do so. To show how this works, lets look at how the create mutation would work for the Draft type above:"
      },
      {
        "heading": "Ownership with create mutations",
        "depth": 3,
        "text": "Let's assume that when I call this mutation I am logged in as someuser@my-domain.com. The result would be:"
      },
      {
        "heading": "Ownership with create mutations",
        "depth": 3,
        "text": "The Mutation.createDraft resolver is smart enough to match your auth rules to attributes and will fill them in by default."
      },
      {
        "heading": "Ownership with create mutations",
        "depth": 3,
        "text": "To specify a list of editors, you could run this:"
      },
      {
        "heading": "Ownership with create mutations",
        "depth": 3,
        "text": "This would return:"
      },
      {
        "heading": "Ownership with create mutations",
        "depth": 3,
        "text": "You can try to perform a modification to owner but this will throw an Unauthorized exception because you are no longer the owner of the object you are trying to create."
      },
      {
        "heading": "Static group authorization",
        "depth": 3,
        "text": "Static group authorization allows you to protect @model types by restricting access\nto a known set of groups. For example, you can allow all Admin users to create,\nupdate, delete, get, and list Salary objects."
      },
      {
        "heading": "Static group authorization",
        "depth": 3,
        "text": "When calling the GraphQL API, if the user credential (as specified by the resolver's $ctx.identity) is not\nenrolled in the Admin group, the operation will fail."
      },
      {
        "heading": "Static group authorization",
        "depth": 3,
        "text": "To enable advanced authorization use cases, you can layer auth rules to provide specialized functionality.\nTo show how you might do that, let's expand the Draft example you started in the Owner Authorization\nsection above. When you last left off, a Draft object could be updated and read by both its owner\nand any of its editors and could be created and deleted only by its owner. Let's change it so that\nnow any member of the \"Admin\" group can also create, update, delete, and read a Draft object."
      },
      {
        "heading": "Dynamic group authorization",
        "depth": 3,
        "text": "With dynamic group authorization, each record contains an attribute specifying what Cognito groups should be able to access it. Use the groupsField argument to specify which attribute in the underlying data store holds this group information. To specify that a single group should have access, use a field of type String. To specify that multiple groups should have access, use a field of type [String]."
      },
      {
        "heading": "Dynamic group authorization",
        "depth": 3,
        "text": "Just as with the other auth rules, you can layer dynamic group rules on top of other rules. Let's again expand the Draft example from the Owner Authorization and Static Group Authorization sections above. When you last left off editors could update and read objects, owners had full access, and members of the admin group had full access to Draft objects. Now you have a new requirement where each record should be able to specify an optional list of groups that can read the draft. This would allow you to share an individual document with an external team, for example."
      },
      {
        "heading": "Dynamic group authorization",
        "depth": 3,
        "text": "With this setup, you could create an object that can be read by the \"BizDev\" group:"
      },
      {
        "heading": "Dynamic group authorization",
        "depth": 3,
        "text": "And another draft that can be read by the \"Marketing\" group:"
      },
      {
        "heading": "public authorization",
        "depth": 3,
        "text": "The public authorization specifies that everyone will be allowed to access the API, behind the scenes the API will be protected with an API Key. To be able to use public the API must have API Key configured. For local execution, this key resides in the file aws-exports.js for the JavaScript library and amplifyconfiguration.json for Android and iOS under the key aws_appsync_apiKey."
      },
      {
        "heading": "public authorization",
        "depth": 3,
        "text": "The @auth directive allows the override of the default provider for a given authorization mode. In the sample above iam is specified as the provider which allows you to use an \"UnAuthenticated Role\" from Cognito Identity Pools for public access instead of an API Key. When used in conjunction with amplify add auth the CLI generates scoped down IAM policies for the \"UnAuthenticated\" role automatically."
      },
      {
        "heading": "private authorization",
        "depth": 3,
        "text": "The private authorization specifies that everyone will be allowed to access the API with a valid JWT token from the configured Cognito User Pool. To be able to use private the API must have Cognito User Pool configured."
      },
      {
        "heading": "private authorization",
        "depth": 3,
        "text": "The @auth directive allows the override of the default provider for a given authorization mode. In the sample above iam is specified as the provider which allows you to use an \"Authenticated Role\" from Cognito Identity Pools for private access. When used in conjunction with amplify add auth the CLI generates scoped down IAM policies for the \"Authenticated\" role automatically."
      },
      {
        "heading": "Authorization using an oidc provider",
        "depth": 3,
        "text": "By using a configured oidc provider for the API, it is possible to authenticate the users against it. In the sample above, oidc is specified as the provider for the owner authorization on the type. The field identityClaim: \"sub\" specifies that the \"sub\" claim from your JWT token is used to provider ownership instead of the default username claim, which is used by the Amazon Cognito JWT."
      },
      {
        "heading": "Combining multiple authorization types",
        "depth": 3,
        "text": "Amplify GraphQL APIs have a primary default authentication type and, optionally, additional secondary authentication types. The objects and fields in the GraphQL schema can have rules with different authorization providers assigned based on the authentication types configured in your app."
      },
      {
        "heading": "Combining multiple authorization types",
        "depth": 3,
        "text": "One of the most common scenarios for multiple authorization rules is for combining public and private access. For example, blogs typically allow public access for viewing a post but only allow a post's creator to update or delete that post."
      },
      {
        "heading": "Combining multiple authorization types",
        "depth": 3,
        "text": "Let's take a look at how you can combine public and private access to achieve this:"
      },
      {
        "heading": "Combining multiple authorization types",
        "depth": 3,
        "text": "The above schema assumes a combination of Amazon Cognito User Pools and API key authentication types"
      },
      {
        "heading": "Combining multiple authorization types",
        "depth": 3,
        "text": "Let's take a look at another example. Here the Post model is protected by Cognito User Pools by default and the owner can perform any operation on the Post type. You can also call getPosts and listPosts from an AWS Lambda function if it is configured with the appropriate IAM policies in its execution role."
      },
      {
        "heading": "Combining multiple authorization types",
        "depth": 3,
        "text": "The above schema assumes a combination of Amazon Cognito User Pools and IAM authentication types"
      },
      {
        "heading": "Allowed authorization mode vs. provider combinations",
        "depth": 3,
        "text": "The following table shows the allowed combinations of authorization modes and providers."
      },
      {
        "heading": "Allowed authorization mode vs. provider combinations",
        "depth": 3,
        "text": "|           | owner | groups | public | private |\n|:----------|:-----:|:------:|:------:|:-------:|\n| userPools |✅|✅||✅|\n| oidc |✅|✅|||\n| apiKey |||✅||\n| iam |||✅|✅|"
      },
      {
        "heading": "Allowed authorization mode vs. provider combinations",
        "depth": 3,
        "text": "Please note that groups is leveraging Cognito User Pools but no provider assignment needed/possible."
      },
      {
        "heading": "Custom claims",
        "depth": 3,
        "text": "@auth supports using custom claims if you do not wish to use the default username or cognito:groups claims from your JWT token which are populated by Amazon Cognito. This can be helpful if you are using tokens from a 3rd party OIDC system or if you wish to populate a claim with a list of groups from an external system, such as when using a Pre Token Generation Lambda Trigger which reads from a database. To use custom claims specify identityClaim or groupClaim as appropriate like in the example below:"
      },
      {
        "heading": "Custom claims",
        "depth": 3,
        "text": "In this example the object owner will check against a user_id claim. Please note that this claim is not available by default if the token is generated by Cognito. Use sub instead if you are using Cognito generated token. Similarly if the user_groups claim contains a \"Moderator\" string then access will be granted."
      },
      {
        "heading": "Custom claims",
        "depth": 3,
        "text": "Note identityField is being deprecated for identityClaim."
      },
      {
        "heading": "Authorizing subscriptions",
        "depth": 3,
        "text": "Prior to version 2.0 of the CLI, @auth rules did not apply to subscriptions. Instead you were required to either turn them off or use Custom Resolvers to manually add authorization checks. In the latest versions @auth protections have been added to subscriptions, however this can introduce different behavior into existing applications: First, owner is now a required argument for Owner-based authorization, as shown below. Second, the selection set will set null on fields when mutations are invoked if per-field @auth is set on that field. Read more here. If you wish to keep the previous behavior set level: public on your model as defined below."
      },
      {
        "heading": "Authorizing subscriptions",
        "depth": 3,
        "text": "When @auth is used subscriptions have a few subtle behavior differences than queries and mutations based on their event based nature. When protecting a model using the owner auth strategy, each subscription request will require that the user is passed as an argument to the subscription request. If the user field is not passed, the subscription connection will fail. In the case where it is passed, the user will only get notified of updates to records for which they are the owner."
      },
      {
        "heading": "Authorizing subscriptions",
        "depth": 3,
        "text": "Subscription filtering uses data passed from mutation to do the filtering. If a mutation does not include owner field in the selection set of a owner based auth, Subscription message won't be fired for that mutation."
      },
      {
        "heading": "Authorizing subscriptions",
        "depth": 3,
        "text": "Alternatively, when the model is protected using the static group auth strategy, the subscription request will only succeed if the user is in an allowed group. Further, the user will only get notifications of updates to records if they are in an allowed group. Note: You don't need to pass the user as an argument in the subscription request, since the resolver will instead check the contents of your JWT token."
      },
      {
        "heading": "Authorizing subscriptions",
        "depth": 3,
        "text": "Dynamic groups have no impact to subscriptions. You will not get notified of any updates to them."
      },
      {
        "heading": "Authorizing subscriptions",
        "depth": 3,
        "text": "For example suppose you have the following schema:"
      },
      {
        "heading": "Authorizing subscriptions",
        "depth": 3,
        "text": "This means that the subscription must look like the following or it will fail:"
      },
      {
        "heading": "Authorizing subscriptions",
        "depth": 3,
        "text": "Note that if your type doesn’t already have an owner field the Transformer will automatically add this for you. Passing in the current user can be done dynamically in your code by using Auth.currentAuthenticatedUser() in JavaScript, AWSMobileClient.default().username in iOS, or AWSMobileClient.getInstance().getUsername() in Android."
      },
      {
        "heading": "Authorizing subscriptions",
        "depth": 3,
        "text": "In the case of groups if you define the following:"
      },
      {
        "heading": "Authorizing subscriptions",
        "depth": 3,
        "text": "Then you don’t need to pass an argument, as the resolver will check the contents of your JWT token at subscription time and ensure you are in the “Admin” group."
      },
      {
        "heading": "Authorizing subscriptions",
        "depth": 3,
        "text": "Finally, if you use both owner and group authorization then the username argument becomes optional. This means the following:"
      },
      {
        "heading": "Authorizing subscriptions",
        "depth": 3,
        "text": "If you don’t pass the user in, but are a member of an allowed group, the subscription will notify you of records added."
      },
      {
        "heading": "Authorizing subscriptions",
        "depth": 3,
        "text": "If you don’t pass the user in, but are NOT a member of an allowed group, the subscription will fail to connect."
      },
      {
        "heading": "Authorizing subscriptions",
        "depth": 3,
        "text": "If you pass the user in who IS the owner but is NOT a member of a group, the subscription will notify you of records added of which you are the owner."
      },
      {
        "heading": "Authorizing subscriptions",
        "depth": 3,
        "text": "If you pass the user in who is NOT the owner and is NOT a member of a group, the subscription will not notify you of anything as there are no records for which you own"
      },
      {
        "heading": "Authorizing subscriptions",
        "depth": 3,
        "text": "You may disable authorization checks on subscriptions or completely turn off subscriptions as well by specifying either public or off in @model:"
      },
      {
        "heading": "Field level authorization",
        "depth": 3,
        "text": "The @auth directive specifies that access to a specific field should be restricted\naccording to its own set of rules. Here are a few situations where this is useful:"
      },
      {
        "heading": "Field level authorization",
        "depth": 3,
        "text": "Protect access to a field that has different permissions than the parent model"
      },
      {
        "heading": "Field level authorization",
        "depth": 3,
        "text": "You might want to have a user model where some fields, like username, are a part of the\npublic profile and the ssn field is visible to owners."
      },
      {
        "heading": "Field level authorization",
        "depth": 3,
        "text": "Protect access to a @connection resolver based on some attribute in the source object"
      },
      {
        "heading": "Field level authorization",
        "depth": 3,
        "text": "This schema will protect access to Post objects connected to a user based on an attribute\nin the User model. You may turn off top level queries by specifying queries: null in the @model\ndeclaration which restricts access such that queries must go through the @connection resolvers\nto reach the model."
      },
      {
        "heading": "Field level authorization",
        "depth": 3,
        "text": "Protect mutations such that certain fields can have different access rules than the parent model"
      },
      {
        "heading": "Field level authorization",
        "depth": 3,
        "text": "When used on field definitions, @auth directives protect all operations by default.\nTo protect read operations, a resolver is added to the protected field that implements authorization logic.\nTo protect mutation operations, logic is added to existing mutations that will be run if the mutation's input\ncontains the protected field. For example, here is a model where owners and admins can read employee\nsalaries but only admins may create or update them."
      },
      {
        "heading": "Field level authorization",
        "depth": 3,
        "text": "Note: The delete operation, when used in @auth directives on field definitions, translates\nto protecting the update mutation such that the field cannot be set to null unless authorized."
      },
      {
        "heading": "Field level authorization",
        "depth": 3,
        "text": "Note: When specifying operations as a part of the @auth rule on a field, the operations not included in the operations list are not protected by default. For example, let's say you have the following schema:"
      },
      {
        "heading": "Field level authorization",
        "depth": 3,
        "text": "In this schema, only the owner of the object has the authorization to perform update operations on the content field. But this does not prevent any other owner (any user other than the creator or owner of the object) to update some other field in the object owned by another user. If you want to prevent update operations on a field, the user would need to explicitly add auth rules to restrict access to that field. One of the ways would be to explicitly specify @auth rules on the fields that you would want to protect like the following:"
      },
      {
        "heading": "Field level authorization",
        "depth": 3,
        "text": "You can also provide explicit deny rules to your field like the following:"
      },
      {
        "heading": "Field level authorization",
        "depth": 3,
        "text": "You can also combine top-level @auth rules on the type with field level auth rules. For example, let's consider the following schema:"
      },
      {
        "heading": "Field level authorization",
        "depth": 3,
        "text": "In the above schema users in the Admin group have the authorization to create, read, delete and update (except the content field in the object of another owner) for the type Todo.\nAn owner of an object has the authorization to create Todo types and read all the objects of type Todo. In addition, an owner can perform an update operation on the Todo object only when the content field is present as a part of the input.\nAny other user -- who isn't an owner of an object isn't authorized to update that object."
      },
      {
        "heading": "Per-Field with subscriptions",
        "depth": 4,
        "text": "When setting per-field @auth the Transformer will alter the response of mutations for those fields by setting them to null in order to prevent sensitive data from being sent over subscriptions. For example in the schema below:"
      },
      {
        "heading": "Per-Field with subscriptions",
        "depth": 4,
        "text": "Subscribers might be a member of the \"Admins\" group and should get notified of the new item, however they should not get the ssn field. If you run the following mutation:"
      },
      {
        "heading": "Per-Field with subscriptions",
        "depth": 4,
        "text": "The mutation will run successfully, however ssn will return null in the GraphQL response. This prevents anyone in the \"Admins\" group who is subscribed to updates from receiving the private information. Subscribers would still receive the name and address. The data is still written and this can be verified by running a query."
      },
      {
        "heading": "Generates",
        "depth": 4,
        "text": "The @auth directive will add authorization snippets to any relevant resolver mapping templates at compile time. Different operations use different methods of authorization."
      },
      {
        "heading": "Generates",
        "depth": 4,
        "text": "Owner Authorization"
      },
      {
        "heading": "Generates",
        "depth": 4,
        "text": "The generated resolvers would be protected like so:"
      },
      {
        "heading": "Generates",
        "depth": 4,
        "text": "Mutation.createX: Verify the requesting user has a valid credential and automatically set the owner attribute to equal $ctx.identity.username."
      },
      {
        "heading": "Generates",
        "depth": 4,
        "text": "Mutation.updateX: Update the condition expression so that the DynamoDB UpdateItem operation only succeeds if the record's owner attribute equals the caller's $ctx.identity.username."
      },
      {
        "heading": "Generates",
        "depth": 4,
        "text": "Mutation.deleteX: Update the condition expression so that the DynamoDB DeleteItem operation only succeeds if the record's owner attribute equals the caller's $ctx.identity.username."
      },
      {
        "heading": "Generates",
        "depth": 4,
        "text": "Query.getX: In the response mapping template verify that the result's owner attribute is the same as the $ctx.identity.username. If it is not return null."
      },
      {
        "heading": "Generates",
        "depth": 4,
        "text": "Query.listX: In the response mapping template filter the result's items such that only items with an owner attribute that is the same as the $ctx.identity.username are returned."
      },
      {
        "heading": "Generates",
        "depth": 4,
        "text": "@connection resolvers: In the response mapping template filter the result's items such that only items with an owner attribute that is the same as the $ctx.identity.username are returned. This is not enabled when using the queries argument."
      },
      {
        "heading": "Static group authorization",
        "depth": 3,
        "text": "Static group auth is simpler than the others. The generated resolvers would be protected like so:"
      },
      {
        "heading": "Static group authorization",
        "depth": 3,
        "text": "Mutation.createX: Verify the requesting user has a valid credential and that $ctx.identity.claims.get(\"cognito:groups\") contains the Admin group. If it does not, fail."
      },
      {
        "heading": "Static group authorization",
        "depth": 3,
        "text": "Mutation.updateX: Verify the requesting user has a valid credential and that $ctx.identity.claims.get(\"cognito:groups\") contains the Admin group. If it does not, fail."
      },
      {
        "heading": "Static group authorization",
        "depth": 3,
        "text": "Mutation.deleteX: Verify the requesting user has a valid credential and that $ctx.identity.claims.get(\"cognito:groups\") contains the Admin group. If it does not, fail."
      },
      {
        "heading": "Static group authorization",
        "depth": 3,
        "text": "Query.getX: Verify the requesting user has a valid credential and that $ctx.identity.claims.get(\"cognito:groups\") contains the Admin group. If it does not, fail."
      },
      {
        "heading": "Static group authorization",
        "depth": 3,
        "text": "Query.listX: Verify the requesting user has a valid credential and that $ctx.identity.claims.get(\"cognito:groups\") contains the Admin group. If it does not, fail."
      },
      {
        "heading": "Static group authorization",
        "depth": 3,
        "text": "@connection resolvers: Verify the requesting user has a valid credential and that $ctx.identity.claims.get(\"cognito:groups\") contains the Admin group. If it does not, fail. This is not enabled when using the queries argument."
      },
      {
        "heading": "Dynamic group authorization",
        "depth": 3,
        "text": "The generated resolvers would be protected like so:"
      },
      {
        "heading": "Dynamic group authorization",
        "depth": 3,
        "text": "Mutation.createX: Verify the requesting user has a valid credential and that it contains a claim to at least one group passed to the query in the $ctx.args.input.groups argument."
      },
      {
        "heading": "Dynamic group authorization",
        "depth": 3,
        "text": "Mutation.updateX: Update the condition expression so that the DynamoDB UpdateItem operation only succeeds if the record's groups attribute contains at least one of the caller's claimed groups via $ctx.identity.claims.get(\"cognito:groups\")."
      },
      {
        "heading": "Dynamic group authorization",
        "depth": 3,
        "text": "Mutation.deleteX: Update the condition expression so that the DynamoDB DeleteItem operation only succeeds if the record's groups attribute contains at least one of the caller's claimed groups via $ctx.identity.claims.get(\"cognito:groups\")"
      },
      {
        "heading": "Dynamic group authorization",
        "depth": 3,
        "text": "Query.getX: In the response mapping template verify that the result's groups attribute contains at least one of the caller's claimed groups via $ctx.identity.claims.get(\"cognito:groups\")."
      },
      {
        "heading": "Dynamic group authorization",
        "depth": 3,
        "text": "Query.listX: In the response mapping template filter the result's items such that only items with a groups attribute that contains at least one of the caller's claimed groups via $ctx.identity.claims.get(\"cognito:groups\")."
      },
      {
        "heading": "Dynamic group authorization",
        "depth": 3,
        "text": "@connection resolver: In the response mapping template filter the result's items such that only items with a groups attribute that contains at least one of the caller's claimed groups via $ctx.identity.claims.get(\"cognito:groups\"). This is not enabled when using the queries argument."
      }
    ],
    "source": "export const meta = {\n  title: `Setup authorization rules`,\n  description: `Add authorization rules to your GraphQL schema to control access to your data.`,\n};\n\n<MigrationAlert isLegacy url={\"/cli/graphql/authorization-rules\"}/>\n\n## @auth\n\nAuthorization is required for applications to interact with your GraphQL API. **API Keys** are best used for public APIs (or parts of your schema which you wish to be public) or prototyping, and you must specify the expiration time before deploying. **IAM** authorization uses [Signature Version 4](https://docs.aws.amazon.com/general/latest/gr/signature-version-4.html) to make request with policies attached to Roles. OIDC tokens provided by **Amazon Cognito User Pools** or 3rd party OpenID Connect providers can also be used for authorization, and simply enabling this provides a simple access control requiring users to authenticate to be granted top level access to API actions. You can set finer grained access controls using `@auth` on your schema which leverages authorization metadata provided as part of these tokens or set on the database items themselves.\n\n`@auth` object types that are annotated with `@auth` are protected by a set of authorization rules giving you additional controls than the top level authorization on an API. You may use the `@auth` directive on object type definitions and field definitions in your project's schema.\n\nWhen using the `@auth` directive on object type definitions that are also annotated with\n`@model`, all resolvers that return objects of that type will be protected. When using the\n`@auth` directive on a field definition, a resolver will be added to the field that authorize access\nbased on attributes found in the parent type.\n\n### Definition\n\n```graphql\n# When applied to a type, augments the application with\n# owner and group-based authorization rules.\ndirective @auth(rules: [AuthRule!]!) on OBJECT | FIELD_DEFINITION\ninput AuthRule {\n  allow: AuthStrategy!\n  provider: AuthProvider\n  ownerField: String # defaults to \"owner\" when using owner auth\n  identityClaim: String # defaults to \"username\" when using owner auth\n  groupClaim: String # defaults to \"cognito:groups\" when using Group auth\n  groups: [String]  # Required when using Static Group auth\n  groupsField: String # defaults to \"groups\" when using Dynamic Group auth\n  operations: [ModelOperation] # Required for finer control\n\n  # The following arguments are deprecated. It is encouraged to use the 'operations' argument.\n  queries: [ModelQuery]\n  mutations: [ModelMutation]\n}\nenum AuthStrategy { owner groups private public }\nenum AuthProvider { apiKey iam oidc userPools }\nenum ModelOperation { create update delete read }\n\n# The following objects are deprecated. It is encouraged to use ModelOperations.\nenum ModelQuery { get list }\nenum ModelMutation { create update delete }\n```\n\n> Note: The operations argument was added to replace the 'queries' and 'mutations' arguments. The 'queries' and 'mutations' arguments will continue to work but it is encouraged to move to 'operations'. If both are provided, the 'operations' argument takes precedence over 'queries'.\n\n### Owner authorization\n\nBy default, enabling `owner` authorization allows any signed in user to create records.\n\n```graphql\n# The simplest case\ntype Post @model @auth(rules: [{ allow: owner }]) {\n  id: ID!\n  title: String!\n}\n\n# The long form way\ntype Post\n  @model\n  @auth(\n    rules: [\n      { allow: owner, ownerField: \"owner\", operations: [create, update, delete, read] },\n    ]) {\n  id: ID!\n  title: String!\n  owner: String\n}\n```\n\n<Callout>\n\nOwner authorization requires an authentication type of **Amazon Cognito User Pools** to be enabled in your app.\n\n</Callout>\n\nOwner authorization specifies whether a user can access or operate against an object. To do so, each object will get an `ownerField` field (by default `owner` will be added to the object if not specified) that stores ownership information and is verified in various ways during resolver execution.\n\nYou can use the `operations` argument to specify which operations are enabled as follows:\n\n- **read**: Allow the user to perform queries (`get` and `list` operations) against the API.\n- **create**: Inject the logged in user's identity as the `ownerField` automatically.\n- **update**: Add conditional update that checks the stored `ownerField` is the same as the signed in user.\n- **delete**: Add conditional update that checks the stored `ownerField` is the same as the signed in user.\n\nYou must ensure that the `create` operations rule is specified explicitly or inferred from defaults to ensure that the owner's identity is stored with the record so it can be verified on subsequent requests.\n\n```graphql\n# owner identity inferred from defaults on every object\ntype Post @model @auth(rules: [{ allow: owner }]) {\n  id: ID!\n  title: String!\n}\n\n# owner identity specified explicitly on every object\ntype Post @model @auth(rules: [{ allow: owner, operations: [create] }]) {\n  id: ID!\n  title: String!\n}\n\n# owner identity not stored on objects\ntype Post @model @auth(rules: [{ allow: owner, operations: [read] }]) {\n  id: ID!\n  title: String!\n}\n```\n\n<Callout>\n\nWhen specifying operations as a part of the `@auth` rule, the operations not included in the list are not protected by default.\n\n</Callout>\n\nLet's take a look at a few examples:\n\n```graphql\ntype Todo @model\n  @auth(rules: [{ allow: owner }]) {\n  id: ID!\n  updatedAt: AWSDateTime!\n  content: String!\n}\n```\n\nIn this schema, only the owner of the object has the authorization to perform read (`getTodo` and `listTodos`), update (`updateTodo`), and delete (`deleteTodo`) operations on the owner created object. This prevents the object from being updated or deleted by users other than the creator of the object.\n\nHere's a table outlining which users are permitted to execute which operations. **owner** refers to the user who created the object, **other** refers to all other authenticated users.\n\n|       | getTodo | listTodos | createTodo | updateTodo | deleteTodo |\n|:------|:-------:|:---------:|:----------:|:----------:|:----------:|\n| owner |    ✅   |     ✅    |     ✅     |      ✅   |     ✅     |\n| other |    ❌   |     ❌    |     ✅     |      ❌   |     ❌     |\n\nNext, let's say that you wanted to modify the schema to allow only the owner of the object to be able to update or delete, but allow any authenticated user to read the objects.\n\n```graphql\ntype Todo @model\n  @auth(rules: [{ allow: owner, operations: [create, delete, update] }]) {\n  id: ID!\n  updatedAt: AWSDateTime!\n  content: String!\n}\n```\n\nIn this schema, only the owner of the object has the authorization to perform update (`updateTodo`) and delete (`deleteTodo`) operations on the owner created object, but anyone can read them (`getTodo`, `listTodos`). This prevents the object from being updated or deleted by users other than the creator of the object while allowing all authenticated users of the app to read them.\n\nHere's a table outlining which users are permitted to execute which operations. **owner** refers to the user who created the object, **other** refers to all other authenticated users.\n\n|       | getTodo | listTodos | createTodo | updateTodo | deleteTodo |\n|:------|:-------:|:---------:|:----------:|:----------:|:----------:|\n| owner |    ✅   |     ✅    |     ✅     |      ✅   |     ✅     |\n| other |    ✅   |     ✅    |     ✅     |      ❌   |     ❌     |\n\nNext, let's say that you wanted to modify the schema to allow only the owner of the object to be able to delete, but allow anyone to create, read, and update.\n\n```graphql\ntype Todo @model\n  @auth(rules: [{ allow: owner, operations: [create, delete] }]) {\n  id: ID!\n  updatedAt: AWSDateTime!\n  content: String!\n}\n```\n\nIn this schema, only the owner of the object has the authorization to perform delete operations on the owner created object, but anyone can read or update them. This is because `read` and `update` aren't specified as owner-only actions, so all users are able to perform them. Since `delete` is specified as an owner only action, only the object's creator can delete the object.\n\nHere's a table outlining which users are permitted to execute which operations. **owner** refers to the user who created the object, **other** refers to all other authenticated users.\n\n|       | getTodo | listTodos | createTodo | updateTodo | deleteTodo |\n|:------|:-------:|:---------:|:----------:|:----------:|:----------:|\n| owner |    ✅   |     ✅    |     ✅     |      ✅   |     ✅     |\n| other |    ✅   |     ✅    |     ✅     |      ✅   |     ❌     |\n\n### Multiple authorization rules\n\nYou may also apply multiple ownership rules on a single `@model` type.\n\nFor example, imagine you have a type **Draft** that stores unfinished posts for a blog. You might want to allow the **Draft's** owner to `create`, `update`, `delete`, and `read` **Draft** objects. However, you might also want the **Draft's editors** to be able to update and read **Draft** objects.\n\nTo allow for this use case you could use the following type definition:\n\n```graphql\ntype Draft @model\n  @auth(rules: [\n    # Defaults to use the \"owner\" field.\n    { allow: owner },\n\n    # Authorize the update mutation and both queries.\n    { allow: owner, ownerField: \"editors\", operations: [update, read] }\n  ]) {\n  id: ID!\n  title: String!\n  content: String\n  owner: String\n  editors: [String]\n}\n```\n\n### Ownership with create mutations\n\nThe ownership authorization rule will automatically fill ownership fields unless\ntold explicitly not to do so. To show how this works, lets look at how the create mutation would work for the **Draft** type above:\n\n```graphql\nmutation CreateDraft {\n  createDraft(input: { title: \"A new draft\" }) {\n    id\n    title\n    owner\n    editors\n  }\n}\n```\n\nLet's assume that when I call this mutation I am logged in as `someuser@my-domain.com`. The result would be:\n\n```json\n{\n    \"data\": {\n        \"createDraft\": {\n            \"id\": \"...\",\n            \"title\": \"A new draft\",\n            \"owner\": \"someuser@my-domain.com\",\n            \"editors\": null\n        }\n    }\n}\n```\n\nThe `Mutation.createDraft` resolver is smart enough to match your auth rules to attributes and will fill them in by default.\n\nTo specify a list of **editors**, you could run this:\n\n```graphql\nmutation CreateDraft {\n  createDraft(\n    input: {\n      title: \"A new draft\",\n      editors: [\"editor1@my-domain.com\", \"editor2@my-domain.com\"]\n    }\n  ) {\n    id\n    title\n    owner\n    editors\n  }\n}\n```\n\nThis would return:\n\n```json\n{\n    \"data\": {\n        \"createDraft\": {\n            \"id\": \"...\",\n            \"title\": \"A new draft\",\n            \"owner\": \"someuser@my-domain.com\",\n            \"editors\": [\"editor1@my-domain.com\", \"editor2@my-domain.com\"]\n        }\n    }\n}\n```\n\nYou can try to perform a modification to **owner** but this will throw an **Unauthorized** exception because you are no longer the owner of the object you are trying to create.\n\n```graphql\nmutation CreateDraft {\n  createDraft(\n    input: {\n      title: \"A new draft\",\n      editors: [],\n      owner: null\n    }\n  ) {\n    id\n    title\n    owner\n    editors\n  }\n}\n```\n\n### Static group authorization\n\nStatic group authorization allows you to protect `@model` types by restricting access\nto a known set of groups. For example, you can allow all **Admin** users to create,\nupdate, delete, get, and list Salary objects.\n\n```graphql\ntype Salary @model @auth(rules: [{ allow: groups, groups: [\"Admin\"] }]) {\n  id: ID!\n  wage: Int\n  currency: String\n}\n```\n\nWhen calling the GraphQL API, if the user credential (as specified by the resolver's `$ctx.identity`) is not\nenrolled in the *Admin* group, the operation will fail.\n\nTo enable advanced authorization use cases, you can layer auth rules to provide specialized functionality.\nTo show how you might do that, let's expand the **Draft** example you started in the **Owner Authorization**\nsection above. When you last left off, a **Draft** object could be updated and read by both its owner\nand any of its editors and could be created and deleted only by its owner. Let's change it so that\nnow any member of the \"Admin\" group can also create, update, delete, and read a **Draft** object.\n\n```graphql\ntype Draft @model\n  @auth(rules: [\n    # Defaults to use the \"owner\" field.\n    { allow: owner },\n\n    # Authorize the update mutation and both queries.\n    { allow: owner, ownerField: \"editors\", operations: [update] },\n\n    # Admin users can access any operation.\n    { allow: groups, groups: [\"Admin\"] }\n  ]) {\n  id: ID!\n  title: String!\n  content: String\n  owner: String\n  editors: [String]!\n}\n```\n\n### Dynamic group authorization\n\n```graphql\n# Dynamic group authorization with multiple groups\ntype Post @model @auth(rules: [{ allow: groups, groupsField: \"groups\" }]) {\n  id: ID!\n  title: String\n  groups: [String]\n}\n\n# Dynamic group authorization with a single group\ntype Post @model @auth(rules: [{ allow: groups, groupsField: \"group\" }]) {\n  id: ID!\n  title: String\n  group: String\n}\n```\n\nWith dynamic group authorization, each record contains an attribute specifying what Cognito groups should be able to access it. Use the `groupsField` argument to specify which attribute in the underlying data store holds this group information. To specify that a single group should have access, use a field of type `String`. To specify that multiple groups should have access, use a field of type `[String]`.\n\nJust as with the other auth rules, you can layer dynamic group rules on top of other rules. Let's again expand the **Draft** example from the **Owner Authorization** and **Static Group Authorization** sections above. When you last left off editors could update and read objects, owners had full access, and members of the admin group had full access to **Draft** objects. Now you have a new requirement where each record should be able to specify an optional list of groups that can read the draft. This would allow you to share an individual document with an external team, for example.\n\n```graphql\ntype Draft @model\n  @auth(rules: [\n    # Defaults to use the \"owner\" field.\n    { allow: owner },\n\n    # Authorize the update mutation and both queries.\n    { allow: owner, ownerField: \"editors\", operations: [update] },\n\n    # Admin users can access any operation.\n    { allow: groups, groups: [\"Admin\"] }\n\n    # Each record may specify which groups may read them.\n    { allow: groups, groupsField: \"groupsCanAccess\", operations: [read] }\n  ]) {\n  id: ID!\n  title: String!\n  content: String\n  owner: String\n  editors: [String]!\n  groupsCanAccess: [String]!\n}\n```\n\nWith this setup, you could create an object that can be read by the \"BizDev\" group:\n\n```graphql\nmutation CreateDraft {\n  createDraft(input: {\n    title: \"A new draft\",\n    editors: [],\n    groupsCanAccess: [\"BizDev\"]\n  }) {\n    id\n    groupsCanAccess\n  }\n}\n```\n\nAnd another draft that can be read by the \"Marketing\" group:\n\n```graphql\nmutation CreateDraft {\n  createDraft(input: {\n    title: \"Another draft\",\n    editors: [],\n    groupsCanAccess: [\"Marketing\"]\n  }) {\n    id\n    groupsCanAccess\n  }\n}\n```\n\n### `public` authorization\n\n```graphql\n# The simplest case\ntype Post @model @auth(rules: [{ allow: public }]) {\n  id: ID!\n  title: String!\n}\n```\n\nThe `public` authorization specifies that everyone will be allowed to access the API, behind the scenes the API will be protected with an API Key. To be able to use `public` the API must have API Key configured. For local execution, this key resides in the file `aws-exports.js` for the JavaScript library and `amplifyconfiguration.json` for Android and iOS under the key `aws_appsync_apiKey`.\n\n```graphql\n# public authorization with provider override\ntype Post @model @auth(rules: [{ allow: public, provider: iam }]) {\n  id: ID!\n  title: String!\n}\n```\n\nThe `@auth` directive allows the override of the default provider for a given authorization mode. In the sample above `iam` is specified as the provider which allows you to use an \"UnAuthenticated Role\" from Cognito Identity Pools for public access instead of an API Key. When used in conjunction with amplify add auth the CLI generates scoped down IAM policies for the \"UnAuthenticated\" role automatically.\n\n### `private` authorization\n\n```graphql\n# The simplest case\ntype Post @model @auth(rules: [{ allow: private }]) {\n  id: ID!\n  title: String!\n}\n```\n\nThe `private` authorization specifies that everyone will be allowed to access the API with a valid JWT token from the configured Cognito User Pool. To be able to use `private` the API must have Cognito User Pool configured.\n\n```graphql\n# private authorization with provider override\ntype Post @model @auth(rules: [{ allow: private, provider: iam }]) {\n  id: ID!\n  title: String!\n}\n```\n\nThe `@auth` directive allows the override of the default provider for a given authorization mode. In the sample above `iam` is specified as the provider which allows you to use an \"Authenticated Role\" from Cognito Identity Pools for private access. When used in conjunction with amplify add auth the CLI generates scoped down IAM policies for the \"Authenticated\" role automatically.\n\n### Authorization using an `oidc` provider\n\n```graphql\n# owner authorization with provider override\ntype Profile @model @auth(rules: [{ allow: owner, provider: oidc, identityClaim: \"sub\" }]) {\n  id: ID!\n  displayNAme: String!\n}\n```\n\nBy using a configured `oidc` provider for the API, it is possible to authenticate the users against it. In the sample above, `oidc` is specified as the provider for the `owner` authorization on the type. The field `identityClaim: \"sub\"` specifies that the `\"sub\"` claim from your JWT token is used to provider ownership instead of the default `username` claim, which is used by the Amazon Cognito JWT.\n\n### Combining multiple authorization types\n\nAmplify GraphQL APIs have a primary **default** authentication type and, optionally, additional secondary authentication types. The objects and fields in the GraphQL schema can have rules with different authorization providers assigned based on the authentication types configured in your app.\n\nOne of the most common scenarios for multiple authorization rules is for combining public and private access. For example, blogs typically allow public access for viewing a post but only allow a post's creator to update or delete that post.\n\nLet's take a look at how you can combine public and private access to achieve this:\n\n```graphql\ntype Post @model\n  @auth (\n    rules: [\n      # allow all authenticated users ability to create posts\n      # allow owners ability to update and delete their posts\n      { allow: owner },\n\n      # allow all authenticated users to read posts\n      { allow: private, operations: [read] },\n\n      # allow all guest users (not authenticated) to read posts\n      { allow: public, operations: [read] }\n    ]\n  ) {\n  id: ID!\n  title: String\n  owner: String\n}\n```\n\n<Callout>\n\nThe above schema assumes a combination of **Amazon Cognito User Pools** and **API key** authentication types\n\n</Callout>\n\nLet's take a look at another example. Here the `Post` model is protected by Cognito User Pools by default and the `owner` can perform any operation on the `Post` type. You can also call `getPosts` and `listPosts` from an AWS Lambda function if it is configured with the appropriate IAM policies in its execution role.\n\n```graphql\ntype Post @model\n  @auth (\n    rules: [\n      { allow: owner },\n      { allow: private, provider: iam, operations: [read] }\n    ]\n  ) {\n  id: ID!\n  title: String\n  owner: String\n}\n```\n\n<Callout>\n\nThe above schema assumes a combination of **Amazon Cognito User Pools** and **IAM** authentication types\n\n</Callout>\n\n### Allowed authorization mode vs. provider combinations\n\nThe following table shows the allowed combinations of authorization modes and providers.\n\n|           | owner | groups | public | private |\n|:----------|:-----:|:------:|:------:|:-------:|\n| userPools |✅|✅||✅|\n| oidc |✅|✅|||\n| apiKey |||✅||\n| iam |||✅|✅|\n\nPlease note that `groups` is leveraging Cognito User Pools but no provider assignment needed/possible.\n\n### Custom claims\n\n`@auth` supports using custom claims if you do not wish to use the default `username` or `cognito:groups` claims from your JWT token which are populated by Amazon Cognito. This can be helpful if you are using tokens from a 3rd party OIDC system or if you wish to populate a claim with a list of groups from an external system, such as when using a [Pre Token Generation Lambda Trigger](https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-lambda-pre-token-generation.html) which reads from a database. To use custom claims specify `identityClaim` or `groupClaim` as appropriate like in the example below:\n\n```graphql\ntype Post @model\n  @auth(rules: [\n    { allow: owner, identityClaim: \"user_id\" },\n    { allow: groups, groups: [\"Moderator\"], groupClaim: \"user_groups\" }\n  ]) {\n  id: ID!\n  owner: String\n  postname: String\n  content: String\n}\n```\n\nIn this example the object owner will check against a `user_id` claim. Please note that this claim is not available by default if the token is generated by Cognito. Use `sub` instead if you are using Cognito generated token. Similarly if the `user_groups` claim contains a \"Moderator\" string then access will be granted.\n\n<Callout>\n\nNote `identityField` is being deprecated for `identityClaim`.\n\n</Callout>\n\n### Authorizing subscriptions\n\n<Callout warning>\n\nPrior to version 2.0 of the CLI, `@auth` rules did not apply to subscriptions. Instead you were required to either turn them off or use [Custom Resolvers](/cli/graphql-transformer/resolvers#custom-resolvers) to manually add authorization checks. In the latest versions `@auth` protections have been added to subscriptions, however this can introduce different behavior into existing applications: First, `owner` is now a required argument for Owner-based authorization, as shown below. Second, the selection set will set `null` on fields when mutations are invoked if per-field `@auth` is set on that field. [Read more here](#per-field-with-subscriptions). If you wish to keep the previous behavior set `level: public` on your model as defined below.\n\n</Callout>\n\nWhen `@auth` is used subscriptions have a few subtle behavior differences than queries and mutations based on their event based nature. When protecting a model using the owner auth strategy, each subscription request will **require** that the user is passed as an argument to the subscription request. If the user field is not passed, the subscription connection will fail. In the case where it is passed, the user will only get notified of updates to records for which they are the owner.\n\n<Callout warning>\n Subscription filtering uses data passed from mutation to do the filtering. If a mutation does not include `owner` field in the selection set of a owner based auth, Subscription message won't be fired for that mutation.\n</Callout>\n\nAlternatively, when the model is protected using the static group auth strategy, the subscription request will only succeed if the user is in an allowed group. Further, the user will only get notifications of updates to records if they are in an allowed group. Note: You don't need to pass the user as an argument in the subscription request, since the resolver will instead check the contents of your JWT token.\n\n<Callout>\nDynamic groups have no impact to subscriptions. You will not get notified of any updates to them.\n</Callout>\n\nFor example suppose you have the following schema:\n\n```graphql\ntype Post @model\n  @auth(rules: [{allow: owner}]) {\n  id: ID!\n  owner: String\n  postname: String\n  content: String\n}\n```\n\nThis means that the subscription must look like the following or it will fail:\n\n```graphql\nsubscription OnCreatePost {\n  onCreatePost(owner: “Bob”){\n    postname\n    content\n  }\n}\n```\n\nNote that if your type doesn’t already have an `owner` field the Transformer will automatically add this for you. Passing in the current user can be done dynamically in your code by using [Auth.currentAuthenticatedUser()](https://docs.amplify.aws/lib/auth/manageusers/q/platform/js#retrieve-current-authenticated-user) in JavaScript, [AWSMobileClient.default().username](/sdk/auth/working-with-api.md/q/platform/ios#utility-properties) in iOS, or [AWSMobileClient.getInstance().getUsername()](/sdk/auth/working-with-api.md/q/platform/android#utility-properties) in Android.\n\nIn the case of groups if you define the following:\n\n```graphql\ntype Post @model\n  @auth(rules: [{ allow: groups, groups: [\"Admin\"] }]) {\n  id: ID!\n  owner: String\n  postname: String\n  content: String\n}\n```\n\nThen you don’t need to pass an argument, as the resolver will check the contents of your JWT token at subscription time and ensure you are in the “Admin” group.\n\nFinally, if you use both owner and group authorization then the username argument becomes optional. This means the following:\n\n- If you don’t pass the user in, but are a member of an allowed group, the subscription will notify you of records added.\n- If you don’t pass the user in, but are NOT a member of an allowed group, the subscription will fail to connect.\n- If you pass the user in who IS the owner but is NOT a member of a group, the subscription will notify you of records added of which you are the owner.\n- If you pass the user in who is NOT the owner and is NOT a member of a group, the subscription will not notify you of anything as there are no records for which you own\n\nYou may disable authorization checks on subscriptions or completely turn off subscriptions as well by specifying either `public` or `off` in `@model`:\n\n```graphql\n@model (subscriptions: { level: public })\n```\n\n### Field level authorization\n\nThe `@auth` directive specifies that access to a specific field should be restricted\n according to its own set of rules. Here are a few situations where this is useful:\n\n**Protect access to a field that has different permissions than the parent model**\n\nYou might want to have a user model where some fields, like *username*, are a part of the\npublic profile and the *ssn* field is visible to owners.\n\n```graphql\ntype User @model {\n  id: ID!\n  username: String\n  ssn: String @auth(rules: [{ allow: owner, ownerField: \"username\" }])\n}\n```\n\n**Protect access to a `@connection` resolver based on some attribute in the source object**\n\nThis schema will protect access to Post objects connected to a user based on an attribute\nin the User model. You may turn off top level queries by specifying `queries: null` in the `@model`\ndeclaration which restricts access such that queries must go through the `@connection` resolvers\nto reach the model.\n\n```graphql\ntype User @model {\n  id: ID!\n  username: String\n  posts: [Post]\n    @connection(name: \"UserPosts\")\n    @auth(rules: [{ allow: owner, ownerField: \"username\" }])\n}\ntype Post @model(queries: null) { ... }\n```\n\n**Protect mutations such that certain fields can have different access rules than the parent model**\n\nWhen used on field definitions, `@auth` directives protect all operations by default.\nTo protect read operations, a resolver is added to the protected field that implements authorization logic.\nTo protect mutation operations, logic is added to existing mutations that will be run if the mutation's input\ncontains the protected field. For example, here is a model where owners and admins can read employee\nsalaries but only admins may create or update them.\n\n```graphql\ntype Employee @model {\n  id: ID!\n  email: String\n  username: String\n\n  # Owners & members of the \"Admin\" group may read employee salaries.\n  # Only members of the \"Admin\" group may create an employee with a salary\n  # or update a salary.\n  salary: String\n    @auth(rules: [\n      { allow: owner, ownerField: \"username\", operations: [read] },\n      { allow: groups, groups: [\"Admin\"], operations: [create, update, read] }\n    ])\n}\n```\n\n**Note:** The `delete` operation, when used in `@auth` directives on field definitions, translates\nto protecting the update mutation such that the field cannot be set to null unless authorized.\n\n**Note:** When specifying operations as a part of the `@auth` rule on a field, the operations not included in the operations list are not protected by default. For example, let's say you have the following schema:\n\n```graphql\ntype Todo @model {\n  id: ID!\n  owner: String\n  updatedAt: AWSDateTime!\n  content: String! @auth(rules: [{ allow: owner, operations: [update] }])\n}\n```\n\nIn this schema, only the owner of the object has the authorization to perform update operations on the `content` field. But this does not prevent any other owner (any user other than the creator or owner of the object) to update some other field in the object owned by another user. If you want to prevent update operations on a field, the user would need to explicitly add auth rules to restrict access to that field. One of the ways would be to explicitly specify @auth rules on the fields that you would want to protect like the following:\n\n```graphql\ntype Todo @model {\n  id: ID!\n  owner: String\n  updatedAt: AWSDateTime! @auth(rules: [{ allow: owner, operations: [update] }]) // or @auth(rules: [{ allow: groups, groups: [\"Admins\"] }])\n  content: String! @auth(rules: [{ allow: owner, operations: [update] }])\n}\n```\n\nYou can also provide explicit deny rules to your field like the following:\n\n```graphql\ntype Todo @model {\n  id: ID!\n  owner: String\n  updatedAt: AWSDateTime! @auth(rules: [{ allow: groups, groups: [\"ForbiddenGroup\"], operations: [] }])\n  content: String! @auth(rules: [{ allow: owner, operations: [update] }])\n}\n```\n\nYou can also combine top-level @auth rules on the type with field level auth rules. For example, let's consider the following schema:\n\n```graphql\ntype Todo @model\n  @auth(rules: [{ allow: groups, groups: [\"Admin\"], operations:[update] }]) {\n  id: ID!\n  owner: String\n  updatedAt: AWSDateTime!\n  content: String! @auth(rules: [{ allow: owner, operations: [update] }])\n}\n```\n\nIn the above schema users in the `Admin` group have the authorization to create, read, delete and update (except the `content` field in the object of another owner) for the type Todo.\nAn `owner` of an object has the authorization to create Todo types and read all the objects of type Todo. In addition, an `owner` can perform an update operation on the Todo object only when the `content` field is present as a part of the input.\nAny other user -- who isn't an owner of an object isn't authorized to update that object.\n\n#### Per-Field with subscriptions\n\nWhen setting per-field `@auth` the Transformer will alter the response of mutations for those fields by setting them to `null` in order to prevent sensitive data from being sent over subscriptions. For example in the schema below:\n\n```graphql\ntype Employee @model\n  @auth(rules: [\n    { allow: owner },\n    { allow: groups, groups: [\"Admins\"] }\n  ]) {\n  id: ID!\n  name: String!\n  address: String!\n  ssn: String @auth(rules: [{allow: owner}])\n}\n```\n\nSubscribers might be a member of the \"Admins\" group and should get notified of the new item, however they should not get the `ssn` field. If you run the following mutation:\n\n```graphql\nmutation {\n  createEmployee(input: {\n    name: \"Nadia\"\n    address: \"123 First Ave\"\n    ssn: \"392-95-2716\"\n  }){\n    name\n    address\n    ssn\n  }\n}\n```\n\nThe mutation will run successfully, however `ssn` will return null in the GraphQL response. This prevents anyone in the \"Admins\" group who is subscribed to updates from receiving the private information. Subscribers would still receive the `name` and `address`. The data is still written and this can be verified by running a query.\n\n#### Generates\n\nThe `@auth` directive will add authorization snippets to any relevant resolver mapping templates at compile time. Different operations use different methods of authorization.\n\n**Owner Authorization**\n\n```graphql\ntype Post @model @auth(rules: [{ allow: owner }]) {\n  id: ID!\n  title: String!\n}\n```\n\nThe generated resolvers would be protected like so:\n\n- `Mutation.createX`: Verify the requesting user has a valid credential and automatically set the **owner** attribute to equal `$ctx.identity.username`.\n- `Mutation.updateX`: Update the condition expression so that the DynamoDB `UpdateItem` operation only succeeds if the record's **owner** attribute equals the caller's `$ctx.identity.username`.\n- `Mutation.deleteX`: Update the condition expression so that the DynamoDB `DeleteItem` operation only succeeds if the record's **owner** attribute equals the caller's `$ctx.identity.username`.\n- `Query.getX`: In the response mapping template verify that the result's **owner** attribute is the same as the `$ctx.identity.username`. If it is not return `null`.\n- `Query.listX`: In the response mapping template filter the result's **items** such that only items with an **owner** attribute that is the same as the `$ctx.identity.username` are returned.\n- `@connection` resolvers: In the response mapping template filter the result's **items** such that only items with an **owner** attribute that is the same as the `$ctx.identity.username` are returned. This is not enabled when using the `queries` argument.\n\n### Static group authorization\n\n```graphql\ntype Post @model @auth(rules: [{ allow: groups, groups: [\"Admin\"] }]) {\n  id: ID!\n  title: String!\n  groups: String\n}\n```\n\nStatic group auth is simpler than the others. The generated resolvers would be protected like so:\n\n- `Mutation.createX`: Verify the requesting user has a valid credential and that `$ctx.identity.claims.get(\"cognito:groups\")` contains the **Admin** group. If it does not, fail.\n- `Mutation.updateX`: Verify the requesting user has a valid credential and that `$ctx.identity.claims.get(\"cognito:groups\")` contains the **Admin** group. If it does not, fail.\n- `Mutation.deleteX`: Verify the requesting user has a valid credential and that `$ctx.identity.claims.get(\"cognito:groups\")` contains the **Admin** group. If it does not, fail.\n- `Query.getX`: Verify the requesting user has a valid credential and that `$ctx.identity.claims.get(\"cognito:groups\")` contains the **Admin** group. If it does not, fail.\n- `Query.listX`: Verify the requesting user has a valid credential and that `$ctx.identity.claims.get(\"cognito:groups\")` contains the **Admin** group. If it does not, fail.\n- `@connection` resolvers: Verify the requesting user has a valid credential and that `$ctx.identity.claims.get(\"cognito:groups\")` contains the **Admin** group. If it does not, fail. This is not enabled when using the `queries` argument.\n\n### Dynamic group authorization\n\n```graphql\ntype Post @model @auth(rules: [{ allow: groups, groupsField: \"groups\" }]) {\n  id: ID!\n  title: String!\n  groups: String\n}\n```\n\nThe generated resolvers would be protected like so:\n\n- `Mutation.createX`: Verify the requesting user has a valid credential and that it contains a claim to at least one group passed to the query in the `$ctx.args.input.groups` argument.\n- `Mutation.updateX`: Update the condition expression so that the DynamoDB `UpdateItem` operation only succeeds if the record's **groups** attribute contains at least one of the caller's claimed groups via `$ctx.identity.claims.get(\"cognito:groups\")`.\n- `Mutation.deleteX`: Update the condition expression so that the DynamoDB `DeleteItem` operation only succeeds if the record's **groups** attribute contains at least one of the caller's claimed groups via `$ctx.identity.claims.get(\"cognito:groups\")`\n- `Query.getX`: In the response mapping template verify that the result's **groups** attribute contains at least one of the caller's claimed groups via `$ctx.identity.claims.get(\"cognito:groups\")`.\n- `Query.listX`: In the response mapping template filter the result's **items** such that only items with a **groups** attribute that contains at least one of the caller's claimed groups via `$ctx.identity.claims.get(\"cognito:groups\")`.\n- `@connection` resolver: In the response mapping template filter the result's **items** such that only items with a **groups** attribute that contains at least one of the caller's claimed groups via `$ctx.identity.claims.get(\"cognito:groups\")`. This is not enabled when using the `queries` argument.\n",
    "meta": {
      "title": "Setup authorization rules",
      "description": "Add authorization rules to your GraphQL schema to control access to your data.",
      "subcategory": "API (GraphQL)",
      "category": "Amplify CLI (Legacy)"
    },
    "filename": "/cli-legacy/graphql-transformer/auth"
  },
  {
    "searchableText": [
      {
        "heading": "@key",
        "depth": 2,
        "text": "The @key directive makes it simple to configure custom index structures for @model types."
      },
      {
        "heading": "@key",
        "depth": 2,
        "text": "Amazon DynamoDB is a key-value and document database that delivers single-digit millisecond performance at any scale but making it work for your access patterns requires a bit of forethought. DynamoDB query operations may use at most two attributes to efficiently query data. The first query argument passed to a query (the hash key) must use strict equality and the second attribute (the sort key) may use gt, ge, lt, le, eq, beginsWith, and between. DynamoDB can effectively implement a wide variety of access patterns that are powerful enough for the majority of applications."
      },
      {
        "heading": "@key",
        "depth": 2,
        "text": "When modeling your data during schema design there are common patterns that you may need to leverage. We provide a fully working schema with 17 patterns related to relational designs."
      },
      {
        "heading": "Definition",
        "depth": 2,
        "text": "Argument"
      },
      {
        "heading": "Definition",
        "depth": 2,
        "text": "| Argument  | Description  |\n|---|---|\n| fields  | A list of fields that should comprise the @key, used in conjunction with an @model type. The first field in the list will always be the HASH key. If two fields are provided the second field will be the SORT key. If more than two fields are provided, a single composite SORT key will be created from a combination of fields[1...n]. All generated GraphQL queries & mutations will be updated to work with custom @key directives. |\n| name  | When provided, specifies the name of the secondary index. When omitted, specifies that the @key is defining the primary index. You may have at most one primary key per table and therefore you may have at most one @key that does not specify a name per @model type.  |\n| queryField  | When defining a secondary index (by specifying the name argument), this specifies that a new top level query field that queries the secondary index should be generated with the given name.  |"
      },
      {
        "heading": "How to use @key",
        "depth": 2,
        "text": "For an introduction to the @key directive, let's start by looking at a basic Todo app schema with only an @model directive."
      },
      {
        "heading": "How to use @key",
        "depth": 2,
        "text": "By default, the @model directive will enable the following 2 data access patterns:"
      },
      {
        "heading": "How to use @key",
        "depth": 2,
        "text": "getTodo - Get a Todo by id"
      },
      {
        "heading": "How to use @key",
        "depth": 2,
        "text": "listTodos - Query all Todos"
      },
      {
        "heading": "How to use @key",
        "depth": 2,
        "text": "You will often need additional data access patterns. For example, in a Todo app, you may want to fetch Todos by status. The @key directive would allow you to add this additional data access pattern with a single new line of code:"
      },
      {
        "heading": "How to use @key",
        "depth": 2,
        "text": "Using the new todosByStatus query you can fetch todos by status:"
      },
      {
        "heading": "How to use @key",
        "depth": 2,
        "text": "Next, let's take a closer look at how this works by examining a few more common data access patterns and how to model them."
      },
      {
        "heading": "Designing Data Models using @key",
        "depth": 2,
        "text": "When designing data models using the @key directive, the first step should be to write down your application's expected access patterns. For example, let's say you were building an e-commerce application\nand needed to implement access patterns like:"
      },
      {
        "heading": "Designing Data Models using @key",
        "depth": 2,
        "text": "Get customers by email."
      },
      {
        "heading": "Designing Data Models using @key",
        "depth": 2,
        "text": "Get orders by customer by createdAt."
      },
      {
        "heading": "Designing Data Models using @key",
        "depth": 2,
        "text": "Get items by order by status by createdAt."
      },
      {
        "heading": "Designing Data Models using @key",
        "depth": 2,
        "text": "Get items by status by createdAt."
      },
      {
        "heading": "Designing Data Models using @key",
        "depth": 2,
        "text": "Let's take a look at how you would define custom keys to implement these access patterns in your schema.graphql."
      },
      {
        "heading": "Example: Get customers by email",
        "depth": 3,
        "text": "A @key without a name specifies the key for the DynamoDB table's primary index. You may only provide 1 @key without a name per @model type."
      },
      {
        "heading": "Example: Get customers by email",
        "depth": 3,
        "text": "The example above shows the simplest case where you are specifying that the table's primary index should have a simple key where the hash key is email. This allows you to get unique customers by their email."
      },
      {
        "heading": "Example: Get customers by email",
        "depth": 3,
        "text": "This is great for simple lookup operations, but what if you need to perform slightly more complex queries?"
      },
      {
        "heading": "Example: Get orders by customer email by createdAt",
        "depth": 3,
        "text": "This @key above allows you to efficiently query Order objects by both a customerEmail and the createdAt time stamp. The @key above creates a DynamoDB table where the primary index's hash key is customerEmail and the sort key is createdAt. This allows you to write queries like this:"
      },
      {
        "heading": "Example: Get orders by customer email by createdAt",
        "depth": 3,
        "text": "The query above shows how you can use compound key structures to implement more powerful query patterns on top of DynamoDB but you are not quite done yet."
      },
      {
        "heading": "Example: Get orders by customer email by createdAt",
        "depth": 3,
        "text": "Given that DynamoDB limits you to query by at most two attributes at a time, the @key directive helps by streamlining the process of creating composite sort keys such that you can support querying by more than two attributes at a time. For example, you can implement “Get items by orderId, status, and createdAt” as well as “Get items by status and createdAt” for a single @model with this schema."
      },
      {
        "heading": "Example: Get orders by customer email by createdAt",
        "depth": 3,
        "text": "The primary @key with 3 fields performs a bit more magic than the 1 and 2 field variants. The first field orderId will be the HASH key as expected, but the SORT key will be a new composite key named status#createdAt that is made of the status and createdAt fields on the @model. The @key directive creates the table structures and also generates resolvers that inject composite key values for you during queries and mutations."
      },
      {
        "heading": "Example: Get orders by customer email by createdAt",
        "depth": 3,
        "text": "Using this schema, you can query the primary index to get IN_TRANSIT items created in 2019 for a given order."
      },
      {
        "heading": "Example: Get orders by customer email by createdAt",
        "depth": 3,
        "text": "The query above exposes the statusCreatedAt argument that allows you to configure DynamoDB key condition expressions without worrying about how the composite key is formed under the hood. Using the same schema, you can get all PENDING items created in 2019 by querying the secondary index \"ByStatus\" via the Query.itemsByStatus field."
      },
      {
        "heading": "Evolving APIs with @key",
        "depth": 2,
        "text": "There are a few important things to think about when making changes to APIs using @key. When you need to enable a new access pattern or change an existing access pattern you should follow these steps."
      },
      {
        "heading": "Evolving APIs with @key",
        "depth": 2,
        "text": "Create a new index that enables the new or updated access pattern."
      },
      {
        "heading": "Evolving APIs with @key",
        "depth": 2,
        "text": "If adding an @key with 3 or more fields, you will need to back-fill the new composite sort key for existing data. With a @key(fields: [\"email\", \"status\", \"date\"]), you would need to backfill the status#date field with composite key values made up of each object's status and date fields joined by a #. You do not need to backfill data for @key directives with 1 or 2 fields."
      },
      {
        "heading": "Evolving APIs with @key",
        "depth": 2,
        "text": "Deploy your additive changes and update any downstream applications to use the new access pattern."
      },
      {
        "heading": "Evolving APIs with @key",
        "depth": 2,
        "text": "Once you are certain that you do not need the old index, remove its @key and deploy the API again."
      },
      {
        "heading": "Deploying multiple secondary indices (GSI)",
        "depth": 2,
        "text": "You can make multiple global secondary index (@key with name parameter set) updates on one \"amplify push\". Under the hood, Amplify CLI needs to locally sequence multiple individual deployments to your DynamoDB table because each GSI change requires time to create the new index."
      },
      {
        "heading": "Troubleshooting",
        "depth": 3,
        "text": "If your deployment fails locally when updating multiple GSIs, you'll have the ability to run:"
      },
      {
        "heading": "Troubleshooting",
        "depth": 3,
        "text": "amplify push --iterative-rollback to rollback the last-known-good state"
      },
      {
        "heading": "Troubleshooting",
        "depth": 3,
        "text": "amplify push --force rollback the last-known-good state and try redeploying your changes again using."
      },
      {
        "heading": "Troubleshooting",
        "depth": 3,
        "text": "If you're running into the error above during amplify push, it is likely that you don't have this feature enabled. To enable multiple GSI updates, set the \"enableIterativeGsiUpdates\" feature flag to true in your amplify/cli.json."
      },
      {
        "heading": "Combining @key with @connection",
        "depth": 2,
        "text": "Secondary indexes created with the @key directive can be used to resolve connections when creating relationships between types. To learn how this works, check out the documentation for @connection."
      }
    ],
    "source": "export const meta = {\n  title: `Index your data with keys`,\n  description: `The @key directive makes it simple to configure custom index structures for @model types.`,\n};\n\n<MigrationAlert isLegacy url={\"/cli/graphql/data-modeling\"}/>\n\n## @key\n\nThe `@key` directive makes it simple to configure custom index structures for `@model` types.\n\nAmazon DynamoDB is a key-value and document database that delivers single-digit millisecond performance at any scale but making it work for your access patterns requires a bit of forethought. DynamoDB query operations may use at most two attributes to efficiently query data. The first query argument passed to a query (the hash key) must use strict equality and the second attribute (the sort key) may use gt, ge, lt, le, eq, beginsWith, and between. DynamoDB can effectively implement a wide variety of access patterns that are powerful enough for the majority of applications.\n\nWhen modeling your data during schema design there are common patterns that you may need to leverage. [We provide a fully working schema with 17 patterns related to relational designs](/cli/graphql-transformer/dataaccess).\n\n## Definition\n\n```graphql\ndirective @key(fields: [String!]!, name: String, queryField: String) on OBJECT\n```\n\n**Argument**\n\n| Argument  | Description  |\n|---|---|\n| fields  | A list of fields that should comprise the @key, used in conjunction with an `@model` type. The first field in the list will always be the **HASH** key. If two fields are provided the second field will be the **SORT** key. If more than two fields are provided, a single composite **SORT** key will be created from a combination of `fields[1...n]`. All generated GraphQL queries & mutations will be updated to work with custom `@key` directives. |\n| name  | When provided, specifies the name of the secondary index. When omitted, specifies that the `@key` is defining the primary index. You may have at most one primary key per table and therefore you may have at most one `@key` that does not specify a **name** per `@model` type.  |\n| queryField  | When defining a secondary index (by specifying the *name* argument), this specifies that a new top level query field that queries the secondary index should be generated with the given name.  |\n\n## How to use @key\n\nFor an introduction to the `@key` directive, let's start by looking at a basic `Todo` app schema with only an `@model` directive.\n\n```graphql\ntype Todo @model {\n  id: ID!\n  name: String!\n  status: String!\n}\n```\n\nBy default, the `@model` directive will enable the following 2 data access patterns:\n\n1. `getTodo` - Get a Todo by `id`\n2. `listTodos` - Query all Todos\n\nYou will often need additional data access patterns. For example, in a Todo app, you may want to fetch Todos by `status`. The `@key` directive would allow you to add this additional data access pattern with a single new line of code:\n\n```graphql\ntype Todo @model\n  @key(name: \"todosByStatus\", fields: [\"status\"], queryField: \"todosByStatus\") {\n  id: ID!\n  name: String!\n  status: String!\n}\n```\n\nUsing the new `todosByStatus` query you can fetch todos by `status`:\n\n```graphql\nquery todosByStatus {\n  todosByStatus(status: \"completed\") {\n    items {\n      id\n      name\n      status\n    }\n  }\n}\n```\n\nNext, let's take a closer look at how this works by examining a few more common data access patterns and how to model them.\n\n## Designing Data Models using @key\n\nWhen designing data models using the `@key` directive, the first step should be to write down your application's expected access patterns. For example, let's say you were building an e-commerce application\nand needed to implement access patterns like:\n\n1. Get customers by email.\n2. Get orders by customer by createdAt.\n3. Get items by order by status by createdAt.\n4. Get items by status by createdAt.\n\nLet's take a look at how you would define custom keys to implement these access patterns in your `schema.graphql`.\n\n### Example: Get customers by email\n\n```graphql\ntype Customer @model @key(fields: [\"email\"]) {\n  email: String!\n  username: String\n}\n```\n\nA `@key` without a *name* specifies the key for the DynamoDB table's primary index. You may only provide 1 `@key` without a *name* per `@model` type.\n\nThe example above shows the simplest case where you are specifying that the table's primary index should have a simple key where the hash key is *email*. This allows you to get unique customers by their *email*.\n\n```graphql\nquery GetCustomerById {\n  getCustomer(email:\"me@email.com\") {\n    email\n    username\n  }\n}\n```\n\nThis is great for simple lookup operations, but what if you need to perform slightly more complex queries?\n\n### Example: Get orders by customer email by createdAt\n\n```graphql\ntype Order @model @key(fields: [\"customerEmail\", \"createdAt\"]) {\n  customerEmail: String!\n  createdAt: AWSDateTime!\n  orderId: ID!\n}\n```\n\nThis `@key` above allows you to efficiently query *Order* objects by both a *customerEmail* and the *createdAt* time stamp. The `@key` above creates a DynamoDB table where the primary index's hash key is *customerEmail* and the sort key is *createdAt*. This allows you to write queries like this:\n\n```graphql\nquery ListOrdersForCustomerIn2019 {\n  listOrders(customerEmail:\"me@email.com\", createdAt: { beginsWith: \"2019\" }) {\n    items {\n      orderId\n      customerEmail\n      createdAt\n    }\n  }\n}\n```\n\nThe query above shows how you can use compound key structures to implement more powerful query patterns on top of DynamoDB but you are not quite done yet.\n\nGiven that DynamoDB limits you to query by at most two attributes at a time, the `@key` directive helps by streamlining the process of creating composite sort keys such that you can support querying by more than two attributes at a time. For example, you can implement “Get items by `orderId`, `status`, and `createdAt”` as well as “Get items by `status` and `createdAt”` for a single `@model` with this schema.\n\n```graphql\ntype Item @model\n  @key(fields: [\"orderId\", \"status\", \"createdAt\"])\n  @key(name: \"ByStatus\", fields: [\"status\", \"createdAt\"], queryField: \"itemsByStatus\") {\n  orderId: ID!\n  status: Status!\n  createdAt: AWSDateTime!\n  name: String!\n}\nenum Status {\n  DELIVERED\n  IN_TRANSIT\n  PENDING\n  UNKNOWN\n}\n```\n\nThe primary `@key` with 3 fields performs a bit more magic than the 1 and 2 field variants. The first field orderId will be the **HASH** key as expected, but the **SORT** key will be a new composite key named *status#createdAt* that is made of the *status* and *createdAt* fields on the @model. The `@key` directive creates the table structures and also generates resolvers that inject composite key values for you during queries and mutations.\n\nUsing this schema, you can query the primary index to get IN_TRANSIT items created in 2019 for a given order.\n\n```graphql\n# Get items for order by status by createdAt.\nquery ListInTransitItemsForOrder {\n  listItems(orderId:\"order1\", statusCreatedAt: { beginsWith: { status: IN_TRANSIT, createdAt: \"2019\" }}) {\n    items {\n      orderId\n      status\n      createdAt\n      name\n    }\n  }\n}\n```\n\nThe query above exposes the *statusCreatedAt* argument that allows you to configure DynamoDB key condition expressions without worrying about how the composite key is formed under the hood. Using the same schema, you can get all PENDING items created in 2019 by querying the secondary index \"ByStatus\" via the `Query.itemsByStatus` field.\n\n```graphql\nquery ItemsByStatus {\n  itemsByStatus(status: PENDING, createdAt: {beginsWith:\"2019\"}) {\n    items {\n      orderId\n      status\n      createdAt\n      name\n    }\n    nextToken\n  }\n}\n```\n\n## Evolving APIs with @key\n\nThere are a few important things to think about when making changes to APIs using `@key`. When you need to enable a new access pattern or change an existing access pattern you should follow these steps.\n\n1. Create a new index that enables the new or updated access pattern.\n2. If adding an `@key` with 3 or more fields, you will need to back-fill the new composite sort key for existing data. With a `@key(fields: [\"email\", \"status\", \"date\"])`, you would need to backfill the `status#date` field with composite key values made up of each object's *status* and *date* fields joined by a `#`. You do not need to backfill data for `@key` directives with 1 or 2 fields.\n3. Deploy your additive changes and update any downstream applications to use the new access pattern.\n4. Once you are certain that you do not need the old index, remove its `@key` and deploy the API again.\n\n## Deploying multiple secondary indices (GSI)\n\nYou can make multiple global secondary index (`@key` with `name` parameter set) updates on one \"amplify push\". Under the hood, Amplify CLI needs to locally sequence multiple individual deployments to your DynamoDB table because each GSI change requires time to create the new index.\n\n### Troubleshooting\n\nIf your deployment fails locally when updating multiple GSIs, you'll have the ability to run:\n\n- `amplify push --iterative-rollback` to rollback the last-known-good state\n- `amplify push --force` rollback the last-known-good state and try redeploying your changes again using.\n\n```console\nAttempting to mutate more than 1 global secondary index at the same time.\n```\n\nIf you're running into the error above during `amplify push`, it is likely that you don't have this feature enabled. To enable multiple GSI updates, set the [\"enableIterativeGsiUpdates\" feature flag](/cli/reference/feature-flags#enableIterativeGsiUpdates) to `true` in your `amplify/cli.json`.\n\n## Combining @key with @connection\n\nSecondary indexes created with the `@key` directive can be used to resolve connections when creating relationships between types. To learn how this works, check out [the documentation for @connection](/cli/graphql-transformer/connection).\n",
    "meta": {
      "title": "Index your data with keys",
      "description": "The @key directive makes it simple to configure custom index structures for @model types.",
      "subcategory": "API (GraphQL)",
      "category": "Amplify CLI (Legacy)"
    },
    "filename": "/cli-legacy/graphql-transformer/key"
  },
  {
    "searchableText": [
      {
        "heading": "@model",
        "depth": 2,
        "text": "Object types that are annotated with @model are top-level entities in the\ngenerated API. Objects annotated with @model are stored in Amazon DynamoDB and are\ncapable of being protected via @auth, related to other objects via @connection,\nand streamed into Amazon OpenSearch via @searchable. You may also apply the\n@versioned directive to instantly add a version field and conflict detection to a\nmodel type."
      },
      {
        "heading": "Definition",
        "depth": 3,
        "text": "The following SDL defines the @model directive that allows you to easily define\ntop level object types in your API that are backed by Amazon DynamoDB."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Define a GraphQL object type and annotate it with the @model directive to store\nobjects of that type in DynamoDB and automatically configure CRUDL queries and\nmutations."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "You may also override the names of any generated queries, mutations and subscriptions, or remove operations entirely."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "This would create and configure a single query field post(id: ID!): Post and\nno mutation fields."
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "Model directive automatically adds createdAt and updatedAt timestamps to each entities. The timestamp field names can be changed by passing timestamps attribute to the directive"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "The above schema will generate Post with createdOn and updatedOn fields as shown"
      },
      {
        "heading": "Usage",
        "depth": 3,
        "text": "The automatically added createdAt and updatedAt fields can't be set in create or update mutation. If these fields need to be controlled as part of the mutation, they should be in the input schema and should have AWSDateTime as their type"
      },
      {
        "heading": "Generates",
        "depth": 3,
        "text": "A single @model directive configures the following AWS resources:"
      },
      {
        "heading": "Generates",
        "depth": 3,
        "text": "An Amazon DynamoDB table with PAY_PER_REQUEST billing mode enabled by default."
      },
      {
        "heading": "Generates",
        "depth": 3,
        "text": "An AWS AppSync DataSource configured to access the table above."
      },
      {
        "heading": "Generates",
        "depth": 3,
        "text": "An AWS IAM role attached to the DataSource that allows AWS AppSync to call the above table on your behalf."
      },
      {
        "heading": "Generates",
        "depth": 3,
        "text": "Up to 8 resolvers (create, update, delete, get, list, onCreate, onUpdate, onDelete) but this is configurable via the queries, mutations, and subscriptions arguments on the @model directive."
      },
      {
        "heading": "Generates",
        "depth": 3,
        "text": "Input objects for create, update, and delete mutations."
      },
      {
        "heading": "Generates",
        "depth": 3,
        "text": "Filter input objects that allow you to filter objects in list queries and connection fields."
      },
      {
        "heading": "Generates",
        "depth": 3,
        "text": "For list queries the default number of objects returned is 100. You can override this behavior by setting the limit argument."
      },
      {
        "heading": "Generates",
        "depth": 3,
        "text": "This input schema document"
      },
      {
        "heading": "Generates",
        "depth": 3,
        "text": "would generate the following schema parts"
      }
    ],
    "source": "export const meta = {\n  title: `Define your model types`,\n  description: `Specify the various types that make up your schema.`,\n};\n\n<MigrationAlert isLegacy url={\"/cli/graphql/data-modeling\"}/>\n\n## @model\n\nObject types that are annotated with `@model` are top-level entities in the\ngenerated API. Objects annotated with `@model` are stored in Amazon DynamoDB and are\ncapable of being protected via `@auth`, related to other objects via `@connection`,\nand streamed into Amazon OpenSearch via `@searchable`. You may also apply the\n`@versioned` directive to instantly add a version field and conflict detection to a\nmodel type.\n\n### Definition\n\nThe following SDL defines the `@model` directive that allows you to easily define\ntop level object types in your API that are backed by Amazon DynamoDB.\n\n```graphql\ndirective @model(\n  queries: ModelQueryMap\n  mutations: ModelMutationMap\n  subscriptions: ModelSubscriptionMap\n  timestamps: TimestampConfiguration\n) on OBJECT\ninput ModelMutationMap {\n  create: String\n  update: String\n  delete: String\n}\ninput ModelQueryMap {\n  get: String\n  list: String\n}\ninput ModelSubscriptionMap {\n  onCreate: [String]\n  onUpdate: [String]\n  onDelete: [String]\n  level: ModelSubscriptionLevel\n}\nenum ModelSubscriptionLevel {\n  off\n  public\n  on\n}\ninput TimestampConfiguration {\n  createdAt: String\n  updatedAt: String\n}\n```\n\n### Usage\n\nDefine a GraphQL object type and annotate it with the `@model` directive to store\nobjects of that type in DynamoDB and automatically configure CRUDL queries and\nmutations.\n\n```graphql\ntype Post @model {\n  id: ID! # id: ID! is a required attribute.\n  title: String!\n  tags: [String!]!\n}\n```\n\nYou may also override the names of any generated queries, mutations and subscriptions, or remove operations entirely.\n\n```graphql\ntype Post @model(queries: { get: \"post\" }, mutations: null, subscriptions: null) {\n  id: ID!\n  title: String!\n  tags: [String!]!\n}\n```\n\nThis would create and configure a single query field `post(id: ID!): Post` and\nno mutation fields.\n\nModel directive automatically adds createdAt and updatedAt timestamps to each entities. The timestamp field names can be changed by passing `timestamps` attribute to the directive\n\n```graphql\ntype Post @model(timestamps:{createdAt: \"createdOn\", updatedAt: \"updatedOn\"}) {\n  id: ID!\n  title: String!\n  tags: [String!]!\n}\n```\n\nThe above schema will generate Post with `createdOn` and `updatedOn` fields as shown\n\n```graphql\ntype Post {\n  id: ID!\n  title: String!\n  tags: [String!]!\n  createdOn: AWSDateTime!\n  updatedOn: AWSDateTime!\n}\n```\n\nThe automatically added `createdAt` and `updatedAt` fields can't be set in create or update mutation. If these fields need to be controlled as part of the mutation, they should be in the input schema and should have `AWSDateTime` as their type\n\n```graphql\ntype Post @model {\n  id: ID!\n  title: String!\n  tags: [String!]!\n  createdAt: AWSDateTime!\n  updatedAt: AWSDateTime!\n}\n```\n\n### Generates\n\nA single `@model` directive configures the following AWS resources:\n\n- An Amazon DynamoDB table with PAY_PER_REQUEST billing mode enabled by default.\n- An AWS AppSync DataSource configured to access the table above.\n- An AWS IAM role attached to the DataSource that allows AWS AppSync to call the above table on your behalf.\n- Up to 8 resolvers (create, update, delete, get, list, onCreate, onUpdate, onDelete) but this is configurable via the `queries`, `mutations`, and `subscriptions` arguments on the `@model` directive.\n- Input objects for create, update, and delete mutations.\n- Filter input objects that allow you to filter objects in list queries and connection fields.\n- For list queries the default number of objects returned is 100. You can override this behavior by setting the **limit** argument.\n\nThis input schema document\n\n```graphql\ntype Post @model {\n  id: ID!\n  title: String\n  metadata: MetaData\n}\ntype MetaData {\n  category: Category\n}\nenum Category { comedy news }\n```\n\nwould generate the following schema parts\n\n```graphql\ntype Post {\n  id: ID!\n  title: String!\n  metadata: MetaData\n  createdAt: AWSDatetime\n  updatedAt: AWSDateTime\n}\n\ntype MetaData {\n  category: Category\n}\n\nenum Category {\n  comedy\n  news\n}\n\ninput MetaDataInput {\n  category: Category\n}\n\nenum ModelSortDirection {\n  ASC\n  DESC\n}\n\ntype ModelPostConnection {\n  items: [Post]\n  nextToken: String\n}\n\ninput ModelStringFilterInput {\n  ne: String\n  eq: String\n  le: String\n  lt: String\n  ge: String\n  gt: String\n  contains: String\n  notContains: String\n  between: [String]\n  beginsWith: String\n}\n\ninput ModelIDFilterInput {\n  ne: ID\n  eq: ID\n  le: ID\n  lt: ID\n  ge: ID\n  gt: ID\n  contains: ID\n  notContains: ID\n  between: [ID]\n  beginsWith: ID\n}\n\ninput ModelIntFilterInput {\n  ne: Int\n  eq: Int\n  le: Int\n  lt: Int\n  ge: Int\n  gt: Int\n  contains: Int\n  notContains: Int\n  between: [Int]\n}\n\ninput ModelFloatFilterInput {\n  ne: Float\n  eq: Float\n  le: Float\n  lt: Float\n  ge: Float\n  gt: Float\n  contains: Float\n  notContains: Float\n  between: [Float]\n}\n\ninput ModelBooleanFilterInput {\n  ne: Boolean\n  eq: Boolean\n}\n\ninput ModelPostFilterInput {\n  id: ModelIDFilterInput\n  title: ModelStringFilterInput\n  and: [ModelPostFilterInput]\n  or: [ModelPostFilterInput]\n  not: ModelPostFilterInput\n}\n\ntype Query {\n  getPost(id: ID!): Post\n  listPosts(filter: ModelPostFilterInput, limit: Int, nextToken: String): ModelPostConnection\n}\n\ninput CreatePostInput {\n  title: String!\n  metadata: MetaDataInput\n}\n\ninput UpdatePostInput {\n  id: ID!\n  title: String\n  metadata: MetaDataInput\n}\n\ninput DeletePostInput {\n  id: ID\n}\n\ntype Mutation {\n  createPost(input: CreatePostInput!): Post\n  updatePost(input: UpdatePostInput!): Post\n  deletePost(input: DeletePostInput!): Post\n}\n\ntype Subscription {\n  onCreatePost: Post @aws_subscribe(mutations: [\"createPost\"])\n  onUpdatePost: Post @aws_subscribe(mutations: [\"updatePost\"])\n  onDeletePost: Post @aws_subscribe(mutations: [\"deletePost\"])\n}\n```\n",
    "meta": {
      "title": "Define your model types",
      "description": "Specify the various types that make up your schema.",
      "subcategory": "API (GraphQL)",
      "category": "Amplify CLI (Legacy)"
    },
    "filename": "/cli-legacy/graphql-transformer/model"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "The Amplify CLI provides GraphQL directives to enhance your schema with additional capabilities such as custom indexes, authorization rules, function triggers, and more."
      },
      {
        "heading": "Amplify-provided directives",
        "depth": 2,
        "text": "@model: Defines top level object types in your API that are backed by Amazon DynamoDB"
      },
      {
        "heading": "Amplify-provided directives",
        "depth": 2,
        "text": "@key: Configures custom index structures for @model types"
      },
      {
        "heading": "Amplify-provided directives",
        "depth": 2,
        "text": "@auth: Defines authorization rules for your @model types and fields"
      },
      {
        "heading": "Amplify-provided directives",
        "depth": 2,
        "text": "@connection: Defines 1:1, 1:M, and N:M relationships between @model types"
      },
      {
        "heading": "Amplify-provided directives",
        "depth": 2,
        "text": "@function: Configures a Lambda function resolvers for a field"
      },
      {
        "heading": "Amplify-provided directives",
        "depth": 2,
        "text": "@http: Configures an HTTP resolver for a field"
      },
      {
        "heading": "Amplify-provided directives",
        "depth": 2,
        "text": "@predictions: Queries an orchestration of AI/ML services such as Amazon Rekognition, Amazon Translate, and/or Amazon Polly"
      },
      {
        "heading": "Amplify-provided directives",
        "depth": 2,
        "text": "@searchable: Makes your data searchable by streaming it to Amazon OpenSearch"
      },
      {
        "heading": "Amplify-provided directives",
        "depth": 2,
        "text": "@versioned: Defines the versioning and conflict resolution strategy for an @model type"
      },
      {
        "heading": "AWS AppSync-provided directives",
        "depth": 2,
        "text": "The following directives are supported by the AppSync service and can be used within the Amplify GraphQL schemas. These will not be processed by Amplify CLI but passed through to the service as is and will be present in the output schema. For example, Amplify's @auth directive will add these directives under the hood to the output schema."
      },
      {
        "heading": "AWS AppSync-provided directives",
        "depth": 2,
        "text": "@aws_api_key"
      },
      {
        "heading": "AWS AppSync-provided directives",
        "depth": 2,
        "text": "@aws_iam"
      },
      {
        "heading": "AWS AppSync-provided directives",
        "depth": 2,
        "text": "@aws_oidc"
      },
      {
        "heading": "AWS AppSync-provided directives",
        "depth": 2,
        "text": "@aws_cognito_user_pools"
      },
      {
        "heading": "AWS AppSync-provided directives",
        "depth": 2,
        "text": "@aws_auth"
      },
      {
        "heading": "AWS AppSync-provided directives",
        "depth": 2,
        "text": "@aws_subscribe"
      },
      {
        "heading": "AWS AppSync-provided directives",
        "depth": 2,
        "text": "Learn more about these directives in the AWS AppSync Developer Guide."
      },
      {
        "heading": "3rd party directives",
        "depth": 2,
        "text": "@algolia: Add serverless search to your Amplify API with Algolia"
      },
      {
        "heading": "3rd party directives",
        "depth": 2,
        "text": "@ttl: Enable DynamoDB's time-to-live feature to auto-delete old entries in your AWS Amplify API"
      },
      {
        "heading": "3rd party directives",
        "depth": 2,
        "text": "@firehose: Add a simple interceptor to all of your Amplify API mutations and queries"
      },
      {
        "heading": "3rd party directives",
        "depth": 2,
        "text": "@retain: Enable the \"Retain\" deletion policy for your Amplify-generated DynamoDB tables"
      },
      {
        "heading": "3rd party directives",
        "depth": 2,
        "text": "Looking to build your own transformers & directives? Check out the guide on how to author your own transformer & directives."
      }
    ],
    "source": "export const meta = {\n  title: `Directives`,\n  description: `The Amplify CLI provides GraphQL directives to enhance your schema with additional capabilities, such as custom indexes, authorization rules, function triggers and more.`,\n};\n\n<MigrationAlert isLegacy url={\"/cli/graphql/overview\"}/>\n\nThe Amplify CLI provides GraphQL directives to enhance your schema with additional capabilities such as custom indexes, authorization rules, function triggers, and more.\n\n## Amplify-provided directives\n\n- [`@model`: Defines top level object types in your API that are backed by Amazon DynamoDB](/cli/graphql-transformer/model)\n- [`@key`: Configures custom index structures for @model types](/cli/graphql-transformer/key)\n- [`@auth`: Defines authorization rules for your @model types and fields](/cli/graphql-transformer/auth)\n- [`@connection`: Defines 1:1, 1:M, and N:M relationships between @model types](/cli/graphql-transformer/connection)\n- [`@function`: Configures a Lambda function resolvers for a field](/cli/graphql-transformer/function)\n- [`@http`: Configures an HTTP resolver for a field](/cli/graphql-transformer/http)\n- [`@predictions`: Queries an orchestration of AI/ML services such as Amazon Rekognition, Amazon Translate, and/or Amazon Polly](/cli/graphql-transformer/predictions)\n- [`@searchable`: Makes your data searchable by streaming it to Amazon OpenSearch](/cli/graphql-transformer/searchable)\n- [`@versioned`: Defines the versioning and conflict resolution strategy for an @model type](/cli/graphql-transformer/versioned)\n\n## AWS AppSync-provided directives\n\nThe following directives are supported by the AppSync service and can be used within the Amplify GraphQL schemas. These will not be processed by Amplify CLI but passed through to the service as is and will be present in the output schema. For example, Amplify's `@auth` directive will add these directives under the hood to the output schema.\n\n- `@aws_api_key`\n- `@aws_iam`\n- `@aws_oidc`\n- `@aws_cognito_user_pools`\n- `@aws_auth`\n- `@aws_subscribe`\n\nLearn more about these directives in the [AWS AppSync Developer Guide](https://docs.aws.amazon.com/appsync/latest/devguide/security-authz.html).\n\n## 3rd party directives\n\n- [`@algolia`: Add serverless search to your Amplify API with Algolia](https://github.com/thefinnomenon/graphql-algolia-transformer)\n- [`@ttl`: Enable DynamoDB's time-to-live feature to auto-delete old entries in your AWS Amplify API](https://github.com/flogy/graphql-ttl-transformer)\n- [`@firehose`: Add a simple interceptor to all of your Amplify API mutations and queries](https://github.com/LaugnaHealth/graphql-firehose-transformer)\n- [`@retain`: Enable the \"Retain\" deletion policy for your Amplify-generated DynamoDB tables](https://github.com/flogy/graphql-retain-transformer)\n\n> Looking to build your own transformers & directives? Check out the guide on [how to author your own transformer & directives](/cli/plugins/authoring#authoring-custom-graphql-transformers--directives).\n",
    "meta": {
      "title": "Directives",
      "description": "The Amplify CLI provides GraphQL directives to enhance your schema with additional capabilities, such as custom indexes, authorization rules, function triggers and more.",
      "subcategory": "API (GraphQL)",
      "category": "Amplify CLI (Legacy)"
    },
    "filename": "/cli-legacy/graphql-transformer/directives"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "The GraphQL Transform provides a simple to use abstraction that helps you quickly create backends for your web and mobile applications on AWS. With the GraphQL Transform, you define your application's data model using the GraphQL Schema Definition Language (SDL) and the library handles converting your SDL definition into a set of fully descriptive AWS CloudFormation templates that implement your data model."
      },
      {
        "heading": null,
        "depth": null,
        "text": "For example you might create the backend for a blog like this:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "The GraphQL Transform simplifies the process of\ndeveloping, deploying, and maintaining GraphQL APIs. With it, you define your API using the\nGraphQL Schema Definition Language (SDL) and can then use automation to transform it into a fully\ndescriptive cloudformation template that implements the spec. The transform also provides a framework\nthrough which you can define your own transformers as @directives for custom workflows."
      },
      {
        "heading": "Create a GraphQL API",
        "depth": 2,
        "text": "Navigate into the root of a JavaScript, iOS, or Android project and run:"
      },
      {
        "heading": "Create a GraphQL API",
        "depth": 2,
        "text": "Follow the wizard to create a new app. After finishing the wizard run:"
      },
      {
        "heading": "Create a GraphQL API",
        "depth": 2,
        "text": "Select the following options:"
      },
      {
        "heading": "Create a GraphQL API",
        "depth": 2,
        "text": "Select GraphQL"
      },
      {
        "heading": "Create a GraphQL API",
        "depth": 2,
        "text": "When asked if you have a schema, say No"
      },
      {
        "heading": "Create a GraphQL API",
        "depth": 2,
        "text": "Select one of the default samples; you can change this later"
      },
      {
        "heading": "Create a GraphQL API",
        "depth": 2,
        "text": "Choose to edit the schema and it will open the new schema.graphql in your\neditor"
      },
      {
        "heading": "Create a GraphQL API",
        "depth": 2,
        "text": "You can leave the sample as is or try this schema."
      },
      {
        "heading": "Create a GraphQL API",
        "depth": 2,
        "text": "Once you are happy with your schema, save the file and hit enter in your\nterminal window. if no error messages are thrown this means the transformation\nwas successful and you can deploy your new API."
      },
      {
        "heading": "Test the API",
        "depth": 2,
        "text": "Once the API is finished deploying, go to the AWS AppSync console or run amplify mock api to try some of these queries in your new API's query page."
      },
      {
        "heading": "Update schema",
        "depth": 2,
        "text": "If you want to update your API, open your project's backend/api/~apiname~/schema.graphql file (NOT the one in the backend/api/~apiname~/build folder) and edit it in your favorite code editor. You can compile the backend/api/~apiname~/schema.graphql by running:"
      },
      {
        "heading": "Update schema",
        "depth": 2,
        "text": "and view the compiled schema output in backend/api/~apiname~/build/schema.graphql."
      },
      {
        "heading": "Update schema",
        "depth": 2,
        "text": "You can then push updated changes with:"
      },
      {
        "heading": "Update schema",
        "depth": 2,
        "text": "The following schema updates require replacement of the underlying DynamoDB table:"
      },
      {
        "heading": "Update schema",
        "depth": 2,
        "text": "Removing or renaming a model"
      },
      {
        "heading": "Update schema",
        "depth": 2,
        "text": "Modifying the primary key of a model"
      },
      {
        "heading": "Update schema",
        "depth": 2,
        "text": "Modifying a Local Secondary Index of a model (only applies to projects with secondaryKeyAsGSI turned off)"
      },
      {
        "heading": "Update schema",
        "depth": 2,
        "text": "When trying to push a schema change with one or more of these updates you will see an error message explaining that you will lose ALL DATA in any table that requires replacement. To confirm you want to continue with the deployment, run:"
      },
      {
        "heading": "Update schema",
        "depth": 2,
        "text": "In general, this command should only be used during development."
      },
      {
        "heading": "Update schema",
        "depth": 2,
        "text": "If you are making a breaking change to a production API but you want to retain the data in the affected table(s), you can create a backup before running amplify push --allow-destructive-graphql-schema-updates"
      },
      {
        "heading": "Rebuild GraphQL API",
        "depth": 2,
        "text": "Rebuild should NEVER be used in a production environment!"
      },
      {
        "heading": "Rebuild GraphQL API",
        "depth": 2,
        "text": "When in development, sometimes test data gets in a bad state or you want to make many changes to your schema all at once. In these cases, you may wish to \"rebuild\" all of the tables backing your schema. To do this, run:"
      },
      {
        "heading": "Rebuild GraphQL API",
        "depth": 2,
        "text": "This will recreate ALL of the tables backing models in your schema. ALL DATA in ALL TABLES will be deleted."
      },
      {
        "heading": "API Category Project Structure",
        "depth": 2,
        "text": "At a high level, the transform libraries take a schema defined in the GraphQL Schema Definition Language (SDL) and converts it into a set of AWS CloudFormation templates and other assets that are deployed as part of amplify push. The full set of assets uploaded can be found at amplify/backend/api/YOUR-API-NAME/build."
      },
      {
        "heading": "API Category Project Structure",
        "depth": 2,
        "text": "When creating APIs, you will make changes to the other files and directories in the amplify/backend/api/YOUR-API-NAME/ directory but you should not manually change anything in the build directory. The build directory will be overwritten the next time you run amplify push or amplify api gql-compile. Here is an overview of the API directory:"
      }
    ],
    "source": "export const meta = {\n  title: `Overview`,\n  description: `With Amplify CLI and GraphQL Transform, you define your application's data model using the GraphQL Schema Definition Language (SDL) and the library converts your SDL schema into a set of fully descriptive AWS CloudFormation templates that implement your data model.`,\n};\n\n<MigrationAlert isLegacy url={\"/cli/graphql/overview\"}/>\n\nThe GraphQL Transform provides a simple to use abstraction that helps you quickly create backends for your web and mobile applications on AWS. With the GraphQL Transform, you define your application's data model using the GraphQL Schema Definition Language (SDL) and the library handles converting your SDL definition into a set of fully descriptive AWS CloudFormation templates that implement your data model.\n\nFor example you might create the backend for a blog like this:\n\n```graphql\ntype Blog @model {\n  id: ID!\n  name: String!\n  posts: [Post] @connection(name: \"BlogPosts\")\n}\ntype Post @model {\n  id: ID!\n  title: String!\n  blog: Blog @connection(name: \"BlogPosts\")\n  comments: [Comment] @connection(name: \"PostComments\")\n}\ntype Comment @model {\n  id: ID!\n  content: String\n  post: Post @connection(name: \"PostComments\")\n}\n```\n\nThe GraphQL Transform simplifies the process of\ndeveloping, deploying, and maintaining GraphQL APIs. With it, you define your API using the\n[GraphQL Schema Definition Language (SDL)](https://facebook.github.io/graphql/June2018/) and can then use automation to transform it into a fully\ndescriptive cloudformation template that implements the spec. The transform also provides a framework\nthrough which you can define your own transformers as `@directives` for custom workflows.\n\n## Create a GraphQL API\n\nNavigate into the root of a JavaScript, iOS, or Android project and run:\n\n```bash\namplify init\n```\n\nFollow the wizard to create a new app. After finishing the wizard run:\n\n```bash\namplify add api\n```\n\nSelect the following options:\n\n- Select GraphQL\n- When asked if you have a schema, say No\n- Select one of the default samples; you can change this later\n- Choose to edit the schema and it will open the new `schema.graphql` in your\n  editor\n\nYou can leave the sample as is or try this schema.\n\n```graphql\ntype Blog @model {\n  id: ID!\n  name: String!\n  posts: [Post] @connection(name: \"BlogPosts\")\n}\ntype Post @model {\n  id: ID!\n  title: String!\n  blog: Blog @connection(name: \"BlogPosts\")\n  comments: [Comment] @connection(name: \"PostComments\")\n}\ntype Comment @model {\n  id: ID!\n  content: String\n  post: Post @connection(name: \"PostComments\")\n}\n```\n\nOnce you are happy with your schema, save the file and hit enter in your\nterminal window. if no error messages are thrown this means the transformation\nwas successful and you can deploy your new API.\n\n```bash\namplify push\n```\n\n## Test the API\n\nOnce the API is finished deploying, go to the AWS AppSync console or run `amplify mock api` to try some of these queries in your new API's query page.\n\n```graphql\n# Create a blog. Remember the returned id.\n# Provide the returned id as the \"blogId\" variable.\nmutation CreateBlog {\n  createBlog(input: {\n    name: \"My New Blog!\"\n  }) {\n    id\n    name\n  }\n}\n\n# Create a post and associate it with the blog via the \"postBlogId\" input field.\n# Provide the returned id as the \"postId\" variable.\nmutation CreatePost($blogId:ID!) {\n  createPost(input:{title:\"My Post!\", postBlogId: $blogId}) {\n    id\n    title\n    blog {\n      id\n      name\n    }\n  }\n}\n\n# Provide the returned id from the CreateBlog mutation as the \"blogId\" variable\n# in the \"variables\" pane (bottom left pane) of the query editor:\n{\n  \"blogId\": \"returned-id-goes-here\"\n}\n\n# Create a comment and associate it with the post via the \"commentPostId\" input field.\nmutation CreateComment($postId:ID!) {\n  createComment(input:{content:\"A comment!\", commentPostId:$postId}) {\n    id\n    content\n    post {\n      id\n      title\n      blog {\n        id\n        name\n      }\n    }\n  }\n}\n\n# Provide the returned id from the CreatePost mutation as the \"postId\" variable\n# in the \"variables\" pane (bottom left pane) of the query editor:\n{\n  \"postId\": \"returned-id-goes-here\"\n}\n\n# Get a blog, its posts, and its posts' comments.\nquery GetBlog($blogId:ID!) {\n  getBlog(id:$blogId) {\n    id\n    name\n    posts(filter: {\n      title: {\n        eq: \"My Post!\"\n      }\n    }) {\n      items {\n        id\n        title\n        comments {\n          items {\n            id\n            content\n          }\n        }\n      }\n    }\n  }\n}\n\n# List all blogs, their posts, and their posts' comments.\nquery ListBlogs {\n  listBlogs { # Try adding: listBlog(filter: { name: { eq: \"My New Blog!\" } })\n    items {\n      id\n      name\n      posts { # or try adding: posts(filter: { title: { eq: \"My Post!\" } })\n        items {\n          id\n          title\n          comments { # and so on ...\n            items {\n              id\n              content\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n## Update schema\n\nIf you want to update your API, open your project's `backend/api/~apiname~/schema.graphql` file (NOT the one in the `backend/api/~apiname~/build` folder) and edit it in your favorite code editor. You can compile the `backend/api/~apiname~/schema.graphql` by running:\n\n```bash\namplify api gql-compile\n```\n\nand view the compiled schema output in `backend/api/~apiname~/build/schema.graphql`.\n\nYou can then push updated changes with:\n\n```bash\namplify push\n```\n\nThe following schema updates require replacement of the underlying DynamoDB table:\n1. Removing or renaming a model\n2. Modifying the [primary key](/cli/graphql-transformer/key) of a model\n3. Modifying a Local Secondary Index of a model (only applies to projects with [secondaryKeyAsGSI](/cli/reference/feature-flags/#secondaryKeyAsGSI) turned off)\n\nWhen trying to push a schema change with one or more of these updates you will see an error message explaining that you will lose ALL DATA in any table that requires replacement. To confirm you want to continue with the deployment, run:\n```bash\namplify push --allow-destructive-graphql-schema-updates\n```\n<Callout>\nIn general, this command should only be used during development.\n\nIf you are making a breaking change to a production API but you want to retain the data in the affected table(s), you can [create a backup](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/CreateBackupAWS.html) before running `amplify push --allow-destructive-graphql-schema-updates`\n</Callout>\n\n## Rebuild GraphQL API\n\n<Callout>\nRebuild should NEVER be used in a production environment!\n</Callout>\n\nWhen in development, sometimes test data gets in a bad state or you want to make many changes to your schema all at once. In these cases, you may wish to \"rebuild\" all of the tables backing your schema. To do this, run:\n```bash\namplify rebuild api\n```\nThis will recreate ALL of the tables backing models in your schema. ALL DATA in ALL TABLES will be deleted.\n\n## API Category Project Structure\n\nAt a high level, the transform libraries take a schema defined in the GraphQL Schema Definition Language (SDL) and converts it into a set of AWS CloudFormation templates and other assets that are deployed as part of `amplify push`. The full set of assets uploaded can be found at *amplify/backend/api/YOUR-API-NAME/build*.\n\nWhen creating APIs, you will make changes to the other files and directories in the *amplify/backend/api/YOUR-API-NAME/* directory but you should not manually change anything in the *build* directory. The build directory will be overwritten the next time you run `amplify push` or `amplify api gql-compile`. Here is an overview of the API directory:\n\n```console\n-build/\n- resolvers/\n| # Store any resolver templates written in vtl here. E.G.\n|-- Query.ping.req.vtl\n|-- Query.ping.res.vtl\n|\n- stacks/\n| # Create custom resources with CloudFormation stacks that will be deployed as part of `amplify push`.\n|-- CustomResources.json\n|\n- parameters.json\n| # Tweak certain behaviors with custom CloudFormation parameters.\n|\n- schema.graphql\n| # Write your GraphQL schema in SDL\n- schema/\n| # Optionally break up your schema into many files. You must remove schema.graphql to use this.\n|-- Query.graphql\n|-- Post.graphql\n- transform.conf.json\n```\n",
    "meta": {
      "title": "Overview",
      "description": "With Amplify CLI and GraphQL Transform, you define your application's data model using the GraphQL Schema Definition Language (SDL) and the library converts your SDL schema into a set of fully descriptive AWS CloudFormation templates that implement your data model.",
      "subcategory": "API (GraphQL)",
      "category": "Amplify CLI (Legacy)"
    },
    "filename": "/cli-legacy/graphql-transformer/overview"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Feature flags makes it possible to fine tune given functionality in the Amplify CLI."
      },
      {
        "heading": null,
        "depth": null,
        "text": "They are grouped into sections based on the area of the functionality. An area can be a category or some other scope. There are different type of feature flags defined, their lifetime is controlled the lifecycle process."
      },
      {
        "heading": "Release",
        "depth": 3,
        "text": "These types of feature flags are used to enable or disable a given functionality in Amplify CLI that is under active development. These feature flags are removed and become unsupported once a feature has been shipped."
      },
      {
        "heading": "Feature",
        "depth": 3,
        "text": "During the history of the Amplify CLI there are enhancements that can benefit for new projects but potentially can cause breaking changes in existing deployments. These feature flags are controlled by the lifecycle process to provide time for mitigation and migration. These type of flags are disabled for existing projects and enabled for new ones."
      },
      {
        "heading": "Feature",
        "depth": 3,
        "text": "Examples"
      },
      {
        "heading": "Feature",
        "depth": 3,
        "text": "Breaking existing projects by generating different code and would require a backend deployment."
      },
      {
        "heading": "Feature",
        "depth": 3,
        "text": "The push operation of a changed resource would require a resource recreation that could lead to data loss."
      },
      {
        "heading": "Feature",
        "depth": 3,
        "text": "The push operation of a changed resource would require data backfill to make the client application operable."
      },
      {
        "heading": "Feature",
        "depth": 3,
        "text": "The generated code for client applications would require a rebuild and republish to be compatible with the newly pushed backend."
      },
      {
        "heading": "Experimental",
        "depth": 3,
        "text": "Experimental feature flags are to enable experimentation with given functionality, to provide feedback to the Amplify CLI team. Enabling these feature in production is highly discouraged."
      },
      {
        "heading": "Experimental",
        "depth": 3,
        "text": "The outcome of experimental features can be:"
      },
      {
        "heading": "Experimental",
        "depth": 3,
        "text": "The feature will make into the product so it will be turned into a Release type feature flag."
      },
      {
        "heading": "Experimental",
        "depth": 3,
        "text": "The experimental feature is not making into the product and removed from the codebase together with the code itself."
      },
      {
        "heading": "Lifecycle",
        "depth": 2,
        "text": "Each type of feature flags are managed under a lifecycle management process. When a feature flag is added to the Amplify CLI it will be mentioned in the release notes and also this page will be updated with the detailed information. After adding a feature flag this page will contain information about what version a feature flag was added, what is the planned deprecation date - if there is one -, in which version the feature flag was deprecated, in which version the feature flag was removed."
      },
      {
        "heading": "Lifecycle",
        "depth": 2,
        "text": "When a feature flag is deprecated it still can be used but when used a warning will be printed on the screen during the execution of Amplify CLI commands."
      },
      {
        "heading": "Lifecycle",
        "depth": 2,
        "text": "Before removal a removal date is added to the feature flag, and after a feature flag is removed Amplify CLI will shows an error message about it and the version the feature flag was removed added to the page."
      },
      {
        "heading": "Configuration",
        "depth": 2,
        "text": "Configuration of feature flags are primarily done by having an cli.json file in the project's amplify folder. If the file does not exist Amplify CLI creates it during the amplify init command. The emitted values are representing the default values for new projects. This file must be under version control, to make sure that the same features are used locally, in CI/CD environments, between team members. If an environment specific file exists for the currently checked out environment, during amplify env add command the same file will be copied for the newly created environment as well."
      },
      {
        "heading": "Configuration",
        "depth": 2,
        "text": "Example configuration file"
      },
      {
        "heading": "Configuration",
        "depth": 2,
        "text": "If for some reason different functionality is needed to be enabled for a given Amplify CLI environment a copy can be made of the project level file with the following naming convention: cli.{environment name}.json."
      },
      {
        "heading": "Environment variables",
        "depth": 3,
        "text": "Amplify CLI supports the definition and override of feature flags values from environment variables and .env files as well."
      },
      {
        "heading": "Environment variables",
        "depth": 3,
        "text": "The environment variables must follow a naming convention, to be picked up by Amplify CLI:"
      },
      {
        "heading": "Environment variables",
        "depth": 3,
        "text": "Project level override: AMPLIFYCLI_{SECTION}__{PROPERTY}, for example: AMPLIFYCLI_GRAPHQLTRANSFORMER__TRANSFORMERVERSION"
      },
      {
        "heading": "Environment variables",
        "depth": 3,
        "text": "Environment specific override: AMPLIFYCLI_{ENVNAME}_{SECTION}__{PROPERTY}, for example: AMPLIFYCLI_PROD_GRAPHQLTRANSFORMER__TRANSFORMERVERSION"
      },
      {
        "heading": "Environment variables",
        "depth": 3,
        "text": "If a .env file is used in the project's root folder, then it is being merged on top of the current process' environment variables, overwriting those."
      },
      {
        "heading": "Order of evaluation",
        "depth": 3,
        "text": "Due to the multiple levels of configuration options and overrides, Amplify CLI does a top-to-bottom evaluation as follows:"
      },
      {
        "heading": "Order of evaluation",
        "depth": 3,
        "text": "cli.json"
      },
      {
        "heading": "Order of evaluation",
        "depth": 3,
        "text": "cli.{environment name}.json"
      },
      {
        "heading": "Order of evaluation",
        "depth": 3,
        "text": "Project level environment variables"
      },
      {
        "heading": "Order of evaluation",
        "depth": 3,
        "text": "CLI Environment level environment variables"
      },
      {
        "heading": "Feature flags",
        "depth": 2,
        "text": "Note: feature flags are case-insensitive, however are described here in camelCase for readability"
      }
    ],
    "source": "export const meta = {\n  title: `Feature Flags`,\n  description: `More information about feature flags in Amplify CLI`,\n};\n\nFeature flags makes it possible to fine tune given functionality in the Amplify CLI.\n\nThey are grouped into sections based on the area of the functionality. An area can be a category or some other scope. There are different type of feature flags defined, their lifetime is controlled the lifecycle process.\n\n## Types of feature flags\n\n### Release\n\nThese types of feature flags are used to enable or disable a given functionality in Amplify CLI that is under active development. These feature flags are removed and become unsupported once a feature has been shipped.\n\n### Feature\n\nDuring the history of the Amplify CLI there are enhancements that can benefit for new projects but potentially can cause breaking changes in existing deployments. These feature flags are controlled by the lifecycle process to provide time for mitigation and migration. These type of flags are disabled for existing projects and enabled for new ones.\n\nExamples\n\n- Breaking existing projects by generating different code and would require a backend deployment.\n- The push operation of a changed resource would require a resource recreation that could lead to data loss.\n- The push operation of a changed resource would require data backfill to make the client application operable.\n- The generated code for client applications would require a rebuild and republish to be compatible with the newly pushed backend.\n\n### Experimental\n\nExperimental feature flags are to enable experimentation with given functionality, to provide feedback to the Amplify CLI team. Enabling these feature in production is highly discouraged.\n\nThe outcome of experimental features can be:\n\n- The feature will make into the product so it will be turned into a Release type feature flag.\n- The experimental feature is not making into the product and removed from the codebase together with the code itself.\n\n## Lifecycle\n\nEach type of feature flags are managed under a lifecycle management process. When a feature flag is added to the Amplify CLI it will be mentioned in the release notes and also this page will be updated with the detailed information. After adding a feature flag this page will contain information about what version a feature flag was added, what is the planned deprecation date - if there is one -, in which version the feature flag was deprecated, in which version the feature flag was removed.\n\nWhen a feature flag is deprecated it still can be used but when used a warning will be printed on the screen during the execution of Amplify CLI commands.\n\nBefore removal a removal date is added to the feature flag, and after a feature flag is removed Amplify CLI will shows an error message about it and the version the feature flag was removed added to the page.\n\n## Configuration\n\nConfiguration of feature flags are primarily done by having an `cli.json` file in the project's `amplify` folder. If the file does not exist Amplify CLI creates it during the `amplify init` command. The emitted values are representing the default values for new projects. This file must be under version control, to make sure that the same features are used locally, in CI/CD environments, between team members. If an environment specific file exists for the currently checked out environment, during `amplify env add` command the same file will be copied for the newly created environment as well.\n\nExample configuration file\n\n```json\n{\n  \"features\": {\n    \"graphQLTransformer\": {\n      \"addMissingOwnerFields\": true,\n      \"validateTypeNameReservedWords\": true,\n      \"useExperimentalPipelinedTransformer\": false,\n      \"enableIterativeGSIUpdates\": false\n    },\n    \"frontend-ios\": {\n      \"enableXcodeIntegration\": true\n    },\n    \"auth\": {\n      \"enableCaseInsensitivity\": true,\n      \"useInclusiveTerminology\": true,\n      \"breakCircularDependency\": true\n    },\n    \"codegen\": {\n      \"useAppSyncModelgenPlugin\": true\n    }\n  }\n}\n```\n\nIf for some reason different functionality is needed to be enabled for a given Amplify CLI environment a copy can be made of the project level file with the following naming convention: `cli.{environment name}.json`.\n\n### Environment variables\n\nAmplify CLI supports the definition and override of feature flags values from environment variables and `.env` files as well.\n\nThe environment variables must follow a naming convention, to be picked up by Amplify CLI:\n\n- Project level override: `AMPLIFYCLI_{SECTION}__{PROPERTY}`, for example: `AMPLIFYCLI_GRAPHQLTRANSFORMER__TRANSFORMERVERSION`\n- Environment specific override: `AMPLIFYCLI_{ENVNAME}_{SECTION}__{PROPERTY}`, for example: `AMPLIFYCLI_PROD_GRAPHQLTRANSFORMER__TRANSFORMERVERSION`\n\nIf a `.env` file is used in the project's root folder, then it is being merged on top of the current process' environment variables, overwriting those.\n\n### Order of evaluation\n\nDue to the multiple levels of configuration options and overrides, Amplify CLI does a top-to-bottom evaluation as follows:\n\n- `cli.json`\n- `cli.{environment name}.json`\n- Project level environment variables\n- CLI Environment level environment variables\n\n## Feature flags\n\n<Callout>\n\n**Note:** feature flags are case-insensitive, however are described here in camelCase for readability \n\n</Callout>\n\n<FeatureFlags />\n",
    "meta": {
      "title": "Feature Flags",
      "description": "More information about feature flags in Amplify CLI",
      "subcategory": "Reference",
      "category": "Amplify CLI"
    },
    "filename": "/cli/reference/feature-flags"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Non-sensitive configurations of your Amplify backend can be securely shared with Amplify by running the command"
      },
      {
        "heading": null,
        "depth": null,
        "text": "The CLI collects non-sensitive files from your Amplify backend into a zip file and transmits it to a secure location. Below are the files CLI collects, transmits and stores:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "backend-config.json: Includes all the categories that were provided in the project."
      },
      {
        "heading": null,
        "depth": null,
        "text": "CloudFormation files: CLI generated CloudFormation files that are used to provide resources."
      },
      {
        "heading": null,
        "depth": null,
        "text": "cli.json: The feature flag configuration."
      },
      {
        "heading": null,
        "depth": null,
        "text": "amplify.state: Internal metadata on how to invoke the function category."
      },
      {
        "heading": null,
        "depth": null,
        "text": "parameters.json and cli-inputs.json."
      },
      {
        "heading": null,
        "depth": null,
        "text": "schema.graphql or schema folder that are part of the GraphQL API."
      },
      {
        "heading": null,
        "depth": null,
        "text": "override.ts provides any custom extensions to the CloudFormation."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Function category dependency information stored in package files."
      },
      {
        "heading": null,
        "depth": null,
        "text": "After the zip file is transmitted successfully the current project’s unique identifier is printed. The identifier is used to access the zip file for debugging purposes by the support engineer."
      },
      {
        "heading": "Automatic Report Sharing",
        "depth": 3,
        "text": "To help improve Amplify CLI you can opt in to automatically share your project configurations with Amplify CLI on failures. The is a project level setting and can be toggled per project. The project can opt out by running"
      },
      {
        "heading": "Automatic Report Sharing",
        "depth": 3,
        "text": "and opt in by"
      },
      {
        "heading": "Automatic Report Sharing",
        "depth": 3,
        "text": "The CLI collects two extra files including the files below and the files collected using amplify diagnose --send-report"
      },
      {
        "heading": "Automatic Report Sharing",
        "depth": 3,
        "text": "Error details: Including the stack trace, message and error name."
      },
      {
        "heading": "Automatic Report Sharing",
        "depth": 3,
        "text": "CloudFormation updates when an amplify push is invoked."
      },
      {
        "heading": "Security",
        "depth": 2,
        "text": "In transit the zip file is encrypted using a public encrypt and private decrypt scheme. At rest the files are stored with AES 256 bit encryption. The files are retained for 60 days within which the files are marked for deletion. The files are solely used for debugging purposes and are not shared beyond the team."
      }
    ],
    "source": "export const meta = {\n  title: `Diagnose`,\n  description: `More information about diagnose command in Amplify CLI`,\n};\n\nNon-sensitive configurations of your Amplify backend can be securely shared with Amplify by running the command\n\n```bash\namplify diagnose --send-report\n```\n\nThe CLI collects non-sensitive files from your Amplify backend into a zip file and transmits it to a secure location. Below are the files CLI collects, transmits and stores:\n\n* [backend-config.json](https://docs.amplify.aws/cli/reference/files/#backend-configjson): Includes all the categories that were provided in the project.\n* CloudFormation files: CLI generated CloudFormation files that are used to provide resources.\n* [cli.json](https://docs.amplify.aws/cli/reference/files/#clijson): The feature flag configuration.\n* [amplify.state](https://docs.amplify.aws/cli/reference/files/#general-category-files): Internal metadata on how to invoke the function category.\n* [parameters.json](https://docs.amplify.aws/cli/reference/files/#category-parametersjson) and cli-inputs.json. \n* schema.graphql or schema folder that are part of the GraphQL API.\n* override.ts provides any custom extensions to the CloudFormation.\n* Function category dependency information stored in package files.\n\nAfter the zip file is transmitted successfully the current project’s unique identifier is printed. The identifier is used to access the zip file for debugging purposes by the support engineer.\n\n\n```bash\nProject Identifier: 56b5981ed6cf5caad90fb2f8aed150e2\n```\n\n### Automatic Report Sharing\n\n\nTo help improve Amplify CLI you can opt in to automatically share your project configurations with Amplify CLI on failures. The is a project level setting and can be toggled per project. The project can opt out by running\n\n\n```bash\namplify diagnose --auto-send-off\n```\n\nand opt in by \n\n```bash\namplify diagnose --auto-send-on\n``` \n\nThe CLI collects two extra files including the files below and the files collected using `amplify diagnose --send-report`\n\n* Error details: Including the stack trace, message and error name.\n* CloudFormation updates when an `amplify push` is invoked.\n\n\n## Security\n\nIn transit the zip file is encrypted using a public encrypt and private decrypt scheme. At rest the files are stored with AES 256 bit encryption. The files are retained for 60 days within which the files are marked for deletion. The files are solely used for debugging purposes and are not shared beyond the team.\n",
    "meta": {
      "title": "Diagnose",
      "description": "More information about diagnose command in Amplify CLI",
      "subcategory": "Reference",
      "category": "Amplify CLI"
    },
    "filename": "/cli/reference/diagnose"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "At AWS, we develop and launch services based on what we learn from interactions with our customers. We use customer feedback to iterate on our product. Anonymized usage data helps us to better understand our customers’ needs, diagnose issues, and deliver features that improve the customer experience."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify CLI sends anonymized information such as system metadata, usage metrics, and errors. The data is marked for deletion in a year from the point of it being collected. Amplify CLI does not collect personally identifiable information such as email addresses, usernames, keys, ARNs or project information such as names, ARNs, and keys."
      },
      {
        "heading": "Manage usage data collection for your Amplify CLI Instance",
        "depth": 3,
        "text": "Disable usage data collection"
      },
      {
        "heading": "Manage usage data collection for your Amplify CLI Instance",
        "depth": 3,
        "text": "Run the following command to turn off Amplify CLI usage data collection"
      },
      {
        "heading": "Manage usage data collection for your Amplify CLI Instance",
        "depth": 3,
        "text": "Enable usage data collection"
      },
      {
        "heading": "Manage usage data collection for your Amplify CLI Instance",
        "depth": 3,
        "text": "Run the following command to turn on Amplify CLI usage data collection"
      },
      {
        "heading": "Manage usage data collection for your Amplify CLI Instance",
        "depth": 3,
        "text": "*Usage data collection is managed on a machine per installation basis enabling/disabling will change it for all the projects on that instance"
      },
      {
        "heading": "Learn More",
        "depth": 2,
        "text": "The usage data that's collected adheres to the AWS data privacy policies. For more information, see the following:"
      },
      {
        "heading": "Learn More",
        "depth": 2,
        "text": "AWS Service Terms"
      },
      {
        "heading": "Learn More",
        "depth": 2,
        "text": "Data Privacy"
      }
    ],
    "source": "export const meta = {\n  title: `Usage Data in Amplify CLI`,\n  description: `More information about usage data in Amplify CLI`,\n};\n\n  \n\nAt AWS, we develop and launch services based on what we learn from interactions with our customers. We use customer feedback to iterate on our product. Anonymized usage data helps us to better understand our customers’ needs, diagnose issues, and deliver features that improve the customer experience.\n\nAmplify CLI sends anonymized information such as system metadata, usage metrics, and errors. The data is marked for deletion in a year from the point of it being collected. Amplify CLI does **not** collect personally identifiable information such as email addresses, usernames, keys, ARNs or project information such as names, ARNs, and keys.\n\n### Manage usage data collection for your Amplify CLI Instance\n\n**Disable usage data collection**\n\nRun the following command to turn off Amplify CLI usage data collection\n\n```bash\namplify configure --usage-data-off\n```\n\n**Enable usage data collection**\n\nRun the following command to turn on Amplify CLI usage data collection\n\n```bash\namplify configure --usage-data-on\n```\n\n**Usage data collection is managed on a machine per installation basis enabling/disabling will change it for all the projects on that instance*\n\n## Learn More\n\nThe usage data that's collected adheres to the AWS data privacy policies. For more information, see the following:\n\n- [AWS Service Terms](https://aws.amazon.com/service-terms/)\n- [Data Privacy](https://aws.amazon.com/compliance/data-privacy-faq/)\n",
    "meta": {
      "title": "Usage Data in Amplify CLI",
      "description": "More information about usage data in Amplify CLI",
      "subcategory": "Reference",
      "category": "Amplify CLI"
    },
    "filename": "/cli/reference/usage-data"
  },
  {
    "searchableText": [
      {
        "heading": "Folders",
        "depth": 2,
        "text": "The CLI places the following folder structure in the root directory of the project during amplify init:"
      },
      {
        "heading": "amplify/.config",
        "depth": 3,
        "text": "Manual edits okay: NO"
      },
      {
        "heading": "amplify/.config",
        "depth": 3,
        "text": "Add to version control: YES"
      },
      {
        "heading": "amplify/.config",
        "depth": 3,
        "text": "Contains files that store cloud configuration and settings/preferences. Run amplify configure to change the project configuration."
      },
      {
        "heading": "amplify/#current-cloud-backend",
        "depth": 3,
        "text": "Manual edits okay: NO"
      },
      {
        "heading": "amplify/#current-cloud-backend",
        "depth": 3,
        "text": "Add to version control: NO"
      },
      {
        "heading": "amplify/#current-cloud-backend",
        "depth": 3,
        "text": "Contains the current cloud state of the checked out environment's resources. The contents of this folder should never be manually updated. It will be overwritten on operations such as amplify push, amplify pull or amplify env checkout."
      },
      {
        "heading": "amplify/backend",
        "depth": 3,
        "text": "Manual edits okay: YES"
      },
      {
        "heading": "amplify/backend",
        "depth": 3,
        "text": "Add to version control: YES"
      },
      {
        "heading": "amplify/backend",
        "depth": 3,
        "text": "Contains the latest local development state of the checked out environment's resources. The contents of this folder can be modified and running amplify push will push changes in this directory to the cloud.\nEach plugin stores contents in its own subfolder within this folder."
      },
      {
        "heading": "amplify/mock-data",
        "depth": 3,
        "text": "Manual edits okay: NO"
      },
      {
        "heading": "amplify/mock-data",
        "depth": 3,
        "text": "Add to version control: NO"
      },
      {
        "heading": "amplify/mock-data",
        "depth": 3,
        "text": "Only created after running amplify mock api. It contains the SQLite databases that are used to back the local API when mocking. The contents should not be modified but you can delete the folder if you want to wipe your local API state."
      },
      {
        "heading": "Core Amplify Files",
        "depth": 2,
        "text": "These files work together to maintain the overall state of the Amplify project such as what resources are configured in the project, dependencies between resources, and when the last push was."
      },
      {
        "heading": "backend-config.json",
        "depth": 3,
        "text": "Manual edits okay: YES"
      },
      {
        "heading": "backend-config.json",
        "depth": 3,
        "text": "Add to version control: YES"
      },
      {
        "heading": "backend-config.json",
        "depth": 3,
        "text": "The backend-config.json in the backend directory contains configuration about your project's backend, such as how connects to AWS resources (eg. Cognito for auth or AppSync for an API backend). Typically, this file is updated by the CLI commands like amplify add auth or amplify add api. It can also be extended manually to configure your backend beyond Amplify CLI's features. Both the amplify/backend and amplify/#current-cloud-backend directories contain an backend-config.json file."
      },
      {
        "heading": "amplify-meta.json",
        "depth": 3,
        "text": "Manual edits okay: NO"
      },
      {
        "heading": "amplify-meta.json",
        "depth": 3,
        "text": "Add to version control: NO"
      },
      {
        "heading": "amplify-meta.json",
        "depth": 3,
        "text": "Both the amplify/backend and amplify/#current-cloud-backend directories contain an amplify-meta.json file. The amplify-meta.json in the backend directory serves as the whiteboard for the CLI core and the plugins to log internal information and communicate with each other."
      },
      {
        "heading": "amplify-meta.json",
        "depth": 3,
        "text": "The CLI core provides read and write access to the file for the plugins. Core collects the selected providers' outputs after init and logs them under the \"providers\" object, e.g. the awscloudformation provider outputs the information of the root stack, the deployment S3 bucket, and the authorized/unauthorized IAM roles, and they are logged under the providers.awscloudformation object. Each category plugin logs information under its own name."
      },
      {
        "heading": "amplify-meta.json",
        "depth": 3,
        "text": "Because one category might create multiple services within one project (e.g. the interactions category can create multiple bots), the category metadata generally follows a two-level structure like the following:"
      },
      {
        "heading": "amplify-meta.json",
        "depth": 3,
        "text": "The metadata for each service is first logged into the meta file after the amplify <category> add command is executed, containing some general information that indicates one service of the category has been added locally.\nThen, on the successful execution of the amplify push command, the output object will be added/updated in the service's metadata with information that describes the actual cloud resources that have been created or updated."
      },
      {
        "heading": "aws-exports.js",
        "depth": 3,
        "text": "Manual edits okay: NO"
      },
      {
        "heading": "aws-exports.js",
        "depth": 3,
        "text": "Add to version control: NO"
      },
      {
        "heading": "aws-exports.js",
        "depth": 3,
        "text": "This file is generated only for JavaScript projects.\nIt contains the consolidated outputs from all the categories and is placed under the src directory specified during the init process. It is updated after amplify push."
      },
      {
        "heading": "aws-exports.js",
        "depth": 3,
        "text": "This file is consumed by the Amplify JavaScript library for configuration. It contains information which is non-sensitive and only required for external, unauthenticated actions from clients (such as user registration or sign-in flows in the case of Auth) or for constructing appropriate endpoint URLs after authorization has taken place. Please see the following more detailed explanations:"
      },
      {
        "heading": "aws-exports.js",
        "depth": 3,
        "text": "Cognito security best practices for web app"
      },
      {
        "heading": "aws-exports.js",
        "depth": 3,
        "text": "Security / Best Practice for poolData (UserPoolId, ClientId) in a browser JS app"
      },
      {
        "heading": "aws-exports.js",
        "depth": 3,
        "text": "Are the Cognito User pool id and Client Id sensitive?"
      },
      {
        "heading": "amplifyconfiguration.json",
        "depth": 3,
        "text": "Manual edits okay: NO"
      },
      {
        "heading": "amplifyconfiguration.json",
        "depth": 3,
        "text": "Add to version control: NO"
      },
      {
        "heading": "amplifyconfiguration.json",
        "depth": 3,
        "text": "This file is the same as aws-exports.js but for Android and iOS projects."
      },
      {
        "heading": "amplifyconfiguration.json",
        "depth": 3,
        "text": "It is consumed by the iOS and Android native SDKs for configuration."
      },
      {
        "heading": ".gitignore",
        "depth": 3,
        "text": "Manual edits okay: YES"
      },
      {
        "heading": ".gitignore",
        "depth": 3,
        "text": "Add to version control: YES"
      },
      {
        "heading": ".gitignore",
        "depth": 3,
        "text": "When a new project is initialized from the Amplify CLI, Amplify will append the following to the .gitignore file in the root directory. A .gitignore file will be created if one does not exist."
      },
      {
        "heading": "team-provider-info.json",
        "depth": 3,
        "text": "Manual edits okay: NO"
      },
      {
        "heading": "team-provider-info.json",
        "depth": 3,
        "text": "Add to version control: YES"
      },
      {
        "heading": "team-provider-info.json",
        "depth": 3,
        "text": "Used to share project info within your team. Learn more at Share single environment."
      },
      {
        "heading": "cli.json",
        "depth": 3,
        "text": "Manual edits okay: YES"
      },
      {
        "heading": "cli.json",
        "depth": 3,
        "text": "Add to version control: YES"
      },
      {
        "heading": "cli.json",
        "depth": 3,
        "text": "Contains feature flag configuration for the project. If this file does not exist, it is created by Amplify CLI during amplify init. Environment specific feature flag overrides can also be defined in cli.<environment name>.json.  If an environment specific file exists for the currently checked out environment, during amplify env add command the same file will be copied for the newly created environment as well. Learn more at Feature flags."
      },
      {
        "heading": "General Category Files",
        "depth": 2,
        "text": "While each category plugin has some unique files, there are also some common files stored across all categories."
      },
      {
        "heading": "cli-inputs.json",
        "depth": 3,
        "text": "Manual edits okay: YES"
      },
      {
        "heading": "cli-inputs.json",
        "depth": 3,
        "text": "Add to version control: YES"
      },
      {
        "heading": "cli-inputs.json",
        "depth": 3,
        "text": "Stores the input parameters necessary to generate CloudFormation stacks for the associated resource."
      },
      {
        "heading": "override.ts",
        "depth": 3,
        "text": "Manual edits okay: YES"
      },
      {
        "heading": "override.ts",
        "depth": 3,
        "text": "Add to version control: YES"
      },
      {
        "heading": "override.ts",
        "depth": 3,
        "text": "TypeScript file that allows overriding the associated CloudFormation stack for categories that support it. To create this file, run amplify override <category>."
      },
      {
        "heading": "<category>-parameters.json",
        "depth": 3,
        "text": "Manual edits okay: NO"
      },
      {
        "heading": "<category>-parameters.json",
        "depth": 3,
        "text": "Add to version control: YES"
      },
      {
        "heading": "<category>-parameters.json",
        "depth": 3,
        "text": "Stores the parameters selected during amplify add <category> so they can be used to populate answers during amplify update <category>. This file does NOT change the underlying category configuration; it is only used to populate answers in the walkthrough."
      },
      {
        "heading": "parameters.json",
        "depth": 3,
        "text": "Manual edits okay: YES"
      },
      {
        "heading": "parameters.json",
        "depth": 3,
        "text": "Add to version control: YES"
      },
      {
        "heading": "parameters.json",
        "depth": 3,
        "text": "Contains a JSON object that maps CloudFormation parameter names to values that will be passed to the CloudFormation template for the category. For example, if the CloudFormation template has the parameter:"
      },
      {
        "heading": "parameters.json",
        "depth": 3,
        "text": "And parameters.json contains"
      },
      {
        "heading": "parameters.json",
        "depth": 3,
        "text": "Then the value of \"RoleArn\" when the template is pushed will be \"<role ARN override>\"."
      },
      {
        "heading": "amplify.state",
        "depth": 3,
        "text": "Manual edits okay: NO"
      },
      {
        "heading": "amplify.state",
        "depth": 3,
        "text": "Add to version control: YES"
      },
      {
        "heading": "amplify.state",
        "depth": 3,
        "text": "Contains internal metadata about how the CLI should build and invoke the function."
      },
      {
        "heading": "transform.conf.json",
        "depth": 3,
        "text": "Manual edits okay: NO"
      },
      {
        "heading": "transform.conf.json",
        "depth": 3,
        "text": "Add to version control: YES"
      },
      {
        "heading": "transform.conf.json",
        "depth": 3,
        "text": "Contains configuration about how to interpret the GraphQL schema and transform it into AppSync resolvers. Run amplify api update to change API category configuration."
      }
    ],
    "source": "export const meta = {\n  title: `Files and Folders`,\n  description: `Learn more about the files and folders Amplify uses to maintain project state.`,\n};\n\n## Folders\n\nThe CLI places the following folder structure in the root directory of the project during `amplify init`:\n\n```text\namplify\n  .config\n  #current-cloud-backend\n  backend\n```\n\n### amplify/.config\n\n> Manual edits okay: NO\n\n> Add to version control: YES\n\nContains files that store cloud configuration and `settings/preferences`. Run `amplify configure` to change the project configuration.\n\n### amplify/#current-cloud-backend\n\n> Manual edits okay: NO\n\n> Add to version control: NO\n\nContains the current cloud state of the checked out environment's resources. The contents of this folder should never be manually updated. It will be overwritten on operations such as `amplify push`, `amplify pull` or `amplify env checkout`.\n\n### amplify/backend\n\n> Manual edits okay: YES\n\n> Add to version control: YES\n\nContains the latest local development state of the checked out environment's resources. The contents of this folder can be modified and running `amplify push` will push changes in this directory to the cloud.\nEach plugin stores contents in its own subfolder within this folder.\n\n### amplify/mock-data\n\n> Manual edits okay: NO\n\n> Add to version control: NO\n\nOnly created after running `amplify mock api`. It contains the SQLite databases that are used to back the local API when mocking. The contents should not be modified but you can delete the folder if you want to wipe your local API state.\n\n## Core Amplify Files\n\nThese files work together to maintain the overall state of the Amplify project such as what resources are configured in the project, dependencies between resources, and when the last push was.\n\n### backend-config.json\n> Manual edits okay: YES\n\n> Add to version control: YES\n\nThe `backend-config.json` in the `backend` directory contains configuration about your project's backend, such as how connects to AWS resources (eg. Cognito for auth or AppSync for an API backend). Typically, this file is updated by the CLI commands like `amplify add auth` or `amplify add api`. It can also be [extended manually](/cli/usage/customcf) to configure your backend beyond Amplify CLI's features. Both the `amplify/backend` and `amplify/#current-cloud-backend` directories contain an `backend-config.json` file.\n\n### amplify-meta.json\n\n> Manual edits okay: NO\n\n> Add to version control: NO\n\nBoth the `amplify/backend` and `amplify/#current-cloud-backend` directories contain an `amplify-meta.json` file. The `amplify-meta.json` in the `backend` directory serves as the whiteboard for the CLI core and the plugins to log internal information and communicate with each other.\n\nThe CLI core provides read and write access to the file for the plugins. Core collects the selected providers' outputs after init and logs them under the \"providers\" object, e.g. the awscloudformation provider outputs the information of the root stack, the deployment S3 bucket, and the authorized/unauthorized IAM roles, and they are logged under the providers.awscloudformation object. Each category plugin logs information under its own name.\n\nBecause one category might create multiple services within one project (e.g. the interactions category can create multiple bots), the category metadata generally follows a two-level structure like the following:\n\n```json\n{\n  \"<category>\": {\n    \"<service1>\": {\n      //service1 metadata\n    },\n    \"<service2>\": {\n      //service2 metadata\n    }\n  }\n}\n```\n\nThe metadata for each service is first logged into the meta file after the `amplify <category> add` command is executed, containing some general information that indicates one service of the category has been added locally.\nThen, on the successful execution of the `amplify push` command, the `output` object will be added/updated in the service's metadata with information that describes the actual cloud resources that have been created or updated.\n\n### aws-exports.js\n\n> Manual edits okay: NO\n\n> Add to version control: NO\n\nThis file is generated only for JavaScript projects.\nIt contains the consolidated outputs from all the categories and is placed under the `src` directory specified during the `init` process. It is updated after `amplify push`.\n\nThis file is consumed by the [Amplify](https://github.com/aws-amplify/amplify-js) JavaScript library for configuration. It contains information which is non-sensitive and only required for external, unauthenticated actions from clients (such as user registration or sign-in flows in the case of Auth) or for constructing appropriate endpoint URLs after authorization has taken place. Please see the following more detailed explanations:\n\n- [Cognito security best practices for web app](https://forums.aws.amazon.com/message.jspa?messageID=757990#757990)\n- [Security / Best Practice for poolData (UserPoolId, ClientId) in a browser JS app](https://github.com/amazon-archives/amazon-cognito-identity-js/issues/312)\n- [Are the Cognito User pool id and Client Id sensitive?](https://stackoverflow.com/a/47865747/194974)\n\n### amplifyconfiguration.json\n\n> Manual edits okay: NO\n\n> Add to version control: NO\n\nThis file is the same as `aws-exports.js` but for Android and iOS projects.\n\nIt is consumed by the [iOS](https://github.com/aws/aws-sdk-ios/) and [Android](https://github.com/aws/aws-sdk-android) native SDKs for configuration.\n\n### .gitignore\n\n> Manual edits okay: YES\n\n> Add to version control: YES\n\nWhen a new project is initialized from the Amplify CLI, Amplify will append the following to the .gitignore file in the root directory. A .gitignore file will be created if one does not exist.\n\n```text\n#amplify-do-not-edit-begin\namplify/\\#current-cloud-backend\namplify/.config/local-*\namplify/logs\namplify/mock-data\namplify/backend/amplify-meta.json\namplify/backend/awscloudformation\namplify/backend/.temp\nbuild/\ndist/\nnode_modules/\naws-exports.js\nawsconfiguration.json\namplifyconfiguration.json\namplifyconfiguration.dart\namplify-build-config.json\namplify-gradle-config.json\namplifytools.xcconfig\n.secret-*\n#amplify-do-not-edit-end\n```\n\n### team-provider-info.json\n\n> Manual edits okay: NO\n\n> Add to version control: YES\n\nUsed to share project info within your team. Learn more at [Share single environment](/cli/teams/shared#sharing-projects-within-the-team).\n\n### cli.json\n\n> Manual edits okay: YES\n\n> Add to version control: YES\n\nContains feature flag configuration for the project. If this file does not exist, it is created by Amplify CLI during `amplify init`. Environment specific feature flag overrides can also be defined in `cli.<environment name>.json`.  If an environment specific file exists for the currently checked out environment, during `amplify env add` command the same file will be copied for the newly created environment as well. Learn more at [Feature flags](/cli/reference/feature-flags).\n\n## General Category Files\n\nWhile each category plugin has some unique files, there are also some common files stored across all categories.\n\n### cli-inputs.json\n\n> Manual edits okay: YES\n\n> Add to version control: YES\n\nStores the input parameters necessary to generate CloudFormation stacks for the associated resource.\n\n### override.ts\n\n> Manual edits okay: YES\n\n> Add to version control: YES\n\nTypeScript file that allows overriding the associated CloudFormation stack for categories that support it. To create this file, run `amplify override <category>`.\n\n### &lt;category&gt;-parameters.json\n\n> Manual edits okay: NO\n\n> Add to version control: YES\n\nStores the parameters selected during `amplify add <category>` so they can be used to populate answers during `amplify update <category>`. This file does NOT change the underlying category configuration; it is only used to populate answers in the walkthrough.\n\n### parameters.json\n\n> Manual edits okay: YES\n\n> Add to version control: YES\n\nContains a JSON object that maps CloudFormation parameter names to values that will be passed to the CloudFormation template for the category. For example, if the CloudFormation template has the parameter:\n\n```json\n{\n  \"Parameters\": {\n    \"RoleArn\": {\n      \"Type\": \"String\",\n      \"Default\": \"<default role ARN>\"\n    }\n  }\n}\n```\n\nAnd `parameters.json` contains\n\n```json\n{\n  \"RoleArn\": \"<role ARN override>\"\n}\n```\n\nThen the value of \"RoleArn\" when the template is pushed will be \"&lt;role ARN override&gt;\".\n\n## Function Category Files\n\n### amplify.state\n\n> Manual edits okay: NO\n\n> Add to version control: YES\n\nContains internal metadata about how the CLI should build and invoke the function.\n\n## AppSync API Category Files\n\n### transform.conf.json\n\n> Manual edits okay: NO\n\n> Add to version control: YES\n\nContains configuration about how to interpret the GraphQL schema and transform it into AppSync resolvers. Run `amplify api update` to change API category configuration.\n",
    "meta": {
      "title": "Files and Folders",
      "description": "Learn more about the files and folders Amplify uses to maintain project state.",
      "subcategory": "Reference",
      "category": "Amplify CLI"
    },
    "filename": "/cli/reference/files"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "You can optionally configure the Amplify CLI to assume an IAM role by defining a profile for the role in the shared ~/.aws/config file. This is similar to how the AWS CLI functions, including short term credentials. This can be useful when you have multiple developers using one or more AWS accounts, including team workflows where you want to restrict the category updates they might be permitted to make."
      },
      {
        "heading": null,
        "depth": null,
        "text": "When prompted during the execution of amplify init or the amplify configure project command, you will select a configured profile for the role, and the Amplify CLI will handle the logic to retrieve, cache and refresh the temp credentials. If Multi-Factor Authentication (MFA) is enabled, the CLI will prompt you to enter the MFA token code when it needs to retrieve or refresh temporary credentials."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The Amplify CLI has its own mechanism of caching temporary credentials, it does NOT use the same cache of the AWS CLI. The temporary credentials are cached at ~/.amplify/awscloudformation/cache.json. You can remove all cached credentials by removing this file.\nIf you only want to remove the cached temp credentials associated with a particular project, execute amplify awscloudformation reset-cache or it's alias amplify aws reset-cache in the project."
      },
      {
        "heading": "Step by step guide to create and assume an IAM role",
        "depth": 2,
        "text": "The following is a step by step guide on how to create an IAM role and make it available for the Amplify CLI."
      },
      {
        "heading": "Step by step guide to create and assume an IAM role",
        "depth": 2,
        "text": "The setup has three parts, we will use an example to demonstrate this capability."
      },
      {
        "heading": "Step by step guide to create and assume an IAM role",
        "depth": 2,
        "text": "Assume Biz Corp has decided to hire Dev Corp to develop its inventory management web portal, and Dev Corp is using the Amplify CLI to speed up the development process."
      },
      {
        "heading": "1. Set up the role (Biz Corp)",
        "depth": 2,
        "text": "Sign in to the AWS Management Console and open the IAM console."
      },
      {
        "heading": "1. Set up the role (Biz Corp)",
        "depth": 2,
        "text": "In the navigation pane of the console, choose Roles and then choose Create role."
      },
      {
        "heading": "1. Set up the role (Biz Corp)",
        "depth": 2,
        "text": "Choose the Another AWS account role type."
      },
      {
        "heading": "1. Set up the role (Biz Corp)",
        "depth": 2,
        "text": "For Account ID, type Dev Corp's AWS account ID (the account ID of the entity you want to grant access to your AWS resources)."
      },
      {
        "heading": "1. Set up the role (Biz Corp)",
        "depth": 2,
        "text": "Although optional, it is recommended to select Require external ID and enter the external id given to you by Dev Corp. (click here for more details on external IDs)."
      },
      {
        "heading": "1. Set up the role (Biz Corp)",
        "depth": 2,
        "text": "If you want to restrict the role to users who sign in with multi-factor authentication (MFA), select Require MFA(click here for more details on MFA)."
      },
      {
        "heading": "1. Set up the role (Biz Corp)",
        "depth": 2,
        "text": "Choose Next: Permissions."
      },
      {
        "heading": "1. Set up the role (Biz Corp)",
        "depth": 2,
        "text": "Select permissions policies that you want the developers from Dev Corp to have when the role is assumed.\nNote: You MUST grant the role permissions to perform CloudFormation actions and create associated resources (depending on the categories you use in your project) such as:"
      },
      {
        "heading": "1. Set up the role (Biz Corp)",
        "depth": 2,
        "text": "Cognito User and Identity Pools"
      },
      {
        "heading": "1. Set up the role (Biz Corp)",
        "depth": 2,
        "text": "S3 buckets"
      },
      {
        "heading": "1. Set up the role (Biz Corp)",
        "depth": 2,
        "text": "DynamoDB tables"
      },
      {
        "heading": "1. Set up the role (Biz Corp)",
        "depth": 2,
        "text": "AppSync APIs"
      },
      {
        "heading": "1. Set up the role (Biz Corp)",
        "depth": 2,
        "text": "API Gateway APIs"
      },
      {
        "heading": "1. Set up the role (Biz Corp)",
        "depth": 2,
        "text": "Pinpoint endpoints"
      },
      {
        "heading": "1. Set up the role (Biz Corp)",
        "depth": 2,
        "text": "Cloudfront distributions"
      },
      {
        "heading": "1. Set up the role (Biz Corp)",
        "depth": 2,
        "text": "IAM Roles"
      },
      {
        "heading": "1. Set up the role (Biz Corp)",
        "depth": 2,
        "text": "Lambda functions"
      },
      {
        "heading": "1. Set up the role (Biz Corp)",
        "depth": 2,
        "text": "Lex bots"
      },
      {
        "heading": "1. Set up the role (Biz Corp)",
        "depth": 2,
        "text": "Choose Next: Tagging, attach tags if you want (optional)."
      },
      {
        "heading": "1. Set up the role (Biz Corp)",
        "depth": 2,
        "text": "Choose Next: Review, type a name for your role, and optionally add the role description."
      },
      {
        "heading": "1. Set up the role (Biz Corp)",
        "depth": 2,
        "text": "Enter the required fields such as the \"Role name\"."
      },
      {
        "heading": "1. Set up the role (Biz Corp)",
        "depth": 2,
        "text": "Choose Create role."
      },
      {
        "heading": "1. Set up the role (Biz Corp)",
        "depth": 2,
        "text": "Give the Role Arn to Dev Corp."
      },
      {
        "heading": "2.1 Create a policy that has permission to assume the role created above by Biz corp",
        "depth": 3,
        "text": "Get the Role Arn from Biz Corp."
      },
      {
        "heading": "2.1 Create a policy that has permission to assume the role created above by Biz corp",
        "depth": 3,
        "text": "Sign in to the AWS Management Console and open the IAM console. (Assuming Dev corp has a separate AWS account)."
      },
      {
        "heading": "2.1 Create a policy that has permission to assume the role created above by Biz corp",
        "depth": 3,
        "text": "In the navigation pane of the console, choose Policies and then choose Create policy."
      },
      {
        "heading": "2.1 Create a policy that has permission to assume the role created above by Biz corp",
        "depth": 3,
        "text": "Select the 'JSON' tab and paste the following contents in the pane, replacing <biz_corp_rol_arn> with the value previously noted."
      },
      {
        "heading": "2.1 Create a policy that has permission to assume the role created above by Biz corp",
        "depth": 3,
        "text": "Choose Review policy."
      },
      {
        "heading": "2.1 Create a policy that has permission to assume the role created above by Biz corp",
        "depth": 3,
        "text": "Type in the policy Name, and optionally add the policy description."
      },
      {
        "heading": "2.1 Create a policy that has permission to assume the role created above by Biz corp",
        "depth": 3,
        "text": "Choose Create policy."
      },
      {
        "heading": "2.2 Attach the policy to the user",
        "depth": 3,
        "text": "Sign in to the AWS Management Console and open the IAM console."
      },
      {
        "heading": "2.2 Attach the policy to the user",
        "depth": 3,
        "text": "In the navigation pane of the console, choose Users and then choose Add user."
      },
      {
        "heading": "2.2 Attach the policy to the user",
        "depth": 3,
        "text": "Type the User name for the new user."
      },
      {
        "heading": "2.2 Attach the policy to the user",
        "depth": 3,
        "text": "Select Programmatic access for Access type."
      },
      {
        "heading": "2.2 Attach the policy to the user",
        "depth": 3,
        "text": "Choose Next: Permissions."
      },
      {
        "heading": "2.2 Attach the policy to the user",
        "depth": 3,
        "text": "On the Set Permissions Page, select Attach existing policies directly."
      },
      {
        "heading": "2.2 Attach the policy to the user",
        "depth": 3,
        "text": "Select the policy created in 2.1."
      },
      {
        "heading": "2.2 Attach the policy to the user",
        "depth": 3,
        "text": "Choose Next: Tagging, attach tags if you wish (optional)."
      },
      {
        "heading": "2.2 Attach the policy to the user",
        "depth": 3,
        "text": "Choose Next: Review."
      },
      {
        "heading": "2.2 Attach the policy to the user",
        "depth": 3,
        "text": "Choose Create User."
      },
      {
        "heading": "2.2 Attach the policy to the user",
        "depth": 3,
        "text": "Click Download .csv to download a copy of the credentials. You can, optionally, copy paste the Access Key ID and Secret Access Key and store it in a safe location. These credentials would be used in a later section."
      },
      {
        "heading": "2.3 Assign MFA device (Optional)",
        "depth": 3,
        "text": "This must be set up if the Biz Corp selected to Require MFA when creating the role. This needs to be set up by Dev Corp users and in their respective AWS account.\nWe are using a virtual MFA device, such as the Google Authenticator app, in this example."
      },
      {
        "heading": "2.3 Assign MFA device (Optional)",
        "depth": 3,
        "text": "Sign in to the AWS Management Console and open the IAM console."
      },
      {
        "heading": "2.3 Assign MFA device (Optional)",
        "depth": 3,
        "text": "In the navigation pane of the console, choose Users and select the user created above in 2.2."
      },
      {
        "heading": "2.3 Assign MFA device (Optional)",
        "depth": 3,
        "text": "Select the Security Credentials tab."
      },
      {
        "heading": "2.3 Assign MFA device (Optional)",
        "depth": 3,
        "text": "Next to the Assigned MFA device label, choose the Manage option."
      },
      {
        "heading": "2.3 Assign MFA device (Optional)",
        "depth": 3,
        "text": "In the Manage MFA Device wizard, choose Virtual MFA device, and then choose Continue."
      },
      {
        "heading": "2.3 Assign MFA device (Optional)",
        "depth": 3,
        "text": "Choose Show QR code if the MFA app supports QR code, and scan the QR code from your virtual device(Google Authenticator app in our case), if not, choose Show secret key and type it into the MFA app."
      },
      {
        "heading": "2.3 Assign MFA device (Optional)",
        "depth": 3,
        "text": "In the MFA code 1 box, type the one-time password that currently appears in the virtual MFA device. Wait for the device to generate a new one-time password. Then type the second one-time password into the MFA code 2 box. Then choose Assign MFA."
      },
      {
        "heading": "2.3 Assign MFA device (Optional)",
        "depth": 3,
        "text": "Copy the MFA device arn next to Assigned MFA device, which will be used in part 3."
      },
      {
        "heading": "3. Set up the local development environment (Dev Corp)",
        "depth": 2,
        "text": "On the local development system, create the following two files if they do not exist.\n~/.aws/config\n~/.aws/credentials"
      },
      {
        "heading": "3. Set up the local development environment (Dev Corp)",
        "depth": 2,
        "text": "Insert the following contents into the ~/.aws/config file:"
      },
      {
        "heading": "3. Set up the local development environment (Dev Corp)",
        "depth": 2,
        "text": "mfa_serial and external_id are optional, leave them out if they are not configured."
      },
      {
        "heading": "3. Set up the local development environment (Dev Corp)",
        "depth": 2,
        "text": "Insert the following contents into the ~/.aws/credentials file:"
      },
      {
        "heading": "3. Set up the local development environment (Dev Corp)",
        "depth": 2,
        "text": "Now, when Dev Corp is trying to initialize an Amplify Project, the user can select the bizcorprole profile configured above, and based on the authentication method set up the user would be prompted with corresponding questions such as MFA codes. After this, the user would be able to successfully deploy/manage AWS resources in Biz corps account (based on the access policies set by the Biz corp)."
      },
      {
        "heading": "3. Set up the local development environment (Dev Corp)",
        "depth": 2,
        "text": "You can take a look at AWS IAM and the AWS CLI documentation for more details on IAM role and its usage."
      }
    ],
    "source": "export const meta = {\n  title: `IAM Roles & MFA`,\n  description: 'Configure the Amplify CLI to assume an IAM role by defining a profile for the role in the shared `~/.aws/config` file.',\n};\n\n \n\nYou can optionally configure the Amplify CLI to assume an IAM role by defining a profile for the role in the shared `~/.aws/config` file. This is similar to how the [AWS CLI](https://aws.amazon.com/cli/) functions, including short term credentials. This can be useful when you have multiple developers using one or more AWS accounts, including team workflows where you want to restrict the category updates they might be permitted to make.\n\nWhen prompted during the execution of `amplify init` or the `amplify configure project` command, you will select a configured profile for the role, and the Amplify CLI will handle the logic to retrieve, cache and refresh the temp credentials. If Multi-Factor Authentication (MFA) is enabled, the CLI will prompt you to enter the MFA token code when it needs to retrieve or refresh temporary credentials.\n\nThe Amplify CLI has its own mechanism of caching temporary credentials, it does NOT use the same cache of the AWS CLI. The temporary credentials are cached at `~/.amplify/awscloudformation/cache.json`. You can remove all cached credentials by removing this file.\nIf you only want to remove the cached temp credentials associated with a particular project, execute `amplify awscloudformation reset-cache` or it's alias `amplify aws reset-cache` in the project.\n\n## Step by step guide to create and assume an IAM role\n\nThe following is a step by step guide on how to create an IAM role and make it available for the Amplify CLI.\n\nThe setup has three parts, we will use an example to demonstrate this capability.\n\nAssume Biz Corp has decided to hire Dev Corp to develop its inventory management web portal, and Dev Corp is using the Amplify CLI to speed up the development process.\n\n## 1. Set up the role (Biz Corp)\n\n1. Sign in to the AWS Management Console and open the [IAM](https://console.aws.amazon.com/iam/) console.\n2. In the navigation pane of the console, choose `Roles` and then choose `Create role`.\n3. Choose the `Another AWS account` role type.\n4. For Account ID, type Dev Corp's AWS account ID (the account ID of the entity you want to grant access to your AWS resources).\n5. Although optional, it is recommended to select `Require external ID` and enter the external id given to you by Dev Corp. (click [here](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-user_externalid.html) for more details on external IDs).\n6. If you want to restrict the role to users who sign in with multi-factor authentication (MFA), select `Require MFA`(click [here](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_mfa.html) for more details on MFA).\n7. Choose `Next: Permissions`.\n8. Select permissions policies that you want the developers from Dev Corp to have when the role is assumed.\nNote: You MUST grant the role permissions to perform CloudFormation actions and create associated resources (depending on the categories you use in your project) such as:\n\n- Cognito User and Identity Pools\n- S3 buckets\n- DynamoDB tables\n- AppSync APIs\n- API Gateway APIs\n- Pinpoint endpoints\n- Cloudfront distributions\n- IAM Roles\n- Lambda functions\n- Lex bots\n\n9. Choose `Next: Tagging`, attach tags if you want (optional).\n10. Choose `Next: Review`, type a name for your role, and optionally add the role description.\n11. Enter the required fields such as the \"Role name\".\n11. Choose `Create role`.\n12. Give the Role Arn to Dev Corp.\n\n## 2. Set up the user to assume the role (Dev Corp)\n\n### 2.1 Create a policy that has permission to assume the role created above by Biz corp\n\n1. Get the Role Arn from Biz Corp.\n2. Sign in to the AWS Management Console and open the [IAM](https://console.aws.amazon.com/iam/) console. (Assuming Dev corp has a separate AWS account).\n3. In the navigation pane of the console, choose `Policies` and then choose `Create policy`.\n4. Select the 'JSON' tab and paste the following contents in the pane, replacing `<biz_corp_rol_arn>` with the value previously noted.\n\n```json\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": \"sts:AssumeRole\",\n            \"Resource\": \"<biz_corp_rol_arn>\"\n        }\n    ]\n}\n```\n\n5. Choose `Review policy`.\n6. Type in the policy Name, and optionally add the policy description.\n7. Choose `Create policy`.\n\n### 2.2 Attach the policy to the user\n\n1. Sign in to the AWS Management Console and open the [IAM](https://console.aws.amazon.com/iam/) console.\n2. In the navigation pane of the console, choose `Users` and then choose `Add user`.\n3. Type the `User name` for the new user.\n4. Select Programmatic access for `Access type`.\n5. Choose `Next: Permissions`.\n6. On the Set Permissions Page, select `Attach existing policies directly`.\n7. Select the policy created in 2.1.\n8. Choose `Next: Tagging`, attach tags if you wish (optional).\n9. Choose `Next: Review`.\n10. Choose `Create User`.\n11. Click `Download .csv` to download a copy of the credentials. You can, optionally, copy paste the Access Key ID and Secret Access Key and store it in a safe location. These credentials would be used in a later section.\n\n### 2.3 Assign MFA device (Optional)\n\nThis must be set up if the Biz Corp selected to `Require MFA` when creating the role. This needs to be set up by Dev Corp users and in their respective AWS account.<br/>\nWe are using a virtual MFA device, such as the Google Authenticator app, in this example.\n\n1. Sign in to the AWS Management Console and open the [IAM](https://console.aws.amazon.com/iam/) console.\n2. In the navigation pane of the console, choose `Users` and select the user created above in 2.2.\n3. Select the `Security Credentials` tab.\n4. Next to the `Assigned MFA device` label, choose the `Manage` option.\n5. In the Manage MFA Device wizard, choose `Virtual MFA device`, and then choose `Continue`.\n6. Choose `Show QR code` if the MFA app supports QR code, and scan the QR code from your virtual device(Google Authenticator app in our case), if not, choose `Show secret key` and type it into the MFA app.\n7. In the MFA code 1 box, type the one-time password that currently appears in the virtual MFA device. Wait for the device to generate a new one-time password. Then type the second one-time password into the MFA code 2 box. Then choose Assign MFA.\n8. Copy the MFA device arn next to `Assigned MFA device`, which will be used in part 3.\n\n## 3. Set up the local development environment (Dev Corp)\n\n1. On the local development system, create the following two files if they do not exist.<br/>\n  `~/.aws/config`<br/>\n  `~/.aws/credentials`<br/>\n2. Insert the following contents into the `~/.aws/config` file:\n\n```ini\n[profile bizcorprole]\nrole_arn=<role_arn_from_part#1>\nsource_profile=devcorpuser\nmfa_serial=<mfa_serial_from_part_2.3---optional>\nexternal_id=<external_id_as_mentioned_in_part#1--optional>\nregion=us-east-1\n\n[profile devcorpuser]\nregion=us-east-1\n```\n\n`mfa_serial` and `external_id` are optional, leave them out if they are not configured.\n\n3. Insert the following contents into the `~/.aws/credentials` file:\n\n```ini\n[devcorpuser]\naws_access_key_id=<key_id_from_part_2.2>\naws_secret_access_key=<secret_access_key_from_part_2.2>\n```\n\nNow, when Dev Corp is trying to initialize an Amplify Project, the user can select the `bizcorprole` profile configured above, and based on the authentication method set up the user would be prompted with corresponding questions such as MFA codes. After this, the user would be able to successfully deploy/manage AWS resources in Biz corps account (based on the access policies set by the Biz corp).\n\nYou can take a look at [AWS IAM](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-user.html) and the [AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-role.html) documentation for more details on IAM role and its usage.\n",
    "meta": {
      "title": "IAM Roles & MFA",
      "description": "Configure the Amplify CLI to assume an IAM role by defining a profile for the role in the shared `~/.aws/config` file.",
      "subcategory": "Reference",
      "category": "Amplify CLI"
    },
    "filename": "/cli/reference/iam-roles-mfa"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "The Amplify CLI requires the below IAM policies for performing actions across all categories. You can grant or restrict category permissions by including or removing items from the Action section as appropriate. For example, if you wish to restrict operations on the Auth category you can remove any of the lines starting with cognito."
      }
    ],
    "source": "export const meta = {\n  title: `IAM Policy`,\n  description: 'The Amplify CLI requires several IAM policies for performing actions across all categories. You can grant or restrict category permissions by including or removing items from the `Action` section as appropriate.',\n};\n\nThe Amplify CLI requires the below IAM policies for performing actions across all categories. You can grant or restrict category permissions by including or removing items from the `Action` section as appropriate. For example, if you wish to restrict operations on the `Auth` category you can remove any of the lines starting with `cognito`.\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"amplify:CreateApp\",\n        \"amplify:CreateBackendEnvironment\",\n        \"amplify:CreateBranch\",\n        \"amplify:DeleteApp\",\n        \"amplify:DeleteBackendEnvironment\",\n        \"amplify:DeleteBranch\",\n        \"amplify:GetApp\",\n        \"amplify:GetBackendEnvironment\",\n        \"amplify:GetBranch\",\n        \"amplify:ListApps\",\n        \"amplify:ListBackendEnvironments\",\n        \"amplify:ListBranches\",\n        \"amplify:ListDomainAssociations\",\n        \"amplify:UpdateApp\",\n        \"apigateway:DELETE\",\n        \"apigateway:GET\",\n        \"apigateway:PATCH\",\n        \"apigateway:POST\",\n        \"apigateway:PUT\",\n        \"appsync:CreateApiKey\",\n        \"appsync:CreateDataSource\",\n        \"appsync:CreateFunction\",\n        \"appsync:CreateGraphqlApi\",\n        \"appsync:CreateResolver\",\n        \"appsync:CreateType\",\n        \"appsync:DeleteApiKey\",\n        \"appsync:DeleteDataSource\",\n        \"appsync:DeleteFunction\",\n        \"appsync:DeleteGraphqlApi\",\n        \"appsync:DeleteResolver\",\n        \"appsync:DeleteType\",\n        \"appsync:GetDataSource\",\n        \"appsync:GetFunction\",\n        \"appsync:GetGraphqlApi\",\n        \"appsync:GetIntrospectionSchema\",\n        \"appsync:GetResolver\",\n        \"appsync:GetSchemaCreationStatus\",\n        \"appsync:GetType\",\n        \"appsync:GraphQL\",\n        \"appsync:ListApiKeys\",\n        \"appsync:ListDataSources\",\n        \"appsync:ListFunctions\",\n        \"appsync:ListGraphqlApis\",\n        \"appsync:ListResolvers\",\n        \"appsync:ListResolversByFunction\",\n        \"appsync:ListTagsForResource\",\n        \"appsync:ListTypes\",\n        \"appsync:StartSchemaCreation\",\n        \"appsync:TagResource\",\n        \"appsync:UpdateApiKey\",\n        \"appsync:UpdateDataSource\",\n        \"appsync:UpdateFunction\",\n        \"appsync:UpdateGraphqlApi\",\n        \"appsync:UpdateResolver\",\n        \"appsync:UpdateType\",\n        \"cloudformation:CreateChangeSet\",\n        \"cloudformation:CreateStack\",\n        \"cloudformation:CreateStackSet\",\n        \"cloudformation:DeleteStack\",\n        \"cloudformation:DeleteStackSet\",\n        \"cloudformation:DescribeChangeSet\",\n        \"cloudformation:DescribeStackEvents\",\n        \"cloudformation:DescribeStackResource\",\n        \"cloudformation:DescribeStackResources\",\n        \"cloudformation:DescribeStacks\",\n        \"cloudformation:DescribeStackSet\",\n        \"cloudformation:DescribeStackSetOperation\",\n        \"cloudformation:ExecuteChangeSet\",\n        \"cloudformation:GetTemplate\",\n        \"cloudformation:GetTemplateSummary\",\n        \"cloudformation:ListStackResources\",\n        \"cloudformation:UpdateStack\",\n        \"cloudformation:UpdateStackSet\",\n        \"cloudfront:CreateCloudFrontOriginAccessIdentity\",\n        \"cloudfront:CreateDistribution\",\n        \"cloudfront:DeleteCloudFrontOriginAccessIdentity\",\n        \"cloudfront:DeleteDistribution\",\n        \"cloudfront:GetCloudFrontOriginAccessIdentity\",\n        \"cloudfront:GetCloudFrontOriginAccessIdentityConfig\",\n        \"cloudfront:GetDistribution\",\n        \"cloudfront:GetDistributionConfig\",\n        \"cloudfront:TagResource\",\n        \"cloudfront:UntagResource\",\n        \"cloudfront:UpdateCloudFrontOriginAccessIdentity\",\n        \"cloudfront:UpdateDistribution\",\n        \"cognito-identity:CreateIdentityPool\",\n        \"cognito-identity:DeleteIdentityPool\",\n        \"cognito-identity:DescribeIdentity\",\n        \"cognito-identity:DescribeIdentityPool\",\n        \"cognito-identity:GetIdentityPoolRoles\",\n        \"cognito-identity:ListIdentityPools\",\n        \"cognito-identity:SetIdentityPoolRoles\",\n        \"cognito-identity:TagResource\",\n        \"cognito-identity:UpdateIdentityPool\",\n        \"cognito-idp:AdminAddUserToGroup\",\n        \"cognito-idp:AdminCreateUser\",\n        \"cognito-idp:CreateGroup\",\n        \"cognito-idp:CreateUserPool\",\n        \"cognito-idp:CreateUserPoolClient\",\n        \"cognito-idp:DeleteGroup\",\n        \"cognito-idp:DeleteUser\",\n        \"cognito-idp:DeleteUserPool\",\n        \"cognito-idp:DeleteUserPoolClient\",\n        \"cognito-idp:DescribeIdentityProvider\",\n        \"cognito-idp:DescribeUserPool\",\n        \"cognito-idp:DescribeUserPoolClient\",\n        \"cognito-idp:GetUserPoolMfaConfig\",\n        \"cognito-idp:ListIdentityProviders\",\n        \"cognito-idp:ListTagsForResource\",\n        \"cognito-idp:ListUserPoolClients\",\n        \"cognito-idp:ListUserPools\",\n        \"cognito-idp:UpdateGroup\",\n        \"cognito-idp:UpdateUserPool\",\n        \"cognito-idp:UpdateUserPoolClient\",\n        \"dynamodb:CreateTable\",\n        \"dynamodb:DeleteItem\",\n        \"dynamodb:DeleteTable\",\n        \"dynamodb:DescribeContinuousBackups\",\n        \"dynamodb:DescribeTable\",\n        \"dynamodb:DescribeTimeToLive\",\n        \"dynamodb:ListStreams\",\n        \"dynamodb:ListTables\",\n        \"dynamodb:PutItem\",\n        \"dynamodb:TagResource\",\n        \"dynamodb:UpdateContinuousBackups\",\n        \"dynamodb:UpdateItem\",\n        \"dynamodb:UpdateTable\",\n        \"dynamodb:UpdateTimeToLive\",\n        \"es:AddTags\",\n        \"es:CreateElasticsearchDomain\",\n        \"es:DeleteElasticsearchDomain\",\n        \"es:DescribeElasticsearchDomain\",\n        \"events:DeleteRule\",\n        \"events:DescribeRule\",\n        \"events:ListRuleNamesByTarget\",\n        \"events:PutRule\",\n        \"events:PutTargets\",\n        \"events:RemoveTargets\",\n        \"geo:GetMapStyleDescriptor\",\n        \"geo:GetMapGlyphs\",\n        \"geo:GetMapSprites\",\n        \"geo:GetMapTile\",\n        \"geo:SearchPlaceIndexForPosition\",\n        \"geo:SearchPlaceIndexForText\",\n        \"geo:SearchPlaceIndexForSuggestions\",\n        \"iam:AttachRolePolicy\",\n        \"iam:CreatePolicy\",\n        \"iam:CreatePolicyVersion\",\n        \"iam:CreateRole\",\n        \"iam:DeletePolicy\",\n        \"iam:DeletePolicyVersion\",\n        \"iam:DeleteRole\",\n        \"iam:DeleteRolePermissionsBoundary\",\n        \"iam:DeleteRolePolicy\",\n        \"iam:DetachRolePolicy\",\n        \"iam:GetPolicy\",\n        \"iam:GetRole\",\n        \"iam:GetRolePolicy\",\n        \"iam:GetUser\",\n        \"iam:ListAttachedRolePolicies\",\n        \"iam:ListPolicyVersions\",\n        \"iam:PassRole\",\n        \"iam:PutRolePermissionsBoundary\",\n        \"iam:PutRolePolicy\",\n        \"iam:TagRole\",\n        \"iam:UpdateRole\",\n        \"kinesis:AddTagsToStream\",\n        \"kinesis:CreateStream\",\n        \"kinesis:DeleteStream\",\n        \"kinesis:DescribeStream\",\n        \"kinesis:DescribeStreamSummary\",\n        \"kinesis:ListTagsForStream\",\n        \"kinesis:PutRecords\",\n        \"lambda:AddLayerVersionPermission\",\n        \"lambda:AddPermission\",\n        \"lambda:CreateEventSourceMapping\",\n        \"lambda:CreateFunction\",\n        \"lambda:DeleteEventSourceMapping\",\n        \"lambda:DeleteFunction\",\n        \"lambda:DeleteLayerVersion\",\n        \"lambda:GetEventSourceMapping\",\n        \"lambda:GetFunction\",\n        \"lambda:GetFunctionConfiguration\",\n        \"lambda:GetLayerVersion\",\n        \"lambda:InvokeAsync\",\n        \"lambda:InvokeFunction\",\n        \"lambda:ListEventSourceMappings\",\n        \"lambda:ListLayerVersions\",\n        \"lambda:PublishLayerVersion\",\n        \"lambda:RemoveLayerVersionPermission\",\n        \"lambda:RemovePermission\",\n        \"lambda:UpdateFunctionCode\",\n        \"lambda:UpdateFunctionConfiguration\",\n        \"lex:GetBot\",\n        \"lex:GetBuiltinIntent\",\n        \"lex:GetBuiltinIntents\",\n        \"lex:GetBuiltinSlotTypes\",\n        \"logs:DescribeLogStreams\",\n        \"logs:GetLogEvents\",\n        \"mobiletargeting:CreateApp\",\n        \"mobiletargeting:DeleteApnsChannel\",\n        \"mobiletargeting:DeleteApnsSandboxChannel\",\n        \"mobiletargeting:DeleteApp\",\n        \"mobiletargeting:DeleteEmailChannel\",\n        \"mobiletargeting:DeleteGcmChannel\",\n        \"mobiletargeting:DeleteSmsChannel\",\n        \"mobiletargeting:GetApnsChannel\",\n        \"mobiletargeting:GetApnsSandboxChannel\",\n        \"mobiletargeting:GetApp\",\n        \"mobiletargeting:GetEmailChannel\",\n        \"mobiletargeting:GetGcmChannel\",\n        \"mobiletargeting:GetSmsChannel\",\n        \"mobiletargeting:UpdateApnsChannel\",\n        \"mobiletargeting:UpdateApnsSandboxChannel\",\n        \"mobiletargeting:UpdateEmailChannel\",\n        \"mobiletargeting:UpdateGcmChannel\",\n        \"mobiletargeting:UpdateSmsChannel\",\n        \"rekognition:DescribeCollection\",\n        \"s3:CreateBucket\",\n        \"s3:DeleteBucket\",\n        \"s3:DeleteBucketPolicy\",\n        \"s3:DeleteBucketWebsite\",\n        \"s3:DeleteObject\",\n        \"s3:DeleteObjectVersion\",\n        \"s3:GetBucketLocation\",\n        \"s3:GetObject\",\n        \"s3:ListAllMyBuckets\",\n        \"s3:ListBucket\",\n        \"s3:ListBucketVersions\",\n        \"s3:PutBucketAcl\",\n        \"s3:PutBucketCORS\",\n        \"s3:PutBucketNotification\",\n        \"s3:PutBucketPolicy\",\n        \"s3:PutBucketWebsite\",\n        \"s3:PutEncryptionConfiguration\",\n        \"s3:PutObject\",\n        \"s3:PutObjectAcl\"\n      ],\n      \"Resource\": \"*\"\n    }\n  ]\n}\n```\n",
    "meta": {
      "title": "IAM Policy",
      "description": "The Amplify CLI requires several IAM policies for performing actions across all categories. You can grant or restrict category permissions by including or removing items from the `Action` section as appropriate.",
      "subcategory": "Reference",
      "category": "Amplify CLI"
    },
    "filename": "/cli/reference/iam"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "The Amplify CLI is changing the default owner value in GraphQL APIs in v8.1.0. Previously, the API stored only the username by default. In this next release behind a feature flag, and in an upcoming major CLI release, the GraphQL Transformer will store a user's unique sub and username."
      },
      {
        "heading": "What is changing?",
        "depth": 2,
        "text": "In the Amplify CLI >= v8.0.3 owner-based @auth rule uses \"username\" as the default identity claim from a JSON Web Token from AWS Cognito and stores it under the owner field in your app's DynamoDB table. This means the owner field of a record will be queried and populated with a user's username. The Amplify CLI GraphQL Transformer is changing the default identityClaim to use a combination of sub - the unique ID (uuid) given by Cognito in your User Pool - and username from the JWT token with a delimiter of ::."
      },
      {
        "heading": "What are the breaking changes?",
        "depth": 2,
        "text": "The sort key fields for your @primaryKeys can no longer be part of an owner-based authorization's ownerField. This also applies to the auto-generated owner field when you add owner-based authorization @auth(rules: [{ allow: owner }]). Here are two primary examples that don't support this:"
      },
      {
        "heading": "What are the breaking changes?",
        "depth": 2,
        "text": "If your table requires this configuration, it is recommended to set the identityClaim to username."
      },
      {
        "heading": "What are the breaking changes?",
        "depth": 2,
        "text": "Additionally, if you want to continue making queries with the owner field as the secondary query parameter, consider using the @index directive instead. Using the mentioned example, you can set up a query as the following:"
      },
      {
        "heading": "What are the breaking changes?",
        "depth": 2,
        "text": "You will be able to query your Todo by user with the following query:"
      },
      {
        "heading": "What are the breaking changes?",
        "depth": 2,
        "text": "Learn more about configuring the @index directive here."
      },
      {
        "heading": "What are the breaking changes?",
        "depth": 2,
        "text": "There are no other breaking changes to your GraphQL API when using the new default identity claim. The resolvers will store these values in your DynamoDB tables in the format of <sub>::<username>, and return username to the client code by default."
      },
      {
        "heading": "What are the breaking changes?",
        "depth": 2,
        "text": "While the other directives will work as they are currently expected to function (i.e. @searchable, @function), using custom queries to your databases may need to be changed. For example, if you are performing a query with the filter parameter, you will need to change it from using the filter query with just 1 argument to using an or conditional statement like the following:"
      },
      {
        "heading": "What are the breaking changes?",
        "depth": 2,
        "text": "Another example of changing your queries is if you are using OpenSearch for a custom query like the one below, you will need your queries to account for the format of the stored owner field with a matching operation (https://docs.amplify.aws/cli/graphql/search-and-result-aggregations/#supported-search-operations). Here's an example of using the match operation:"
      },
      {
        "heading": "Automatic changes the CLI will make for new apps",
        "depth": 3,
        "text": "If you are creating a new Amplify app, your app's GraphQL API will be created using the \"sub::username\" identity claim, and no further action is required from you. Your database records will store the uuid and username in the owner field in the format of <sub>::<username>, and the API will return <username>."
      },
      {
        "heading": "Automatic changes the CLI will make for new apps",
        "depth": 3,
        "text": "If you would like to use username for the identity claim without storing sub, specify in your schema the following:"
      },
      {
        "heading": "Manual changes to continue using \"username\" for existing apps",
        "depth": 3,
        "text": "If you have an existing schema that uses owner-based @auth with an implicit identity claim rule on a type or field similar to this:"
      },
      {
        "heading": "Manual changes to continue using \"username\" for existing apps",
        "depth": 3,
        "text": "Your GraphQL schema is using the default identity claim \"username\" and the Amplify CLI GraphQL Transformer is using the default value to generate your VTL files. Therefore, your schema is read as:"
      },
      {
        "heading": "Manual changes to continue using \"username\" for existing apps",
        "depth": 3,
        "text": "The Amplify CLI is changing the default to \"sub::username\" in v9.0.0, so if your identityClaim is not explicitly defined, the transformers will use \"sub::username\" unless you have set \"username\" to your schema as shown above."
      },
      {
        "heading": "Manual changes to continue using \"username\" for existing apps",
        "depth": 3,
        "text": "In the initial release, this functionality will be behind a feature flag, useSubUsernameForDefaultIdentityClaim, with false as the default value. Setting the feature flag to true enables the transformers to use the new identity claim; however, it is recommended to explicitly state your identity claim moving forward as this feature flag is only temporary (as shown above)."
      },
      {
        "heading": "Manual changes to use \"sub::username\" for existing apps",
        "depth": 3,
        "text": "If you wish to migrate your VTL files before the changes in v9.0.0, set your identityClaim to \"sub::username\"."
      },
      {
        "heading": "Manual changes to use \"sub::username\" for existing apps",
        "depth": 3,
        "text": "Keep in mind that if you have existing owner records in your database and owner-reliant code in your code base, these changes will not migrate your data. The resolvers are backwards compatible, so your API will still be compatible with the former contract that uses username for the owner field. In other words, when using the sub::username identity claim, your resolvers will authorize both username and sub values from the record that match the JWT, but the resolvers will write <sub>::<username> when no owner field input is specified."
      },
      {
        "heading": "What is the timeline?",
        "depth": 2,
        "text": "v8.1.0 of the Amplify CLI is introducing the feature flag, useSubUsernameForDefaultIdentityClaim, that will allow developers to opt into the sub::username default. New Amplify apps created will already be opted into the feature flag, but developers that want to use the new default will have to opt in. For existing Amplify apps, that do not have the feature flag, useSubUsernameForDefaultIdentityClaim will default to false."
      },
      {
        "heading": "What is the timeline?",
        "depth": 2,
        "text": "The Amplify CLI team will release v9.0.0, with the feature flag removed, and developers will need to manually set \"username\" to their schemas to maintain their former API contract, or the resolvers will start to store sub::username in their databases."
      }
    ],
    "source": "export const meta = {\n  title: `Changing the default identity claim for owner-based auth`,\n  description: ``\n};\n\nThe Amplify CLI is changing the default owner value in GraphQL APIs in v8.1.0. Previously, the API stored only the `username` by default. In this next release behind a feature flag, and in an upcoming major CLI release, the GraphQL Transformer will store a user's unique `sub` and `username`.\n\n## What is changing?\n\nIn the Amplify CLI >= v8.0.3 owner-based `@auth` rule uses `\"username\"` as the default identity claim from a JSON Web Token from AWS Cognito and stores it under the `owner` field in your app's DynamoDB table. This means the `owner` field of a record will be queried and populated with a user's username. The Amplify CLI GraphQL Transformer is changing the default `identityClaim` to use a combination of `sub` - the unique ID (uuid) given by Cognito in your User Pool - and `username` from the JWT token with a delimiter of `::`.\n\n## What are the breaking changes?\n\nThe sort key fields for your `@primaryKey`s can no longer be part of an owner-based authorization's `ownerField`. This also applies to the auto-generated `owner` field when you add owner-based authorization `@auth(rules: [{ allow: owner }])`. Here are two primary examples that don't support this:\n\n```graphql\n## NOT supported schema example 1 ##\ntype Item @auth(rules: [{ allow: owner }]) @model {\n   id: ID! @primaryKey(sortKeyFields: [ \"owner\" ])\n   owner: String ## \"owner\" is an auto-generated field of the owner-based authorization rule\n}\n```\n\n```graphql\n## NOT supported schema example 2 ##\ntype Item @auth(rules: [{ allow: owner, ownerField: \"user\" }]) @model {\n   id: ID! @primaryKey(sortKeyFields: [ \"owner\" ])\n   user: String ## \"user\" is the designated \"ownerField\" of the owner-based authorization rule\n}\n```\n\nIf your table requires this configuration, it is recommended to set the `identityClaim` to `username`.\n\nAdditionally, if you want to continue making queries with the owner field as the secondary query parameter, consider using the `@index` directive instead. Using the mentioned example, you can set up a query as the following:\n\n```graphql\ntype Todo @auth(rules: [\n  { allow: owner, ownerField: \"user\" }\n]) {\n  listId: ID! @primaryKey @index(name: \"byUser\", sortKeyFields: [\"user\"], queryField: \"todoByUser\")\n  user: String!\n}\n```\n\nYou will be able to query your `Todo` by `user` with the following query:\n\n```\nquery byUser($user: String!) {\n  todoByUser(user: $user) {\n    items {\n      listId\n      user\n    }\n    nextToken\n  }\n}\n```\n\nLearn more about [configuring the `@index` directive here](https://docs.amplify.aws/cli/graphql/data-modeling/#configure-a-secondary-index).\n\nThere are no other breaking changes to your GraphQL API when using the new default identity claim. The resolvers will store these values in your DynamoDB tables in the format of `<sub>::<username>`, and return `username` to the client code by default.\n\nWhile the other directives will work as they are currently expected to function (i.e. `@searchable`, `@function`), using custom queries to your databases may need to be changed. For example, if you are performing a query with the `filter` parameter, you will need to change it from using the `filter` query with just 1 argument to using an `or` conditional statement like the following:\n\n```graphql\nquery MyQuery {\n  listPrivateNotes(\n    filter: {\n      or: [{ owner: { contains: \"::user1\" } }, { owner: { eq: \"user1\" } }]\n    }\n  ) {\n    nextToken\n    items {\n      id\n      content\n    }\n  }\n}\n```\n\nAnother example of changing your queries is if you are using OpenSearch for a custom query like the one below, you will need your queries to account for the format of the stored owner field with a matching operation (https://docs.amplify.aws/cli/graphql/search-and-result-aggregations/#supported-search-operations). Here's an example of using the `match` operation:\n\n```graphql\nquery SearchAndSort {\n  searchStudents(filter:\n    or: [{\n      owner: { match: \"*::user1\" }\n    }, {\n      owner: { eq: \"user1\" }\n    }],\n  ) {\n    items {\n      name\n      id\n    }\n  }\n}\n```\n\n## How do I migrate my GraphQL API?\n\n### Automatic changes the CLI will make for new apps\n\nIf you are creating a new Amplify app, your app's GraphQL API will be created using the `\"sub::username\"` identity claim, and no further action is required from you. Your database records will store the uuid and username in the `owner` field in the format of `<sub>::<username>`, and the API will return `<username>`.\n\nIf you would like to use username for the identity claim without storing sub, specify in your schema the following:\n\n```graphql\ntype Todo\n  @model\n  @auth(\n    rules: [\n      {\n        allow: owner\n        identityClaim: \"username\" # explicit use of username\n      }\n    ]\n  ) {\n  id: ID!\n  title: String!\n}\n```\n\n### Manual changes to continue using `\"username\"` for existing apps\n\nIf you have an existing schema that uses owner-based `@auth` with an implicit identity claim rule on a type or field similar to this:\n\n```graphql\ntype Todo\n  @model\n  @auth(\n    rules: [\n      {\n        allow: owner # no explicit identity claim\n      }\n    ]\n  ) {\n  id: ID!\n  title: String!\n}\n```\n\nYour GraphQL schema is using the default identity claim `\"username\"` and the Amplify CLI GraphQL Transformer is using the default value to generate your VTL files. Therefore, your schema is read as:\n\n```graphql\ntype Todo\n  @model\n  @auth(\n    rules: [\n      {\n        allow: owner\n        identityClaim: \"username\" # explicit identity claim\n      }\n    ]\n  ) {\n  id: ID!\n  title: String!\n}\n```\n\nThe Amplify CLI is changing the default to `\"sub::username\"` in v9.0.0, so if your `identityClaim` is not explicitly defined, the transformers will use `\"sub::username\"` unless you have set `\"username\"` to your schema as shown above.\n\nIn the initial release, this functionality will be behind a feature flag, `useSubUsernameForDefaultIdentityClaim`, with `false` as the default value. Setting the feature flag to `true` enables the transformers to use the new identity claim; however, it is recommended to explicitly state your identity claim moving forward as this feature flag is only temporary (as shown above).\n\n### Manual changes to use `\"sub::username\"` for existing apps\n\nIf you wish to migrate your VTL files before the changes in v9.0.0, set your `identityClaim` to `\"sub::username\"`.\n\n```graphql\ntype Todo\n  @model\n  @auth(\n    rules: [\n      {\n        allow: owner\n        identityClaim: \"sub::username\" # set your identity claim\n      }\n    ]\n  ) {\n  id: ID!\n  title: String!\n}\n```\n\nKeep in mind that if you have existing owner records in your database and owner-reliant code in your code base, these changes will not migrate your data. The resolvers are backwards compatible, so your API will still be compatible with the former contract that uses `username` for the `owner` field. In other words, when using the `sub::username` identity claim, your resolvers will authorize both `username` and `sub` values from the record that match the JWT, but the resolvers will write `<sub>::<username>` when no owner field input is specified.\n\n## What is the timeline?\n\nv8.1.0 of the Amplify CLI is introducing the feature flag, `useSubUsernameForDefaultIdentityClaim`, that will allow developers to opt into the `sub::username` default. New Amplify apps created will already be opted into the feature flag, but developers that want to use the new default will have to opt in. For existing Amplify apps, that do not have the feature flag, `useSubUsernameForDefaultIdentityClaim` will default to `false`.\n\nThe Amplify CLI team will release v9.0.0, with the feature flag removed, and developers will need to manually set `\"username\"` to their schemas to maintain their former API contract, or the resolvers will start to store `sub::username` in their databases.\n",
    "meta": {
      "title": "GraphQL Transformer @auth identity claim changes",
      "description": "",
      "subcategory": "Migration & Backwards Compatibility",
      "category": "Amplify CLI"
    },
    "filename": "/cli/migration/identity-claim-changes"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Amplify CLI can be used to easily re-create resources in a different AWS account."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Run the following steps to migrate an existing project to another AWS account."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Clone your repository"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Run amplify init"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Select an AWS Profile that will connect to the new account (Do not use an existing environment)"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify CLI updates the amplify/team-provider-info.json file with the new environment name. Run amplify env list to see an additional environment that is connected to the account of the new profile."
      },
      {
        "heading": null,
        "depth": null,
        "text": "If your project includes custom resources, cloning the project to a new environment may not work correctly.\nEnsure that custom resource names are parameterized to guarantee uniqueness when cloning between accounts, regions and Amplify environments"
      }
    ],
    "source": "export const meta = {\n  title: `Migrate project to another AWS account`,\n  description: `Amplify CLI can be used to easily re-create resources in a different AWS account.`\n};\n\nAmplify CLI can be used to easily re-create resources in a different AWS account.\n\nRun the following steps to migrate an existing project to another AWS account.\n\n1. Clone your repository\n2. Run `amplify init`\n3. Select an AWS Profile that will connect to the new account (Do not use an existing environment)\n\nAmplify CLI updates the `amplify/team-provider-info.json` file with the new environment name. Run `amplify env list` to see an additional environment that is connected to the account of the new profile.\n\n<Callout warning>\n\nIf your project includes custom resources, cloning the project to a new environment may not work correctly.\nEnsure that custom resource names are parameterized to guarantee uniqueness when cloning between accounts, regions and Amplify environments\n\n</Callout>\n",
    "meta": {
      "title": "Migrate project to another AWS account",
      "description": "Amplify CLI can be used to easily re-create resources in a different AWS account.",
      "subcategory": "Migration & Backwards Compatibility",
      "category": "Amplify CLI"
    },
    "filename": "/cli/migration/cli-migrate-aws-account"
  },
  {
    "searchableText": [
      {
        "heading": "What is changing?",
        "depth": 3,
        "text": "Amplify CLI 5.1.2 has updated the codegen process to correctly set the optionality for types in models."
      },
      {
        "heading": "What is changing?",
        "depth": 3,
        "text": "Schema example"
      },
      {
        "heading": "What is changing?",
        "depth": 3,
        "text": "In this example, there are four fields with different combinations of optionality:"
      },
      {
        "heading": "What is changing?",
        "depth": 3,
        "text": "requiredElementRequiredList - the list itself is required. Elements it contains must be non-null. Empty lists can only be represented as an empty array."
      },
      {
        "heading": "What is changing?",
        "depth": 3,
        "text": "requiredElementOptionalList - the list itself is optional. If present, elements it contains must be non-null. Empty lists could be represented as either an empty array or a null field."
      },
      {
        "heading": "What is changing?",
        "depth": 3,
        "text": "optionalElementRequiredList - the list itself is required. If present, elements it contains may be null."
      },
      {
        "heading": "What is changing?",
        "depth": 3,
        "text": "optionalElementOptionalList - the list itself is optional. If present, elements it contains may be null."
      },
      {
        "heading": "What is changing?",
        "depth": 3,
        "text": "The list component in this example is a String type, however, this applies for other types as well such as Int, Bool, and embedded types that you define yourself."
      },
      {
        "heading": "Why are we introducing this change?",
        "depth": 3,
        "text": "This is to align the optionality of the generated Swift models as closely as possible to the type defined in the schema."
      },
      {
        "heading": "Who is impacted?",
        "depth": 3,
        "text": "Developers building an iOS app with Amplify DataStore or Amplify API generates Swift models by running the command amplify codegen models."
      },
      {
        "heading": "Who is impacted?",
        "depth": 3,
        "text": "Previous generated Swift code"
      },
      {
        "heading": "Who is impacted?",
        "depth": 3,
        "text": "Current code generated Swift code"
      },
      {
        "heading": "Who is impacted?",
        "depth": 3,
        "text": "The difference between the current and previous code:"
      },
      {
        "heading": "Who is impacted?",
        "depth": 3,
        "text": "requiredElementRequiredList - No changes"
      },
      {
        "heading": "Who is impacted?",
        "depth": 3,
        "text": "requiredElementOptionalList - the list was required and is now optional."
      },
      {
        "heading": "Who is impacted?",
        "depth": 3,
        "text": "optionalElementRequiredList - the list component was required and is now optional. The list was optional and is now required"
      },
      {
        "heading": "Who is impacted?",
        "depth": 3,
        "text": "optionalElementOptionalList - the list component was required and is now optional."
      },
      {
        "heading": "When do I have to upgrade?",
        "depth": 3,
        "text": "This is behind a feature flag in Amplify CLI 5.1.2 and will be deprecated by November 1st, 2021. Developers with existing apps should upgrade to the latest CLI, set the feature flag, and update their app code or their schema (see recommendations following) to account for the change in optionality of the types. Developers building a new app will automatically generate code with the latest changes and no action is required."
      },
      {
        "heading": "Where do I make these changes?",
        "depth": 3,
        "text": "Update Amplify CLI to the latest version"
      },
      {
        "heading": "Where do I make these changes?",
        "depth": 3,
        "text": "The version should be at least 5.1.2"
      },
      {
        "heading": "Where do I make these changes?",
        "depth": 3,
        "text": "If building an existing app, set the feature flag handleListNullabilityTransparently to true in cli.json at the amplify project root."
      },
      {
        "heading": "Where do I make these changes?",
        "depth": 3,
        "text": "Run amplify codegen models to generate the latest models."
      },
      {
        "heading": "Where do I make these changes?",
        "depth": 3,
        "text": "Open the App and make sure the app compiles with the latest generated models. Depending on your schema, you may be in the following scenarios."
      },
      {
        "heading": "Where do I make these changes?",
        "depth": 3,
        "text": "Scenario 1. Schema: requiredElementOptionalList: [String!]"
      },
      {
        "heading": "Where do I make these changes?",
        "depth": 3,
        "text": "Since the list was required and is now optional, unwrap the optional to retrieve the values."
      },
      {
        "heading": "Where do I make these changes?",
        "depth": 3,
        "text": "Recommendation: Update the type in the schema from [String!] to[String!]! to make the list required if you do not have an app use case for storing a null list. This will remove the need to unwrap the list in code."
      },
      {
        "heading": "Where do I make these changes?",
        "depth": 3,
        "text": "Scenario 2. Schema: optionalElementRequiredList: [String]!"
      },
      {
        "heading": "Where do I make these changes?",
        "depth": 3,
        "text": "Since the list component was required and is now optional, unwrap the optional value to retrieve the value. The list was optional and is now required, remove any unwrapping done for the list."
      },
      {
        "heading": "Where do I make these changes?",
        "depth": 3,
        "text": "Recommendation: Update the type in the schema from [String]! to [String!]! to make the list component required if you do not store null values in the list. This will remove the need to unwrap the list component in code."
      },
      {
        "heading": "Where do I make these changes?",
        "depth": 3,
        "text": "Scenario 3. Schema: optionalElementOptionalList: [String]"
      },
      {
        "heading": "Where do I make these changes?",
        "depth": 3,
        "text": "Since the list component was required and is now optional, unwrap the optional value to retrieve the value."
      },
      {
        "heading": "Where do I make these changes?",
        "depth": 3,
        "text": "Recommendation: Update the type in the schema from [String] to [String!]! to make the list and list component required if you do not store null values in the list or a null list. This will remove the need to unwrap the list and the list components."
      }
    ],
    "source": "export const meta = {\n  title: `Amplify Codegen Models - List and list components nullability`,\n  description: `Generating Amplify models with Amplify CLI 5.1.2`,\n};\n\n### **What is changing?** \n\nAmplify CLI 5.1.2 has updated the codegen process to correctly set the optionality for types in models.\n\n_Schema example_\n\n```\ntype ListStringContainer @model {\n  requiredElementRequiredList: [String!]!\n  requiredElementOptionalList: [String!]\n  optionalElementRequiredList: [String]!\n  optionalElementOptionalList: [String]\n}\n```\n\nIn this example, there are four fields with different combinations of optionality:\n- `requiredElementRequiredList` - the list itself is required. Elements it contains must be non-null. Empty lists can only be represented as an empty array.\n- `requiredElementOptionalList` - the list itself is optional. If present, elements it contains must be non-null. Empty lists could be represented as either an empty array or a null field.\n- `optionalElementRequiredList` - the list itself is required. If present, elements it contains may be null.\n- `optionalElementOptionalList` - the list itself is optional. If present, elements it contains may be null.\n\n> The list component in this example is a String type, however, this applies for other types as well such as Int, Bool, and embedded types that you define yourself.\n\n### **Why are we introducing this change?** \n\nThis is to align the optionality of the generated Swift models as closely as possible to the type defined in the schema.\n\n### **Who is impacted?** \n\n<BlockSwitcher>\n\n<Block name=\"iOS\">\n\nDevelopers building an iOS app with Amplify DataStore or Amplify API generates Swift models by running the command `amplify codegen models`. \n\n _Previous generated Swift code_\n\n```swift\npublic struct ListStringContainer: Model {\n  public var requiredElementRequiredList: [String]\n  public var requiredElementOptionalList: [String]\n  public var optionalElementRequiredList: [String]?\n  public var optionalElementOptionalList: [String]?\n  ...\n}\n```\n\n_Current code generated Swift code_\n\n```swift\npublic struct ListStringContainer: Model {\n  public var requiredElementRequiredList: [String]\n  public var requiredElementOptionalList: [String]?\n  public var optionalElementRequiredList: [String?]\n  public var optionalElementOptionalList: [String?]?\n  ...\n}\n```\n\nThe difference between the current and previous code:\n\n- `requiredElementRequiredList` - No changes\n- `requiredElementOptionalList` - the list was required and is now optional.\n- `optionalElementRequiredList` - the list component was required and is now optional. The list was optional and is now required\n- `optionalElementOptionalList` - the list component was required and is now optional. \n\n</Block>\n\n</BlockSwitcher>\n\n### **When do I have to upgrade?**\n\nThis is behind a feature flag in Amplify CLI 5.1.2 and will be deprecated by November 1st, 2021. Developers with existing apps should upgrade to the latest CLI, set the feature flag, and update their app code or their schema (see recommendations following) to account for the change in optionality of the types. Developers building a new app will automatically generate code with the latest changes and no action is required.\n\n### **Where do I make these changes?**\n\n1. Update Amplify CLI to the latest version\n\n```\namplify upgrade\n```\n\n2. The version should be at least 5.1.2\n\n```\namplify --v # at least 5.1.2\n```\n\n3. If building an existing app, set the feature flag `handleListNullabilityTransparently` to `true` in `cli.json` at the amplify project root.\n\n4. Run `amplify codegen models` to generate the latest models.\n\n5. Open the App and make sure the app compiles with the latest generated models. Depending on your schema, you may be in the following scenarios.\n\n<BlockSwitcher>\n\n<Block name=\"iOS\">\n\nScenario 1. Schema: `requiredElementOptionalList: [String!]`\n\n```swift\n// Previous - Swift type\npublic var requiredElementOptionalList: [String]\n\n// Current - Swift type\npublic var requiredElementOptionalList: [String]?\n\n// Previous - Code \nprint(container.requiredElementOptionalList) // [\"value1\", \"value2\"]\n\n// Current - Code\nif let requiredElementList = container.requiredElementOptionalList { \n    print(requiredElementList) // [\"value1\", \"value2\"]\n}\n```\n\nSince the list was required and is now optional, unwrap the optional to retrieve the values.\n\n**Recommendation:** Update the type in the schema from `[String!]` to`[String!]!` to make the list required if you do not have an app use case for storing a null list. This will remove the need to unwrap the list in code.\n\n Scenario 2. Schema: `optionalElementRequiredList: [String]!`\n\n```swift\n// Previous - Swift type\npublic var optionalElementRequiredList: [String]?\n\n// Current - Swift type\npublic var optionalElementRequiredList: [String?]\n\n// Previous - Code\nif let optionalElementRequiredList = container.optionalElementRequiredList { \n    print(optionalElementRequiredList) // [\"value1\", \"value2\"]\n    for value in optionalElementRequiredList {\n        print(value) // \"value1\", \"value2\n    }\n}\n\n// After\nprint(container.optionalElementRequiredList) // [Optional(\"value1\"), Optional(\"value2\")]\nfor value in container.optionalElementRequiredList {\n    if let value = value {\n        print(value) // \"value1\", \"value2\n    }\n}\n```\n\nSince the list component was required and is now optional, unwrap the optional value to retrieve the value. The list was optional and is now required, remove any unwrapping done for the list.\n\n**Recommendation:** Update the type in the schema from `[String]!` to `[String!]!` to make the list component required if you do not store null values in the list. This will remove the need to unwrap the list component in code.\n\nScenario 3. Schema: `optionalElementOptionalList: [String]`\n\n```swift\n// Previous - Swift type\npublic var optionalElementOptionalList: [String]?\n\n// Current - Swift type\npublic var optionalElementOptionalList: [String?]?\n\n// Previous - Code\nif let optionalElementOptionalList = container.optionalElementOptionalList { \n    print(optionalElementOptionalList) // [\"value1\", \"value2\"]\n    for value in optionalElementOptionalList {\n        print(value) // \"value1\", \"value2\n    }\n}\n\n// After\nif let optionalElementList = container.optionalElementOptionalList { \n    print(optionalElementList) // [Optional(\"value1\"), Optional(\"value2\")]\n    for value in optionalElementList {\n        if let value = value {\n            print(value) // \"value1\", \"value2\n        }\n    }\n}\n```\n\nSince the list component was required and is now optional, unwrap the optional value to retrieve the value.\n\n**Recommendation:** Update the type in the schema from `[String]` to `[String!]!` to make the list and list component required if you do not store null values in the list or a null list. This will remove the need to unwrap the list and the list components.\n\n</Block>\n\n</BlockSwitcher>\n",
    "meta": {
      "title": "Amplify Codegen Models - List and list components nullability",
      "description": "Generating Amplify models with Amplify CLI 5.1.2",
      "subcategory": "Migration & Backwards Compatibility",
      "category": "Amplify CLI"
    },
    "filename": "/cli/migration/list-nullability"
  },
  {
    "searchableText": [
      {
        "heading": "Who is affected?",
        "depth": 2,
        "text": "This article is relevant to you if you have an Auth resource created using  amplify add auth  with CLI versions 5.2.0 - 5.6.0."
      },
      {
        "heading": "Who is affected?",
        "depth": 2,
        "text": "If your Auth resource was created with   amplify add auth using Amplify CLI Version 5.1.2 or earlier, or with Amplify CLI version 6.0.0 or later, you are not affected and you can ignore the rest of this article."
      },
      {
        "heading": "The Original CLI  amplify add auth Behavior (versions prior to 5.2.0)",
        "depth": 3,
        "text": "Prior to CLI version 5.2.0, developers could choose one of these options:"
      },
      {
        "heading": "The Changed CLI amplify add auth Behavior (CLI versions 5.2.0 - 5.6.0)",
        "depth": 3,
        "text": "In the CLI release 5.2.0 (July 27, 2021), additional functionality was added for developers configuring Auth.\nBeginning in CLI version 5.2.0, developers could choose any of these options"
      },
      {
        "heading": "Back to the Original Behavior (CLI version 6.0.0 and later)",
        "depth": 3,
        "text": "Beginning in CLI v6.0.0, the original behavior is reinstated and developers can once again choose one of these options:"
      },
      {
        "heading": "What is the impact of this change",
        "depth": 2,
        "text": "If you configured the Auth Resource with the changed amplify add auth behavior (CLI v5.2 - v5.6) you will need to use the changed  amplify add auth behavior whenever you run amplify add auth in order to get a compatible configuration. You can use the changed amplify add auth behavior in CLI v6.0.0 by enabling the \"auth.forceAliasAttributes\" feature flag."
      },
      {
        "heading": "What is the impact of this change",
        "depth": 2,
        "text": "The following code segment demonstrates how Auth.signup() can be used with the Auth resource created with CLI versions 5.2.0 - 5.6.0:"
      },
      {
        "heading": "What is the impact of this change",
        "depth": 2,
        "text": "The following code segment demonstrates how Auth.signup() can be used with the Auth resource created with CLI versions 6.0 and later (this segment would not work for Auth configured with CLI 5.2.0 - 5.6.0):"
      }
    ],
    "source": "export const meta = {\n  title: `CLI Default Auth Signup Behavior`,\n  description: ``,\n};\n\n## Who is affected? \n\nThis article is relevant to you if you have an Auth resource created using  `amplify add auth`  with CLI versions 5.2.0 - 5.6.0.\n\nIf your Auth resource was created with   `amplify add auth` using Amplify CLI Version 5.1.2 or earlier, or with Amplify CLI version 6.0.0 or later, you are not affected and you can ignore the rest of this article. \n\n\n## What Changed\n\n### **The *Original* CLI  `amplify add auth` Behavior (versions prior to 5.2.0)** \n\nPrior to CLI version 5.2.0, developers could choose **one** of these options:\n\n```\nHow do you want users to be able to sign in? (Use the arrow keys)\n>Email\n Username\n Phone Number\n Email or Phone Number\n```\n\n### **The *Changed* CLI `amplify add auth` Behavior (CLI versions 5.2.0 - 5.6.0)**\n\nIn the CLI release 5.2.0 (July 27, 2021), additional functionality was added for developers configuring Auth. \nBeginning in CLI version 5.2.0, developers could choose **any** of these options\n\n```\nHow do you want users to be able to sign in?\n[x] Email Address\n[ ] Phone Number\n[ ] Username\n```\n\n### **Back to the *Original* Behavior (CLI version 6.0.0 and later)**\n\nBeginning in CLI v6.0.0, the original behavior is reinstated and developers can once again choose **one** of these options:\n\n```\nHow do you want users to be able to sign in? (Use the arrow keys)\n>Email\n Username\n Phone Number\n Email or Phone Number\n```\n\n## What is the impact of this change\n\nIf you configured the Auth Resource with the changed `amplify add auth` behavior (CLI v5.2 - v5.6) you will need to use the changed  `amplify add auth` behavior whenever you run `amplify add auth` in order to get a compatible configuration. You can use the changed `amplify add auth` behavior in CLI v6.0.0 by enabling the \"**auth.forceAliasAttributes**\" feature flag.\n\nThe following code segment demonstrates how Auth.signup() can be used with the Auth resource created with CLI versions 5.2.0 - 5.6.0:\n\n```ts\nconst username = getGUID(); \nconst {user} = await Auth.signUp({\n      username,\n      password: \"your-secure-password\",\n      attributes: {\n        email: \"youremail@yourdomain.com\",\n      },\n});\nawait Auth.confirmSignUp(username, code);\nawait Auth.signIn(\"youremail@yourdomain.com\", \"your-secure-password\");\n```\n\nThe following code segment demonstrates how Auth.signup() can be used with the Auth resource created with CLI versions 6.0 and later (this segment would not work for Auth configured with CLI 5.2.0 - 5.6.0):\n\n```ts\nconst {user} = await Auth.signUp({\n      username: \"youremail@yourdomain.com\",\n      password: \"your-secure-password\",\n      attributes: {\n        email: \"youremail@yourdomain.com\", \n      }\n});\n```\n\n\n\n",
    "meta": {
      "title": "CLI Auth Signup Changes",
      "description": "",
      "subcategory": "Migration & Backwards Compatibility",
      "category": "Amplify CLI"
    },
    "filename": "/cli/migration/cli-auth-signup-changes"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Amplify has updated the way Lambda layer versions are managed with Amplify CLI version 5.0.0. Amplify CLI enables you to configure Lambda layers to pull common code & assets for your Lambda functions into a centralized location."
      },
      {
        "heading": null,
        "depth": null,
        "text": "In order to take advantage of the newest features and bug fixes, a one-way migration is required for layers created with an older Amplify CLI version. All developers working on a common Amplify project and any CI/CD pipelines should upgrade to the latest version of Amplify CLI."
      },
      {
        "heading": "How to initiate layer migration",
        "depth": 2,
        "text": "Any update to an existing Lambda layer triggers a migration for that layer upon amplify push. Once the layers are migrated, the layers CANNOT be used with Amplify CLI below version 5.0.0."
      },
      {
        "heading": "Changes to layer behavior",
        "depth": 2,
        "text": "Starting with the Amplify CLI version 5.0.0 and above, the following changes are coming to Lambda layers:"
      },
      {
        "heading": "Changes to layer behavior",
        "depth": 2,
        "text": "Ability to pin a function to always use the latest layer version of a Lambda layer"
      },
      {
        "heading": "Changes to layer behavior",
        "depth": 2,
        "text": "Layers auto-installs and packages dependencies listed within package.json or Pipfile"
      },
      {
        "heading": "Changes to layer behavior",
        "depth": 2,
        "text": "Ability to customize layer version descriptions"
      },
      {
        "heading": "Changes to layer behavior",
        "depth": 2,
        "text": "Ability to delete individual Lambda layer versions"
      },
      {
        "heading": "Changes to layer behavior",
        "depth": 2,
        "text": "Bug fix: Layer version updates are now managed globally, preventing multiple team members from creating conflicting layer versions"
      }
    ],
    "source": "export const meta = {\n  title: `Lambda layer behavior updates`,\n  description: `Amplify has updated the way Lambda layer versions are managed with Amplify CLI version 5.0.0.`,\n};\n\nAmplify has updated the way [Lambda layer](/cli/function/layers) versions are managed with Amplify CLI version 5.0.0. Amplify CLI enables you to configure Lambda layers to pull common code & assets for your Lambda functions into a centralized location. \n\nIn order to take advantage of the newest features and bug fixes, a one-way migration is required for layers created with an older Amplify CLI version. All developers working on a common Amplify project and any CI/CD pipelines should [upgrade to the latest version of Amplify CLI](/cli/usage/upgrade).\n\n## How to initiate layer migration\n\nAny update to an existing Lambda layer triggers a migration for that layer upon `amplify push`. Once the layers are migrated, the layers CANNOT be used with Amplify CLI below version 5.0.0.\n\n## Changes to layer behavior\n\nStarting with the Amplify CLI version 5.0.0 and above, the following changes are coming to Lambda layers:\n- Ability to pin a function to always use the latest layer version of a Lambda layer\n- Layers auto-installs and packages dependencies listed within `package.json` or `Pipfile`\n- Ability to customize layer version descriptions\n- Ability to delete individual Lambda layer versions\n- _Bug fix:_ Layer version updates are now managed globally, preventing multiple team members from creating conflicting layer versions\n",
    "meta": {
      "title": "Lambda layer behavior updates",
      "description": "Amplify has updated the way Lambda layer versions are managed with Amplify CLI version 5.0.0.",
      "subcategory": "Migration & Backwards Compatibility",
      "category": "Amplify CLI"
    },
    "filename": "/cli/migration/lambda-layers-update"
  },
  {
    "searchableText": [
      {
        "heading": "Node.js 8.10 to Node.js 10.x",
        "depth": 2,
        "text": "According to AWS Lambda Runtime Support Policy, AWS Lambda deprecates Node.js runtime Node.js 8.10 on January 6th, 2020."
      },
      {
        "heading": "Node.js 8.10 to Node.js 10.x",
        "depth": 2,
        "text": "The Amplify CLI code base has been updated to reflect this change. Amplify CLI replaces Node.js 8.10 with Node.js 10 in the Lambda functions that it creates for you. If you use Amplify CLI version 4.10.0 and above to create new aws resources, this does not concern you."
      },
      {
        "heading": "Node.js 8.10 to Node.js 10.x",
        "depth": 2,
        "text": "However, if you have used previous versions of the Amplify CLI to create AWS resources in the following categories,\nyou will need to manually update your project artifacts to avoid NodeJS runtime upgrade issues with AWS Lambda."
      },
      {
        "heading": "Node.js 8.10 to Node.js 10.x",
        "depth": 2,
        "text": "auth"
      },
      {
        "heading": "Node.js 8.10 to Node.js 10.x",
        "depth": 2,
        "text": "function"
      },
      {
        "heading": "Node.js 8.10 to Node.js 10.x",
        "depth": 2,
        "text": "interactions"
      },
      {
        "heading": "Node.js 8.10 to Node.js 10.x",
        "depth": 2,
        "text": "Before you make the following manual changes, please make sure to back up your entire project."
      },
      {
        "heading": "Node.js 8.10 to Node.js 10.x",
        "depth": 2,
        "text": "After you make the following manual changes, run amplify push to update the AWS Lambda functions in the cloud."
      },
      {
        "heading": "auth",
        "depth": 3,
        "text": "Auth category allows you to add/configure Lambda Triggers for cognito, such as PostAuthentication and PostConfirmation using amplify add/update auth command.\nLambda triggers are stored as a part of the functions category under the amplify/function/<prefix><TriggerName>/src directory."
      },
      {
        "heading": "auth",
        "depth": 3,
        "text": "In the index files for the Lambda Triggers, Located in amplify/function/<prefix><TriggerName>/src/index.js"
      },
      {
        "heading": "auth",
        "depth": 3,
        "text": "Replace"
      },
      {
        "heading": "auth",
        "depth": 3,
        "text": "With"
      },
      {
        "heading": "function",
        "depth": 3,
        "text": "If you use NodeJS require to import local modules, relative path is needed to specify the local module's location.\nHowever, we have noticed that you can just use the module name to require them with nodejs8.10 runtime on AWS Lambda Functions.\nBut with the nodejs10.x runtime, it is not allowed anymore. AWS Lambda Function will throw an error complaining that it can not find the module, and you have to provide the relative path instead of just the module name to require a local module.\nSo, if you added resources in the function category, and you did not specify relative path to require local modules, you need to update the code base just like the above section for the auth triggers."
      },
      {
        "heading": "interactions",
        "depth": 3,
        "text": "In the <project-root>/amplify/backend/interactions/<resource-name>/src/index.js file"
      },
      {
        "heading": "interactions",
        "depth": 3,
        "text": "Replace"
      },
      {
        "heading": "interactions",
        "depth": 3,
        "text": "With"
      },
      {
        "heading": "runtime string replacement",
        "depth": 3,
        "text": "With the latest version of the Amplify CLI (> 4.7.0), when you execute any amplify command on a project initialized by CLI version prior to 4.7.0, it will prompt for your confirmation to automatically upgrade your NodeJS Lambda runtime versions, from nodejs8.10 to nodejs10.x in all the CloudFormation template files under the amplify/backend folder. If you do not confirm, you will need to manually carry out such replacements. You can go to each category subdirectory, then each resource subdirectory under it, and locate the template file (it could be either .yml or .json file), the template file has template in its name. Then do a global string replacement of nodejs8.10 to nodejs10.x in the file."
      }
    ],
    "source": "export const meta = {\n  title: `Node Version Update`,\n  description: `Upgrading from NodeJS 8.10 to NodeJS 10.x`,\n};\n\n## Node.js 8.10 to Node.js 10.x\n\nAccording to AWS Lambda [Runtime Support Policy](https://docs.aws.amazon.com/lambda/latest/dg/runtime-support-policy.html), AWS Lambda deprecates Node.js runtime Node.js 8.10 on January 6th, 2020.\n\nThe Amplify CLI code base has been updated to reflect this change. Amplify CLI replaces Node.js 8.10 with Node.js 10 in the Lambda functions that it creates for you. If you use Amplify CLI version 4.10.0 and above to create new aws resources, this does not concern you.\n\nHowever, if you have used previous versions of the Amplify CLI to create AWS resources in the following categories,\nyou will need to manually update your project artifacts to avoid NodeJS runtime upgrade issues with AWS Lambda.\n\n- auth\n- function\n- interactions\n\nBefore you make the following manual changes, please make sure to back up your entire project.\n\nAfter you make the following manual changes, run `amplify push` to update the AWS Lambda functions in the cloud.\n\n### auth\n\nAuth category allows you to add/configure Lambda Triggers for cognito, such as PostAuthentication and PostConfirmation using amplify add/update auth command.\nLambda triggers are stored as a part of the functions category under the `amplify/function/<prefix><TriggerName>/src` directory.\n\nIn the index files for the Lambda Triggers, Located in `amplify/function/<prefix><TriggerName>/src/index.js`\n\nReplace\n\n```js\n//...\nconst { handler } = require(`${modules[i]}`);\n//...\n```\n\nWith\n\n```js\n//...\nconst { handler } = require(`./${modules[i]}`);\n//...\n```\n\n### function\n\nIf you use NodeJS [`require`](https://nodejs.org/dist/latest-v12.x/docs/api/modules.html#modules_require_id) to import local modules, relative path is needed to specify the local module's location.\nHowever, we have noticed that you can just use the module name to require them with `nodejs8.10` runtime on AWS Lambda Functions.\nBut with the `nodejs10.x` runtime, it is not allowed anymore. AWS Lambda Function will throw an error complaining that it can not find the module, and you have to provide the relative path instead of just the module name to require a local module.\nSo, if you added resources in the `function` category, and you did not specify relative path to require local modules, you need to update the code base just like the above section for the auth triggers.\n\n### interactions\n\nIn the `<project-root>/amplify/backend/interactions/<resource-name>/src/index.js` file\n\nReplace\n\n```js\nconst response = require('cfn-response');\n//...\n```\n\nWith\n\n```js\nconst response = require('./cfn-response');\n//...\n```\n\n### runtime string replacement\n\nWith the latest version of the Amplify CLI (> 4.7.0), when you execute any `amplify` command on a project initialized by CLI version prior to 4.7.0, it will prompt for your confirmation to automatically upgrade your NodeJS Lambda runtime versions, from `nodejs8.10` to `nodejs10.x` in all the CloudFormation template files under the `amplify/backend` folder. If you do not confirm, you will need to manually carry out such replacements. You can go to each category subdirectory, then each resource subdirectory under it, and locate the template file (it could be either `.yml` or `.json` file), the template file has `template` in its name. Then do a global string replacement of `nodejs8.10` to `nodejs10.x` in the file.\n",
    "meta": {
      "title": "Node Version Update",
      "description": "Upgrading from NodeJS 8.10 to NodeJS 10.x",
      "subcategory": "Migration & Backwards Compatibility",
      "category": "Amplify CLI"
    },
    "filename": "/cli/migration/lambda-node-version-update"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Amplify CLI version 7 and above has been updated to give developers the ability to override Amplify-generated IAM, Cognito, and S3 configuration to best meet app requirements. With the new override capability, developers can easily configure their backend with Amplify-provided defaults but still customize fine-grained resource settings."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The new overrides capabilities or any future resource changes modifies the file structures of your Amplify project under the hood. Projects created before Amplify CLI version 7 require a migration. It is recommended to test this migration in a non-production environment first, without any updates to the app:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "amplify add env test"
      },
      {
        "heading": null,
        "depth": null,
        "text": "amplify override <api|auth|project|storage> or amplify update <api|auth|project|storage>"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Answer \"y\" to migrate your resources"
      },
      {
        "heading": null,
        "depth": null,
        "text": "amplify push"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Test your app scenarios now with this test environment"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Once verified, switch to your original environment amplify env checkout <env-name> and apply the override migration by either running amplify override <category> or amplify update <category>."
      }
    ],
    "source": "export const meta = {\n  title: `Migration to enabled override feature`,\n  description: `Upgrading to Amplify CLI version 7 and above with a project created prior requires a migration to enable the new \"override\" capability.`\n};\n\nAmplify CLI version 7 and above has been updated to give developers the ability to override Amplify-generated IAM, Cognito, and S3 configuration to best meet app requirements. With the new override capability, developers can easily configure their backend with Amplify-provided defaults but still customize fine-grained resource settings.\n\nThe new overrides capabilities or any future resource changes modifies the file structures of your Amplify project under the hood. Projects created before Amplify CLI version 7 require a migration. It is recommended to test this migration in a non-production environment first, without any updates to the app:\n\n1. `amplify add env test`\n2. `amplify override <api|auth|project|storage>` or `amplify update <api|auth|project|storage>`\n3. Answer \"y\" to migrate your resources\n4. `amplify push`\n5. Test your app scenarios now with this test environment\n\nOnce verified, switch to your original environment `amplify env checkout <env-name>` and apply the override migration by either running `amplify override <category>` or `amplify update <category>`.\n",
    "meta": {
      "title": "Override feature enablement migration",
      "description": "Upgrading to Amplify CLI version 7 and above with a project created prior requires a migration to enable the new \"override\" capability.",
      "subcategory": "Migration & Backwards Compatibility",
      "category": "Amplify CLI"
    },
    "filename": "/cli/migration/override"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "The Amplify CLI provides the command amplify plugin init (with alias amplify plugin new) for the development of plugins. This command first collects requirements, and then creates the skeleton of the plugin package for you to start the development. The newly created plugin is added to your local Amplify CLI plugin platform, so you can conveniently test its functionalities while it is being developed. It can be easily removed from the local plugin platform with the amplify plugin remove command, and added back with the amplify plugin add command."
      },
      {
        "heading": "Step 2: Initialize plugin",
        "depth": 3,
        "text": "You will be prompted to enter the plugin name, then select the plugin type, and event subscriptions. The CLI will then create a plugin package for you and add it to the local Amplify CLI plugin platform."
      },
      {
        "heading": "Step 3: Test your plugin",
        "depth": 3,
        "text": "The newly created plugin package is already added to the local Amplify CLI, so you can start testing it immediately.\nLet's say you have chosen to use the default plugin name: my-amplify-plugin"
      },
      {
        "heading": "Step 3: Test your plugin",
        "depth": 3,
        "text": "You will see that the default help message is printed out.\nAt this point, there are only two sub commands in the plugin package, help and version, with dummy implementations. If you try to execute any other command, it will trigger the Amplify CLI plugin platform to perform a fresh scan, and then after it failed to find the command, it will print out the default help message."
      },
      {
        "heading": "Step 3: Test your plugin",
        "depth": 3,
        "text": "From here, you can start to develop the plugin package. See below for the detailed explanation of the package structure."
      },
      {
        "heading": "Step 4: Publish to NPM",
        "depth": 3,
        "text": "After the completion of one development cycle and you are ready to release your plugin to the public, you can publish it to the NPM: https://docs.npmjs.com/getting-started/publishing-npm-packages"
      },
      {
        "heading": "Step 5: Install and Use",
        "depth": 3,
        "text": "Once your plugin is published to the NPM, other developers can install and use it"
      },
      {
        "heading": "Plugin Package Structure",
        "depth": 2,
        "text": "Here's the plugin package directory structure"
      },
      {
        "heading": "amplify-plugin.json",
        "depth": 3,
        "text": "The amplify-plugin.json file is the plugin's manifest file, it specifies the plugin's name, type, commands and event handlers. The Amplify CLI uses it to verify and add the plugin package into its plugin platform."
      },
      {
        "heading": "amplify-plugin.json",
        "depth": 3,
        "text": "Here's the contents of the file when it's first generated by the amplify plugin init command for a util plugin."
      },
      {
        "heading": "index.js",
        "depth": 3,
        "text": "The \"main\" file specified in the package.json is the Amplify CLI's entry to invoke the plugin's functionalities specified in the manifest file amplify-plugin.json."
      },
      {
        "heading": "index.js",
        "depth": 3,
        "text": "Here's the contents of the file when it's first generated by the amplify plugin init command for a util plugin."
      },
      {
        "heading": "commands",
        "depth": 3,
        "text": "The commands folder contains files that implement the commands specified in the manifest file amplify-plugin.json."
      },
      {
        "heading": "event-handlers",
        "depth": 3,
        "text": "The event-handlers folder contains files that implement the eventHandlers specified in the manifest file amplify-plugin.json."
      }
    ],
    "source": "export const meta = {\n  title: `Authoring a new plugin`,\n  description: `Plugins enable you to add additional commands and functionality to existing Amplify CLI. Learn how to create, publish, consume a plugin package.`,\n};\n\n  \n\nThe Amplify CLI provides the command `amplify plugin init` (with alias `amplify plugin new`) for the development of plugins. This command first collects requirements, and then creates the skeleton of the plugin package for you to start the development. The newly created plugin is added to your local Amplify CLI plugin platform, so you can conveniently test its functionalities while it is being developed. It can be easily removed from the local plugin platform with the `amplify plugin remove` command, and added back with the `amplify plugin add` command.\n\n### Step 1: Install Amplify CLI\n\nimport all0 from \"/src/fragments/cli-install-block.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\n### Step 2: Initialize plugin\n\n```bash\namplify plugin init\n```\n\nYou will be prompted to enter the plugin name, then select the plugin type, and event subscriptions. The CLI will then create a plugin package for you and add it to the local Amplify CLI plugin platform.\n\n### Step 3: Test your plugin\n\nThe newly created plugin package is already added to the local Amplify CLI, so you can start testing it immediately.\nLet's say you have chosen to use the default plugin name: `my-amplify-plugin`\n\n```console\n$ amplify my-amplify-plugin help\nhelp command to be implemented.\n```\n\nYou will see that the default help message is printed out.\nAt this point, there are only two sub commands in the plugin package, `help` and `version`, with dummy implementations. If you try to execute any other command, it will trigger the Amplify CLI plugin platform to perform a fresh scan, and then after it failed to find the command, it will print out the default help message.\n\nFrom here, you can start to develop the plugin package. See below for the detailed explanation of the package structure.\n\n### Step 4: Publish to NPM\n\nAfter the completion of one development cycle and you are ready to release your plugin to the public, you can publish it to the NPM: [https://docs.npmjs.com/getting-started/publishing-npm-packages](https://docs.npmjs.com/getting-started/publishing-npm-packages)\n\n### Step 5: Install and Use\n\nOnce your plugin is published to the NPM, other developers can install and use it\n\n```bash\nnpm install -g my-amplify-plugin\namplify plugin add my-amplify-plugin\namplify my-amplify-plugin help\n```\n\n## Plugin Package Structure\n\nHere's the plugin package directory structure\n\n```md\n|_my-amplify-plugin/\n  |_commands/\n  |   |_ help.js\n  |   |_ version.js\n  |\n  |_event-handlers\n  |   |_handle-PostInit.js\n  |   |_handle-PostPush.js\n  |   |_handle-PreInit.js\n  |   |_handle-PrePush.js\n  |\n  |_amplify-plugin.json\n  |_index.js\n  |_package.json\n```\n\n### amplify-plugin.json\n\nThe `amplify-plugin.json` file is the plugin's manifest file, it specifies the plugin's name, type, commands and event handlers. The Amplify CLI uses it to verify and add the plugin package into its plugin platform.\n\nHere's the contents of the file when it's first generated by the `amplify plugin init` command for a util plugin.\n\n```json\n {\n  \"name\": \"my-amplify-plugin\",\n  \"type\": \"util\",\n  \"commands\": [\n    \"version\",\n    \"help\"\n  ],\n  \"eventHandlers\": [\n    \"PreInit\",\n    \"PostInit\",\n    \"PrePush\",\n    \"PostPush\"\n  ]\n}\n```\n\n### index.js\n\nThe `\"main\"` file specified in the `package.json` is the Amplify CLI's entry to invoke the plugin's functionalities specified in the manifest file `amplify-plugin.json`.\n\nHere's the contents of the file when it's first generated by the `amplify plugin init` command for a util plugin.\n\n```js\nconst path = require('path');\n\nasync function executeAmplifyCommand(context) {\n  const commandsDirPath = path.normalize(path.join(__dirname, 'commands'));\n  const commandPath = path.join(commandsDirPath, context.input.command);\n  const commandModule = require(commandPath);\n  await commandModule.run(context);\n}\n\nasync function handleAmplifyEvent(context, args) {\n  const eventHandlersDirPath = path.normalize(path.join(__dirname, 'event-handlers'));\n  const eventHandlerPath = path.join(eventHandlersDirPath, `handle-${args.event}`);\n  const eventHandlerModule = require(eventHandlerPath);\n  await eventHandlerModule.run(context, args);\n}\n\nmodule.exports = {\n  executeAmplifyCommand,\n  handleAmplifyEvent,\n};\n```\n\n### commands\n\nThe `commands` folder contains files that implement the `commands` specified in the manifest file `amplify-plugin.json`.\n\n### event-handlers\n\nThe `event-handlers` folder contains files that implement the `eventHandlers` specified in the manifest file `amplify-plugin.json`.\n\nimport all1 from \"/src/fragments/cli/plugins/custom-transformer.mdx\";\n\n<Fragments fragments={{all: all1}} />\n",
    "meta": {
      "title": "Authoring a new plugin",
      "description": "Plugins enable you to add additional commands and functionality to existing Amplify CLI. Learn how to create, publish, consume a plugin package.",
      "subcategory": "Plugins",
      "category": "Amplify CLI"
    },
    "filename": "/cli/plugins/authoring"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "The Amplify CLI has a pluggable architecture. The CLI core provides the pluggable platform, and most of the CLI category functions are implemented as plugins."
      },
      {
        "heading": "Overview",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Overview",
        "depth": 2,
        "text": "The Amplify CLI Core maintains a plugins.json file to store the plugin management configuration settings and information of all the installed plugins.  \nThe Amplify CLI plugins each contain an amplify-plugin.json file to manifest themselves as valid plugins.  \nThe Amplify CLI Core provides a set of utility commands under amplify plugin for plugin management and to facilitate the development of plugins."
      },
      {
        "heading": "Overview",
        "depth": 2,
        "text": "The Amplify CLI Core does not dynamically scan for plugins at the beginning of each command execution. Instead, information about the installed plugins are retrieved from the plugins.json file and only the plugins that are needed for the execution of the command will be loaded."
      },
      {
        "heading": "Overview",
        "depth": 2,
        "text": "The plugins.json file is stored at path <os.homedir>/.amplify/plugins.json. Unless you really know what you are doing, you should NOT manually edit this file, otherwise you run the risk of corrupting your local installation of the Amplify CLI."
      },
      {
        "heading": "Overview",
        "depth": 2,
        "text": "The plugins.json file will be created or updated in the following situations:"
      },
      {
        "heading": "Overview",
        "depth": 2,
        "text": "If the plugins.json file is not found when the Amplify CLI Core tries to access it, the Amplify CLI Core will create this file and scan the local environment for plugins, and then store the information in the file."
      },
      {
        "heading": "Overview",
        "depth": 2,
        "text": "If the last scan time was more than one day (configurable) ago, the Amplify CLI Core will scan again and update the information."
      },
      {
        "heading": "Overview",
        "depth": 2,
        "text": "If inaccuracy is detected, e.g. a specified plugin cannot be loaded, the Amplify CLI Core will scan again and update the information."
      },
      {
        "heading": "Overview",
        "depth": 2,
        "text": "After the execution of any of the amplify plugin commands that could change it, e.g. amplify plugin scan, amplify plugin add/remove."
      },
      {
        "heading": "Overview",
        "depth": 2,
        "text": "By default, the CLI core searches for plugins in its parent directory, its local node_modules directory, and the global node_modules directory. Plugins are recognized by the amplify- prefix in the package names."
      },
      {
        "heading": "Overview",
        "depth": 2,
        "text": "Plugins communicate with the CLI core and with each other through the project metadata. The CLI core provides the read and write access to the project metadata for the plugins. The project metadata is stored in file amplify/backend/amplify-meta.json in the user project."
      },
      {
        "heading": "Plugin types",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Plugin types",
        "depth": 2,
        "text": "There are four types of plugins"
      },
      {
        "heading": "Plugin types",
        "depth": 2,
        "text": "category"
      },
      {
        "heading": "Plugin types",
        "depth": 2,
        "text": "provider"
      },
      {
        "heading": "Plugin types",
        "depth": 2,
        "text": "frontend"
      },
      {
        "heading": "Plugin types",
        "depth": 2,
        "text": "util"
      },
      {
        "heading": "Category plugin",
        "depth": 3,
        "text": "Amplify maintained category plugins are recognized by the amplify-category- prefix in the package name.\nA category plugin wraps up the logic to create and manage one category of backend resources in the cloud. It defines the \"shape\" of the cloud resources based on user (the developer) input, constructs parameters to CRUD cloud resource, and exports relevant cloud resource information to the project metadata."
      },
      {
        "heading": "Category plugin",
        "depth": 3,
        "text": "Categories are managed by AWS and are a functional use case that a client engineer is building as part of their UX, rather than service implementations."
      },
      {
        "heading": "Provider plugin",
        "depth": 3,
        "text": "Amplify maintained provider plugins are recognized by the amplify-provider- prefix in the package name.\nA provider plugin abstracts the actual cloud resource provider. It wraps up communication details such as access credentials, api invoke, wait logic, and response data parsing. It also exposes simple interface methods for the category plugins to CRUD cloud resource."
      },
      {
        "heading": "AWS CloudFormation provider",
        "depth": 4,
        "text": "Currently, the only official provider plugin, amplify-provider-awscloudformation, uses the AWS CloudFormation to form and update the backend resources in the AWS for the amplify categories. For more information about  AWS CloudFormation, check its user guide:\nAWS CloudFormation User Guide. The amplify-provider-awscloudformation uses\nnested stacks."
      },
      {
        "heading": "Frontend plugin",
        "depth": 3,
        "text": "Amplify maintained frontend plugins are recognized by the amplify-frontend- prefix in the package name.\nA frontend plugin handles a specific type of frontend projects, such as Javascript, Android or iOS projects. Among other things, it provides the following functionalities:"
      },
      {
        "heading": "Frontend plugin",
        "depth": 3,
        "text": "Formats the cloud resource information and writes it to a file at the right location so it can be recognized and consumed by the frontend project"
      },
      {
        "heading": "Frontend plugin",
        "depth": 3,
        "text": "Builds and serves the frontend application locally with backend hot-wired to the cloud resources"
      },
      {
        "heading": "Frontend plugin",
        "depth": 3,
        "text": "Builds and publishes the application (frontend and backend) to its intended users"
      },
      {
        "heading": "util plugin",
        "depth": 3,
        "text": "Official util plugins are recognized by the amplify- prefix, without a plugin type decoration in the package name, a util purpose plugin does not manage any backend resources in the cloud, but provides certain CLI commands and/or certain functionalities for the CLI core, and other plugins."
      }
    ],
    "source": "export const meta = {\n  title: `Architecture`,\n  description: `The Amplify CLI has a pluggable architecture. The CLI core provides the pluggable platform, and most of the CLI category functions are implemented as plugins.`,\n};\n\n  \n\nThe Amplify CLI has a pluggable architecture. The CLI core provides the pluggable platform, and most of the CLI category functions are implemented as plugins.\n\n## Overview\n\n![Image](/images/plugin-platform.png)\n\nThe Amplify CLI Core maintains a `plugins.json` file to store the plugin management configuration settings and information of all the installed plugins.  <br/>\nThe Amplify CLI plugins each contain an `amplify-plugin.json` file to manifest themselves as valid plugins.  <br/>\nThe Amplify CLI Core provides a set of utility commands under `amplify plugin` for plugin management and to facilitate the development of plugins.\n\nThe Amplify CLI Core does not dynamically scan for plugins at the beginning of each command execution. Instead, information about the installed plugins are retrieved from the `plugins.json` file and only the plugins that are needed for the execution of the command will be loaded.\n\nThe `plugins.json` file is stored at path `<os.homedir>/.amplify/plugins.json`. Unless you really know what you are doing, you should NOT manually edit this file, otherwise you run the risk of corrupting your local installation of the Amplify CLI.\n\nThe `plugins.json` file will be created or updated in the following situations:\n\n- If the `plugins.json` file is not found when the Amplify CLI Core tries to access it, the Amplify CLI Core will create this file and scan the local environment for plugins, and then store the information in the file.\n- If the last scan time was more than one day (configurable) ago, the Amplify CLI Core will scan again and update the information.\n- If inaccuracy is detected, e.g. a specified plugin cannot be loaded, the Amplify CLI Core will scan again and update the information.\n- After the execution of any of the `amplify plugin` commands that could change it, e.g. `amplify plugin scan`, `amplify plugin add/remove`.\n\nBy default, the CLI core searches for plugins in its parent directory, its local `node_modules` directory, and the global `node_modules` directory. Plugins are recognized by the `amplify-` prefix in the package names.\n\nPlugins communicate with the CLI core and with each other through the project metadata. The CLI core provides the read and write access to the project metadata for the plugins. The project metadata is stored in file `amplify/backend/amplify-meta.json` in the user project.\n\n## Plugin types\n\n![Image](/images/AmplifyCliConcept.jpg)\n\nThere are four types of plugins\n\n- category\n- provider\n- frontend\n- util\n\n### Category plugin\n\nAmplify maintained category plugins are recognized by the `amplify-category-` prefix in the package name.<br/>\nA category plugin wraps up the logic to create and manage one category of backend resources in the cloud. It defines the \"shape\" of the cloud resources based on user (the developer) input, constructs parameters to CRUD cloud resource, and exports relevant cloud resource information to the project metadata.\n\nCategories are managed by AWS and are a functional use case that a client engineer is building as part of their UX, rather than service implementations.\n\n### Provider plugin\n\nAmplify maintained provider plugins are recognized by the `amplify-provider-` prefix in the package name.<br/>\nA provider plugin abstracts the actual cloud resource provider. It wraps up communication details such as access credentials, api invoke, wait logic, and response data parsing. It also exposes simple interface methods for the category plugins to CRUD cloud resource.\n\n#### AWS CloudFormation provider\n\nCurrently, the only official provider plugin, amplify-provider-awscloudformation, uses the AWS CloudFormation to form and update the backend resources in the AWS for the amplify categories. For more information about  AWS CloudFormation, check its user guide:\n[AWS CloudFormation User Guide](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/Welcome.html). The `amplify-provider-awscloudformation` uses\n[nested stacks](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-nested-stacks.html).\n\n### Frontend plugin\n\nAmplify maintained frontend plugins are recognized by the `amplify-frontend-` prefix in the package name.<br/>\nA frontend plugin handles a specific type of frontend projects, such as Javascript, Android or iOS projects. Among other things, it provides the following functionalities:\n\n- Formats the cloud resource information and writes it to a file at the right location so it can be recognized and consumed by the frontend project\n- Builds and serves the frontend application locally with backend hot-wired to the cloud resources\n- Builds and publishes the application (frontend and backend) to its intended users\n\n### util plugin\n\nOfficial util plugins are recognized by the `amplify-` prefix, without a plugin type decoration in the package name, a util purpose plugin does not manage any backend resources in the cloud, but provides certain CLI commands and/or certain functionalities for the CLI core, and other plugins.\n",
    "meta": {
      "title": "Architecture",
      "description": "The Amplify CLI has a pluggable architecture. The CLI core provides the pluggable platform, and most of the CLI category functions are implemented as plugins.",
      "subcategory": "Plugins",
      "category": "Amplify CLI"
    },
    "filename": "/cli/plugins/architecture"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Plugins are explicitly managed in the Amplify CLI pluggable platform. Plugins enable you to add additional commands and functionality to existing Amplify CLI. This section goes through the steps to create, publish, consume a plugin package, explains the folder structure, and key files in the plugin package."
      },
      {
        "heading": "Official plugins",
        "depth": 2,
        "text": "amplify-category-analytics"
      },
      {
        "heading": "Official plugins",
        "depth": 2,
        "text": "amplify-category-api"
      },
      {
        "heading": "Official plugins",
        "depth": 2,
        "text": "amplify-category-auth"
      },
      {
        "heading": "Official plugins",
        "depth": 2,
        "text": "amplify-category-function"
      },
      {
        "heading": "Official plugins",
        "depth": 2,
        "text": "amplify-category-hosting"
      },
      {
        "heading": "Official plugins",
        "depth": 2,
        "text": "amplify-category-interactions"
      },
      {
        "heading": "Official plugins",
        "depth": 2,
        "text": "amplify-category-notifications"
      },
      {
        "heading": "Official plugins",
        "depth": 2,
        "text": "amplify-category-predictions"
      },
      {
        "heading": "Official plugins",
        "depth": 2,
        "text": "amplify-category-storage"
      },
      {
        "heading": "Official plugins",
        "depth": 2,
        "text": "amplify-category-xr"
      },
      {
        "heading": "Official plugins",
        "depth": 2,
        "text": "amplify-codegen"
      },
      {
        "heading": "Official plugins",
        "depth": 2,
        "text": "amplify-frontend-javascript"
      },
      {
        "heading": "Official plugins",
        "depth": 2,
        "text": "amplify-frontend-android"
      },
      {
        "heading": "Official plugins",
        "depth": 2,
        "text": "amplify-frontend-ios"
      },
      {
        "heading": "Official plugins",
        "depth": 2,
        "text": "amplify-provider-awscloudformation"
      },
      {
        "heading": "Third-party plugins",
        "depth": 2,
        "text": "amplify-category-video - Make it easy to incorporate video streaming into your mobile and web applications powered by AWS Amplify and AWS Media Services"
      },
      {
        "heading": "Third-party plugins",
        "depth": 2,
        "text": "amplify-category-docs - An easy way to view the Amplify Docs from the Amplify CLI"
      },
      {
        "heading": "Third-party plugins",
        "depth": 2,
        "text": "amplify-category-data-importer - Automate the process of seeding, importing, and managing data for Amplify projects"
      },
      {
        "heading": "Third-party plugins",
        "depth": 2,
        "text": "graphql-ttl-transformer - Enable DynamoDB's time-to-live feature to auto-delete old entries in your AWS Amplify API"
      },
      {
        "heading": "Third-party plugins",
        "depth": 2,
        "text": "amplify-graphql-seed-plugin - Seed your local and remote databases with highly customizable mock data using your GraphQL API"
      },
      {
        "heading": "Plugin installation",
        "depth": 2,
        "text": "You can add a 3rd party plugin to the Amplify CLI with the following steps:"
      },
      {
        "heading": "Plugin installation",
        "depth": 2,
        "text": "If the plugin author named the plugin package according to the naming convention."
      },
      {
        "heading": "Plugin installation",
        "depth": 2,
        "text": "Run npm install -g <plugin> and install the plugin to the global node_modules directory."
      },
      {
        "heading": "Plugin installation",
        "depth": 2,
        "text": "Run amplify plugin scan so the Amplify CLI plugin platform will pick up the newly added plugin."
      },
      {
        "heading": "Plugin installation",
        "depth": 2,
        "text": "If the plugin author did NOT name the plugin package according to the naming convention outlined above."
      },
      {
        "heading": "Plugin installation",
        "depth": 2,
        "text": "Run npm install -g <plugin> and install the plugin to the global node_modules directory."
      },
      {
        "heading": "Plugin installation",
        "depth": 2,
        "text": "Run amplify plugin add and provide the path to the plugin to explicitly add the plugin package into the Amplify CLI plugin platform."
      },
      {
        "heading": "Plugin Commands",
        "depth": 2,
        "text": "The following is the suite of the commands under the amplify plugin:"
      },
      {
        "heading": "Plugin Commands",
        "depth": 2,
        "text": "amplify plugin configure"
      },
      {
        "heading": "Plugin Commands",
        "depth": 2,
        "text": "amplify plugin scan"
      },
      {
        "heading": "Plugin Commands",
        "depth": 2,
        "text": "amplify plugin add"
      },
      {
        "heading": "Plugin Commands",
        "depth": 2,
        "text": "amplify plugin remove"
      },
      {
        "heading": "Plugin Commands",
        "depth": 2,
        "text": "amplify plugin list"
      },
      {
        "heading": "Plugin Commands",
        "depth": 2,
        "text": "amplify plugin init"
      },
      {
        "heading": "Plugin Commands",
        "depth": 2,
        "text": "amplify plugin verify"
      },
      {
        "heading": "Plugin Commands",
        "depth": 2,
        "text": "amplify plugin help"
      },
      {
        "heading": "configure",
        "depth": 3,
        "text": "amplify plugin configure is used to configure the following settings in the plugins.json file:"
      },
      {
        "heading": "configure",
        "depth": 3,
        "text": "plugin-directories : contains the directories that plugin packages are searched for during a plugin scan."
      },
      {
        "heading": "configure",
        "depth": 3,
        "text": "plugin-prefixes: contains the plugin package name prefixes. A package named with such prefix is considered a plugin candidate and checked during a plugin scan. If plugin-prefixes is empty, all packages inside the scanned directories will be checked."
      },
      {
        "heading": "configure",
        "depth": 3,
        "text": "max-scan-interval-in-seconds : the Amplify CLI Core will scan again if the last scan time has passed for longer than max-scan-interval-in-seconds. Setting this value to 0 will result in fresh scan at the beginning of each Amplify CLI command execution. The default value is 1 day."
      },
      {
        "heading": "scan",
        "depth": 3,
        "text": "amplify plugin scan will start a fresh scan for plugins in the local environment. A configurable set of directories specified in plugin-directories, such as the global node_modules, are scanned for plugins.\nExecution of this command will completely update the contents of the plugins field in the plugins.json.\nThe last-scan-time field in the plugins.json is the time stamp of the last plugin scan.\nNote that, other than manually started by this command, a plugin scan can also be triggered by a regular amplify command execution, for example if the Amplify CLI Core noticed something is incorrect, or the last scan time has passed for longer than max-scan-interval-in-seconds(set to be one day by default)."
      },
      {
        "heading": "add",
        "depth": 3,
        "text": "amplify plugin add will prompt you to select a previously removed plugin (see below), or enter the full path of a local package to be added as a plugin into the Amplify CLI. The Amplify CLI Core verifies the existence and validity of the plugin package during execution of the this command. You can use this command to add a plugin that will not be found by the plugin scan process, e.g. if it is not in one of the plugin-directories, or its package name does not have the proper prefix as specified in the plugin-prefixes."
      },
      {
        "heading": "remove",
        "depth": 3,
        "text": "amplify plugin remove will prompt you with the list of all the currently active plugins, and allow you to select the ones that you do not want to be included in the Amplify CLI. The Amplify CLI Core will remove the manifest of those plugins from the plugins field, so they will NOT be counted as active plugins anymore and will NOT be loaded during command executions.\nIf a removed plugin is in one of the directories specified in the plugin-directories, and its package name has the prefix as specified in the plugin-prefixes, it is then inserted in the excluded field of the plugins.json file. This will not be inserted back to the plugins field in the next plugin scan.\nThe actual plugin packages themselves are not removed from your computer, and they can be added back as active plugins by amplify plugin add."
      },
      {
        "heading": "list",
        "depth": 3,
        "text": "amplify plugin list lists all the active plugins, along with other information of the local Amplify CLI plugin platform."
      },
      {
        "heading": "init",
        "depth": 3,
        "text": "The Amplify CLI provides the command amplify plugin init (with alias amplify plugin new) for the development of plugins.\nThis command first collects the requirements from you and then creates the skeleton of the plugin package for you to start the development.\nThe newly created plugin package is added to your local Amplify CLI platform, so you can conveniently test its functionalities while it is being developed.\nIt can be easily removed from the platform with the amplify plugin remove command and added back with the amplify plugin add command."
      },
      {
        "heading": "verify",
        "depth": 3,
        "text": "The Amplify CLI provides the utility command amplify plugin verify to verify that:"
      },
      {
        "heading": "verify",
        "depth": 3,
        "text": "The package implements the required interface methods for plugins."
      },
      {
        "heading": "verify",
        "depth": 3,
        "text": "The commands field contains all the required commands for the type of the plugin.\namplify plugin verify command treats the folder where it is executed as the root directory of the plugin package. The command can be executed manually. Its functionality is also invoked by the amplify plugin scan and amplify plugin add commands."
      },
      {
        "heading": "help",
        "depth": 3,
        "text": "Prints out help information for the commands under amplify plugin."
      }
    ],
    "source": "export const meta = {\n  title: `Overview`,\n  description: `Plugins enable you to add additional commands and functionality to existing Amplify CLI. Learn how to create, publish, consume a plugin package.`,\n};\n\n  \n\nPlugins are explicitly managed in the Amplify CLI pluggable platform. Plugins enable you to add additional commands and functionality to existing Amplify CLI. This section goes through the steps to create, publish, consume a plugin package, explains the folder structure, and key files in the plugin package.\n\n## Official plugins\n\n- amplify-category-analytics\n- amplify-category-api\n- amplify-category-auth\n- amplify-category-function\n- amplify-category-hosting\n- amplify-category-interactions\n- amplify-category-notifications\n- amplify-category-predictions\n- amplify-category-storage\n- amplify-category-xr\n- amplify-codegen\n- amplify-frontend-javascript\n- amplify-frontend-android\n- amplify-frontend-ios\n- amplify-provider-awscloudformation\n\n## Third-party plugins\n\n- [amplify-category-video](https://www.npmjs.com/package/amplify-category-video) - Make it easy to incorporate video streaming into your mobile and web applications powered by AWS Amplify and AWS Media Services\n- [amplify-category-docs](https://www.npmjs.com/package/amplify-category-docs) - An easy way to view the Amplify Docs from the Amplify CLI\n- [amplify-category-data-importer](https://www.npmjs.com/package/amplify-category-data-importer) - Automate the process of seeding, importing, and managing data for Amplify projects\n- [graphql-ttl-transformer](https://github.com/flogy/graphql-ttl-transformer) - Enable DynamoDB's time-to-live feature to auto-delete old entries in your AWS Amplify API\n- [amplify-graphql-seed-plugin](https://www.npmjs.com/package/amplify-graphql-seed-plugin) - Seed your local and remote databases with highly customizable mock data using your GraphQL API\n\n## Plugin installation\n\nYou can add a 3rd party plugin to the Amplify CLI with the following steps:\n\n- If the plugin author named the plugin package according to the [naming convention](/cli/plugins/architecture#plugin-types).\n\n1. Run `npm install -g <plugin>` and install the plugin to the global node_modules directory.<br/>\n2. Run `amplify plugin scan` so the Amplify CLI plugin platform will pick up the newly added plugin.\n\n- If the plugin author did NOT name the plugin package according to the naming convention outlined above.\n\n1. Run `npm install -g <plugin>` and install the plugin to the global node_modules directory.<br/>\n2. Run `amplify plugin add` and provide the path to the plugin to explicitly add the plugin package into the Amplify CLI plugin platform.\n\n## Plugin Commands\n\nThe following is the suite of the commands under the `amplify plugin`:\n\n- amplify plugin configure\n- amplify plugin scan\n- amplify plugin add\n- amplify plugin remove\n- amplify plugin list\n- amplify plugin init\n- amplify plugin verify\n- amplify plugin help\n\n### configure\n\n`amplify plugin configure` is used to configure the following settings in the `plugins.json` file:\n\n- `plugin-directories` : contains the directories that plugin packages are searched for during a plugin scan.\n- `plugin-prefixes`: contains the plugin package name prefixes. A package named with such prefix is considered a plugin candidate and checked during a plugin scan. If `plugin-prefixes` is empty, all packages inside the scanned directories will be checked.\n- `max-scan-interval-in-seconds` : the Amplify CLI Core will scan again if the last scan time has passed for longer than `max-scan-interval-in-seconds`. Setting this value to 0 will result in fresh scan at the beginning of each Amplify CLI command execution. The default value is 1 day.\n\n### scan\n\n`amplify plugin scan` will start a fresh scan for plugins in the local environment. A configurable set of directories specified in `plugin-directories`, such as the global node_modules, are scanned for plugins.<br/>\nExecution of this command will completely update the contents of the `plugins` field in the `plugins.json`.\nThe `last-scan-time` field in the `plugins.json` is the time stamp of the last plugin scan.\nNote that, other than manually started by this command, a plugin scan can also be triggered by a regular amplify command execution, for example if the Amplify CLI Core noticed something is incorrect, or the last scan time has passed for longer than `max-scan-interval-in-seconds`(set to be one day by default).\n\n### add\n\n`amplify plugin add` will prompt you to select a previously removed plugin (see below), or enter the full path of a local package to be added as a plugin into the Amplify CLI. The Amplify CLI Core verifies the existence and validity of the plugin package during execution of the this command. You can use this command to add a plugin that will not be found by the plugin scan process, e.g. if it is not in one of the `plugin-directories`, or its package name does not have the proper prefix as specified in the `plugin-prefixes`.\n\n### remove\n\n`amplify plugin remove` will prompt you with the list of all the currently active plugins, and allow you to select the ones that you do not want to be included in the Amplify CLI. The Amplify CLI Core will remove the manifest of those plugins from the `plugins` field, so they will NOT be counted as active plugins anymore and will NOT be loaded during command executions.<br/>\nIf a removed plugin is in one of the directories specified in the `plugin-directories`, and its package name has the prefix as specified in the `plugin-prefixes`, it is then inserted in the `excluded` field of the `plugins.json` file. This will not be inserted back to the `plugins` field in the next plugin scan.\nThe actual plugin packages themselves are not removed from your computer, and they can be added back as active plugins by `amplify plugin add`.\n\n### list\n\n`amplify plugin list` lists all the active plugins, along with other information of the local Amplify CLI plugin platform.\n\n### init\n\nThe Amplify CLI provides the command `amplify plugin init` (with alias `amplify plugin new`) for the development of plugins.<br/>\nThis command first collects the requirements from you and then creates the skeleton of the plugin package for you to start the development.\nThe newly created plugin package is added to your local Amplify CLI platform, so you can conveniently test its functionalities while it is being developed.\nIt can be easily removed from the platform with the `amplify plugin remove` command and added back with the `amplify plugin add` command.\n\n### verify\n\nThe Amplify CLI provides the utility command `amplify plugin verify` to verify that:\n\n- The package implements the required interface methods for plugins.\n- The `commands` field contains all the required commands for the type of the plugin.\n`amplify plugin verify` command treats the folder where it is executed as the root directory of the plugin package. The command can be executed manually. Its functionality is also invoked by the `amplify plugin scan` and `amplify plugin add` commands.\n\n### help\n\nPrints out help information for the commands under `amplify plugin`.\n",
    "meta": {
      "title": "Overview",
      "description": "Plugins enable you to add additional commands and functionality to existing Amplify CLI. Learn how to create, publish, consume a plugin package.",
      "subcategory": "Plugins",
      "category": "Amplify CLI"
    },
    "filename": "/cli/plugins/plugins"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Several commands in the Amplify CLI support arguments which could be used in a CI/CD workflow or other non-interactive shell. The CLI will work non-interactively if the required information is provided by an argument."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Arguments are used mostly for scripting so that the command execution flow is not interrupted by prompts. Examples for this can be found here"
      },
      {
        "heading": null,
        "depth": null,
        "text": "--yes flag"
      },
      {
        "heading": null,
        "depth": null,
        "text": "The --yes flag, or its alias -y, suppresses command line prompts if defaults are available, and uses the defaults in command execution.\nThe following commands take the --yes flag:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "amplify init"
      },
      {
        "heading": null,
        "depth": null,
        "text": "amplify configure project"
      },
      {
        "heading": null,
        "depth": null,
        "text": "amplify push"
      },
      {
        "heading": null,
        "depth": null,
        "text": "amplify publish"
      },
      {
        "heading": null,
        "depth": null,
        "text": "amplify pull"
      },
      {
        "heading": "amplify init parameters",
        "depth": 2,
        "text": "The amplify init command takes these parameters:"
      },
      {
        "heading": "amplify init parameters",
        "depth": 2,
        "text": "--amplify"
      },
      {
        "heading": "amplify init parameters",
        "depth": 2,
        "text": "--frontend"
      },
      {
        "heading": "amplify init parameters",
        "depth": 2,
        "text": "--providers"
      },
      {
        "heading": "amplify init parameters",
        "depth": 2,
        "text": "--categories"
      },
      {
        "heading": "amplify init parameters",
        "depth": 2,
        "text": "--yes"
      },
      {
        "heading": "amplify init parameters",
        "depth": 2,
        "text": "--app"
      },
      {
        "heading": "--amplify",
        "depth": 3,
        "text": "Contains basic information of the project, it has these keys:"
      },
      {
        "heading": "--amplify",
        "depth": 3,
        "text": "projectName: the name of the project under development"
      },
      {
        "heading": "--amplify",
        "depth": 3,
        "text": "appId: the Amplify Service project Id (optional, see below)"
      },
      {
        "heading": "--amplify",
        "depth": 3,
        "text": "envName: the name of your first environment"
      },
      {
        "heading": "--amplify",
        "depth": 3,
        "text": "defaultEditor: your default code editor"
      },
      {
        "heading": "--amplify",
        "depth": 3,
        "text": "The appId parameter is optional and it is used in two use cases."
      },
      {
        "heading": "--amplify",
        "depth": 3,
        "text": "Amplify Service uses it internally when you initialize a project on Amplify web console."
      },
      {
        "heading": "--amplify",
        "depth": 3,
        "text": "For project migrations. For projects initialized by Amplify CLI version prior to 4.0.0, no Amplify Service project is created online to track the backend environment's resources. The latest version of the Amplify CLI will create a new Amplify Service project for them in the post-push check. If you wanted to add the backend environment to an existing Amplify Service project instead of creating a new one, you can run amplify init again, and provide the appId inside the --amplify parameter, or explicitly as amplify init --appId <Amplify-Service-Project-AppId>."
      },
      {
        "heading": "--frontend",
        "depth": 3,
        "text": "Contains information for the CLI's frontend plugin, it has these keys:"
      },
      {
        "heading": "--frontend",
        "depth": 3,
        "text": "frontend: the name of the chosen frontend plugin (without the amplify-frontend- prefix)."
      },
      {
        "heading": "--frontend",
        "depth": 3,
        "text": "framework: the frontend framework used in the project, such as react. Only the javascript frontend handler takes it."
      },
      {
        "heading": "--frontend",
        "depth": 3,
        "text": "config: the configuration settings for the frontend plugin."
      },
      {
        "heading": "--frontend",
        "depth": 3,
        "text": "There are currently three official frontend plugins, and the following are the specifications of their respective config object:"
      },
      {
        "heading": "--frontend",
        "depth": 3,
        "text": "config for javascript"
      },
      {
        "heading": "--frontend",
        "depth": 3,
        "text": "SourceDir:\nThe project's source directory. The CLI will place and update the aws-exports.js file in it, the aws-exports.js file is used to configure the Amplify JS library."
      },
      {
        "heading": "--frontend",
        "depth": 3,
        "text": "DistributionDir:\nThe project's distribution directory, where the build artifacts are stored. The CLI will upload the contents inside this directory to the S3 hosting buckets in the execution of the amplify publish command."
      },
      {
        "heading": "--frontend",
        "depth": 3,
        "text": "BuildCommand:\nThe build command for the project. The CLI invokes the build command before uploading the contents in the distribution directory in the execution of the amplify publish command."
      },
      {
        "heading": "--frontend",
        "depth": 3,
        "text": "StartCommand:\nThe start command for the project, used for local testing. The CLI invokes the start command after it has pushed the latest development of the backend to the cloud in the execution of the amplify run command."
      },
      {
        "heading": "--frontend",
        "depth": 3,
        "text": "config for android"
      },
      {
        "heading": "--frontend",
        "depth": 3,
        "text": "ResDir: The Android project's resource directory, such as app/src/main/res."
      },
      {
        "heading": "--frontend",
        "depth": 3,
        "text": "config for ios"
      },
      {
        "heading": "--frontend",
        "depth": 3,
        "text": "The ios frontend handler does NOT take the config object."
      },
      {
        "heading": "--providers",
        "depth": 3,
        "text": "Contains configuration settings for provider plugins. The key is the name of the provider plugin (without the amplify-provider- prefix), and the value is its configuration. Provider plugins contained in this object will be initialized, and able to provide functionalities for creation and maintenance of the cloud resources."
      },
      {
        "heading": "--providers",
        "depth": 3,
        "text": "Currently there is only one official provider plugin: amplify-provider-awscloudformation, its configuration is for the CLI to resolve aws credentials and region, the following are the specifications:"
      },
      {
        "heading": "--providers",
        "depth": 3,
        "text": "configLevel:\nThe configuration level is either project or general. Unless explicitly set to general, the project level is chosen.\ngeneral level means the CLI will not manage configuration at the project level, it instead relies on the AWS SDK to resolve aws credentials and region. To learn how it works, check the AWS SDK's documents on credentials and region.\nproject level means the configuration is managed at the project level by the CLI, each project gets its own independent configuration. The following attributes are used only when the configuration is at project level"
      },
      {
        "heading": "--providers",
        "depth": 3,
        "text": "useProfile:\nA boolean indicating whether to use a profile defined in the shared config file (~/.aws/config) and credentials file (~/.aws/credentials). "
      },
      {
        "heading": "--providers",
        "depth": 3,
        "text": "profileName:\nThe name of the profile if useProfile is set to true."
      },
      {
        "heading": "--providers",
        "depth": 3,
        "text": "accessKeyId:\nThe aws access key id if useProfile is set to false."
      },
      {
        "heading": "--providers",
        "depth": 3,
        "text": "secretAccessKey:\nThe aws secret access key if useProfile is set to false."
      },
      {
        "heading": "--providers",
        "depth": 3,
        "text": "region:\nThe aws region if useProfile is set to false."
      },
      {
        "heading": "--categories",
        "depth": 3,
        "text": "Contains configuration settings for resources in the given categories. The key is the name of the category and the value is its configuration. There are resource parameters that are not persisted into configuration files and requires prompting for them during a headless CLI operation and to support headless workflows they are required to be passed in for each resource.."
      },
      {
        "heading": "Imported resources",
        "depth": 4,
        "text": "Currently auth and storage category resources can be imported to an Amplify CLI project."
      },
      {
        "heading": "auth category",
        "depth": 4,
        "text": "userPoolId: The Id of the Cognito User Pool that was imported into the project."
      },
      {
        "heading": "auth category",
        "depth": 4,
        "text": "webClientId: The Id of the app client configured for the given Cognito User Pool to be used by web applications."
      },
      {
        "heading": "auth category",
        "depth": 4,
        "text": "nativeClientId: The Id of the app client configured for the given Cognito User Pool to be used by Native applications."
      },
      {
        "heading": "auth category",
        "depth": 4,
        "text": "identityPoolId: In case if an Cognito Identity Pool was also configured for the auth resource this parameter is the Id of that resource. If there is no associated Cognito Identity Pool was configured, this parameter should not be passed in."
      },
      {
        "heading": "auth category",
        "depth": 4,
        "text": "Sample auth category configuration:"
      },
      {
        "heading": "storage category",
        "depth": 4,
        "text": "Storage category supports the importing of S3 Buckets and DynamoDB tables. They require different parameter sets within the storage category."
      },
      {
        "heading": "S3 Buckets",
        "depth": 4,
        "text": "region: The region of the S3 bucket resource. S3 Buckets are global, but the CLI requires to storage of the region as a parameter, so it needs to be passed in. Currently it must be the same region where the Amplify project was created."
      },
      {
        "heading": "S3 Buckets",
        "depth": 4,
        "text": "bucketName: The name of the imported S3 bucket."
      },
      {
        "heading": "DynamoDB Tables",
        "depth": 4,
        "text": "An Amplify project can have multiple DynamoDB storage resources imported and the parameters must be supplied to each of them."
      },
      {
        "heading": "DynamoDB Tables",
        "depth": 4,
        "text": "region: The region of the DynamoDB table resources. Currently it must be the same region where the Amplify project was created."
      },
      {
        "heading": "DynamoDB Tables",
        "depth": 4,
        "text": "tables: An object where the key is the Amplify resource name and the value is the name of the DynamoDB table."
      },
      {
        "heading": "--app",
        "depth": 3,
        "text": "amplify init --app git@github.com:<github-username>/<repository-name>.git"
      },
      {
        "heading": "--app",
        "depth": 3,
        "text": "Installs, initializes, and provisions resources for a sample amplify application from the provided GitHub repository URL. This option must be executed in an empty directory. The sample repository must have an amplify folder, including the following:"
      },
      {
        "heading": "--app",
        "depth": 3,
        "text": "project-config.json in .config folder"
      },
      {
        "heading": "--app",
        "depth": 3,
        "text": "backend-config.json in backend folder"
      },
      {
        "heading": "--app",
        "depth": 3,
        "text": "The necessary cloudformation files in the backend folder"
      },
      {
        "heading": "--app",
        "depth": 3,
        "text": "e.g. stacks, schema.graphql for api"
      },
      {
        "heading": "--app",
        "depth": 3,
        "text": "e.g. cloudformation template for auth"
      },
      {
        "heading": "--app",
        "depth": 3,
        "text": "local files local-env.json and local-aws-info.json are NOT required"
      },
      {
        "heading": "--app",
        "depth": 3,
        "text": "If the repository contains a yarn.lock and/or package.json file, the sample will be installed with the corresponding package manager and started after resources have been provisioned."
      },
      {
        "heading": "amplify configure project parameters",
        "depth": 2,
        "text": "The amplify configure project command allows the user to change the configuration settings that were first set by amplify init, and it takes the same parameters as the amplify init command:"
      },
      {
        "heading": "amplify configure project parameters",
        "depth": 2,
        "text": "--amplify"
      },
      {
        "heading": "amplify configure project parameters",
        "depth": 2,
        "text": "--frontend"
      },
      {
        "heading": "amplify configure project parameters",
        "depth": 2,
        "text": "--providers"
      },
      {
        "heading": "amplify configure project parameters",
        "depth": 2,
        "text": "--yes"
      },
      {
        "heading": "amplify push/publish parameters",
        "depth": 2,
        "text": "The amplify publish command internally executes amplify push so it takes the same parameters as push command. The amplify push command takes the following parameters"
      },
      {
        "heading": "amplify push/publish parameters",
        "depth": 2,
        "text": "--codegen"
      },
      {
        "heading": "amplify push/publish parameters",
        "depth": 2,
        "text": "--yes"
      },
      {
        "heading": "amplify push/publish parameters",
        "depth": 2,
        "text": "--force"
      },
      {
        "heading": "amplify push/publish parameters",
        "depth": 2,
        "text": "--allow-destructive-graphql-schema-updates"
      },
      {
        "heading": "--codegen",
        "depth": 3,
        "text": "Contains configuration for AppSync codegen, the following are the specifications:"
      },
      {
        "heading": "--codegen",
        "depth": 3,
        "text": "generateCode: \nA boolean indicating if to generate code for your GraphQL API."
      },
      {
        "heading": "--codegen",
        "depth": 3,
        "text": "codeLanguage: \nThe targeted language of the generated code, such as javascript."
      },
      {
        "heading": "--codegen",
        "depth": 3,
        "text": "fileNamePattern:  \nThe file name pattern of GraphQL queries, mutations and subscriptions."
      },
      {
        "heading": "--codegen",
        "depth": 3,
        "text": "generatedFileName:  \nThe file name for the generated code."
      },
      {
        "heading": "--codegen",
        "depth": 3,
        "text": "generateDocs:  \nA boolean indicating whether to generate GraphQL statements (queries, mutations and subscription) based on the GraphQL schema types. The generated version will overwrite the current GraphQL queries, mutations and subscriptions."
      },
      {
        "heading": "--yes",
        "depth": 3,
        "text": "Will skip all interactive prompts by selecting default options."
      },
      {
        "heading": "--force",
        "depth": 3,
        "text": "Pushes all resources regardless of update status and bypasses all guardrails to push the local state to the cloud. Only use this flag if you have tested the change in a non-production environment and fully understand the implications."
      },
      {
        "heading": "--force",
        "depth": 3,
        "text": "It includes all of the behavior of --allow-destructive-graphql-schema-updates"
      },
      {
        "heading": "--allow-destructive-graphql-schema-updates",
        "depth": 3,
        "text": "Pushes schema changes that require removal or replacement of underlying tables. See update schema."
      },
      {
        "heading": "amplify pull parameters",
        "depth": 2,
        "text": "The amplify pull command pulls down the latest backend environment to your local development.\nIt is used in two scenarios:"
      },
      {
        "heading": "amplify pull parameters",
        "depth": 2,
        "text": "On projects already initialized by the Amplify CLI, it pulls down the latest from the Cloud and updates the contents in the amplify/#current-cloud-backend directory. The command does not take any parameters when used in this scenario."
      },
      {
        "heading": "amplify pull parameters",
        "depth": 2,
        "text": "On projects NOT yet initialized by the Amplify CLI, it pulls down a particular backend environment, and \"attaches\" it to the project. It will fully set up the amplify directory for the project.  The backend environment being pulled is specified by appId and envName in the amplify parameter (see below). The command takes the following parameters when used in this scenario."
      },
      {
        "heading": "amplify pull parameters",
        "depth": 2,
        "text": "--amplify"
      },
      {
        "heading": "amplify pull parameters",
        "depth": 2,
        "text": "--frontend"
      },
      {
        "heading": "amplify pull parameters",
        "depth": 2,
        "text": "--providers"
      },
      {
        "heading": "amplify pull parameters",
        "depth": 2,
        "text": "--yes"
      },
      {
        "heading": "--amplify",
        "depth": 3,
        "text": "Contains basic information of the project, it has these keys:"
      },
      {
        "heading": "--amplify",
        "depth": 3,
        "text": "projectName: the name of the project under development"
      },
      {
        "heading": "--amplify",
        "depth": 3,
        "text": "appId: the Amplify Service project Id"
      },
      {
        "heading": "--amplify",
        "depth": 3,
        "text": "envName: the name of the backend environment in the above mention Amplify Service that you want to pull down"
      },
      {
        "heading": "--amplify",
        "depth": 3,
        "text": "defaultEditor: your default code editor"
      },
      {
        "heading": "--frontend",
        "depth": 3,
        "text": "Contains information for the CLI's frontend plugin, it has these keys:"
      },
      {
        "heading": "--frontend",
        "depth": 3,
        "text": "frontend: the name of the chosen frontend plugin (without the amplify-frontend- prefix)."
      },
      {
        "heading": "--frontend",
        "depth": 3,
        "text": "framework: the frontend framework used in the project, such as react. Only the javascript frontend handler takes it."
      },
      {
        "heading": "--frontend",
        "depth": 3,
        "text": "config: the configuration settings for the frontend plugin."
      },
      {
        "heading": "--frontend",
        "depth": 3,
        "text": "There are currently three official frontend plugins, and the following are the specifications of their respective config object:"
      },
      {
        "heading": "--frontend",
        "depth": 3,
        "text": "config for javascript"
      },
      {
        "heading": "--frontend",
        "depth": 3,
        "text": "SourceDir:\nThe project's source directory. The CLI will place and update the aws-exports.js file in it, the aws-exports.js file is used to configure the Amplify JS library."
      },
      {
        "heading": "--frontend",
        "depth": 3,
        "text": "DistributionDir:\nThe project's distribution directory, where the build artifacts are stored. The CLI will upload the contents inside this directory to the S3 hosting buckets in the execution of the amplify publish command."
      },
      {
        "heading": "--frontend",
        "depth": 3,
        "text": "BuildCommand:\nThe build command for the project. The CLI invokes the build command before uploading the contents in the distribution directory in the execution of the amplify publish command."
      },
      {
        "heading": "--frontend",
        "depth": 3,
        "text": "StartCommand:\nThe start command for the project, used for local testing. The CLI invokes the start command after it has pushed the latest development of the backend to the cloud in the execution of the amplify run command."
      },
      {
        "heading": "--frontend",
        "depth": 3,
        "text": "config for android"
      },
      {
        "heading": "--frontend",
        "depth": 3,
        "text": "ResDir: The Android project's resource directory, such as app/src/main/res."
      },
      {
        "heading": "--frontend",
        "depth": 3,
        "text": "config for ios"
      },
      {
        "heading": "--frontend",
        "depth": 3,
        "text": "The ios frontend handler does NOT take the config object."
      },
      {
        "heading": "--providers",
        "depth": 3,
        "text": "The pull command is tied to the official provider plugin: amplify-provider-awscloudformation to pull down and attach a backend environment to your frontend project."
      },
      {
        "heading": "--providers",
        "depth": 3,
        "text": "configLevel:\nThe configuration level is either project or general. Unless explicitly set to general, the project level is chosen.\ngeneral level means the CLI will not manage configuration at the project level, it instead relies on the AWS SDK to resolve aws credentials and region. To learn how it works, check the AWS SDK's documents on credentials and region.\nproject level means the configuration is managed at the project level by the CLI, each project gets its own independent configuration. The following attributes are used only when the configuration is at project level"
      },
      {
        "heading": "--providers",
        "depth": 3,
        "text": "useProfile:\nA boolean indicating whether to use a profile defined in the shared config file (~/.aws/config) and credentials file (~/.aws/credentials). "
      },
      {
        "heading": "--providers",
        "depth": 3,
        "text": "profileName:\nThe name of the profile if useProfile is set to true."
      },
      {
        "heading": "--providers",
        "depth": 3,
        "text": "accessKeyId:\nThe aws access key id if useProfile is set to false."
      },
      {
        "heading": "--providers",
        "depth": 3,
        "text": "secretAccessKey:\nThe aws secret access key if useProfile is set to false."
      },
      {
        "heading": "--providers",
        "depth": 3,
        "text": "region:\nThe aws region if useProfile is set to false."
      },
      {
        "heading": "amplify delete parameters",
        "depth": 2,
        "text": "The amplify delete command deletes all of the resources tied to the current project in the cloud, and removes all of the local files created by the Amplify CLI from the filesystem. The amplify delete command takes these parameters:"
      },
      {
        "heading": "amplify delete parameters",
        "depth": 2,
        "text": "--force"
      },
      {
        "heading": "--force",
        "depth": 3,
        "text": "Equivalent to the --yes parameter that other commands support for use in headless environments."
      },
      {
        "heading": "Headless category payloads",
        "depth": 2,
        "text": "Some categories' headless mode work differently than above in that they expect a JSON payload on stdin rather than reading command parameters. The --headless flag is used to let Amplify CLI know that it should read the JSON payload in a single line from stdin. The input JSON is validated against the expected shape (described below). Once the validation passes, the operation is executed."
      },
      {
        "heading": "Headless category payloads",
        "depth": 2,
        "text": "Because the CLI reads a single line from stdin, it is necessary to make sure the JSON does not contain any newlines. jq can be used to accomplish this:"
      },
      {
        "heading": "Headless category payloads",
        "depth": 2,
        "text": "As an alternative to using jq, here's an example Node.js script that adds an API:"
      },
      {
        "heading": "Supported commands",
        "depth": 3,
        "text": "The commands that currently support this method of supplying headless parameters are:"
      },
      {
        "heading": "Supported commands",
        "depth": 3,
        "text": "amplify add auth --headless"
      },
      {
        "heading": "Supported commands",
        "depth": 3,
        "text": "amplify import auth --headless"
      },
      {
        "heading": "Supported commands",
        "depth": 3,
        "text": "amplify update auth --headless"
      },
      {
        "heading": "Supported commands",
        "depth": 3,
        "text": "amplify add api --headless"
      },
      {
        "heading": "Supported commands",
        "depth": 3,
        "text": "amplify update api --headless"
      },
      {
        "heading": "Supported commands",
        "depth": 3,
        "text": "amplify add storage --headless"
      },
      {
        "heading": "Supported commands",
        "depth": 3,
        "text": "amplify import storage --headless"
      },
      {
        "heading": "Supported commands",
        "depth": 3,
        "text": "amplify remove storage --headless"
      },
      {
        "heading": "Supported commands",
        "depth": 3,
        "text": "amplify update storage --headless"
      },
      {
        "heading": "Payload structure",
        "depth": 3,
        "text": "The structure of the JSON objects supplied on stdin are defined in amplify-headless-interface. This package contains both JSON Schema and TypeScript definitions for:"
      },
      {
        "heading": "Payload structure",
        "depth": 3,
        "text": "Add Auth Payload"
      },
      {
        "heading": "Payload structure",
        "depth": 3,
        "text": "Import Auth Payload"
      },
      {
        "heading": "Payload structure",
        "depth": 3,
        "text": "Update Auth Payload"
      },
      {
        "heading": "Payload structure",
        "depth": 3,
        "text": "Add API Payload"
      },
      {
        "heading": "Payload structure",
        "depth": 3,
        "text": "Update API Payload"
      },
      {
        "heading": "Payload structure",
        "depth": 3,
        "text": "Add Storage Payload"
      },
      {
        "heading": "Payload structure",
        "depth": 3,
        "text": "Import Storage Payload"
      },
      {
        "heading": "Payload structure",
        "depth": 3,
        "text": "Remove Storage Payload"
      },
      {
        "heading": "Payload structure",
        "depth": 3,
        "text": "Update Storage Payload"
      },
      {
        "heading": "(Optional) IDE setup for headless development",
        "depth": 3,
        "text": "To get started, install the interface package using npm i amplify-headless-interface. Then, if your editor supports it, configure your editor to know about the schemas in this package."
      },
      {
        "heading": "(Optional) IDE setup for headless development",
        "depth": 3,
        "text": "In Visual Studio Code add the following to settings.json under the json.schemas block to associate the specified file extensions with the corresponding schemas:"
      },
      {
        "heading": "(Optional) IDE setup for headless development",
        "depth": 3,
        "text": "Create a file such as MyAuthTemplate.addauth.json. Once you start editing, Visual Studio Code will provide auto-completion and suggestions based on the schema."
      },
      {
        "heading": "(Optional) IDE setup for headless development",
        "depth": 3,
        "text": "If you prefer not to add this configuration, you can also specify a $schema block your JSON body to tell Visual Studio Code how to validate the JSON. See Visual Studio Code's JSON schemas and settings for more details on this configuration."
      },
      {
        "heading": "Example: \"amplify add api\" headless configuration",
        "depth": 3,
        "text": "This example showcases how to use headless mode to configure amplify add api."
      },
      {
        "heading": "Example: \"amplify add api\" headless configuration",
        "depth": 3,
        "text": "Create a file called newHeadlessApi.addapi.json and paste in the following contents:"
      },
      {
        "heading": "Example: \"amplify add api\" headless configuration",
        "depth": 3,
        "text": "Run cat newHeadlessApi.addapi.json | jq -c | amplify add api --headless to add the API resource."
      },
      {
        "heading": "Example: \"amplify import auth\" headless configuration",
        "depth": 3,
        "text": "This example showcases how to use headless mode to configure amplify import auth."
      },
      {
        "heading": "Example: \"amplify import auth\" headless configuration",
        "depth": 3,
        "text": "Create a file called authconfig.importauth.json and paste in the following contents:"
      },
      {
        "heading": "Example: \"amplify import auth\" headless configuration",
        "depth": 3,
        "text": "Run cat authconfig.importauth.json | jq -c | amplify import auth --headless to import an Cognito resource."
      },
      {
        "heading": "Example: \"amplify import auth\" headless configuration",
        "depth": 3,
        "text": "If you don't have jq installed, see https://stedolan.github.io/jq/download."
      }
    ],
    "source": "export const meta = {\n  title: `Headless mode for CI/CD`,\n  description: `Several commands in the Amplify CLI support arguments which could potentially be used in your CI/CD flows.`,\n};\n\nSeveral commands in the Amplify CLI support arguments which could be used in a CI/CD workflow or other non-interactive shell. The CLI will work non-interactively if the required information is provided by an argument.\n\nArguments are used mostly for scripting so that the command execution flow is not interrupted by prompts. Examples for this can be found [here](https://github.com/aws-amplify/amplify-cli/tree/main/packages/amplify-cli/sample-headless-scripts)\n\n**`--yes` flag**\n\nThe `--yes` flag, or its alias `-y`, suppresses command line prompts if defaults are available, and uses the defaults in command execution.\nThe following commands take the `--yes` flag:\n\n- `amplify init`\n- `amplify configure project`\n- `amplify push`\n- `amplify publish`\n- `amplify pull`\n\n## `amplify init` parameters\n\nThe `amplify init` command takes these parameters:\n\n- `--amplify`\n- `--frontend`\n- `--providers`\n- `--categories`\n- `--yes`\n- `--app`\n\n### `--amplify`\n\nContains basic information of the project, it has these keys:\n\n- `projectName`: the name of the project under development\n- `appId`: the Amplify Service project Id (optional, see below)\n- `envName`: the name of your first environment\n- `defaultEditor`: your default code editor\n\nThe `appId` parameter is optional and it is used in two use cases.\n\n- Amplify Service uses it internally when you initialize a project on Amplify web console.\n- For project migrations. For projects initialized by Amplify CLI version prior to 4.0.0, no Amplify Service project is created online to track the backend environment's resources. The latest version of the Amplify CLI will create a new Amplify Service project for them in the post-push check. If you wanted to add the backend environment to an existing Amplify Service project instead of creating a new one, you can run `amplify init` again, and provide the `appId` inside the `--amplify` parameter, or explicitly as `amplify init --appId <Amplify-Service-Project-AppId>`.\n\n### `--frontend`\n\nContains information for the CLI's frontend plugin, it has these keys:\n\n- `frontend`: the name of the chosen frontend plugin (without the `amplify-frontend-` prefix).\n- `framework`: the frontend framework used in the project, such as `react`. Only the `javascript` frontend handler takes it.\n- `config`: the configuration settings for the frontend plugin.\n\nThere are currently three official frontend plugins, and the following are the specifications of their respective `config` object:\n\n1. **`config` for `javascript`**\n    - `SourceDir`:\n    The project's source directory. The CLI will place and update the `aws-exports.js` file in it, the `aws-exports.js` file is used to configure the `Amplify JS` library.\n    - `DistributionDir`:\n    The project's distribution directory, where the build artifacts are stored. The CLI will upload the contents inside this directory to the S3 hosting buckets in the execution of the `amplify publish` command.\n    - `BuildCommand`:\n    The build command for the project. The CLI invokes the build command before uploading the contents in the distribution directory in the execution of the `amplify publish` command.\n    - `StartCommand`:\n    The start command for the project, used for local testing. The CLI invokes the start command after it has pushed the latest development of the backend to the cloud in the execution of the `amplify run` command.\n2. **`config` for `android`**\n    - `ResDir`: The Android project's resource directory, such as `app/src/main/res`.\n3. **`config` for `ios`**\n    - The `ios` frontend handler does NOT take the `config` object.\n\n### `--providers`\n\nContains configuration settings for provider plugins. The key is the name of the provider plugin (without the `amplify-provider-` prefix), and the value is its configuration. Provider plugins contained in this object will be initialized, and able to provide functionalities for creation and maintenance of the cloud resources.\n\nCurrently there is only one official provider plugin: `amplify-provider-awscloudformation`, its configuration is for the CLI to resolve aws credentials and region, the following are the specifications:\n\n- `configLevel`:\nThe configuration level is either `project` or `general`. Unless explicitly set to `general`, the `project` level is chosen.\n`general` level means the CLI will not manage configuration at the project level, it instead relies on the AWS SDK to resolve aws credentials and region. To learn how it works, check the AWS SDK's documents on [credentials](https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/setting-credentials-node.html) and [region](https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/setting-region.html).\n`project` level means the configuration is managed at the project level by the CLI, each project gets its own independent configuration. The following attributes are used only when the configuration is at project level\n- `useProfile`:\nA boolean indicating whether to use a profile defined in the shared config file (`~/.aws/config`) and credentials file (`~/.aws/credentials`). <br/>\n- `profileName`:\nThe name of the profile if `useProfile` is set to true.\n- `accessKeyId`:\nThe aws access key id if `useProfile` is set to false.\n- `secretAccessKey`:\nThe aws secret access key if `useProfile` is set to false.\n- `region`:\nThe aws region if `useProfile` is set to false.\n\n### `--categories`\nContains configuration settings for resources in the given categories. The key is the name of the category and the value is its configuration. There are resource parameters that are not persisted into configuration files and requires prompting for them during a headless CLI operation and to support headless workflows they are required to be passed in for each resource..\n\n#### Imported resources\n\nCurrently `auth` and `storage` category resources can be imported to an Amplify CLI project.\n\n#### `auth` category\n\n- `userPoolId`: The Id of the Cognito User Pool that was imported into the project.\n- `webClientId`: The Id of the app client configured for the given Cognito User Pool to be used by web applications.\n- `nativeClientId`: The Id of the app client configured for the given Cognito User Pool to be used by Native applications.\n- `identityPoolId`: In case if an Cognito Identity Pool was also configured for the `auth` resource this parameter is the Id of that resource. If there is no associated Cognito Identity Pool was configured, this parameter should not be passed in.\n\nSample `auth` category configuration:\n```bash\nAUTHCONFIG=\"{\\\n\\\"userPoolId\\\": \\\"myproject-userpool-id\\\",\\\n\\\"webClientId\\\": \\\"appid-web\\\",\\\n\\\"nativeClientId\\\": \\\"appid-native\\\",\\\n\\\"identityPoolId\\\": \\\"myproject-idp-poolid\\\"\\\n}\"\n\nCATEGORIES=\"{\\\n\\\"auth\\\":$AUTHCONFIG\\\n}\"\n```\n\n#### `storage` category\n\nStorage category supports the importing of S3 Buckets and DynamoDB tables. They require different parameter sets within the storage category.\n\n#### S3 Buckets\n\n- `region`: The region of the S3 bucket resource. S3 Buckets are global, but the CLI requires to storage of the region as a parameter, so it needs to be passed in. Currently it must be the same region where the Amplify project was created.\n- `bucketName`: The name of the imported S3 bucket.\n\n```bash\nSTORAGECONFIG=\"{\\\n  \\\"region\\\": \\\"us-east-1\\\",\\\n  \\\"bucketName\\\": \\\"my-project-bucket\\\"\\\n}\"\n\nCATEGORIES=\"{\\\n  \\\"storage\\\":$STORAGECONFIG\\\n}\"\n```\n\n#### DynamoDB Tables\n\nAn Amplify project can have multiple DynamoDB storage resources imported and the parameters must be supplied to each of them.\n- `region`: The region of the DynamoDB table resources. Currently it must be the same region where the Amplify project was created.\n- `tables`: An object where the key is the Amplify resource name and the value is the name of the DynamoDB table.\n\n```bash\nSTORAGECONFIG=\"{\\\n  \\\"region\\\": \\\"us-east-1\\\",\n  \\\"tables\\\": {\\\"\n    \\\"posts\\\": \\\"myproject-posts-dev\\\",\\\n    \\\"comments\\\": \\\"myproject-comments-dev\\\",\\\n  }\"\\\n}\"\n\nCATEGORIES=\"{\\\n  \\\"storage\\\":$STORAGECONFIG\n}\"\n```\n\n### `--app`\n\n`amplify init --app git@github.com:<github-username>/<repository-name>.git`\n\nInstalls, initializes, and provisions resources for a sample amplify application from the provided GitHub repository URL. This option must be executed in an empty directory. The sample repository must have an amplify folder, including the following:\n\n- `project-config.json` in .config folder\n- `backend-config.json` in backend folder\n- The necessary cloudformation files in the backend folder\n  - e.g. stacks, `schema.graphql` for api\n  - e.g. cloudformation template for auth\n\n- local files local-env.json and local-aws-info.json are *NOT* required\n\nIf the repository contains a `yarn.lock` and/or `package.json` file, the sample will be installed with the corresponding package manager and started after resources have been provisioned.\n\n### Sample script\n\n```bash\n#!/bin/bash\nset -e\nIFS='|'\n\nREACTCONFIG=\"{\\\n\\\"SourceDir\\\":\\\"src\\\",\\\n\\\"DistributionDir\\\":\\\"build\\\",\\\n\\\"BuildCommand\\\":\\\"npm run-script build\\\",\\\n\\\"StartCommand\\\":\\\"npm run-script start\\\"\\\n}\"\nAWSCLOUDFORMATIONCONFIG=\"{\\\n\\\"configLevel\\\":\\\"project\\\",\\\n\\\"useProfile\\\":false,\\\n\\\"profileName\\\":\\\"default\\\",\\\n\\\"accessKeyId\\\":\\\"headlessaccesskeyid\\\",\\\n\\\"secretAccessKey\\\":\\\"headlesssecrectaccesskey\\\",\\\n\\\"region\\\":\\\"us-east-1\\\"\\\n}\"\nAMPLIFY=\"{\\\n\\\"projectName\\\":\\\"headlessProjectName\\\",\\\n\\\"envName\\\":\\\"myenvname\\\",\\\n\\\"defaultEditor\\\":\\\"code\\\"\\\n}\"\nFRONTEND=\"{\\\n\\\"frontend\\\":\\\"javascript\\\",\\\n\\\"framework\\\":\\\"react\\\",\\\n\\\"config\\\":$REACTCONFIG\\\n}\"\nPROVIDERS=\"{\\\n\\\"awscloudformation\\\":$AWSCLOUDFORMATIONCONFIG\\\n}\"\n\namplify init \\\n--amplify $AMPLIFY \\\n--frontend $FRONTEND \\\n--providers $PROVIDERS \\\n--yes\n```\n\n## `amplify configure project` parameters\n\nThe `amplify configure project` command allows the user to change the configuration settings that were first set by `amplify init`, and it takes the same parameters as the `amplify init` command:\n\n- `--amplify`\n- `--frontend`\n- `--providers`\n- `--yes`\n\n### Sample script\n\n```bash\n#!/bin/bash\nset -e\nIFS='|'\n\nREACTCONFIG=\"{\\\n\\\"SourceDir\\\":\\\"src\\\",\\\n\\\"DistributionDir\\\":\\\"build\\\",\\\n\\\"BuildCommand\\\":\\\"npm run-script build\\\",\\\n\\\"StartCommand\\\":\\\"npm run-script start\\\"\\\n}\"\nAWSCLOUDFORMATIONCONFIG=\"{\\\n\\\"configLevel\\\":\\\"project\\\",\\\n\\\"useProfile\\\":false,\\\n\\\"profileName\\\":\\\"default\\\",\\\n\\\"accessKeyId\\\":\\\"headlessaccesskeyid\\\",\\\n\\\"secretAccessKey\\\":\\\"headlesssecrectaccesskey\\\",\\\n\\\"region\\\":\\\"us-east-1\\\"\\\n}\"\nAMPLIFY=\"{\\\n\\\"projectName\\\":\\\"headlessProjectName\\\",\\\n\\\"defaultEditor\\\":\\\"code\\\"\\\n}\"\nFRONTEND=\"{\\\n\\\"frontend\\\":\\\"javascript\\\",\\\n\\\"framework\\\":\\\"react\\\",\\\n\\\"config\\\":$REACTCONFIG\\\n}\"\nPROVIDERS=\"{\\\n\\\"awscloudformation\\\":$AWSCLOUDFORMATIONCONFIG\\\n}\"\n\namplify configure project \\\n--amplify $AMPLIFY \\\n--frontend $FRONTEND \\\n--providers $PROVIDERS \\\n--yes\n```\n\n## `amplify push/publish` parameters\n\nThe `amplify publish` command internally executes `amplify push` so it takes the same parameters as push command. The `amplify push` command takes the following parameters\n\n- `--codegen`\n- `--yes`\n- `--force`\n- `--allow-destructive-graphql-schema-updates`\n\n### `--codegen`\n\nContains configuration for AppSync [codegen](/cli/graphql/client-code-generation), the following are the specifications:\n\n- `generateCode`: <br/>\nA boolean indicating if to generate code for your GraphQL API.<br/>\n- `codeLanguage`: <br/>\nThe targeted language of the generated code, such as `javascript`.<br/>\n- `fileNamePattern`:  <br/>\nThe file name pattern of GraphQL queries, mutations and subscriptions.<br/>\n- `generatedFileName`:  <br/>\nThe file name for the generated code.<br/>\n- `generateDocs`:  <br/>\nA boolean indicating whether to generate GraphQL statements (queries, mutations and subscription) based on the GraphQL schema types. The generated version will overwrite the current GraphQL queries, mutations and subscriptions.<br/>\n\n### `--yes`\nWill skip all interactive prompts by selecting default options.\n\n### `--force`\nPushes all resources regardless of update status and bypasses all guardrails to push the local state to the cloud. Only use this flag if you have tested the change in a non-production environment and fully understand the implications.\n\nIt includes all of the behavior of `--allow-destructive-graphql-schema-updates`\n\n### `--allow-destructive-graphql-schema-updates`\nPushes schema changes that require removal or replacement of underlying tables. See [update schema](/cli/graphql/overview/#update-schema).\n\n### Sample script\n\n```bash\n#!/bin/bash\nset -e\nIFS='|'\n\nCODEGEN=\"{\\\n\\\"generateCode\\\":true,\\\n\\\"codeLanguage\\\":\\\"javascript\\\",\\\n\\\"fileNamePattern\\\":\\\"src/graphql/**/*.js\\\",\\\n\\\"generatedFileName\\\":\\\"API\\\",\\\n\\\"generateDocs\\\":true\\\n}\"\n\namplify push \\\n--codegen $CODEGEN \\\n--yes\n```\n\n## `amplify pull` parameters\n\nThe `amplify pull` command pulls down the latest backend environment to your local development.\nIt is used in two scenarios:\n\n1. On projects already initialized by the Amplify CLI, it pulls down the latest from the Cloud and updates the contents in the `amplify/#current-cloud-backend` directory. The command does not take any parameters when used in this scenario.\n2. On projects NOT yet initialized by the Amplify CLI, it pulls down a particular backend environment, and \"attaches\" it to the project. It will fully set up the `amplify` directory for the project.  The backend environment being pulled is specified by `appId` and `envName` in the `amplify` parameter (see below). The command takes the following parameters when used in this scenario.\n- `--amplify`\n- `--frontend`\n- `--providers`\n- `--yes`\n\n### `--amplify`\n\nContains basic information of the project, it has these keys:\n\n- `projectName`: the name of the project under development\n- `appId`: the Amplify Service project Id\n- `envName`: the name of the backend environment in the above mention Amplify Service that you want to pull down\n- `defaultEditor`: your default code editor\n\n### `--frontend`\n\nContains information for the CLI's frontend plugin, it has these keys:\n\n- `frontend`: the name of the chosen frontend plugin (without the `amplify-frontend-` prefix).\n- `framework`: the frontend framework used in the project, such as `react`. Only the `javascript` frontend handler takes it.\n- `config`: the configuration settings for the frontend plugin.\n\nThere are currently three official frontend plugins, and the following are the specifications of their respective `config` object:\n\n1. **`config` for `javascript`**\n    - `SourceDir`:\n    The project's source directory. The CLI will place and update the `aws-exports.js` file in it, the `aws-exports.js` file is used to configure the `Amplify JS` library.\n    - `DistributionDir`:\n    The project's distribution directory, where the build artifacts are stored. The CLI will upload the contents inside this directory to the S3 hosting buckets in the execution of the `amplify publish` command.\n    - `BuildCommand`:\n    The build command for the project. The CLI invokes the build command before uploading the contents in the distribution directory in the execution of the `amplify publish` command.\n    - `StartCommand`:\n    The start command for the project, used for local testing. The CLI invokes the start command after it has pushed the latest development of the backend to the cloud in the execution of the `amplify run` command.\n2. **`config` for `android`**\n    - `ResDir`: The Android project's resource directory, such as `app/src/main/res`.\n3. **`config` for `ios`**\n    - The `ios` frontend handler does NOT take the `config` object.\n\n### `--providers`\n\nThe pull command is tied to the official provider plugin: `amplify-provider-awscloudformation` to pull down and attach a backend environment to your frontend project.\n\n- `configLevel`:\nThe configuration level is either `project` or `general`. Unless explicitly set to `general`, the `project` level is chosen.\n`general` level means the CLI will not manage configuration at the project level, it instead relies on the AWS SDK to resolve aws credentials and region. To learn how it works, check the AWS SDK's documents on [credentials](https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/setting-credentials-node.html) and [region](https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/setting-region.html).\n`project` level means the configuration is managed at the project level by the CLI, each project gets its own independent configuration. The following attributes are used only when the configuration is at project level\n- `useProfile`:\nA boolean indicating whether to use a profile defined in the shared config file (`~/.aws/config`) and credentials file (`~/.aws/credentials`). <br/>\n- `profileName`:\nThe name of the profile if `useProfile` is set to true.\n- `accessKeyId`:\nThe aws access key id if `useProfile` is set to false.\n- `secretAccessKey`:\nThe aws secret access key if `useProfile` is set to false.\n- `region`:\nThe aws region if `useProfile` is set to false.\n\n### Sample script\n\n```bash\n#!/bin/bash\nset -e\nIFS='|'\n\nREACTCONFIG=\"{\\\n\\\"SourceDir\\\":\\\"src\\\",\\\n\\\"DistributionDir\\\":\\\"build\\\",\\\n\\\"BuildCommand\\\":\\\"npm run-script build\\\",\\\n\\\"StartCommand\\\":\\\"npm run-script start\\\"\\\n}\"\nAWSCLOUDFORMATIONCONFIG=\"{\\\n\\\"configLevel\\\":\\\"project\\\",\\\n\\\"useProfile\\\":false,\\\n\\\"profileName\\\":\\\"default\\\",\\\n\\\"accessKeyId\\\":\\\"headlessaccesskeyid\\\",\\\n\\\"secretAccessKey\\\":\\\"headlesssecrectaccesskey\\\",\\\n\\\"region\\\":\\\"us-east-1\\\"\\\n}\"\nAMPLIFY=\"{\\\n\\\"projectName\\\":\\\"headlessProjectName\\\",\\\n\\\"appId\\\":\\\"amplifyServiceProjectAppId\\\",\\\n\\\"envName\\\":\\\"myenvname\\\",\\\n\\\"defaultEditor\\\":\\\"code\\\"\\\n}\"\nFRONTEND=\"{\\\n\\\"frontend\\\":\\\"javascript\\\",\\\n\\\"framework\\\":\\\"react\\\",\\\n\\\"config\\\":$REACTCONFIG\\\n}\"\nPROVIDERS=\"{\\\n\\\"awscloudformation\\\":$AWSCLOUDFORMATIONCONFIG\\\n}\"\n\namplify pull \\\n--amplify $AMPLIFY \\\n--frontend $FRONTEND \\\n--providers $PROVIDERS \\\n--yes\n```\n\n## `amplify delete` parameters\n\nThe `amplify delete` command deletes all of the resources tied to the current project in the cloud, and removes all of the local files created by the Amplify CLI from the filesystem. The `amplify delete` command takes these parameters:\n\n- `--force`\n\n### `--force`\n\nEquivalent to the `--yes` parameter that other commands support for use in headless environments.\n\n### Sample script\n\n```bash\n#!/bin/bash\nset -e\n\namplify delete --force\n```\n\n## Headless category payloads\n\nSome categories' headless mode work differently than above in that they expect a JSON payload on `stdin` rather than reading command parameters. The `--headless` flag is used to let Amplify CLI know that it should read the JSON payload in a single line from `stdin`. The input JSON is validated against the expected shape (described below). Once the validation passes, the operation is executed.\n\n> Because the CLI reads a single line from `stdin`, it is necessary to make sure the JSON does not contain any newlines. [jq](https://stedolan.github.io/jq/) can be used to accomplish this:\n\n```bash\ncat myAddApiRequest.json | jq -c | amplify add api --headless\n```\n\nAs an alternative to using `jq`, here's an example Node.js script that adds an API:\n```javascript\nconst amplify_api = require('./myAddApiRequest.json');\nconst fs = require('fs');\nconst path = require('path');\n\nconst schema = fs.readFileSync(\n  path.resolve(__dirname, './schema.graphql'),\n  'utf8',\n);\n\nimport('execa').then((module) => {\n  amplify_api.serviceConfiguration.transformSchema = schema;\n  module\n    .execa('amplify', ['add', 'api', '--headless'], {\n      input: JSON.stringify(amplify_api),\n    })\n    .stdout.pipe(process.stdout);\n});\n```\n\n### Supported commands\n\nThe commands that currently support this method of supplying headless parameters are:\n\n- `amplify add auth --headless`\n- `amplify import auth --headless`\n- `amplify update auth --headless`\n- `amplify add api --headless`\n- `amplify update api --headless`\n- `amplify add storage --headless`\n- `amplify import storage --headless`\n- `amplify remove storage --headless`\n- `amplify update storage --headless`\n\n### Payload structure\n\nThe structure of the JSON objects supplied on `stdin` are defined in [amplify-headless-interface](https://www.npmjs.com/package/amplify-headless-interface). This package contains both JSON Schema and TypeScript definitions for:\n\n- [Add Auth Payload](https://github.com/aws-amplify/amplify-cli/blob/main/packages/amplify-headless-interface/src/interface/auth/add.ts)\n- [Import Auth Payload](https://github.com/aws-amplify/amplify-cli/blob/main/packages/amplify-headless-interface/src/interface/auth/import.ts)\n- [Update Auth Payload](https://github.com/aws-amplify/amplify-cli/blob/main/packages/amplify-headless-interface/src/interface/auth/update.ts)\n- [Add API Payload](https://github.com/aws-amplify/amplify-cli/blob/main/packages/amplify-headless-interface/src/interface/api/add.ts)\n- [Update API Payload](https://github.com/aws-amplify/amplify-cli/blob/main/packages/amplify-headless-interface/src/interface/api/update.ts)\n- [Add Storage Payload](https://github.com/aws-amplify/amplify-cli/blob/main/packages/amplify-headless-interface/src/interface/storage/add.ts)\n- [Import Storage Payload](https://github.com/aws-amplify/amplify-cli/blob/main/packages/amplify-headless-interface/src/interface/storage/import.ts)\n- [Remove Storage Payload](https://github.com/aws-amplify/amplify-cli/blob/main/packages/amplify-headless-interface/src/interface/storage/remove.ts)\n- [Update Storage Payload](https://github.com/aws-amplify/amplify-cli/blob/main/packages/amplify-headless-interface/src/interface/storage/update.ts)\n\n### (Optional) IDE setup for headless development\n\nTo get started, install the interface package using `npm i amplify-headless-interface`. Then, if your editor supports it, configure your editor to know about the schemas in this package.\n\nIn Visual Studio Code add the following to `settings.json` under the `json.schemas` block to associate the specified file extensions with the corresponding schemas:\n\n```json\n\"json.schemas\": [\n  {\n    \"fileMatch\": [\n      \"*.addauth.json\"\n    ],\n    \"url\": \"./node_modules/amplify-headless-interface/schemas/auth/2/AddAuthRequest.schema.json\"\n  },\n  {\n    \"fileMatch\": [\n      \"*.updateauth.json\"\n    ],\n    \"url\": \"./node_modules/amplify-headless-interface/schemas/auth/2/UpdateAuthRequest.schema.json\"\n  },\n  {\n    \"fileMatch\": [\n      \"*.importauth.json\"\n    ],\n    \"url\": \"./node_modules/amplify-headless-interface/schemas/auth/1/ImportAuthRequest.schema.json\"\n  },\n  {\n    \"fileMatch\": [\n      \"*.addapi.json\"\n    ],\n    \"url\": \"./node_modules/amplify-headless-interface/schemas/api/1/AddApiRequest.schema.json\"\n  },\n  {\n    \"fileMatch\": [\n      \"*.updateapi.json\"\n    ],\n    \"url\": \"./node_modules/amplify-headless-interface/schemas/api/1/UpdateApiRequest.schema.json\"\n  }\n]\n```\n\nCreate a file such as `MyAuthTemplate.addauth.json`. Once you start editing, Visual Studio Code will provide auto-completion and suggestions based on the schema.\n\n> If you prefer not to add this configuration, you can also specify a `$schema` block your JSON body to tell Visual Studio Code how to validate the JSON. See Visual Studio Code's [JSON schemas and settings](https://code.visualstudio.com/docs/languages/json#_json-schemas-and-settings) for more details on this configuration.\n\n### Example: \"amplify add api\" headless configuration\n\nThis example showcases how to use headless mode to configure `amplify add api`.\n\nCreate a file called `newHeadlessApi.addapi.json` and paste in the following contents:\n\n```json\n{\n  \"version\": 1,\n  \"serviceConfiguration\": {\n    \"serviceName\": \"AppSync\",\n    \"apiName\": \"myNewHeadlessApi\",\n    \"transformSchema\": \"type Todo @model {\\r\\n  id: ID!\\r\\n  name: String!\\r\\n  description: String\\r\\n}\",\n    \"defaultAuthType\": {\n      \"mode\": \"API_KEY\"\n    }\n  }\n}\n```\n\nRun `cat newHeadlessApi.addapi.json | jq -c | amplify add api --headless` to add the API resource.\n\n### Example: \"amplify import auth\" headless configuration\n\nThis example showcases how to use headless mode to configure `amplify import auth`.\n\nCreate a file called `authconfig.importauth.json` and paste in the following contents:\n\n```json\n  \"version\": 1,\n  \"userPoolId\": \"myUserPoolId\",\n  \"webClientId\": \"myWebAppClientId\",\n  \"nativeClientId\": \"myNativeAppClientId\",\n  \"identityPoolId\": \"myIdentityPoolId\" //optional \n```\n\nRun `cat authconfig.importauth.json | jq -c | amplify import auth --headless` to import an Cognito resource.\n\n> If you don't have `jq` installed, see [https://stedolan.github.io/jq/download](https://stedolan.github.io/jq/download).\n",
    "meta": {
      "title": "Headless mode for CI/CD",
      "description": "Several commands in the Amplify CLI support arguments which could potentially be used in your CI/CD flows.",
      "subcategory": "Advanced workflows",
      "category": "Amplify CLI"
    },
    "filename": "/cli/usage/headless"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Export Amplify CLI-generated backends as a Cloud Development Kit (CDK) stack and incorporate into existing CDK deployment pipelines. This capability allows frontend developers to build their app backend quickly and, each time it is ready to ship, hand it over to DevOps teams to deploy to production."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The command above exports your Amplify projects with CDK-compatible CloudFormation files and assets."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Note: notifications category is not supported for export."
      },
      {
        "heading": null,
        "depth": null,
        "text": "In the exported location you should see a file structure like this:"
      },
      {
        "heading": "Use an exported Amplify backend in AWS Cloud Development Kit (CDK)",
        "depth": 2,
        "text": "amplify export uses the current state of the Amplify backend to build, package, and generate the CloudFormation files and assets to the provided path."
      },
      {
        "heading": "Use an exported Amplify backend in AWS Cloud Development Kit (CDK)",
        "depth": 2,
        "text": "To integrate the Amplify backend into your CDK app, install the AmplifyExportedBackend CDK construct:"
      },
      {
        "heading": "Use an exported Amplify backend in AWS Cloud Development Kit (CDK)",
        "depth": 2,
        "text": "Then, import and initialize a new AmplifyExportedBackend stack:"
      },
      {
        "heading": "Use an exported Amplify backend in AWS Cloud Development Kit (CDK)",
        "depth": 2,
        "text": "Specify the amplifyEnvironment parameter to return the Amplify stack for the corresponding backend environment created through (amplify env add)."
      },
      {
        "heading": "Use an exported Amplify backend in AWS Cloud Development Kit (CDK)",
        "depth": 2,
        "text": "Deploy the CDK app:"
      },
      {
        "heading": "Use an exported Amplify backend in AWS Cloud Development Kit (CDK)",
        "depth": 2,
        "text": "Remember: \"export\" is not an \"eject\" workflow in the sense that \"export\" can iteratively apply Amplify CLI changes as they are ready to ship. Developers can use the Amplify CLI to iterate on their app backend quickly and prior to each new production deployment, run \"amplify export\" to provide an exported Amplify backend for an existing deployment system."
      },
      {
        "heading": "Use CDK for cross-account or cross-region Amplify backend deployments",
        "depth": 2,
        "text": "To deploy an Amplify backend across accounts or regions, you must ensure that the amplifyEnvironment parameter is globally unique across all of AWS. This is due to the underlying resources, such as S3 buckets and IAM roles, need to be globally unique."
      },
      {
        "heading": "Use CDK for cross-account or cross-region Amplify backend deployments",
        "depth": 2,
        "text": "One way to ensure that is to use the AWS Account ID or Region as the Amplify environment identifier:"
      },
      {
        "heading": "Use CDK for cross-account or cross-region Amplify backend deployments",
        "depth": 2,
        "text": "In order to get the region and account ID strings to populate in CDK, you need to provide the env parameter on the parent stack. The amplifyEnvironment can't include a CloudFormation Ref."
      }
    ],
    "source": "export const meta = {\n  title: `Export Amplify project to CDK`,\n  description: `Export your Amplify CLI-generated backends as a Cloud Development Kit (CDK) stack and incorporate it into existing CDK deployment pipelines. This capability allows frontend developers to build their app backend quickly and, each time it is ready to ship, hand it over to DevOps teams to deploy to production.`,\n};\n\nExport Amplify CLI-generated backends as a Cloud Development Kit (CDK) stack and incorporate into existing CDK deployment pipelines. This capability allows frontend developers to build their app backend quickly and, each time it is ready to ship, hand it over to DevOps teams to deploy to production. \n\n```bash\namplify export --out <your-cdk-project-location> \n```\n\nThe command above exports your Amplify projects with CDK-compatible CloudFormation files and assets. \n\n> Note: `notifications` category is not supported for export.\n\nIn the exported location you should see a file structure like this:\n\n```bash\namplify-export-myAmplifyProject/\n├── <YOUR_AMPLIFY_CATEGORIES>/\n│   ├──...\n│   ├──...\n│   └──...\n├── amplify-export-manifest.json\n├── category-stack-mapping.json\n├── export-tags.json\n└── root-stack-template.json\n```\n\n## Use an exported Amplify backend in AWS Cloud Development Kit (CDK)\n\n`amplify export` uses the current state of the Amplify backend to build, package, and generate the CloudFormation files and assets to the provided path.\n\nTo integrate the Amplify backend into your CDK app, install the `AmplifyExportedBackend` CDK construct:\n\n```\nnpm i @aws-amplify/cdk-exported-backend\n```\n\nThen, import and initialize a new `AmplifyExportedBackend` stack:\n\n```ts\nimport { AmplifyExportedBackend } from '@aws-amplify/cdk-exported-backend'\nimport * as path from 'path' // To resolve the path to your exported Amplify backend assets\n\n...\n\nconst amplifyBackend = new AmplifyExportedBackend(this, \"amplifyExportedBackend\", {\n  amplifyEnvironment: \"dev\", // Specify your Amplify environment\n  path: path.resolve(__dirname, 'amplify-export-<YOUR_AMPLIFY_PROJECT_NAME>')\n})\n```\n\nSpecify the `amplifyEnvironment` parameter to return the Amplify stack for the corresponding backend environment created through (`amplify env add`).\n\nDeploy the CDK app:\n\n```bash\nnpx cdk deploy\n```\n\nRemember: \"export\" is not an \"eject\" workflow in the sense that \"export\" can iteratively apply Amplify CLI changes as they are ready to ship. Developers can use the Amplify CLI to iterate on their app backend quickly and prior to each new production deployment, run \"amplify export\" to provide an exported Amplify backend for an existing deployment system.\n\n## Use CDK for cross-account or cross-region Amplify backend deployments\n\nTo deploy an Amplify backend across accounts or regions, you must ensure that the `amplifyEnvironment` parameter is globally unique across all of AWS. This is due to the underlying resources, such as S3 buckets and IAM roles, need to be globally unique.\n\nOne way to ensure that is to use the AWS Account ID or Region as the Amplify environment identifier:\n\n```ts\nconst amplifyBackend = new AmplifyExportedBackend(this, \"amplifyExportedBackend\", {\n  amplifyEnvironment: cdk.Stack.of(this).region + cdk.Stack.of(this).account, // <---------\n  path: path.resolve(__dirname, 'amplify-export-<YOUR_AMPLIFY_PROJECT_NAME>')\n})\n```\n\nIn order to get the region and account ID strings to populate in CDK, you need to provide the `env` parameter on the parent stack. The `amplifyEnvironment` can't include a [CloudFormation `Ref`](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/intrinsic-function-reference-ref.html).\n\n```ts\nconst service = new MyAmplifyStack(this, 'AmplifyStack', {\n  env: {\n    account: process.env.CDK_DEFAULT_ACCOUNT, // or for example: \"172387324923\"\n    region: process.env.CDK_DEFAULT_REGION, // or \"us-east-1\"\n  }\n});\n```\n",
    "meta": {
      "title": "Export Amplify project to CDK",
      "description": "Export your Amplify CLI-generated backends as a Cloud Development Kit (CDK) stack and incorporate it into existing CDK deployment pipelines. This capability allows frontend developers to build their app backend quickly and, each time it is ready to ship, hand it over to DevOps teams to deploy to production.",
      "subcategory": "Advanced workflows",
      "category": "Amplify CLI"
    },
    "filename": "/cli/usage/export-to-cdk"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Serverless containers provide the ability for you to deploy APIs and host websites using AWS Fargate. Customers with existing applications or those who require a lower level of control can bring Docker containers and deploy them into an Amplify project fully integrating with other resources."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify libraries can be used with the Auth category giving mobile and web applications secure connectivity and access controls to your Serverless containers. Additionally, existing GraphQL and REST services such as AWS AppSync and Amazon API Gateway can be used in the same project along with Fargate-backed APIs giving flexibility to mix and match for cost optimization and operational needs."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Note that serverless containers do incur additional costs and operational overhead, as such we recommend using AWS AppSync with the GraphQL Transform as a starting point when building mobile and web apps with Amplify."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Billing warning: When you deploy serverless containers with Amplify, it incurs additional costs when resources are not in use for services such as VPC, Fargate, ECR, Cloud Map, CodePipeline, and CodeBuild. For more information refer to VPC pricing, Fargate pricing, ECR Pricing, CodePipeline pricing, CodeBuild pricing, and Cloud Map pricing."
      },
      {
        "heading": "Getting Started",
        "depth": 2,
        "text": "Serverless containers are not enabled in your Amplify CLI project by default. To get started you will need to run amplify configure project in order to see the options for deploying to Fargate. To get started initialize your project and enable container-based deployments:"
      },
      {
        "heading": "Getting Started",
        "depth": 2,
        "text": "Next add a NoSQL Database table named posts with column called id of type number (N). Make this the partition key."
      },
      {
        "heading": "Getting Started",
        "depth": 2,
        "text": "You can select no for all other questions. After this add an API using the REST (or GraphQL) default ExpressJS template and grant it access to this DynamoDB table."
      },
      {
        "heading": "Getting Started",
        "depth": 2,
        "text": "Note the environment variables printed to the screen. If you choose a different database table name so that your variables are different from STORAGE_POSTS_NAME then update the TableName variable at the top of amplify/backend/api/<apiname>/src/DynamoDBActions.js appropriately."
      },
      {
        "heading": "Getting Started",
        "depth": 2,
        "text": "Finally run amplify push to deploy the backend:"
      },
      {
        "heading": "Getting Started",
        "depth": 2,
        "text": "Once this completes your container will be built via an automated pipeline and deployed to Fargate Tasks on an ECS Cluster fronted by an Amazon API Gateway HTTP API using a direct Cloud Map integration to your VPC. If you selected Yes to protect your API with Authentication, an Amazon Cognito User Pool will be created with an Authorizer integration for that API."
      },
      {
        "heading": "Deploy a single container",
        "depth": 2,
        "text": "The single Dockerfile scenario allows you to take an application running in a single Container which has been built with a Dockerfile and deploy it to AWS Fargate with the Amplify CLI."
      },
      {
        "heading": "Deploy a single container",
        "depth": 2,
        "text": "If you are unfamiliar with using a Dockerfile review the Dockerizing a Node.js web app guide or or add an API with an Amplify-provided template."
      },
      {
        "heading": "Deploy a single container",
        "depth": 2,
        "text": "A simple Dockerfile example is below, which would start a NodeJS application (index.js) in a built image by copying all the source files and installing dependencies. This example also shows how could can specify environment variables and use the EXPOSE statement for defining your container's communication port."
      },
      {
        "heading": "Deploy a single container",
        "depth": 2,
        "text": "You will need an EXPOSE statement in your Dockerfile to specify a port to communicate with the container. If you do not provide one Amplify will suggest to use port 80."
      },
      {
        "heading": "Local development and testing",
        "depth": 3,
        "text": "It is recommended to test your application locally first before deploying with amplify push, otherwise your Fargate Task may fail to start if there are application issues such as missing dependencies. With a Single Dockerfile you can do this by navigating to amplify/backend/api/<name>/src and running docker build -t to build and tag your image followed by docker run to launch your container similar to the below example:"
      },
      {
        "heading": "Local development and testing",
        "depth": 3,
        "text": "You can also run your application using standard tooling such as running node index.js or python server.py in Node or Python. Once you are satisfied with the Dockerfile and your application code, run amplify push and the amplify/backend/api/<name>/src directory will be bundled for the build pipeline to run and deploy your image to Fargate. At the end of the deployment the endpoint URL will be printed and client configuration files will be updated."
      },
      {
        "heading": "Deploy multiple containers",
        "depth": 2,
        "text": "If you wish to deploy multiple containers into Fargate to define your API, Amplify will parse a Docker Compose file (docker-compose.yml) in your amplify/backend/api/<name>/src directory to define the backend service. If you are unfamiliar with using a Docker Compose review the Docker Compose getting started guide or or add an API with an Amplify-provided template."
      },
      {
        "heading": "Deploy multiple containers",
        "depth": 2,
        "text": "A Compose file includes the logical container names, build & images settings, launch commands, ports, and more. An example Docker Compose file is below:"
      },
      {
        "heading": "Deploy multiple containers",
        "depth": 2,
        "text": "This docker-compose.yml file would be placed in your amplify/backend/api/<name>/src when using the \"bring your own container\" flow. It defines two containers called express and python which each have a Dockerfile in two sub directories along with the application source files"
      },
      {
        "heading": "Local development and testing",
        "depth": 3,
        "text": "As with the single container workflow, it is recommended to test your application locally first before deploying with amplify push, otherwise your Fargate Task may fail to start if there are application issues such as missing dependencies. Navigate to amplify/backend/api/<name>/src and run docker-compose up which will build your images and start them locally."
      },
      {
        "heading": "Local development and testing",
        "depth": 3,
        "text": "If your application source changes for any of the images, you can rebuild them by running docker-compose build before running docker-compose up during your test and development cycle."
      },
      {
        "heading": "Container networking",
        "depth": 3,
        "text": "Multiple containers are deployed as a single unit in Fargate (e.g. same Task Definition). This opinionated deployment allows ease of networking between containers on the local loopback interface and avoids extra configuration, costs, operations, and debugging."
      },
      {
        "heading": "When container is deployed to Fargate",
        "depth": 4,
        "text": "The loopback interface has an IP of 127.0.0.1 and a hostname of localhost which you can use in one container's application code to communicate with another."
      },
      {
        "heading": "When container is deployed to Fargate",
        "depth": 4,
        "text": "Using the docker-compose.yml example from earlier, you might have the following code in your NodeJS application. It references the port of the Redis container and a host using the loopback adapter with localhost:"
      },
      {
        "heading": "When testing locally using docker-compose up",
        "depth": 4,
        "text": "When performing local development and testing with docker-compose up you will use the logical container name defined in your docker-compose.yaml file."
      },
      {
        "heading": "Supported Configurations",
        "depth": 3,
        "text": "Amplify will configure your Fargate infrastructure (ECS Service and Task Definition) automatically while allowing you to override specific settings with a Docker Compose file. Older versions of Compose files are supported however not all configuration values will be honored, therefore it is recommended you update to 3.8. Additionally if a value has been deprecated in one version of Compose, Amplify will prefer the newest version (3.8)."
      },
      {
        "heading": "Supported Configurations",
        "depth": 3,
        "text": "build"
      },
      {
        "heading": "Supported Configurations",
        "depth": 3,
        "text": "name"
      },
      {
        "heading": "Supported Configurations",
        "depth": 3,
        "text": "ports"
      },
      {
        "heading": "Supported Configurations",
        "depth": 3,
        "text": "command"
      },
      {
        "heading": "Supported Configurations",
        "depth": 3,
        "text": "entrypoint"
      },
      {
        "heading": "Supported Configurations",
        "depth": 3,
        "text": "env_file"
      },
      {
        "heading": "Supported Configurations",
        "depth": 3,
        "text": "image"
      },
      {
        "heading": "Supported Configurations",
        "depth": 3,
        "text": "healthcheck"
      },
      {
        "heading": "Supported Configurations",
        "depth": 3,
        "text": "working_dir"
      },
      {
        "heading": "Supported Configurations",
        "depth": 3,
        "text": "user"
      },
      {
        "heading": "Supported Configurations",
        "depth": 3,
        "text": "secrets"
      },
      {
        "heading": "Supported Configurations",
        "depth": 3,
        "text": "replicas"
      },
      {
        "heading": "Supported Configurations",
        "depth": 3,
        "text": "By default Amplify will use a single Availability Zone however if you choose the High Availability option it will spread Fargate Tasks across 3 Availability Zones. The replicas value should be used to increase the number of Fargate tasks running in your Cluster depending on your traffic requirements, however note that more running tasks will accrue more costs."
      },
      {
        "heading": "Supported Configurations",
        "depth": 3,
        "text": "When you have multiple container entries specifying a port Amplify will prompt you upon running amplify push to select an Entrypoint Container. Since all containers are deployed as a \"unit\" and fronted by an API Gateway HTTP endpoint for client applications to access, Amplify needs to know which container in the Cluster's Service to route requests. The answer to the Entrypoint question will use the first specified ports entry to perform this routing."
      },
      {
        "heading": "Supported Configurations",
        "depth": 3,
        "text": "It is recommended that you define container settings early in the development process if possible. While these settings can be updated later, it will cause an in-place replacement of the Fargate service configuration and could lead to your endpoint being unavailable for a few moments while the process completes. For best results minimize configuration changes in your Docker Compose settings and make more frequents updates to your application code in order to take advantage of rolling updates in the build and deploy pipeline."
      },
      {
        "heading": "Environment variables and secrets",
        "depth": 3,
        "text": "You can use environment variables in your application code that are specified in your Docker Compose file, but do not specify the hostname when deploying in amplify push. For example the DATABASE_HOST variable below might be specified locally when using docker-compose up with the  environment setting:"
      },
      {
        "heading": "Environment variables and secrets",
        "depth": 3,
        "text": "Then your application code can switch between local and cloud deployment automatically and communicate with the db container:"
      },
      {
        "heading": "Environment variables and secrets",
        "depth": 3,
        "text": "secrets allow you to pass sensitive data to your containers from AWS Secrets Manager. Amplify will do this for you when you populate the secrets configuration at the root level of your docker-compose.yml. It must be a file name that starts with .secret- and cannot be in the src directory of amplify/backend/api/<name>, but can be anywhere outside of it including a relative path. It is recommended to place your secrets in a amplify/backend/api/<name>/secrets directory. Every .secret- file has only one string value and will referenced by the name you provide in the docker-compose.yml entry."
      },
      {
        "heading": "Environment variables and secrets",
        "depth": 3,
        "text": "When you perform an amplify push you will be prompted to store the secrets in the cloud or bypass (which may be the case in team workflows when one person controls secrets). The name of the secret will be available in your application code similar to if you specified other variables via the environment configuration:"
      },
      {
        "heading": "Environment variables and secrets",
        "depth": 3,
        "text": "NodeJS example"
      },
      {
        "heading": "Environment variables and secrets",
        "depth": 3,
        "text": "Python example"
      },
      {
        "heading": "Bring Your Own Container Specification For Your REST API",
        "depth": 2,
        "text": "When creating an API using containers, you have the option to bring in your own Dockerfile(s) and docker-compose.yml. When selecting the Docker image for your REST API, choose Custom and then select when to deploy code and configuration changes to your container."
      },
      {
        "heading": "Bring Your Own Container Specification For Your REST API",
        "depth": 2,
        "text": "The CLI will provide you with the next steps to bring your existing Docker specification and source files into your project by populating the src directory."
      },
      {
        "heading": "Client Configuration",
        "depth": 2,
        "text": "Serverless containers are fronted by a secure endpoint by which you can interact with them from a mobile or web application. Amplify CLI will attempt to update the project aws-exports.js or amplifyconfiguration.json file with the endpoint, however for GraphQL API types this is not possible and you will need to manually specify it in an Amplify.configure() call within your application code. The endpoint will be printed out to the screen after running an amplify push for you to make these changes, take note of it and follow one of the guides below appropriately."
      },
      {
        "heading": "Client Configuration",
        "depth": 2,
        "text": "JavaScript GraphQL configuration"
      },
      {
        "heading": "Client Configuration",
        "depth": 2,
        "text": "JavaScript REST configuration"
      },
      {
        "heading": "Client Configuration",
        "depth": 2,
        "text": "Android GraphQL configuration"
      },
      {
        "heading": "Client Configuration",
        "depth": 2,
        "text": "Android REST configuration"
      },
      {
        "heading": "Client Configuration",
        "depth": 2,
        "text": "iOS GraphQL configuration"
      },
      {
        "heading": "Client Configuration",
        "depth": 2,
        "text": "iOS REST configuration"
      },
      {
        "heading": "Client Configuration",
        "depth": 2,
        "text": "Note that if you have enabled Authorization checks on your endpoints during amplify add api your clients will need to Authenticate against the Cognito User Pool configured and pass tokens. Please see the appropriate platform guide for adding Sign-Up and Sign-In calls to your application."
      },
      {
        "heading": "Access existing AWS resource from container",
        "depth": 2,
        "text": "You can grant your Fargate Task access to additional AWS resources and services.  After running amplify add api, the CLI generates a custom-policies.json under the folder amplify/backend/api/<api-name>/custom-policies.json. The file is where you can specify the resources and actions that grant the Fargate task additional AWS resources and services access."
      },
      {
        "heading": "Custom Policy File Structure",
        "depth": 3,
        "text": "Action: Specify the actions that are required to be granted to your AWS resource. Wild characters ‘*’ is accepted."
      },
      {
        "heading": "Custom Policy File Structure",
        "depth": 3,
        "text": "Resource: Specify resources that the AWS resource needs access. The resource accepts multiple ARNs for a service and wild card character ‘*’ is accepted."
      },
      {
        "heading": "Custom Policy File Structure",
        "depth": 3,
        "text": "Note: Specifying resource or action as ‘*’ is not recommended as best practice. This gives the Amplify api resource Administrative privileges which should be avoided."
      },
      {
        "heading": "Custom Policy File Structure",
        "depth": 3,
        "text": "If your Amplify resource requires access to multiple AWS services and resources, create another block to grant access to these additional services and resources."
      },
      {
        "heading": "Custom Policy File Structure",
        "depth": 3,
        "text": "Optionally, the Effect field can be specified to use ‘Allow’ or ‘Deny’. If not specified, the field defaults to ‘Allow’."
      },
      {
        "heading": "Custom Policy File Structure",
        "depth": 3,
        "text": "On running amplify push command, the IAM policies specified in the custom-policies.json file will be appended to the existing IAM policy list tied to the Fargate Task's execution role."
      },
      {
        "heading": "Multi-Environment Workflow",
        "depth": 3,
        "text": "To specify AWS ARN resources across environments, an optional ‘$’ parameter can be used within the resource string. The ‘$’ parameter in the AWS ARN resource will get populated with the current Amplify environment name at deployment."
      },
      {
        "heading": "Hosting",
        "depth": 2,
        "text": "When using containers in the amplify add hosting workflow the setup will be largely the same, including the ability to define your backend with a single Dockerfile or Docker Compose file yaml. However the ECS cluster will be fronted by an Application Load Balancer (ALB) and CloudFront distribution, and you will be required to provide a domain name which you own. This can either be a domain which you have purchased on a 3rd party registrar or with Route53. The domain will be used with Amazon Certificate Manager to configure SSL between ALB and Cognito User Pools to perform authorization to your website hosted on Fargate containers."
      },
      {
        "heading": "Hosting",
        "depth": 2,
        "text": "Hosting with Fargate in Amplify is only available in US-East-1 at this time"
      },
      {
        "heading": "Hosting",
        "depth": 2,
        "text": "If you are using a non-Route53 registrar, you will need two additional steps:"
      },
      {
        "heading": "Hosting",
        "depth": 2,
        "text": "Approve the certificate request. This will come via email to your registered address. If you do not see it you may need to resend the email."
      },
      {
        "heading": "Hosting",
        "depth": 2,
        "text": "Add a CNAME (A Record) on your to your DNS for the CloudFront distribution and Application Load Balancer. These will be printed out to the screen after amplify push succeeds."
      },
      {
        "heading": "Hosting",
        "depth": 2,
        "text": "For Route53 registered domains these steps are not needed and Amplify will register everything automatically. You can learn more about registering a domain name in the Route53 documentation."
      },
      {
        "heading": "Hosting",
        "depth": 2,
        "text": "You can additionally restrict access to your hosted site using Amazon Cognito User Pools. The ALB will authorize requests by using the OAuth endpoint of the Cognito Hosted UI with an SSL-enabled HTTP listener. To do this run amplify add auth first and select Default configuration with Social Provider (Federation) to enable the Hosted UI (you don't need to select any of the 3rd party social providers if it's not needed in your application). After this select Yes when prompted Do you want to automatically protect your web app using Amazon Cognito Hosted UI in the amplify add hosting flow. Alternatively, you can first add hosting and later add auth to your project by running amplify configure hosting after this is completed."
      },
      {
        "heading": "Build Pipeline",
        "depth": 2,
        "text": "Amplify creates APIs as an ECS Service to ensure that your application is monitored and tasks are in a healthy and active state, automatically recovering if an instance fails. When you make changes to your source code, the build and deployment pipeline will take your source code and Dockerfile/Docker Compose configuration as inputs. One or more containers will be built in AWS CodeBuild using your source code and pushed to ECR with a build hash as a tag, allowing you to roll back deployments if something unexpected happens in your application code. After the build is complete, the pipeline will perform a rolling deployment to launch Fargate Tasks automatically. Only when all new versions of the image are in a healthy & running state will the old tasks be stopped. Finally the build artifacts in S3 (in the fully managed scenario) and ECR images are set with a lifecycle policy retention of 7 days for cost optimization."
      },
      {
        "heading": "Fully Managed",
        "depth": 4,
        "text": "The fully managed workflow does not require you to have a source control repository or even Docker installed on your local workstation in order to build and deploy a container to Fargate. Amplify will package the contents of amplify/backend/api/<name>/src and place it onto an S3 deployment bucket. This will trigger a Code Pipeline process which builds your container(s), stores the results in ECR, and deploys them to Fargate."
      },
      {
        "heading": "Fully Managed",
        "depth": 4,
        "text": ""
      },
      {
        "heading": "Fully Managed",
        "depth": 4,
        "text": "For single containers only one ECR entry and deployment will take place. When using a Dockerfile, a build and push to ECR will take place for each container that has a corresponding build entry. For containers that only have an image entry no ECR push will take place and this image will be launched directly into the Fargate Task. As you make changes to your source code in amplify/backend/api/<name>/src, Amplify will detect any changes when you run amplify push, package the new files together and place them on S3. This will start another run of the build and deploy pipeline automatically updating your Fargate Service."
      },
      {
        "heading": "GitHub Source",
        "depth": 4,
        "text": "If you are using GitHub as your source repository for an Amplify project, you can use this to invoke the pipeline instead of having Amplify package and upload source to S3. In this use case you will need to provide a GitHub personal access token which will be stored in Secrets Manager as well as the full URL to your repository folder (or the branch). For instance if you push an Amplify project to GitHub called MyFargateProject you would use https://github.com/username/MyFargateProject/tree/main/amplify/backend/api/APINAME/src. repo and admin:repo_hook scopes will be needed. Please see the Code Pipeline documentation for more details."
      },
      {
        "heading": "GitHub Source",
        "depth": 4,
        "text": "Code Pipeline will use this for accessing the GitHub repo of your choosing and invoke the build and deploy to your Fargate Service, just as with the Fully Managed flow. Your repository must have the same structure as you would have had locally in amplify/backend/api/APINAME/src, that is to say:"
      },
      {
        "heading": "GitHub Source",
        "depth": 4,
        "text": "Single container needs to have a Dockerfile and all other required files (package.json, etc.)"
      },
      {
        "heading": "GitHub Source",
        "depth": 4,
        "text": "Multiple containers needs to have a docker-compose.yml and related file structure"
      },
      {
        "heading": "GitHub Source",
        "depth": 4,
        "text": "Code Pipeline will create a webhook on the GitHub repository which will trigger an invocation of the build and deployment pipeline to Fargate."
      },
      {
        "heading": "Self-managed builds",
        "depth": 4,
        "text": "You can always interact directly with the resources in your account to build containers locally and deploy them to ECR. This is an advanced option that we do not recommend for customers getting started. As you will need to run manual docker commands for building, tagging, and pushing your images to ECR. You will also need to restart the tasks manually on your ECS Service. Please see the ECR documentation for more information."
      },
      {
        "heading": "Troubleshooting",
        "depth": 3,
        "text": "Note that a container deployment could fail or be problematic in a few different ways ranging from a build issue to bugs in your application code not seen until production. There are different checkpoints along the way to help prevent application issues as well as methods to revert changes which are outlined below. To access the AWS Console with details of your container status, logging, or build pipeline at any time run amplify console api and select your deployed API."
      },
      {
        "heading": "Build failure",
        "depth": 3,
        "text": "When your code is submitted to the pipeline either via amplify push or check-in to GitHub, it will be packaged and submitted to a CodeBuild job. If this build phase fails your the rest of the pipeline stops and your code will not even attempt to launch on Fargate until the build errors have been resolved. The job will perform the following:"
      },
      {
        "heading": "Build failure",
        "depth": 3,
        "text": "Login to ECR"
      },
      {
        "heading": "Build failure",
        "depth": 3,
        "text": "Create a commit hash"
      },
      {
        "heading": "Build failure",
        "depth": 3,
        "text": "Build each container (e.g. docker build)"
      },
      {
        "heading": "Build failure",
        "depth": 3,
        "text": "Tag each container (e.g. docker tag)"
      },
      {
        "heading": "Build failure",
        "depth": 3,
        "text": "Push each container to ECR (docker push with commit hash)"
      },
      {
        "heading": "Build failure",
        "depth": 3,
        "text": "Write the build artifact (imagedefinitions.json) to S3"
      },
      {
        "heading": "Build failure",
        "depth": 3,
        "text": "If you see a failure in the Code Pipeline console at this step, you can view the details of the build (even clicking \"Tail Logs\" while the pipeline is running) to see what error occurred. It's possible you have a misconfiguration in your Dockerfile or even a network failure pulling an image from a 3rd party repository. To help avoid this issue you can always run docker build or docker-compose up locally before submitting a build and validating the application runs."
      },
      {
        "heading": "Build failure",
        "depth": 3,
        "text": "Note that on your first deployment a queueing process will take a bit longer to setup your project networking stack and run initial builds in Code Pipeline. During this time if your build fails for any reason (even external image throttling or Dockerfile config) the process will roll back. If you wish to debug this during initial rollout the Amplify CLI will print out the URL of the pipeline when amplify push starts to process the stack for you to view the build phase actively."
      },
      {
        "heading": "Container launch failure",
        "depth": 3,
        "text": "If your build pipeline completes and rolling deployment to your ECS cluster begins, but you notice that the process is not completing, it may be due to an application issue or container configuration problem in the Dockerfile. For example if you had a NodeJS or Python application that crashed upon startup (such as a file/module not found) the task may shut down. Since ECS is trying to keep the service alive it will retry starting the task several times to see if the problem will self correct. If you know what the problem is and want to stop this retry process early so that you can try another push, simply open the Cluster and click on the Service in the ECS console. Update the service and set the desired count for running tasks to 0 (zero) and update the cluster. Then fix the problem and perform another amplify push to try a deployment again."
      },
      {
        "heading": "Container launch failure",
        "depth": 3,
        "text": "Common issues are the application level crashes mentioned above, as well as incorrect Dockerfile/Docker-Compose commands such as those specified in entrypoint, command, or RUN. It's also possible that a specified healthcheck is continually failing. To troubleshoot this further you can click on the Cluster then Service in the ECS console followed by Tasks to see the Stopped containers. If you expand them there may be a top level error message giving information such as permissions or resource issues. Amplify also sets up logging by default and on this screen you will also find \"Log Configuration\" to view the logs in CloudWatch when you expand each container entry."
      },
      {
        "heading": "Application code bug",
        "depth": 3,
        "text": "Finally you may have an issue in your application code. This would be seen either in the CloudWatch logs outlined above or through functional testing. You can log to CloudWatch via standard language logging (e.g. console.log() in NodeJS). The simple and most straight forward way to make a fix is roll forward deployments, such as fixing the code and performing another amplify push. Sometimes this is not possible and you need to revert a change to an older image. Amplify automatically creates a commit hash for each successful build before storing the record in ECR, with the most recent build having an additional latest tag applied. Older revisions are kept in ECR for 7 days before being cleaned up in order to avoid extra storage costs. If you need to revert to an older version you can note the commit hash and re-tag it along with the latest tag, then stop the tasks in your Cluster Service. ECS will automatically pull your newly tagged revision from ECR and deploy that version."
      }
    ],
    "source": "export const meta = {\n  title: `Serverless containers`,\n  description: `Deploy containers to AWS. Serverless containers leverage AWS Fargate when building REST or GraphQL APIs in your account. containers can be deployed via a single Dockerfile definition or by using a Docker Compose file, with a build and deployment pipeline created inside your AWS account.`,\n};\n\nServerless containers provide the ability for you to deploy APIs and host websites using AWS Fargate. Customers with existing applications or those who require a lower level of control can bring Docker containers and deploy them into an Amplify project fully integrating with other resources.\n\nAmplify [libraries](/lib) can be used with the [Auth category](/lib/auth/start) giving mobile and web applications secure connectivity and access controls to your Serverless containers. Additionally, existing GraphQL and REST services such as AWS AppSync and Amazon API Gateway can be used in the same project along with Fargate-backed APIs giving flexibility to mix and match for cost optimization and operational needs.\n\nNote that serverless containers do incur additional costs and operational overhead, as such we recommend using AWS AppSync with the [GraphQL Transform](/cli/graphql/overview) as a starting point when building mobile and web apps with Amplify.\n\n> **Billing warning**: When you deploy serverless containers with Amplify, it incurs additional costs when resources are not in use for services such as VPC, Fargate, ECR, Cloud Map, CodePipeline, and CodeBuild. For more information refer to [VPC pricing](https://aws.amazon.com/vpc/pricing/), [Fargate pricing](https://aws.amazon.com/fargate/pricing/), [ECR Pricing](https://aws.amazon.com/ecr/pricing/), [CodePipeline pricing](https://aws.amazon.com/codepipeline/pricing/), [CodeBuild pricing](https://aws.amazon.com/codebuild/pricing/), and [Cloud Map pricing](https://aws.amazon.com/cloud-map/pricing/).\n\n## Getting Started\n\nServerless containers are not enabled in your Amplify CLI project by default. To get started you will need to run `amplify configure project` in order to see the options for deploying to Fargate. To get started initialize your project and enable **container-based deployments**:\n\n```console\n$ amplify init\n\n$ amplify configure project\n > Do you want to enable container-based deployments? Yes\n```\n\nNext add a NoSQL Database table named **posts** with column called **id** of type **number** (N). Make this the **partition key**.\n\n```bash\namplify add storage\n```\n\n```console\n> NoSQL Database # Name table “posts”\n\n> What would you like to name this column: id\n\n? Please choose the data type:\n  string\n> number\n  binary\n\n? Please choose partition key for the table: (Use arrow keys)\n> id\n```\n\nYou can select **no** for all other questions. After this add an API using the REST (or GraphQL) default ExpressJS template and grant it access to this DynamoDB table.\n\n```bash\namplify add api\n```\n\n```console\n> REST\n> API Gateway + AWS Fargate (Container-based)\n> ExpressJS - REST template\n? Do you want to access other resources in this project from your api? Y   # select yes\n> storage  # select posts table              # select post table and all permissions\n  ◉ create\n  ◉ read\n  ◉ update\n  ◉ delete\n> Do you want to restrict API access (Y/n)    # Will use Amazon Cognito if Yes is selected\n```\n\nNote the environment variables printed to the screen. If you choose a different database table name so that your variables are different from `STORAGE_POSTS_NAME` then update the `TableName` variable at the top of `amplify/backend/api/<apiname>/src/DynamoDBActions.js` appropriately.\n\nFinally run `amplify push` to deploy the backend:\n\n```bash\namplify push\n```\n\nOnce this completes your container will be built via an automated pipeline and deployed to Fargate Tasks on an ECS Cluster fronted by an Amazon API Gateway HTTP API using a direct Cloud Map integration to your VPC. If you selected *Yes* to protect your API with Authentication, an Amazon Cognito User Pool will be created with an Authorizer integration for that API.\n\n## Deploy a single container\n\nThe single Dockerfile scenario allows you to take an application running in a single Container which has been built with a Dockerfile and deploy it to AWS Fargate with the Amplify CLI.\n\nIf you are unfamiliar with using a Dockerfile review the [Dockerizing a Node.js web app](https://nodejs.org/en/docs/guides/nodejs-docker-webapp/) guide or or add an API with an Amplify-provided template.\n\nA simple Dockerfile example is below, which would start a NodeJS application (`index.js`) in a built image by copying all the source files and installing dependencies. This example also shows how could can specify environment variables and use the `EXPOSE` statement for defining your container's communication port.\n\n```docker\nFROM public.ecr.aws/bitnami/node:14.15.1-debian-10-r8\n\nENV PORT=8080\nEXPOSE 8080\n\nWORKDIR /usr/src/app\n\nCOPY package*.json ./\nRUN npm install\nCOPY . .\n\nCMD [ \"node\", \"index.js\" ]\n```\n\nYou will need an [`EXPOSE` statement in your Dockerfile](https://docs.docker.com/engine/reference/builder/#expose) to specify a port to communicate with the container. If you do not provide one Amplify will suggest to use port 80.\n\n### Local development and testing\n\nIt is recommended to test your application locally first before deploying with `amplify push`, otherwise your Fargate Task may fail to start if there are application issues such as missing dependencies. With a Single Dockerfile you can do this by navigating to `amplify/backend/api/<name>/src` and running `docker build -t` to build and tag your image followed by `docker run` to launch your container similar to the below example:\n\n```console\n$ cd ./amplify/backend/api/<name>/src\n$ docker build -t node-app:1.0 .\n$ docker run -p 8080:8080 -d node-app:1.0\n$ curl -i localhost:8080  ## Alternatively open in a web browser\n```\n\nYou can also run your application using standard tooling such as running `node index.js` or `python server.py` in Node or Python. Once you are satisfied with the Dockerfile and your application code, run `amplify push` and the `amplify/backend/api/<name>/src` directory will be bundled for the build pipeline to run and deploy your image to Fargate. At the end of the deployment the endpoint URL will be printed and client configuration files will be updated.\n\n## Deploy multiple containers\n\nIf you wish to deploy multiple containers into Fargate to define your API, Amplify will parse a Docker Compose file (`docker-compose.yml`) in your `amplify/backend/api/<name>/src` directory to define the backend service. If you are unfamiliar with using a Docker Compose review the [Docker Compose getting started guide](https://docs.docker.com/compose/gettingstarted/) or or add an API with an Amplify-provided template.\n\nA Compose file includes the logical container names, build & images settings, launch commands, ports, and more. An example Docker Compose file is below:\n\n```yaml\nversion: \"3.8\"\nservices:\n  express:\n    build:\n      context: ./express\n      dockerfile: Dockerfile\n    ports:\n      - \"8080:8080\"\n    networks:\n      - public\n      - private\n  python:\n    build:\n      context: ./python\n      dockerfile: Dockerfile\n    networks:\n      - public\n      - private\n    ports:\n      - \"5000:5000\"\nnetworks:\n  public:\n  private:\n```\n\nThis `docker-compose.yml` file would be placed in your `amplify/backend/api/<name>/src` when using the \"bring your own container\" flow. It defines two containers called **express** and **python** which each have a Dockerfile in two sub directories along with the application source files\n\n```text\n./amplify/backend/api/<name>/src\n docker-compose.yml\n /express\n   Dockerfile\n   package.json\n   index.js\n /python\n   Dockerfile\n   requirements.txt\n   server.py\n```\n\n### Local development and testing\n\nAs with the single container workflow, it is recommended to test your application locally first before deploying with `amplify push`, otherwise your Fargate Task may fail to start if there are application issues such as missing dependencies. Navigate to `amplify/backend/api/<name>/src` and run `docker-compose up` which will build your images and start them locally.\n\n```console\n$ cd ./amplify/backend/api/<name>/src\n$ docker-compose up\n$ curl -i localhost:8080  ## Alternatively open in a web browser\n```\n\nIf your application source changes for any of the images, you can rebuild them by running `docker-compose build` before running `docker-compose up` during your test and development cycle.\n\n### Container networking\n\nMultiple containers are deployed as a single unit in Fargate (e.g. same Task Definition). This opinionated deployment allows ease of networking between containers on the local loopback interface and avoids extra configuration, costs, operations, and debugging.\n\n#### When container is deployed to Fargate\n\nThe loopback interface has an IP of 127.0.0.1 and a hostname of `localhost` which you can use in one container's application code to communicate with another.\n\nUsing the `docker-compose.yml` example from earlier, you might have the following code in your NodeJS application. It references the *port* of the Redis container and a *host* using the loopback adapter with `localhost`:\n\n```js\nconst options = {\n  port: 5000,\n  host: 'localhost',  // Loopback interface communication\n  method: 'GET',\n  path: '/images'\n};\n\nhttp.get(options, data => {...})\n```\n\n#### When testing locally using `docker-compose up`\n\nWhen performing local development and testing with `docker-compose up` you will use the logical container name defined in your `docker-compose.yaml` file.\n\n```js\nconst options = {\n  port: 5000,\n  host: 'python',   // Name of other container in docker-compose\n  method: 'GET',\n  path: '/images'\n};\n\nhttp.get(options, data => {...})\n```\n\n### Supported Configurations\n\nAmplify will configure your Fargate infrastructure (ECS Service and Task Definition) automatically while allowing you to override specific settings with a Docker Compose file. Older versions of Compose files are supported however not all configuration values will be honored, therefore [it is recommended you update to 3.8](https://docs.docker.com/compose/compose-file/). Additionally if a value has been deprecated in one version of Compose, Amplify will prefer the newest version (3.8).\n\n- build\n- name\n- ports\n- command\n- entrypoint\n- env_file\n- image\n- healthcheck\n- working_dir\n- user\n- secrets\n- replicas\n\nBy default Amplify will use a single Availability Zone however if you choose the *High Availability* option it will spread Fargate Tasks across 3 Availability Zones. The [`replicas`](https://docs.docker.com/compose/compose-file/#replicas) value should be used to increase [the number of Fargate tasks running in your Cluster](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service_definition_parameters.html#sd-desiredcount) depending on your traffic requirements, however note that more running tasks will accrue more costs.\n\nWhen you have multiple container entries specifying a `port` Amplify will prompt you upon running `amplify push` to select an **Entrypoint Container**. Since all containers are deployed as a \"unit\" and fronted by an API Gateway HTTP endpoint for client applications to access, Amplify needs to know which container in the Cluster's Service to route requests. The answer to the Entrypoint question will use the first specified `ports` entry to perform this routing.\n\nIt is recommended that you define container settings early in the development process if possible. While these settings can be updated later, it will cause an in-place replacement of the Fargate service configuration and could lead to your endpoint being unavailable for a few moments while the process completes. For best results minimize configuration changes in your Docker Compose settings and make more frequents updates to your application code in order to take advantage of rolling updates in the build and deploy pipeline.\n\n### Environment variables and secrets\n\nYou can use environment variables in your application code that are specified in your Docker Compose file, but do not specify the hostname when deploying in `amplify push`. For example the `DATABASE_HOST` variable below might be specified locally when using `docker-compose up` with the  `environment` setting:\n\n```yaml\nenvironment:\n  - DATABASE_DB=amplify\n  - DATABASE_USER=root\n  - DATABASE_PASSWORD=/run/secrets/db-password\n  - DATABASE_HOST=db  #comment out before pushing\n```\n\nThen your application code can switch between local and cloud deployment automatically and communicate with the `db` container:\n\n```js\nmodule.exports = {\n  database: {\n    host: process.env.DATABASE_HOST || \"localhost\",\n    port: process.env.DATABASE_PORT || 3306,\n    database: process.env.DATABASE_DB,\n    user: process.env.DATABASE_USER,\n    password: process.env.DATABASE_PASSWORD\n  },\n  port: process.env.PORT || 8080\n};\n```\n\n`secrets` allow you to [pass sensitive data to your containers from AWS Secrets Manager](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/specifying-sensitive-data.html). Amplify will do this for you when you populate the `secrets` configuration at the root level of your `docker-compose.yml`. It must be a file name that starts with `.secret-` and cannot be in the `src` directory of `amplify/backend/api/<name>`, but can be anywhere outside of it including a relative path. It is recommended to place your secrets in a `amplify/backend/api/<name>/secrets` directory. Every `.secret-` file has only one string value and will referenced by the name you provide in the `docker-compose.yml` entry.\n\nWhen you perform an `amplify push` you will be prompted to store the secrets in the cloud or bypass (which may be the case in team workflows when one person controls secrets). The name of the secret will be available in your application code similar to if you specified other variables via the `environment` configuration:\n\n```yaml\nversion: \"3.8\"\nservices:\n  backend:\n    build:\n      args:\n      - NODE_ENV=development\n      context: backend\n    environment:\n      - DATABASE_NAME=mydb\n    secrets:\n      - DB_PASSWORD\nsecrets:\n  DB_PASSWORD:\n    file: ../secrets/.secret-pass\n```\n\n**NodeJS example**\n\n```js\nconst database = process.env.DATABASE_NAME;\nconst password = process.env.DB_PASSWORD;\n```\n\n**Python example**\n\n```python\nimport os\n\ndatabase = os.environ['DATABASE_NAME']\npassword = os.environ['DB_PASSWORD']\n```\n\n## Bring Your Own Container Specification For Your REST API\n\nWhen creating an API using containers, you have the option to bring in your own `Dockerfile`(s) and `docker-compose.yml`. When selecting the Docker image for your REST API, choose `Custom` and then select when to deploy code and configuration changes to your container.\n\n```console\n? What image would you like to use Custom (bring your own Dockerfile or docker-compose.yml)\n? When do you want to build & deploy the Fargate task \n> On every \"amplify push\" (Fully managed container source) \n  On every Github commit (Independently managed container source) \n  Advanced: Self-managed (Learn more: docs.amplify.aws/cli/usage/containers) \n```\n\nThe CLI will provide you with the next steps to bring your existing Docker specification and source files into your project by populating the `src` directory.\n\n```console\n✅ Next steps:\n- Place your Dockerfile, docker-compose.yml and any related container source files in \"amplify/backend/api/{API_NAME}/src\"\n- Amplify CLI infers many configuration settings from the \"docker-compose.yaml\" file. Learn more: docs.amplify.aws/cli/usage/containers\n- To access AWS resources outside of this Amplify app, edit the amplify/local/test/amplify/backend/api/{API_NAME}/custom-policies.json\n- Run \"amplify push\" to build and deploy your image\n```\n\n## Client Configuration\n\nServerless containers are fronted by a secure endpoint by which you can interact with them from a mobile or web application. Amplify CLI will attempt to update the project `aws-exports.js` or `amplifyconfiguration.json` file with the endpoint, however for GraphQL API types this is not possible and you will need to manually specify it in an `Amplify.configure()` call within your application code. The endpoint will be printed out to the screen after running an `amplify push` for you to make these changes, take note of it and follow one of the guides below appropriately.\n\n- [JavaScript GraphQL configuration](/lib/graphqlapi/create-or-re-use-existing-backend)\n- [JavaScript REST configuration](/lib/restapi/getting-started#manual-setup-import-existing-rest-api)\n- [Android GraphQL configuration](https://docs.amplify.aws/lib/graphqlapi/existing-resources/q/platform/android)\n- [Android REST configuration](https://docs.amplify.aws/lib/restapi/getting-started/q/platform/android)\n- [iOS GraphQL configuration](https://docs.amplify.aws/lib/graphqlapi/existing-resources/q/platform/ios)\n- [iOS REST configuration](https://docs.amplify.aws/lib/restapi/getting-started/q/platform/ios)\n\nNote that if you have enabled Authorization checks on your endpoints during `amplify add api` your clients will need to Authenticate against the Cognito User Pool configured and pass tokens. Please see the [appropriate platform guide](/lib/auth/getting-started) for adding Sign-Up and Sign-In calls to your application.\n\n\n## Access existing AWS resource from container\n\nYou can grant your Fargate Task access to additional AWS resources and services.  After running `amplify add api`, the CLI generates a `custom-policies.json` under the folder `amplify/backend/api/<api-name>/custom-policies.json`. The file is where you can specify the [resources](https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_resource.html) and [actions](https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_action.html) that grant the Fargate task additional AWS resources and services access.\n\n\n### Custom Policy File Structure\n\n```json\n[\n    {\n        \"Action\": [\"s3:CreateBucket\"],\n        \"Resource\": [\"arn:aws:s3:::*\"]\n    }\n]\n```\n\n**Action:** Specify the actions that are required to be granted to your AWS resource. Wild characters ‘*’ is accepted.\n\n**Resource**: Specify resources that the AWS resource needs access. The resource accepts multiple ARNs for a service and wild card character ‘*’ is accepted.\n\n\n> Note: Specifying resource or action as ‘*’ is not recommended as best practice. This gives the Amplify api resource Administrative privileges which should be avoided.\n\n\nIf your Amplify resource requires access to multiple AWS services and resources, create another block to grant access to these additional services and resources.\n\n```json\n[\n    {\n        \"Action\": [\"s3:CreateBucket\"],\n        \"Resource\": [\"arn:aws:s3:::*\"]\n    },\n    {\n        \"Action\": [\"iam:GetPolicy\"],\n        \"Resource\": [\"arn:aws:iam:::policy/*\"]\n    }\n]\n```\n\n\nOptionally, the `Effect` field can be specified to use ‘Allow’ or ‘Deny’. If not specified, the field defaults to ‘Allow’.\n\n```json\n{\n    \"Action\": [\"s3:CreateBucket\"],\n    \"Resource\": [\"arn:aws:s3:::*\"],\n    \"Effect\": \"Allow\"\n}\n```\n\nOn running `amplify push` command, the IAM policies specified in the `custom-policies.json` file will be appended to the existing IAM policy list tied to the Fargate Task's execution role.\n\n### Multi-Environment Workflow\n\nTo specify AWS ARN resources across environments, an optional ‘\\${env}’ parameter can be used within the resource string. The ‘\\${env}’ parameter in the AWS ARN resource will get populated with the current Amplify environment name at deployment.\n\n``` json\n\"Resource\": [\"arn:aws:s3:::${env}my-bucket\"]\n```\n\n## Hosting\n\nWhen using containers in the `amplify add hosting` workflow the setup will be largely the same, including the ability to define your backend with a single Dockerfile or Docker Compose file yaml. However the ECS cluster will be fronted by an Application Load Balancer (ALB) and CloudFront distribution, and you will be required to provide a domain name which you own. This can either be a domain which you have purchased on a 3rd party registrar or with Route53. The domain will be used with Amazon Certificate Manager to configure SSL between ALB and Cognito User Pools to perform authorization to your website hosted on Fargate containers.\n\n> Hosting with Fargate in Amplify is only available in US-East-1 at this time\n\nIf you are using a non-Route53 registrar, you will need two additional steps:\n\n1. Approve the certificate request. This will come via email to your registered address. If you do not see it you may need to [resend the email](https://docs.aws.amazon.com/acm/latest/userguide/gs-acm-resend.html).\n2. Add a CNAME (A Record) on your to your DNS for the CloudFront distribution and Application Load Balancer. These will be printed out to the screen after `amplify push` succeeds.\n\nFor Route53 registered domains these steps are not needed and Amplify will register everything automatically. You can learn more about [registering a domain name in the Route53 documentation](https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/registrar.html).\n\nYou can additionally restrict access to your hosted site using Amazon Cognito User Pools. The ALB will authorize requests by using the OAuth endpoint of the Cognito Hosted UI with an SSL-enabled HTTP listener. To do this run `amplify add auth` first and select *Default configuration with Social Provider (Federation)* to enable the Hosted UI (you don't need to select any of the 3rd party social providers if it's not needed in your application). After this select *Yes* when prompted *Do you want to automatically protect your web app using Amazon Cognito Hosted UI* in the `amplify add hosting` flow. Alternatively, you can first add hosting and later add auth to your project by running `amplify configure hosting` after this is completed.\n\n## Build Pipeline\n\nAmplify creates APIs as an [ECS Service](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs_services.html) to ensure that your application is monitored and tasks are in a healthy and active state, automatically recovering if an instance fails. When you make changes to your source code, the build and deployment pipeline will take your source code and Dockerfile/Docker Compose configuration as inputs. One or more containers will be built in AWS CodeBuild using your source code and pushed to ECR with a build hash as a tag, allowing you to roll back deployments if something unexpected happens in your application code. After the build is complete, the pipeline will perform a rolling deployment to launch Fargate Tasks automatically. Only when all new versions of the image are in a healthy & running state will the old tasks be stopped. Finally the build artifacts in S3 (in the fully managed scenario) and ECR images are set with a lifecycle policy retention of 7 days for cost optimization.\n\n#### Fully Managed\n\nThe fully managed workflow does not require you to have a source control repository or even Docker installed on your local workstation in order to build and deploy a container to Fargate. Amplify will package the contents of `amplify/backend/api/<name>/src` and place it onto an S3 deployment bucket. This will trigger a Code Pipeline process which builds your container(s), stores the results in ECR, and deploys them to Fargate.\n\n![Fully Managed Pipeline](/images/containers/build-workflow.png)\n\nFor single containers only one ECR entry and deployment will take place. When using a Dockerfile, a build and push to ECR will take place for each container that has a corresponding `build` entry. For containers that only have an `image` entry no ECR push will take place and this image will be launched directly into the Fargate Task. As you make changes to your source code in `amplify/backend/api/<name>/src`, Amplify will detect any changes when you run `amplify push`, package the new files together and place them on S3. This will start another run of the build and deploy pipeline automatically updating your Fargate Service.\n\n#### GitHub Source\n\nIf you are using GitHub as your source repository for an Amplify project, you can use this to invoke the pipeline instead of having Amplify package and upload source to S3. In this use case you will need to provide a [GitHub personal access token](https://docs.github.com/en/enterprise/2.17/user/github/authenticating-to-github/creating-a-personal-access-token-for-the-command-line) which will be stored in Secrets Manager as well as the full URL to your repository folder (or the branch). For instance if you push an Amplify project to GitHub called **MyFargateProject** you would use **`https://github.com/username/MyFargateProject/tree/main/amplify/backend/api/APINAME/src`**. `repo` and `admin:repo_hook` scopes will be needed. Please see the [Code Pipeline documentation for more details](https://docs.aws.amazon.com/codepipeline/latest/userguide/appendix-github-oauth.html).\n\nCode Pipeline will use this for accessing the GitHub repo of your choosing and invoke the build and deploy to your Fargate Service, just as with the Fully Managed flow. Your repository must have the same structure as you would have had locally in `amplify/backend/api/APINAME/src`, that is to say:\n\n- Single container needs to have a Dockerfile and all other required files (package.json, etc.)\n- Multiple containers needs to have a `docker-compose.yml` and related file structure\n\nCode Pipeline will create a [webhook on the GitHub repository](https://docs.github.com/en/free-pro-team@latest/developers/webhooks-and-events/about-webhooks) which will trigger an invocation of the build and deployment pipeline to Fargate.\n\n#### Self-managed builds\n\nYou can always interact directly with the resources in your account to build containers locally and deploy them to ECR. This is an advanced option that we do not recommend for customers getting started. As you will need to run manual docker commands for building, tagging, and pushing your images to ECR. You will also need to restart the tasks manually on your ECS Service. Please see the [ECR documentation](https://docs.aws.amazon.com/AmazonECR/latest/userguide/getting-started-cli.html) for more information.\n\n### Troubleshooting\n\nNote that a container deployment could fail or be problematic in a few different ways ranging from a build issue to bugs in your application code not seen until production. There are different checkpoints along the way to help prevent application issues as well as methods to revert changes which are outlined below. To access the AWS Console with details of your container status, logging, or build pipeline at any time run `amplify console api` and select your deployed API.\n\n### Build failure\n\nWhen your code is submitted to the pipeline either via `amplify push` or check-in to GitHub, it will be packaged and submitted to a CodeBuild job. If this build phase fails your the rest of the pipeline stops and your code will not even attempt to launch on Fargate until the build errors have been resolved. The job will perform the following:\n\n- Login to ECR\n- Create a commit hash\n- Build each container (e.g. `docker build`)\n- Tag each container (e.g. `docker tag`)\n- Push each container to ECR (`docker push` with commit hash)\n- Write the build artifact (`imagedefinitions.json`) to S3\n\nIf you see a failure in the Code Pipeline console at this step, you can view the details of the build (even clicking \"Tail Logs\" while the pipeline is running) to see what error occurred. It's possible you have a misconfiguration in your Dockerfile or even a network failure pulling an image from a 3rd party repository. To help avoid this issue you can always run `docker build` or `docker-compose up` locally before submitting a build and validating the application runs.\n\nNote that on your first deployment a queueing process will take a bit longer to setup your project networking stack and run initial builds in Code Pipeline. During this time if your build fails for any reason (even external image throttling or Dockerfile config) the process will roll back. If you wish to debug this during initial rollout the Amplify CLI will print out the URL of the pipeline when `amplify push` starts to process the stack for you to view the build phase actively.\n\n### Container launch failure\n\nIf your build pipeline completes and rolling deployment to your ECS cluster begins, but you notice that the process is not completing, it may be due to an application issue or container configuration problem in the Dockerfile. For example if you had a NodeJS or Python application that crashed upon startup (such as a file/module not found) the task may shut down. Since ECS is trying to keep the service alive it will retry starting the task several times to see if the problem will self correct. If you know what the problem is and want to stop this retry process early so that you can try another push, simply open the Cluster and click on the Service in the ECS console. Update the service and set the desired count for running tasks to 0 (zero) and update the cluster. Then fix the problem and perform another `amplify push` to try a deployment again.\n\nCommon issues are the application level crashes mentioned above, as well as incorrect Dockerfile/Docker-Compose commands such as those specified in `entrypoint`, `command`, or `RUN`. It's also possible that a specified `healthcheck` is continually failing. To troubleshoot this further you can click on the Cluster then Service in the ECS console followed by Tasks to see the **Stopped** containers. If you expand them there may be a top level error message giving information such as permissions or resource issues. Amplify also sets up logging by default and on this screen you will also find \"Log Configuration\" to view the logs in CloudWatch when you expand each container entry.\n\n### Application code bug\n\nFinally you may have an issue in your application code. This would be seen either in the CloudWatch logs outlined above or through functional testing. You can log to CloudWatch via standard language logging (e.g. `console.log()` in NodeJS). The simple and most straight forward way to make a fix is roll forward deployments, such as fixing the code and performing another `amplify push`. Sometimes this is not possible and you need to revert a change to an older image. Amplify automatically creates a commit hash for each successful build before storing the record in ECR, with the most recent build having an additional **latest** tag applied. Older revisions are kept in ECR for 7 days before being cleaned up in order to avoid extra storage costs. If you need to revert to an older version you can note the commit hash and re-tag it along with the **latest** tag, then stop the tasks in your Cluster Service. ECS will automatically pull your newly tagged revision from ECR and deploy that version.\n",
    "meta": {
      "title": "Serverless containers",
      "description": "Deploy containers to AWS. Serverless containers leverage AWS Fargate when building REST or GraphQL APIs in your account. containers can be deployed via a single Dockerfile definition or by using a Docker Compose file, with a build and deployment pipeline created inside your AWS account.",
      "subcategory": "Advanced workflows",
      "category": "Amplify CLI"
    },
    "filename": "/cli/usage/containers"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "It is highly recommended that you complete the Getting Started section of Amplify setup before using local mocking."
      },
      {
        "heading": null,
        "depth": null,
        "text": "🚀 Get Started"
      },
      {
        "heading": null,
        "depth": null,
        "text": "In order to quickly test and debug without pushing all changes in your project to the cloud, Amplify supports Local Mocking and Testing for certain categories including API (AWS AppSync), Storage (Amazon DynamoDB and Amazon S3), and Functions (AWS Lambda). This includes using directives from the GraphQL Transformer, editing & debug resolvers, hot reloading, JWT mocking of authorization checks, and even performing S3 operations such as uploading and downloading content."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Java is required on your development workstation to use Local Mocking in Amplify"
      },
      {
        "heading": null,
        "depth": null,
        "text": "NOTE: Currently, on Apple Silicon Macs, Amplify sometimes fails to start mocks when using certain JDK versions built for ARM processors."
      },
      {
        "heading": null,
        "depth": null,
        "text": "If you encounter this issue, please try using the official openJDK 16.0.1 from the Java website: JDK Download"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Blog walk-through with sample app."
      },
      {
        "heading": "API mocking setup",
        "depth": 2,
        "text": "After running amplify init you can immediately add a GraphQL API and begin mocking without first pushing to the cloud. REST APIs are not yet supported. For example:"
      },
      {
        "heading": "API mocking setup",
        "depth": 2,
        "text": "When you run amplify mock api the codegen process will run and create any required GraphQL assets such as queries, mutations, and subscriptions as well as TypeScript or Swift classes for your app. Android requires a build step for Gradle to create required classes after the codegen process completes, as well as an extra configuration in your AndroidManifest.xml."
      },
      {
        "heading": "API mocking setup",
        "depth": 2,
        "text": "If you do not wish to test your app locally, you can still use the local GraphQL console as well as edit, debug, and test your VTL resolvers locally against the mock endpoint."
      },
      {
        "heading": "API mocking setup",
        "depth": 2,
        "text": "When adding a schema use an API Key at first to ensure everything works, though you can authenticate against a Cognito User Pool and the local testing server will honor the JWT tokens. You can also mock the JWT tokens in the local console (outlined below), however in that case you will need to do an amplify push first to create the User Pool."
      },
      {
        "heading": "API mocking setup",
        "depth": 2,
        "text": "When defining a schema you can use directives from the GraphQL Transformer in local testing as well as local code generation from the schema for types. The following directives are currently supported in local testing:"
      },
      {
        "heading": "API mocking setup",
        "depth": 2,
        "text": "@auth"
      },
      {
        "heading": "API mocking setup",
        "depth": 2,
        "text": "@primaryKey, @index"
      },
      {
        "heading": "API mocking setup",
        "depth": 2,
        "text": "@hasOne, @hasMany, @belongsTo, @manyToMany"
      },
      {
        "heading": "API mocking setup",
        "depth": 2,
        "text": "@function"
      },
      {
        "heading": "API mocking setup",
        "depth": 2,
        "text": "If you have DynamoDB Lambda triggers set up on @model types in your GraphQL schema, by following steps listed here,\nthen you can test those Lambda triggers locally via amplify mock or amplify mock api."
      },
      {
        "heading": "API mocking setup",
        "depth": 2,
        "text": "The connected Lambda triggers are automatically invoked locally if you perform a CRUD operation on the @model type using either the local DynamoDB endpoint (http://localhost:62224) or\nthe local AppSync console (should be http://localhost:20002). The structure of the event that is sent to the lambda trigger can be found here."
      },
      {
        "heading": "API mocking setup",
        "depth": 2,
        "text": "The environment variables that are listed below in Function mock environment variables, are available for each invocation of the Lambda trigger."
      },
      {
        "heading": "API mocking setup",
        "depth": 2,
        "text": "In addition, you can use a .env file within the function directory (ie. <project root>/amplify/backend/function/<function name>/.env) to override any environment variables for local mocking."
      },
      {
        "heading": "API mocking setup",
        "depth": 2,
        "text": "Note: IAM authorization rules in Mock get are treated as Auth role if the request is signed with AccessKey ASIAVJKIAM-AuthRole. Otherwise the request is treated as made by an unAuth user."
      },
      {
        "heading": "API mocking setup",
        "depth": 2,
        "text": "Note: that @searchable is not supported at this time."
      },
      {
        "heading": "Storage mocking setup",
        "depth": 2,
        "text": "For S3 storage mocking, after running amplify init you must first run through amplify add auth, either explicitly or implicitly if adding storage first, and then run an amplify push. This is because mocking storage in client libraries requires credentials for initial setup. Note however that S3 authorization rules, such as those placed on a bucket policy, are not checked by local mocking at this time."
      },
      {
        "heading": "Storage mocking setup",
        "depth": 2,
        "text": "Once you have done an initial push you can run the mock server and hit the local endpoint:"
      },
      {
        "heading": "Storage mocking setup",
        "depth": 2,
        "text": "To use an iOS application with the local S3 endpoint you will need to modify your Info.plist file. To use an Android application with the local S3 endpoint you will need an extra configuration in your AndroidManifest.xml."
      },
      {
        "heading": "Storage mocking setup",
        "depth": 2,
        "text": "For DynamoDB storage, setup is automatically done when creating a GraphQL API with no action is needed on your part. Resources for the mocked data, such as the DynamoDB Local database or objects uploaded using the local S3 endpoint, inside your project under amplify/mock-data."
      },
      {
        "heading": "Function mocking setup",
        "depth": 2,
        "text": "After adding a function to your project with amplify add function you can test it using amplify mock function."
      },
      {
        "heading": "Function mocking setup",
        "depth": 2,
        "text": "amplify mock function supports the following arguments:"
      },
      {
        "heading": "Function mocking setup",
        "depth": 2,
        "text": "<function name> - The name of the function to mock. Must immediately follow amplify mock function, eg. amplify mock function myFunctionName"
      },
      {
        "heading": "Function mocking setup",
        "depth": 2,
        "text": "--event \"<path to event JSON file>\" - Use the specified JSON file as the event to pass to the Lambda handler"
      },
      {
        "heading": "Function mocking setup",
        "depth": 2,
        "text": "--timeout <number of seconds> - Override the default 10 second function response timeout with a custom timeout value"
      },
      {
        "heading": "Function mocking with GraphQL",
        "depth": 3,
        "text": "A GraphQL Lambda resolver connected to your schema using @function can be mocked using amplify mock api.\nFor example, if you have a function named quoteOfTheDay and a schema like:"
      },
      {
        "heading": "Function mocking with GraphQL",
        "depth": 3,
        "text": "Then when running amplify mock api, the local GraphQL endpoint will invoke this function locally when running a GraphQL query such as:"
      },
      {
        "heading": "Function mock environment variables",
        "depth": 3,
        "text": "amplify mock functionpopulates environment variables that mimic what will be present when deployed in the cloud. Amplify parses the function's CloudFormation template and attempts to resolve any environment variables specified there (also review function mock limitations)."
      },
      {
        "heading": "Function mock environment variables",
        "depth": 3,
        "text": "CloudFormation parameters will be resolved by:"
      },
      {
        "heading": "Function mock environment variables",
        "depth": 3,
        "text": "Resolving values specified in the parameters.json file for the function"
      },
      {
        "heading": "Function mock environment variables",
        "depth": 3,
        "text": "Resolving values specified in team-provider-info.json within the <env>.categories.function.<function name> block, where <env> is the currently checked out environment and <function name> is the function being mocked"
      },
      {
        "heading": "Function mock environment variables",
        "depth": 3,
        "text": "AWS::Region, AWS::AccountID, AWS::StackName, and AWS::StackId are resolved by parsing the awscloudformation configuration of the current environment in team-provider-info.json"
      },
      {
        "heading": "Function mock environment variables",
        "depth": 3,
        "text": "Parameters constructed from dependencies on other resources in the project are resolved by parsing amplify-meta.json. Additionally, if a mock API is currently running and the function depends on the API, the local API URL will replace the cloud URL"
      },
      {
        "heading": "Function mock environment variables",
        "depth": 3,
        "text": "The mock environment will also populate lambda runtime environment variables in the following way:"
      },
      {
        "heading": "Function mock environment variables",
        "depth": 3,
        "text": "AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, and AWS_SESSION_TOKEN will be populated using the AWS credentials that the Amplify project is currently configured to use"
      },
      {
        "heading": "Function mock environment variables",
        "depth": 3,
        "text": "_HANDLER, AWS_REGION, AWS_LAMBDA_FUNCTION_NAME, LAMBDA_TASK_ROOT, and LAMBDA_RUNTIME_DIR will be set based on the function being mocked"
      },
      {
        "heading": "Function mock environment variables",
        "depth": 3,
        "text": "Static defaults will be specified for all other runtime environment variables. The full list of static defaults can be found here"
      },
      {
        "heading": "Function mock environment variables",
        "depth": 3,
        "text": "You can also override any mock environment variables in a .env file within the function directory (ie. <project root>/amplify/backend/function/<function name>/.env)."
      },
      {
        "heading": "Connecting to a mock @model table",
        "depth": 3,
        "text": "Connect a mock function that operates on a table generated by @model to the mock table when running amplify mock api by:"
      },
      {
        "heading": "Connecting to a mock @model table",
        "depth": 3,
        "text": "Create a .env file in the function directory with the following:"
      },
      {
        "heading": "Connecting to a mock @model table",
        "depth": 3,
        "text": "Replace <api name> with the name of your API and <model> with the name of your model. The environment variable name should be all capitalized. For example, if you have an API named \"FlightStats\" and a model defined as type Airplane @model {...}, then then last line of the .env file should be:"
      },
      {
        "heading": "Connecting to a mock @model table",
        "depth": 3,
        "text": "Configure the DynamoDB client in your function as follows:"
      },
      {
        "heading": "Connecting to a mock @model table",
        "depth": 3,
        "text": "Run amplify mock api to activate the local DynamoDB endpoint"
      },
      {
        "heading": "Connecting to a mock @model table",
        "depth": 3,
        "text": "Run amplify mock function which will now connect to the mock DynamoDB table"
      },
      {
        "heading": "Connecting to a mock @model table",
        "depth": 3,
        "text": "When running in the cloud, these environment variables will have valid values except DDB_ENDPOINT which will be undefined. In this case the DynamoDB client will use the default endpoint."
      },
      {
        "heading": "Connecting to a mock @model table",
        "depth": 3,
        "text": "When running locally, these environment variables will be populated using the local .env file which specifies the fake values required to connect to the local database."
      },
      {
        "heading": "Connecting to a mock @model table",
        "depth": 3,
        "text": "Note: While connected to the mock database, calls to other AWS resources within the mock function will not work because the AWS credential environment variables have been overwritten with fake credentials. To call a mock table as well as other AWS services, add logic to switch between the fake credentials and the real ones in the DynamoDB client configuration. In this case, you could configure your .env file with:"
      },
      {
        "heading": "Connecting to a mock @model table",
        "depth": 3,
        "text": "And configure the DynamoDB client with:"
      },
      {
        "heading": "Function mock limitations",
        "depth": 3,
        "text": "amplify mock function does not attempt to fully simulate the Lambda runtime environment. There may be some cases where the behavior of your function when mocking differs from executing in the cloud."
      },
      {
        "heading": "Function mock limitations",
        "depth": 3,
        "text": "For example, mock runs on your local OS and does not attempt to emulate Amazon Linux which executes your function in the cloud. Testing with amplify mock function should be used to get quick feedback on the correctness of your function but should not be used as a substitute for testing in a cloud development environment."
      },
      {
        "heading": "Config files",
        "depth": 2,
        "text": "When performing operations against the local mock endpoint, the Amplify CLI will automatically update your aws-exports.js and awsconfiguration.json with the local endpoints, fake values where necessary (e.g. fake API key), and disable SSL with an explicit value (DangerouslyConnectToHTTPEndpointForTesting) to indicate the functionality is only for local mocking and testing. This happens automatically when you run amplify mock and the server is running. Once you stop the mock server the config files are updated with the correct cloud endpoints for your project and DangerouslyConnectToHTTPEndpointForTesting is removed from the config file."
      },
      {
        "heading": "iOS config",
        "depth": 2,
        "text": "When running against the local mock S3 server with iOS you must update your Info.plist to not require SSL when on a local network. To enable this set NSAllowsLocalNetworking to YES under NSAppTransportSecurity. This will scope the security exception to only run on localhost domains as outlined in Apple Developer documentation for NSAllowsLocalNetworking."
      },
      {
        "heading": "Android config",
        "depth": 2,
        "text": "When running against the local mock server with Android it is recommended to use additional Build Variants, such as a Debug and Release, to enable cleartext traffic only if the app is running on your local network. This will help ensure that you do not allow unsecured HTTP traffic in your Release Build Variant."
      },
      {
        "heading": "Android config",
        "depth": 2,
        "text": "For example, in your Android Studio project create /src/debug/AndroidManifest.xml and in this file create a network configuration file reference android:networkSecurityConfig=\"@xml/network_security_config\":"
      },
      {
        "heading": "Android config",
        "depth": 2,
        "text": "Then create the network configuration file /src/debug/res/xml/network_security_config.xml and restrict to only run on your localhost IP range:"
      },
      {
        "heading": "Android config",
        "depth": 2,
        "text": "Then use a Build Variant and run the Debug build and only test this setting with your local mock server. To learn more about this please see the official Android documentation."
      },
      {
        "heading": "Android config",
        "depth": 2,
        "text": "Alternatively, if you are running a non-production application and do not want to use multiple Build Variants, you can set android:usesClearTextTraffic=\"true\" in your AndroidManifest.xml as in the code snippet below. This is not a recommended practice. Ensure you remove this once mocking is complete."
      },
      {
        "heading": "GraphQL Local Console",
        "depth": 2,
        "text": "To start testing, before starting your JavaScript/Android/iOS application run the following command:"
      },
      {
        "heading": "GraphQL Local Console",
        "depth": 2,
        "text": "Alternatively, you can run amplify mock api to only mock the API category. When prompted, ensure you select YES to automatically generate queries, mutations, and subscriptions if you are building a client application."
      },
      {
        "heading": "GraphQL Local Console",
        "depth": 2,
        "text": "Once the server starts it will print a URL. Open this URL in your browser (it should be http://localhost:20002) and the OneGraph GraphQL console will open up in your browser. You can use the explorer on the left to build out a query/mutation or manually type your statements in the main window. Amplify mocking will use DynamoDB Local to persist the records on your system. If you wish, you can view these in Visual Studio code with SQLite Explorer. Follow the instructions in that repo for connecting to local databases."
      },
      {
        "heading": "GraphQL Local Console",
        "depth": 2,
        "text": "When your API is configured to use Cognito User Pools, the local console provides a way to change Username, Groups, and email of the bundled JWT token. These values are used by GraphQL transformers Auth directive. Edit them by clicking Auth and saving your changes, then run operations in the console to test your rules."
      },
      {
        "heading": "GraphQL Resolver Debugging",
        "depth": 2,
        "text": "You can edit VTL templates locally to see if they contain errors, including the line numbers causing problems, before pushing to AppSync. With the local API running navigate to amplify/backend/api/APINAME/resolvers where APINAME is the logical name that you used when running $amplify add api. You will see a list of resolver templates that the Transformer generated. Modify any of them and save, and they will be immediately loaded into the locally running API service with a message Mapping template change detected. Reloading.. If there is an error you will see something such as the following:"
      },
      {
        "heading": "GraphQL Resolver Debugging",
        "depth": 2,
        "text": "If you stop the server locally, for instance to push your changes to the cloud, all of the templates in the ../APINAME/resolvers directory will be removed except for any that you modified. When you subsequently push to the cloud these local changes will be merged with your AppSync API."
      },
      {
        "heading": "Modify schema and test again",
        "depth": 3,
        "text": "As you are developing your app, you can always modify the GraphQL schema which lives in amplify/backend/api/APINAME/schema.graphql. You can modify any types using any of the supported directives and save this file, while the local server is still running. The changes will be detected and if your schema is valid they will be hot reloaded into the local API. If there is an error in the schema an error will be printed to the terminal like so:"
      },
      {
        "heading": "Modify schema and test again",
        "depth": 3,
        "text": "Amplify libraries when configured for these categories can use the local mocked endpoints for testing your application. When a mock endpoint is running the CLI will update your aws-exports.js or awsconfiguration.json to use the mock server and once stopped they will be updated to use the cloud endpoint once you have run an amplify push."
      }
    ],
    "source": "export const meta = {\n  title: `Mocking and testing`,\n  description: `Learn how to quickly test and debug without pushing all changes in your Amplify project to the cloud. Use local mocking and testing for certain categories including API (AWS AppSync), Storage (Amazon DynamoDB and Amazon S3), and Functions (AWS Lambda).`,\n};\n\n  \n\nIt is highly recommended that you complete the Getting Started section of Amplify setup before using local mocking.\n\n<InternalLinkButton href=\"/start\">\n  <span slot=\"text\">🚀 Get Started</span>\n</InternalLinkButton>\n\nIn order to quickly test and debug without pushing all changes in your project to the cloud, Amplify supports *Local Mocking and Testing* for certain categories including API (AWS AppSync), Storage (Amazon DynamoDB and Amazon S3), and Functions (AWS Lambda). This includes using directives from the GraphQL Transformer, editing & debug resolvers, hot reloading, JWT mocking of authorization checks, and even performing S3 operations such as uploading and downloading content.\n\n<Callout>\nJava is required on your development workstation to use Local Mocking in Amplify\n</Callout>\n\n> **NOTE:** Currently, on Apple Silicon Macs, Amplify sometimes fails to start mocks when using certain JDK versions built for ARM processors. \n>\n> If you encounter [this issue](https://github.com/aws-amplify/amplify-cli/issues/7411), please try using the official openJDK 16.0.1 from the Java website: [JDK Download](https://jdk.java.net/16/)\n\n[Blog walk-through with sample app](https://aws.amazon.com/blogs/mobile/amplify-framework-local-mocking/).\n\n## API mocking setup\n\nAfter running `amplify init` you can immediately add a GraphQL API and begin mocking without first pushing to the cloud. REST APIs are not yet supported. For example:\n\n```bash\namplify init\namplify add api # Select GraphQL, use API key\namplify mock api\n```\n\nWhen you run `amplify mock api` the codegen process will run and create any required GraphQL assets such as queries, mutations, and subscriptions as well as TypeScript or Swift classes for your app. Android requires a build step for Gradle to create required classes after the codegen process completes, as well as an extra [configuration in your AndroidManifest.xml](#android-config).\n\nIf you do not wish to test your app locally, you can still use the [local GraphQL console](#graphql-local-console) as well as [edit, debug, and test your VTL resolvers](#graphql-resolver-debugging) locally against the mock endpoint.\n\nWhen adding a schema use an API Key at first to ensure everything works, though you can authenticate against a Cognito User Pool and the local testing server will honor the JWT tokens. You can also mock the JWT tokens in the local console (outlined below), however in that case you will need to do an `amplify push` first to create the User Pool.\n\nWhen defining a schema you can use directives from the GraphQL Transformer in local testing as well as local code generation from the schema for types. The following directives are currently supported in local testing:\n\n- [@auth](/cli/graphql/authorization-rules)\n- [@primaryKey, @index](/cli/graphql/data-modeling)\n- [@hasOne, @hasMany, @belongsTo, @manyToMany](/cli/graphql/data-modeling)\n- [@function](/cli/graphql/custom-business-logic#lambda-function-resolver)\n\nIf you have DynamoDB Lambda triggers set up on `@model` types in your GraphQL schema, by following steps [listed here](/cli/usage/lambda-triggers/#as-a-part-of-the-graphql-api-types-with-model-annotation),\nthen you can test those Lambda triggers locally via `amplify mock` or `amplify mock api`. \n\nThe connected Lambda triggers are automatically invoked locally if you perform a CRUD operation on the `@model` type using either the local DynamoDB endpoint (`http://localhost:62224`) or \nthe local AppSync console (should be `http://localhost:20002`). The structure of the event that is sent to the lambda trigger can be found [here](https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_streams_GetRecords.html).\n\nThe environment variables that are listed below in [Function mock environment variables](/cli/usage/mock/#function-mock-environment-variables), are available for each invocation of the Lambda trigger.\n\nIn addition, you can use a `.env` file within the function directory (ie. `<project root>/amplify/backend/function/<function name>/.env`) to override any environment variables for local mocking.\n\n\n> __Note__: IAM authorization rules in Mock get are treated as Auth role if the request is signed with AccessKey `ASIAVJKIAM-AuthRole`. Otherwise the request is treated as made by an unAuth user.\n\n> __Note__: that `@searchable` is not supported at this time.\n\n## Storage mocking setup\n\nFor S3 storage mocking, after running `amplify init` you must first run through `amplify add auth`, either explicitly or implicitly if adding storage first, and then run an `amplify push`. This is because mocking storage in client libraries requires credentials for initial setup. Note however that S3 authorization rules, such as those placed on a bucket policy, are not checked by local mocking at this time.\n\nOnce you have done an initial push you can run the mock server and hit the local endpoint:\n\n```bash\namplify init\namplify add storage # This will prompt you to add auth\namplify push\namplify mock storage\n```\n\nTo use an iOS application with the local S3 endpoint you will need to [modify your Info.plist file](#ios-config). To use an Android application with the local S3 endpoint you will need an extra [configuration in your AndroidManifest.xml](#android-config).\n\nFor DynamoDB storage, setup is automatically done when creating a GraphQL API with no action is needed on your part. Resources for the mocked data, such as the DynamoDB Local database or objects uploaded using the local S3 endpoint, inside your project under `amplify/mock-data`.\n\n## Function mocking setup\n\nAfter adding a function to your project with `amplify add function` you can test it using `amplify mock function`.\n\n`amplify mock function` supports the following arguments:\n\n- `<function name>` - The name of the function to mock. Must immediately follow `amplify mock function`, eg. `amplify mock function myFunctionName`\n- `--event \"<path to event JSON file>\"` - Use the specified JSON file as the event to pass to the Lambda handler\n- `--timeout <number of seconds>` - Override the default 10 second function response timeout with a custom timeout value\n\n### Function mocking with GraphQL\n\nA GraphQL Lambda resolver connected to your schema using [@function](/cli/graphql/custom-business-logic#lambda-function-resolver) can be mocked using [`amplify mock api`](#api-mocking-setup).\nFor example, if you have a function named **quoteOfTheDay** and a schema like:\n\n```graphql\ntype Query {\n  getQuote: String @function(name: \"quoteOfTheDay-${env}\")\n}\n```\n\nThen when running `amplify mock api`, the local GraphQL endpoint will invoke this function locally when running a GraphQL query such as:\n\n```graphql\nquery {\n  getQuote\n}\n```\n\n### Function mock environment variables\n\n`amplify mock function`populates environment variables that mimic what will be present when deployed in the cloud. Amplify parses the function's CloudFormation template and attempts to resolve any environment variables specified there (also review [function mock limitations](#function-mock-limitations)).\n\nCloudFormation parameters will be resolved by:\n\n- Resolving values specified in the `parameters.json` file for the function\n- Resolving values specified in `team-provider-info.json` within the `<env>.categories.function.<function name>` block, where `<env>` is the currently checked out environment and `<function name>` is the function being mocked\n- `AWS::Region`, `AWS::AccountID`, `AWS::StackName`, and `AWS::StackId` are resolved by parsing the `awscloudformation` configuration of the current environment in `team-provider-info.json`\n- Parameters constructed from dependencies on other resources in the project are resolved by parsing `amplify-meta.json`. Additionally, if a mock API is currently running and the function depends on the API, the local API URL will replace the cloud URL\n\nThe mock environment will also populate [lambda runtime environment variables](https://docs.aws.amazon.com/lambda/latest/dg/configuration-envvars.html#configuration-envvars-runtime) in the following way:\n\n- `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, and `AWS_SESSION_TOKEN` will be populated using the AWS credentials that the Amplify project is currently configured to use\n- `_HANDLER`, `AWS_REGION`, `AWS_LAMBDA_FUNCTION_NAME`, `LAMBDA_TASK_ROOT`, and `LAMBDA_RUNTIME_DIR` will be set based on the function being mocked\n- Static defaults will be specified for all other runtime environment variables. The full list of static defaults can be found [here](https://github.com/aws-amplify/amplify-cli/blob/main/packages/amplify-util-mock/src/utils/lambda/populate-lambda-mock-env-vars.ts#L39)\n\nYou can also override any mock environment variables in a `.env` file within the function directory (ie. `<project root>/amplify/backend/function/<function name>/.env`).\n\n### Connecting to a mock `@model` table\n\nConnect a mock function that operates on a table generated by `@model` to the mock table when running `amplify mock api` by:\n\n1. Create a `.env` file in the function directory with the following:\n\n```ini\nAWS_REGION=us-fake-1\nDDB_ENDPOINT=http://localhost:62224\nAWS_ACCESS_KEY_ID=fake\nAWS_SECRET_ACCESS_KEY=fake\nAPI_<api name>_<model>TABLE_NAME=<model>Table\n```\n\nReplace `<api name>` with the name of your API and `<model>` with the name of your model. The environment variable name should be all capitalized. For example, if you have an API named \"FlightStats\" and a model defined as `type Airplane @model {...}`, then then last line of the `.env` file should be:\n\n```ini\nAPI_FLIGHTSTATS_AIRPLANETABLE_NAME=AirplaneTable\n```\n\n2. Configure the DynamoDB client in your function as follows:\n\n```js\nconst ddb = new aws.DynamoDB.DocumentClient({\n  endpoint: process.env.DDB_ENDPOINT,\n});\nconst result = await ddb.put({\n  TableName: process.env.API_FLIGHTSTATS_AIRPLANETABLE_NAME,\n  Item: {\n    id: '1234567890',\n    name: 'F-22',\n    description: 'Cool fighter jet',\n  },\n}).promise();\n```\n\n3. Run `amplify mock api` to activate the local DynamoDB endpoint\n4. Run `amplify mock function` which will now connect to the mock DynamoDB table\n\nWhen running in the cloud, these environment variables will have valid values except `DDB_ENDPOINT` which will be `undefined`. In this case the DynamoDB client will use the default endpoint.\n\nWhen running locally, these environment variables will be populated using the local .env file which specifies the fake values required to connect to the local database.\n\n**Note:** While connected to the mock database, calls to other AWS resources within the mock function will not work because the AWS credential environment variables have been overwritten with fake credentials. To call a mock table as well as other AWS services, add logic to switch between the fake credentials and the real ones in the DynamoDB client configuration. In this case, you could configure your `.env` file with:\n\n```ini\nIS_MOCK=true\n```\n\nAnd configure the DynamoDB client with:\n\n```js\nconst clientConfig = process.env.IS_MOCK ? {\n  region: 'us-fake-1',\n  endpoint: 'http://localhost:62224',\n  credentials: new aws.Credentials({\n    accessKeyId: 'fake',\n    secretAccessKey: 'fake',\n  }),\n} : undefined;\nconst ddb = new aws.DynamoDB.DocumentClient(clientConfig);\n```\n\n### Function mock limitations\n\n`amplify mock function` does not attempt to fully simulate the Lambda runtime environment. There may be some cases where the behavior of your function when mocking differs from executing in the cloud.\n\nFor example, mock runs on your local OS and does not attempt to emulate Amazon Linux which executes your function in the cloud. Testing with `amplify mock function` should be used to get quick feedback on the correctness of your function but should not be used as a substitute for testing in a cloud development environment.\n\n## Config files\n\nWhen performing operations against the local mock endpoint, the Amplify CLI will automatically update your `aws-exports.js` and `awsconfiguration.json` with the local endpoints, fake values where necessary (e.g. fake API key), and disable SSL with an explicit value (`DangerouslyConnectToHTTPEndpointForTesting`) to indicate the functionality is only for local mocking and testing. This happens automatically when you run `amplify mock` and the server is running. Once you stop the mock server the config files are updated with the correct cloud endpoints for your project and `DangerouslyConnectToHTTPEndpointForTesting` is removed from the config file.\n\n### aws-exports.js example\n\n```js\nconst awsmobile = {\n  \"aws_project_region\": \"us-east-1\",\n  \"aws_appsync_graphqlEndpoint\": \"http://localhost:20002/graphql\",\n  \"aws_appsync_region\": \"us-east-1\",\n  \"aws_appsync_authenticationType\": \"AMAZON_COGNITO_USER_POOLS\",\n  \"aws_appsync_apiKey\": \"da2-fakeApiId123456\",\n  \"aws_appsync_dangerously_connect_to_http_endpoint_for_testing\": true,\n  \"aws_cognito_identity_pool_id\": \"us-east-1:270445b2-cc92-4d46-a937-e41e49bdb892\",\n  \"aws_cognito_region\": \"us-east-1\",\n  \"aws_user_pools_id\": \"us-east-1_excPT39ZN\",\n  \"aws_user_pools_web_client_id\": \"4a950rsq08d2gi68ogdt7sjqub\",\n  \"oauth\": {},\n  \"aws_user_files_s3_bucket\": \"local-testing-app-2fbf0a32d1896419b88f004c2755d084c-dev\",\n  \"aws_user_files_s3_bucket_region\": \"us-east-1\",\n  \"aws_user_files_s3_dangerously_connect_to_http_endpoint_for_testing\": true\n};\n```\n\n### awsconfiguration.json example\n\n```json\n\"AppSync\": {\n  \"Default\": {\n    \"ApiUrl\": \"http://localhost:20002/graphql\",\n    \"Region\": \"us-east-1\",\n    \"AuthMode\": \"AMAZON_COGNITO_USER_POOLS\",\n    \"ClientDatabasePrefix\": \"deddd_AMAZON_COGNITO_USER_POOLS\",\n    \"DangerouslyConnectToHTTPEndpointForTesting\": true\n  }\n},\n\"S3TransferUtility\": {\n  \"Default\": {\n    \"Bucket\": \"local-testing-app-2fbf0a32d1896419b88f004c2755d084c-dev\",\n    \"Region\": \"us-east-1\",\n    \"DangerouslyConnectToHTTPEndpointForTesting\": true\n  }\n}\n```\n\n## iOS config\n\nWhen running against the local mock S3 server with iOS you must update your `Info.plist` to not require SSL when on a local network. To enable this set `NSAllowsLocalNetworking` to `YES` under `NSAppTransportSecurity`. This will scope the security exception to only run on localhost domains as outlined in [Apple Developer documentation for NSAllowsLocalNetworking](https://developer.apple.com/documentation/bundleresources/information_property_list/nsapptransportsecurity/nsallowslocalnetworking).\n\n## Android config\n\nWhen running against the local mock server with Android **it is recommended to use additional Build Variants**, such as a Debug and Release, to enable cleartext traffic only if the app is running on your local network. This will help ensure that you do not allow unsecured HTTP traffic in your Release Build Variant.\n\nFor example, in your Android Studio project create `/src/debug/AndroidManifest.xml` and in this file create a network configuration file reference `android:networkSecurityConfig=\"@xml/network_security_config\"`:\n\n```xml\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<manifest xmlns:android=\"http://schemas.android.com/apk/res/android\">\n  <application android:networkSecurityConfig=\"@xml/network_security_config\" />\n</manifest>\n```\n\nThen create the network configuration file `/src/debug/res/xml/network_security_config.xml` and restrict to only run on your localhost IP range:\n\n```xml\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<network-security-config>\n  <domain-config cleartextTrafficPermitted=\"true\">\n    <domain includeSubdomains=\"true\">10.0.2.2</domain>\n  </domain-config>\n</network-security-config>\n```\n\nThen use a [Build Variant](https://developer.android.com/studio/build/build-variants) and run the Debug build and only test this setting with your local mock server. To learn more about this please see the [official Android documentation](https://developer.android.com/studio/build/manifest-merge).\n\nAlternatively, if you are running a non-production application and do not want to use multiple Build Variants, you can set `android:usesClearTextTraffic=\"true\"` in your **AndroidManifest.xml** as in the code snippet below. **This is not a recommended practice. Ensure you remove this once mocking is complete**.\n\n```xml\n<application\n  android:icon=\"@mipmap/ic_launcher\"\n  android:label=\"@string/app_name\"\n  android:theme=\"@style/AppTheme\"\n  android:usesClearTextTraffic=\"true\" >\n\n  <!--other code-->\n</application>\n```\n\n## GraphQL Local Console\n\nTo start testing, before starting your JavaScript/Android/iOS application run the following command:\n\n```bash\namplify mock\n```\n\nAlternatively, you can run `amplify mock api` to only mock the API category. When prompted, ensure you select **YES** to automatically generate queries, mutations, and subscriptions if you are building a client application.\n\nOnce the server starts it will print a URL. Open this URL in your browser (it should be `http://localhost:20002`) and the [OneGraph](https://github.com/OneGraph/graphiql-explorer) GraphQL console will open up in your browser. You can use the explorer on the left to build out a query/mutation or manually type your statements in the main window. Amplify mocking will use DynamoDB Local to persist the records on your system. If you wish, you can view these in Visual Studio code with [SQLite Explorer](https://github.com/AlexCovizzi/vscode-sqlite). Follow the instructions in that repo for connecting to local databases.\n\nWhen your API is configured to use Cognito User Pools, the local console provides a way to change `Username`, `Groups`, and `email` of the bundled JWT token. These values are used by GraphQL transformers Auth directive. Edit them by clicking **Auth** and saving your changes, then run operations in the console to test your rules.\n\n## GraphQL Resolver Debugging\n\nYou can edit VTL templates locally to see if they contain errors, including the line numbers causing problems, before pushing to AppSync. With the local API running navigate to `amplify/backend/api/APINAME/resolvers` where `APINAME` is the logical name that you used when running `$amplify add api`. You will see a list of resolver templates that the Transformer generated. Modify any of them and save, and they will be immediately loaded into the locally running API service with a message `Mapping template change detected. Reloading.`. If there is an error you will see something such as the following:\n\n```console\nReloading failed Error: Parse error on line 1:\n...son($context.result\n----------------------^\n```\n\nIf you stop the server locally, for instance to push your changes to the cloud, all of the templates in the `../APINAME/resolvers` directory will be removed except for any that you modified. When you subsequently push to the cloud these local changes will be merged with your AppSync API.\n\n### Modify schema and test again\n\nAs you are developing your app, you can always modify the GraphQL schema which lives in `amplify/backend/api/APINAME/schema.graphql`. You can modify any types using any of the supported directives and save this file, while the local server is still running. The changes will be detected and if your schema is valid they will be hot reloaded into the local API. If there is an error in the schema an error will be printed to the terminal like so:\n\n```console\nUnknown directive \"mode\".\n\nGraphQL request (1:11)\n1: type Todo @mode{\n             ^\n2:   id: ID!\n\n    at GraphQLTransform.transform\n```\n\nAmplify libraries when configured for these categories can use the local mocked endpoints for testing your application. When a mock endpoint is running the CLI will update your `aws-exports.js` or `awsconfiguration.json` to use the mock server and once stopped they will be updated to use the cloud endpoint once you have run an `amplify push`.\n",
    "meta": {
      "title": "Mocking and testing",
      "description": "Learn how to quickly test and debug without pushing all changes in your Amplify project to the cloud. Use local mocking and testing for certain categories including API (AWS AppSync), Storage (Amazon DynamoDB and Amazon S3), and Functions (AWS Lambda).",
      "subcategory": "Advanced workflows",
      "category": "Amplify CLI"
    },
    "filename": "/cli/usage/mock"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Lambda triggers are useful for adding functionality during certain lifecycles of the user's journey. Amplify ships common trigger templates which you can enable and modify (if necessary) through a few simple questions."
      },
      {
        "heading": "Cognito Lambda Triggers",
        "depth": 2,
        "text": "Certain AWS Services can invoke Lambda functions in response to lifecycle events. The Amplify CLI provides trigger templates for common use cases."
      },
      {
        "heading": "Cognito Lambda Triggers",
        "depth": 2,
        "text": "If you wish to modify the functionality of these templates, you are able to do so locally before pushing them.  After selecting the templates via the CLI, your local copy of the templates are located in amplify/backend/function/<function-name>/src."
      },
      {
        "heading": "Cognito Lambda Triggers",
        "depth": 2,
        "text": "Amazon Cognito allows you to set up one Lambda trigger per event.  In order to create additional flexibility when configuring Cognito triggers via the CLI, the CLI will create an index file which loops through JavaScript modules.  Each template that you configure is its own JavaScript module. This allows you to attach multiple use cases and logical flows to a single lifecycle event."
      },
      {
        "heading": "Cognito Lambda Triggers",
        "depth": 2,
        "text": "You have the opportunity to edit both the index file as well as each module. For example, when creating a email deny list PreSignUp trigger, you will be asked"
      },
      {
        "heading": "Cognito Lambda Triggers",
        "depth": 2,
        "text": "Selecting 'yes' will open the index file in your editor."
      },
      {
        "heading": "Cognito Lambda Triggers",
        "depth": 2,
        "text": "You will then be asked if you want to edit the individual JavaScript module for the email deny list functionality:"
      },
      {
        "heading": "Set up Lambda triggers",
        "depth": 3,
        "text": "There are two ways to setup Lambda Triggers for your Cognito User Pool."
      },
      {
        "heading": "Set up Lambda triggers",
        "depth": 3,
        "text": "In the default Auth CLI workflow, you will be presented with a list of Lambda Trigger templates if you opt to configure advanced settings:"
      },
      {
        "heading": "Set up Lambda triggers",
        "depth": 3,
        "text": "In the manual Auth CLI workflow, you will be given the chance to select the options above, but will also be able to manually configure Lambda Trigger templates:"
      },
      {
        "heading": "Set up Lambda triggers",
        "depth": 3,
        "text": "If your manually-configured Lambda Triggers require enhanced permissions, you can run amplify function update after they have been initially configured."
      },
      {
        "heading": "Auth Templates",
        "depth": 3,
        "text": "The CLI Auth workflow provides the following Lambda trigger templates:"
      },
      {
        "heading": "Custom Auth Challenge with Google reCaptcha",
        "depth": 3,
        "text": "Captchas allow front end applications to guard against bots or other unwanted page interactions by presenting a challenge that is designed to require human intervention. The Google reCaptcha service is a popular implementation of captcha."
      },
      {
        "heading": "Custom Auth Challenge with Google reCaptcha",
        "depth": 3,
        "text": "This template will configure three triggers: CreateAuthChallenge, DefineAuthChallenge, and VerifyAuthChallengeResponse."
      },
      {
        "heading": "Custom Auth Challenge with Google reCaptcha",
        "depth": 3,
        "text": "The first two will essentially allow the standard username/password flow to execute unimpeded, while VerifyAuthChallengeResponse will run when the Auth.sendCustomChallenge function is called with the data that is returned when the user interacts with the Google reCaptcha component.  The VerifyAuthChallengeResponse Lambda function will subsequently execute a POST request to Google, and will pass the success or failure of the reCaptcha interaction back to Cognito."
      },
      {
        "heading": "React Sample",
        "depth": 4,
        "text": "The following code sample demonstrates how to create a custom ConfirmSignIn component in React using the react-google-recaptcha npm package."
      },
      {
        "heading": "Angular Sample",
        "depth": 4,
        "text": "The following code sample demonstrates how to create a custom ConfirmSignIn component in Angular using the ng-recaptcha npm package."
      },
      {
        "heading": "Angular Sample",
        "depth": 4,
        "text": "Be sure to follow all instructions for setting up an Angular application with aws-amplify-angular, and configure your Amplify instance to use the CUSTOM_AUTH flow."
      },
      {
        "heading": "Angular Sample",
        "depth": 4,
        "text": "app.module.ts:"
      },
      {
        "heading": "Angular Sample",
        "depth": 4,
        "text": "app.component.ts:"
      },
      {
        "heading": "Angular Sample",
        "depth": 4,
        "text": "app.component.html"
      },
      {
        "heading": "Vue Sample",
        "depth": 4,
        "text": "The following code sample demonstrates how to create a custom ConfirmSignIn component in Vue using the vue-recaptcha npm package."
      },
      {
        "heading": "Vue Sample",
        "depth": 4,
        "text": "App.vue"
      },
      {
        "heading": "Vue Sample",
        "depth": 4,
        "text": "main.js"
      },
      {
        "heading": "Vue Sample",
        "depth": 4,
        "text": "Finally, in public/index.html add the following script:"
      },
      {
        "heading": "Basic Scaffolding for a Custom Auth Challenge",
        "depth": 3,
        "text": "This template will configure three triggers: CreateAuthChallenge, DefineAuthChallenge, and VerifyAuthChallengeResponse."
      },
      {
        "heading": "Basic Scaffolding for a Custom Auth Challenge",
        "depth": 3,
        "text": "It will not, however, provide a fully-formed custom authentication flow. Instead, it will create a 'hello world' custom auth flow skeleton that you can manually edit. The intent of this template is to give you a starting place for building out your own custom auth flow."
      },
      {
        "heading": "Email Verification Link with Redirect",
        "depth": 3,
        "text": "Cognito allows you to configure your User Pool to send an email to your users when they attempt to register an account. You can configure this email to contain a link to Cognito's Hosted UI where the user's account will be marked as confirmed."
      },
      {
        "heading": "Email Verification Link with Redirect",
        "depth": 3,
        "text": "This trigger template allows you to define an email message with a link to a static S3 bucket that you control, where the user's account will be confirmed and they can then be redirected to a URL of your choice (presumably your application). The URL will automatically contain the username as a query string parameters."
      },
      {
        "heading": "Email Verification Link with Redirect",
        "depth": 3,
        "text": "Please note that this trigger template will create an S3 resource.  The files that populate the static site are available for edit in amplify/backend/auth/<your-resource-name>CustomMessage/assets.  They consist of:"
      },
      {
        "heading": "Email Verification Link with Redirect",
        "depth": 3,
        "text": "index.html"
      },
      {
        "heading": "Email Verification Link with Redirect",
        "depth": 3,
        "text": "spinner.js (controls the spinner that appears on the page while users are awaiting confirmation)"
      },
      {
        "heading": "Email Verification Link with Redirect",
        "depth": 3,
        "text": "style.css"
      },
      {
        "heading": "Email Verification Link with Redirect",
        "depth": 3,
        "text": "verify.js (the script which performs the verification request)"
      },
      {
        "heading": "React Sample",
        "depth": 4,
        "text": "The following is an example of how to configure the aws-amplify-react authenticator so that it displays a message telling the user to check their email, instead of showing the default 'ConfirmSignUp' component."
      },
      {
        "heading": "Angular Sample",
        "depth": 4,
        "text": "The following is an example of how to configure the aws-amplify-angular authenticator so that it displays a message telling the user to check their email, instead of showing the default 'ConfirmSignUp' component."
      },
      {
        "heading": "Angular Sample",
        "depth": 4,
        "text": "Be sure to follow all instructions for setting up an Angular application with aws-amplify-angular."
      },
      {
        "heading": "Angular Sample",
        "depth": 4,
        "text": "app.component.ts:"
      },
      {
        "heading": "Angular Sample",
        "depth": 4,
        "text": "app.component.html:"
      },
      {
        "heading": "Vue Sample",
        "depth": 4,
        "text": "The following is an example of how to configure the aws-amplify-vue authenticator components so that your app displays a message telling the user to check their email, instead of showing the default 'ConfirmSignUp' component."
      },
      {
        "heading": "Add User to Group",
        "depth": 3,
        "text": "This trigger allows you to define a Cognito group to which a user will be added upon registration."
      },
      {
        "heading": "Add User to Group",
        "depth": 3,
        "text": "The trigger will check for the existence of the group in your User Pool, and will create the group if it is not present."
      },
      {
        "heading": "Email Domain Filtering (deny list) and Email Domain Filtering (allow list)",
        "depth": 3,
        "text": "These two templates allow you to define email domains which are allowed or disallowed (respectively). They can be used in tandem or individually."
      },
      {
        "heading": "Override ID Token Claims",
        "depth": 3,
        "text": "This template uses the Pre Token Generation trigger and allows you to add, override or remove claims from the ID token that is returned by Cognito."
      },
      {
        "heading": "Override ID Token Claims",
        "depth": 3,
        "text": "You will need to manually edit the template to define the claims that you wish to manipulate. The template currently contains dummy values as examples."
      },
      {
        "heading": "S3 Lambda Triggers",
        "depth": 2,
        "text": "You can associate a trigger to an S3 bucket managed by the Amplify CLI, by following the amplify add/update storage flows. When attempting to add/update an S3 storage resource, you would get the following CLI prompts to add a trigger for it."
      },
      {
        "heading": "S3 Lambda Triggers",
        "depth": 2,
        "text": "As you can see in the prompt above, you can either choose to use an existing Lambda function created using the CLI as a part of this project using amplify add function or create a new function with a base Lambda function to handle S3 events. We also auto-populate the IAM policies required by the Lambda execution role of the newly created function to access the S3 bucket."
      },
      {
        "heading": "S3 Lambda Triggers",
        "depth": 2,
        "text": "Note: You can associate only one Lambda Function trigger to an S3 bucket."
      },
      {
        "heading": "DynamoDB Lambda Triggers",
        "depth": 2,
        "text": "You can associate a Lambda trigger with a DynamoDB table, managed by the Amplify CLI. There are two ways by which DynamoDB is provisioned by the Amplify CLI"
      },
      {
        "heading": "DynamoDB Lambda Triggers",
        "depth": 2,
        "text": "As a part of the Storage category"
      },
      {
        "heading": "DynamoDB Lambda Triggers",
        "depth": 2,
        "text": "As a part of the GraphQL API (types with @model annotation)"
      },
      {
        "heading": "As a part of the Storage category",
        "depth": 3,
        "text": "You can add and manage a DynamoDB table to your Amplify project using the amplify add/update storage flows. When attempting to add/update a DynamoDB storage resource, you would get the following CLI prompts to add a trigger for it."
      },
      {
        "heading": "As a part of the Storage category",
        "depth": 3,
        "text": "As you can see in the prompt above, you can either choose to use an already existing Lambda function created using the CLI as a part of this project using amplify add function or create a new function with a base Lambda function handle DynamoDB events."
      },
      {
        "heading": "As a part of the Storage category",
        "depth": 3,
        "text": "Note: You can associate more than one Lambda Function trigger to a DynamoDB table."
      },
      {
        "heading": "As a part of the GraphQL API (types with @model annotation)",
        "depth": 3,
        "text": "You can also associate a Lambda trigger with any of the GraphQL transformer schema's DynamoDB backed @models which you can add via amplify add api. GraphQL mutations that result in DynamoDB item changes will in turn result in change records published to DynamoDB streams that can trigger a Lambda function. To create such a function, start with adding a new lambda function with:"
      },
      {
        "heading": "As a part of the GraphQL API (types with @model annotation)",
        "depth": 3,
        "text": "Proceed by providing a name and selecting a Lambda Trigger template:"
      },
      {
        "heading": "As a part of the GraphQL API (types with @model annotation)",
        "depth": 3,
        "text": "Then select Amazon DynamoDB Stream when prompted with event source question."
      },
      {
        "heading": "As a part of the GraphQL API (types with @model annotation)",
        "depth": 3,
        "text": "Now select API category graphql @model backed DynamoDB table."
      },
      {
        "heading": "As a part of the GraphQL API (types with @model annotation)",
        "depth": 3,
        "text": "After the above question, you can select one of the types annotated by @model for which you want to add a trigger for."
      },
      {
        "heading": "As a part of the GraphQL API (types with @model annotation)",
        "depth": 3,
        "text": "On completion of the above mentioned flow, a boilerplate lambda function trigger will be created in your amplify/backend/function directory with the following template:"
      },
      {
        "heading": "As a part of the GraphQL API (types with @model annotation)",
        "depth": 3,
        "text": "record.dynamodb will contain a DynamoDB change json describing the item changed in DynamoDB table.\nPlease note that it does not represent an original and new item as stored in DynamoDB table. To retrieve a original and new item you need to convert a DynamoDB json to original form:"
      },
      {
        "heading": "Kinesis Stream Trigger",
        "depth": 2,
        "text": "Amplify Analytics category Kinesis stream resource can be also used as an event source for Lambda triggers. Event published to Kinesis stream will trigger a lambda function. You can add a Kinesis stream to your Amplify project by going through the amplify add analytics flow. To create a Lambda trigger for the Kinesis Stream, start with adding a new lambda function:"
      },
      {
        "heading": "Kinesis Stream Trigger",
        "depth": 2,
        "text": "Proceed by providing a name and selecting a Lambda Trigger template:"
      },
      {
        "heading": "Kinesis Stream Trigger",
        "depth": 2,
        "text": "Then select Amazon Kinesis Stream when prompted with event source question and select the resource."
      },
      {
        "heading": "Kinesis Stream Trigger",
        "depth": 2,
        "text": "After the completion of the above flow, a Lambda function will be created in your amplify/backend/function directory and will be invoked when a new event is pushed to a Kinesis stream. Please refer to Working with the API to learn more about publishing your events to Kinesis stream."
      }
    ],
    "source": "export const meta = {\n  title: `Lambda Triggers`,\n  description: `Lambda triggers are useful for adding functionality during certain lifecycles of the user's journey. Associate a Lambda trigger with an auth scenario, S3 bucket, DynamoDB table or Kinesis Stream managed through the Amplify CLI.`,\n};\n\nLambda triggers are useful for adding functionality during certain lifecycles of the user's journey. Amplify ships common trigger templates which you can enable and modify (if necessary) through a few simple questions.\n\n## Cognito Lambda Triggers\n\nCertain AWS Services can [invoke Lambda functions](https://docs.aws.amazon.com/lambda/latest/dg/lambda-services.html) in response to lifecycle events. The Amplify CLI provides trigger templates for common use cases.\n\nIf you wish to modify the functionality of these templates, you are able to do so locally before pushing them.  After selecting the templates via the CLI, your local copy of the templates are located in `amplify/backend/function/<function-name>/src`.\n\nAmazon Cognito allows you to set up one Lambda trigger per event.  In order to create additional flexibility when configuring Cognito triggers via the CLI, the CLI will create an index file which loops through JavaScript modules.  Each template that you configure is its own JavaScript module. This allows you to attach multiple use cases and logical flows to a single lifecycle event.\n\nYou have the opportunity to edit both the index file as well as each module. For example, when creating a email deny list [PreSignUp](https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-lambda-pre-sign-up.html) trigger, you will be asked\n\n```console\n$ Do you want to edit the local PreSignUp lambda function now? (Y/n)\n```\n\nSelecting 'yes' will open the index file in your editor.\n\nYou will then be asked if you want to edit the individual JavaScript module for the email deny list functionality:\n\n```console\n$ Do you want to edit your email-filter-deny-list function now?\n```\n\n### Set up Lambda triggers\n\nThere are two ways to setup Lambda Triggers for your Cognito User Pool.\n\n1. In the default Auth CLI workflow, you will be presented with a list of Lambda Trigger templates if you opt to configure advanced settings:\n\n```console\n$ Do you want to enable any of the following capabilities?\n  ❯ ◯ Add Google reCaptcha Challenge\n    ◯ Email Verification Link with Redirect\n    ◯ Add User to Group\n    ◯ Email Domain Filtering (deny list)\n    ◯ Email Domain Filtering (allow list)\n    ◯ Custom Auth Challenge Flow (basic scaffolding - not for production)\n    ◯ Override ID Token Claims\n```\n\n2. In the manual Auth CLI workflow, you will be given the chance to select the options above, but will also be able to manually configure Lambda Trigger templates:\n\n```console\n$ Do you want to configure Lambda Triggers for Cognito? Yes\n\n$ Which triggers do you want to enable for Cognito?\n◯ Learn More\n ──────────────\n ◯ Create Auth Challenge\n❯◉ Custom Message\n ◯ Define Auth Challenge\n ◯ Post Authentication\n ◯ Post Confirmation\n ◯ Pre Sign-up\n ◯ Verify Auth Challenge Response\n ◯ Pre Token Generation\n\n$ What functionality do you want to use for Custom Message\n ◯ Learn More\n ──────────────\n❯◉ Send Account Confirmation Link w/ Redirect\n ◯ Create your own module\n```\n\nIf your manually-configured Lambda Triggers require enhanced permissions, you can run `amplify function update` after they have been initially configured.\n\n### Auth Templates\n\nThe CLI Auth workflow provides the following Lambda trigger templates:\n\n### Custom Auth Challenge with Google reCaptcha\n\nCaptchas allow front end applications to guard against bots or other unwanted page interactions by presenting a challenge that is designed to require human intervention. The Google reCaptcha service is a popular implementation of captcha.  \n\nThis template will configure three triggers: [CreateAuthChallenge](https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-lambda-create-auth-challenge.html), [DefineAuthChallenge](https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-lambda-define-auth-challenge.html), and [VerifyAuthChallengeResponse](https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-lambda-verify-auth-challenge-response.html).\n\nThe first two will essentially allow the standard username/password flow to execute unimpeded, while VerifyAuthChallengeResponse will run when the `Auth.sendCustomChallenge` function is called with the data that is returned when the user interacts with the Google reCaptcha component.  The VerifyAuthChallengeResponse Lambda function will subsequently execute a POST request to Google, and will pass the success or failure of the reCaptcha interaction back to Cognito.\n\n#### React Sample\n\nThe following code sample demonstrates how to create a custom ConfirmSignIn component in React using the react-google-recaptcha npm package.\n\n```js\nimport React from 'react';\nimport './App.css';\nimport { Amplify, Auth, Hub } from 'aws-amplify';\nimport awsconfig from './aws-exports';\nimport { Authenticator, SignUp, SignIn, Greetings, ConfirmSignUp, AuthPiece } from 'aws-amplify-react';\nimport ReCAPTCHA from \"react-google-recaptcha\";\n\nAmplify.configure({\n  Auth: {\n    identityPoolId: awsconfig.aws_cognito_identity_pool_id,\n    region: awsconfig.aws_cognito_region,\n    userPoolId: awsconfig.aws_user_pools_id,\n    userPoolWebClientId: awsconfig.aws_user_pools_web_client_id,\n    authenticationFlowType: 'CUSTOM_AUTH'\n  }\n});\n\nclass MyCustomConfirmation extends AuthPiece {\n  constructor(props) {\n    super(props);\n    this.onChange = this.onChange.bind(this);\n  }\n\n  onChange(data) {\n    Auth.sendCustomChallengeAnswer(this.props.authData, data)\n    .then( (user) => {\n      console.log('user signed in!: ', user)\n      this.changeState('signedIn', user);\n    })\n\n  }\n\n  render() {\n    if (this.props.authState === 'customConfirmSignIn') {\n      return (\n        <div>\n          <ReCAPTCHA\n          sitekey=\"your-client-side-google-recaptcha-key\"\n          onChange={this.onChange}\n          />\n        </div>  \n        );\n      } else {\n        return null;\n      }\n    }\n  }\n\n  class App extends React.Component {\n    render() {\n      return (\n        <div className=\"App\">\n          <Authenticator hideDefault={true}>\n            <SignIn />\n            <SignUp />\n            <ConfirmSignUp />\n            <Greetings />\n            <MyCustomConfirmation override={'ConfirmSignIn'}/>\n            </Authenticator>\n        </div>\n      );\n    }\n  }\n\n  function MyApp() {\n    return <App />\n  }\n\n  export default MyApp;\n```\n\n#### Angular Sample\n\nThe following code sample demonstrates how to create a custom ConfirmSignIn component in Angular using the ng-recaptcha npm package.\n\n> Be sure to follow all instructions for [setting up an Angular application](/start) with aws-amplify-angular, and [configure your Amplify instance](/lib/auth/switch-auth) to use the CUSTOM_AUTH flow.\n\napp.module.ts:\n\n```js\nimport { BrowserModule } from '@angular/platform-browser';\nimport { NgModule } from '@angular/core';\nimport { AppComponent } from './app.component';\nimport { AmplifyAngularModule, AmplifyService } from 'aws-amplify-angular';\nimport { RecaptchaModule } from 'ng-recaptcha';\nimport { FormsModule } from '@angular/forms';\n\n@NgModule({\n  declarations: [\n    AppComponent\n  ],\n  imports: [\n    BrowserModule,\n    AmplifyAngularModule,\n    FormsModule,\n    RecaptchaModule,\n  ],\n  providers: [AmplifyService],\n  bootstrap: [AppComponent]\n})\nexport class AppModule { }\n```\n\napp.component.ts:\n\n```js\nimport { Component } from '@angular/core';\nimport { AmplifyService } from 'aws-amplify-angular';\nimport { Auth } from 'aws-amplify';\n@Component({\n  selector: 'app-root',\n  templateUrl: './app.component.html',\n  styleUrls: ['./app.component.scss']\n})\nexport class AppComponent {\n  title = 'cli-lambda-sample';\n  confirmSignIn: boolean;\n  myRecaptcha: boolean;\n  user: any;\n  constructor( private amplifyService: AmplifyService ) {\n    this.amplifyService.authStateChange$\n      .subscribe(authState => {\n        this.confirmSignIn = authState.state === 'customConfirmSignIn';\n        if (!authState.user) {\n          this.user = null;\n        } else {\n          this.user = authState.user;\n        }\n    });\n  }\n  submitSignIn(e) {\n    Auth.sendCustomChallengeAnswer(this.user, e)\n    .then( (user) => {\n      this.amplifyService.setAuthState({ state: 'signedIn', user });\n    });\n  }\n}\n```\n\napp.component.html\n\n```html\n<amplify-authenticator [hide]=\"['ConfirmSignIn']\"></amplify-authenticator>\n<div  *ngIf=\"confirmSignIn\">\n  <re-captcha (resolved)=\"submitSignIn($event)\" siteKey=\"your-client-side-google-recaptcha-key\"></re-captcha>\n</div>\n```\n\n#### Vue Sample\n\nThe following code sample demonstrates how to create a custom ConfirmSignIn component in Vue using the vue-recaptcha npm package.\n\nApp.vue\n\n```js\n<template>\n  <div id=\"app\">\n    <amplify-authenticator></amplify-authenticator>\n    <vue-recaptcha\n      v-if=\"customConfirmSignIn\"\n      sitekey=\"your-client-side-google-recaptcha-key\" @verify=\"onVerify\"\n    ></vue-recaptcha>\n    <amplify-sign-out\n      v-if=\"signedIn\"\n    ></amplify-sign-out>\n  </div>\n</template>\n\n<script>\nimport { components } from 'aws-amplify-vue'\nimport { AmplifyEventBus } from 'aws-amplify-vue';\nimport VueRecaptcha from 'vue-recaptcha';\n\nexport default {\n  name: 'app',\n  components: {\n    VueRecaptcha,\n    ...components\n  },\n  data() {\n    return {\n      challengeResponse: '',\n      customConfirmSignIn: false,\n      signedIn: false,\n      user: {},\n    }\n  },\n  mounted: async function () {\n    await this.$Amplify.Auth.currentAuthenticatedUser()\n      .then((user) => {\n        this.user = user;\n        this.signedIn = true;\n      })\n      .catch((e) => {\n        console.log('currentUser error', e)\n      })\n    AmplifyEventBus.$on('authState', info => {\n      this.customConfirmSignIn = info === 'customConfirmSignIn';\n      this.signedIn = info === 'signedIn';\n    });\n    AmplifyEventBus.$on('localUser', user => {\n      this.user = user;\n    });\n  },\n  methods: {\n    onVerify: function (data) {\n      this.$Amplify.Auth.sendCustomChallengeAnswer(this.user, data)\n        .then( (user) => {\n          AmplifyEventBus.$emit('authState', 'signedIn')\n          return AmplifyEventBus.$emit('localUser', user)\n        })\n        .catch(function (err) { console.log('challenge error: ', err) });\n    },           \n  }\n}\n</script>\n```\n\nmain.js\n\n```js\nimport Vue from 'vue'\nimport App from './App.vue'\nimport * as AmplifyModules from 'aws-amplify'\nimport { AmplifyPlugin } from 'aws-amplify-vue'\nimport awsconfig from './aws-exports'\n\nAmplifyModules.Amplify.configure({\n  Auth: {\n    identityPoolId: awsconfig.aws_cognito_identity_pool_id,\n    region: awsconfig.aws_cognito_region,\n    userPoolId: awsconfig.aws_user_pools_id,\n    userPoolWebClientId: awsconfig.aws_user_pools_web_client_id,\n    authenticationFlowType: 'CUSTOM_AUTH'\n  }\n});\nVue.use(AmplifyPlugin, AmplifyModules)\n\nnew Vue({\n  render: h => h(App)\n}).$mount('#app')\n```\n\nFinally, in public/index.html add the following script:\n\n```html\n<script src=\"https://www.google.com/recaptcha/api.js?onload=vueRecaptchaApiLoaded&render=explicit\" async defer></script>\n```\n\n### Basic Scaffolding for a Custom Auth Challenge\n\nThis template will configure three triggers: [CreateAuthChallenge](https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-lambda-create-auth-challenge.html), [DefineAuthChallenge](https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-lambda-define-auth-challenge.html), and [VerifyAuthChallengeResponse](https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-lambda-verify-auth-challenge-response.html).\n\nIt will not, however, provide a fully-formed custom authentication flow. Instead, it will create a 'hello world' custom auth flow skeleton that you can manually edit. The intent of this template is to give you a starting place for building out your own custom auth flow.\n\n### Email Verification Link with Redirect\n\nCognito allows you to configure your User Pool to send an email to your users when they attempt to register an account. You can configure this email to contain a link to Cognito's Hosted UI where the user's account will be marked as confirmed.\n\nThis trigger template allows you to define an email message with a link to a static S3 bucket that you control, where the user's account will be confirmed and they can then be redirected to a URL of your choice (presumably your application). The URL will automatically contain the username as a query string parameters.\n\nPlease note that this trigger template will create an S3 resource.  The files that populate the static site are available for edit in `amplify/backend/auth/<your-resource-name>CustomMessage/assets`.  They consist of:\n\n- index.html\n- spinner.js (controls the spinner that appears on the page while users are awaiting confirmation)\n- style.css\n- verify.js (the script which performs the verification request)\n\n#### React Sample\n\nThe following is an example of how to configure the aws-amplify-react authenticator so that it displays a message telling the user to check their email, instead of showing the default 'ConfirmSignUp' component.\n\n```js\nimport React from 'react';\nimport './App.css';\nimport { Amplify, Auth, Hub } from 'aws-amplify';\nimport awsconfig from './aws-exports';\nimport { Authenticator, SignUp, SignIn, Greetings, AuthPiece } from 'aws-amplify-react';\n\nAmplify.configure(awsconfig);\n\nclass MyCustomConfirmation extends AuthPiece {\n  render() {\n    if (this.props.authState === 'confirmSignUp') {\n      return (\n        <div>Check your email for a confirmation link.</div>\n      );\n    } else {\n      return null;\n    }\n  }\n}\n\nclass App extends React.Component {\n  render() {\n    return (\n      <div className=\"App\">\n        <Authenticator hideDefault={true}>\n          <SignIn />\n          <SignUp />\n          <Greetings />\n          <MyCustomConfirmation override={'ConfirmSignUp'}/>\n          </Authenticator>\n      </div>\n    );\n  }\n}\n\nfunction MyApp() {\n  return <App />\n}\n\nexport default MyApp;\n```\n\n#### Angular Sample\n\nThe following is an example of how to configure the aws-amplify-angular authenticator so that it displays a message telling the user to check their email, instead of showing the default 'ConfirmSignUp' component.\n\nBe sure to follow all instructions for [setting up an Angular application](/start) with aws-amplify-angular.\n\napp.component.ts:\n\n```js\nimport { Component } from '@angular/core';\nimport { AmplifyService } from 'aws-amplify-angular';\nimport { Auth } from 'aws-amplify';\n@Component({\n  selector: 'app-root',\n  templateUrl: './app.component.html',\n  styleUrls: ['./app.component.scss']\n})\nexport class AppComponent {\n  title = 'cli-lambda-sample';\n  confirmSignUp: boolean;\n  user: any;\n  constructor( private amplifyService: AmplifyService ) {\n    this.amplifyService.authStateChange$\n    .subscribe(authState => {\n      this.confirmSignUp = authState.state === 'confirmSignUp';\n      if (!authState.user) {\n        this.user = null;\n      } else {\n        this.user = authState.user;\n      }\n    });\n  }\n}\n```\n\napp.component.html:\n\n```html\n<amplify-authenticator [hide]=\"['ConfirmSignUp']\"></amplify-authenticator>\n<div  *ngIf=\"confirmSignUp\">\n  Check your email account for a confirmation message!\n</div>\n```\n\n#### Vue Sample\n\nThe following is an example of how to configure the aws-amplify-vue authenticator components so that your app displays a message telling the user to check their email, instead of showing the default 'ConfirmSignUp' component.\n\n```js\n<template>\n  <div id=\"app\">\n    <amplify-sign-up v-if=\"signUp\"></amplify-sign-up>\n    <amplify-sign-in v-if=\"signIn\"  v-bind:usernameAttributes=\"usernameAttributes\"></amplify-sign-in>\n    <div v-if=\"confirming\">Check your email for a confirmation email</div>\n    <amplify-sign-out\n      v-if=\"signedIn\"\n    ></amplify-sign-out>\n  </div>\n</template>\n\n<script>\nimport { components } from 'aws-amplify-vue'\nimport { AmplifyEventBus } from 'aws-amplify-vue';\nimport VueRecaptcha from 'vue-recaptcha';\n\nexport default {\n  name: 'app',\n  components: {\n    VueRecaptcha,\n    ...components\n  },\n  data() {\n    return {\n      signIn: true,\n      signUp: false,\n      confirming: false,\n      usernameAttributes: 'username',\n      user: {},\n    }\n  },\n  mounted: async function () {\n    await this.$Amplify.Auth.currentAuthenticatedUser()\n      .then((user) => {\n        this.user = user;\n        this.signIn = false;\n      })\n      .catch((e) => {\n        console.log('currentUser error', e)\n      })\n    AmplifyEventBus.$on('authState', info => {\n      this.signIn = info === 'signIn' || info === 'signedOut';\n      this.confirming = info === 'confirmSignUp';\n      this.signUp = info === 'signUp';\n      this.signedIn = info === 'signedIn';\n    });\n    AmplifyEventBus.$on('localUser', user => {\n      this.user = user;\n    });\n  }\n}\n</script>\n```\n\n### Add User to Group\n\nThis trigger allows you to define a Cognito group to which a user will be added upon registration.  \n\nThe trigger will check for the existence of the group in your User Pool, and will create the group if it is not present.\n\n### Email Domain Filtering (deny list) and Email Domain Filtering (allow list)\n\nThese two templates allow you to define email domains which are allowed or disallowed (respectively). They can be used in tandem or individually.  \n\n### Override ID Token Claims\n\nThis template uses the Pre Token Generation trigger and allows you to add, override or remove claims from the [ID token](https://docs.aws.amazon.com/cognito/latest/developerguide/amazon-cognito-user-pools-using-tokens-with-identity-providers.html#amazon-cognito-user-pools-using-the-id-token) that is returned by Cognito.\n\nYou will need to manually edit the template to define the claims that you wish to manipulate. The template currently contains dummy values as examples.\n\n## S3 Lambda Triggers\n\nYou can associate a trigger to an S3 bucket managed by the Amplify CLI, by following the `amplify add/update storage` flows. When attempting to add/update an S3 storage resource, you would get the following CLI prompts to add a trigger for it.\n\n```console\n? Do you want to add a Lambda Trigger for your S3 Bucket? Yes\n? Select from the following options\n❯ Choose an existing function from the project\n  Create a new function\n```\n\nAs you can see in the prompt above, you can either choose to use an existing Lambda function created using the CLI as a part of this project using `amplify add function` or create a new function with a base Lambda function to handle S3 events. We also auto-populate the IAM policies required by the Lambda execution role of the newly created function to access the S3 bucket.\n\n**Note:** You can associate only one Lambda Function trigger to an S3 bucket.\n\n## DynamoDB Lambda Triggers\n\nYou can associate a Lambda trigger with a DynamoDB table, managed by the Amplify CLI. There are two ways by which DynamoDB is provisioned by the Amplify CLI\n\n- As a part of the [Storage category](/cli/storage/overview#)\n- As a part of the [GraphQL API (types with @model annotation)](/cli/graphql/data-modeling)\n\n### As a part of the Storage category\n\nYou can add and manage a DynamoDB table to your Amplify project using the amplify add/update storage flows. When attempting to add/update a DynamoDB storage resource, you would get the following CLI prompts to add a trigger for it.\n\n```console\n? Do you want to add a Lambda Trigger for your Table? Yes\n? Select from the following options (Use arrow keys)\n❯ Choose an existing function from the project\n  Create a new function\n```\n\nAs you can see in the prompt above, you can either choose to use an already existing Lambda function created using the CLI as a part of this project using `amplify add function` or create a new function with a base Lambda function handle DynamoDB events.\n\n**Note:** You can associate more than one Lambda Function trigger to a DynamoDB table.\n\n### As a part of the GraphQL API (types with @model annotation)\n\nYou can also associate a Lambda trigger with any of the GraphQL transformer schema's DynamoDB backed @models which you can add via `amplify add api`. GraphQL mutations that result in DynamoDB item changes will in turn result in change records published to DynamoDB streams that can trigger a Lambda function. To create such a function, start with adding a new lambda function with:\n\n```bash\namplify add function\n```\n\nProceed by providing a name and selecting a Lambda Trigger template:\n\n```console\n? Provide a friendly name for your resource to be used as a label for this category in the project: testtrigger\n? Provide the AWS Lambda function name: mytrigger\n? Choose the function template that you want to use:\n  Hello world function\n  CRUD function for Amazon DynamoDB table (Integration with Amazon API Gateway and Amazon DynamoDB)\n  Serverless express function (Integration with Amazon API Gateway)\n❯ Lambda Trigger\n```\n\nThen select `Amazon DynamoDB Stream` when prompted with event source question.\n\n```bash\n? What event source do you want to associate with Lambda trigger (Use arrow keys)\n❯ Amazon DynamoDB Stream\n  Amazon Kinesis Stream\n```\n\nNow select `API category graphql @model backed DynamoDB table`.\n\n```console\n?\n> Use API category graphql @model backed DynamoDB table(s) in the current Amplify project\n  Use storage category DynamoDB table configured in the current Amplify project\n  Provide the ARN of DynamoDB stream directly\n```\n\nAfter the above question, you can select one of the types annotated by @model for which you want to add a trigger for.\n\nOn completion of the above mentioned flow, a boilerplate lambda function trigger will be created in your `amplify/backend/function` directory with the following template:\n\n```js\nexports.handler = function (event, context) {\n  console.log(JSON.stringify(event, null, 2));\n  event.Records.forEach((record) => {\n    console.log(record.eventID);\n    console.log(record.eventName);\n    console.log('DynamoDB Record: %j', record.dynamodb);\n  });\n  context.done(null, 'Successfully processed DynamoDB record');\n};\n```\n\n`record.dynamodb` will contain a DynamoDB change json describing the item changed in DynamoDB table.\nPlease note that it does not represent an original and new item as stored in DynamoDB table. To retrieve a original and new item you need to convert a DynamoDB json to original form:\n\n```js\nconst AWS = require('aws-sdk');\nconst records = event.Records.map(record => ({\n  new: AWS.DynamoDB.Converter.unmarshall(record.dynamodb.NewImage),\n  old: AWS.DynamoDB.Converter.unmarshall(record.dynamodb.OldImage)\n}));\n```\n\n## Kinesis Stream Trigger\n\nAmplify Analytics category Kinesis stream resource can be also used as an event source for Lambda triggers. Event published to Kinesis stream will trigger a lambda function. You can add a Kinesis stream to your Amplify project by going through the `amplify add analytics` flow. To create a Lambda trigger for the Kinesis Stream, start with adding a new lambda function:\n\n```bash\namplify add function\n```\n\nProceed by providing a name and selecting a Lambda Trigger template:\n\n```console\n? Provide a friendly name for your resource to be used as a label for this category in the project: testtrigger\n? Provide the AWS Lambda function name: mytrigger\n? Choose the function template that you want to use:\n  Hello world function\n  CRUD function for Amazon DynamoDB table (Integration with Amazon API Gateway and Amazon DynamoDB)\n  Serverless express function (Integration with Amazon API Gateway)\n❯ Lambda Trigger\n```\n\nThen select `Amazon Kinesis Stream` when prompted with event source question and select the resource.\n\n```console\n? What event source do you want to associate with Lambda trigger (Use arrow keys)\n  Amazon DynamoDB Stream\n❯ Amazon Kinesis Stream\n? Choose a Kinesis event source option (Use arrow keys)\n❯ Use Analytics category kinesis stream in the current Amplify project\n  Provide the ARN of Kinesis stream directly\n```\n\nAfter the completion of the above flow, a Lambda function will be created in your `amplify/backend/function` directory and will be invoked when a new event is pushed to a Kinesis stream. Please refer to [Working with the API](/lib/analytics/getting-started) to learn more about publishing your events to Kinesis stream.\n",
    "meta": {
      "title": "Lambda Triggers",
      "description": "Lambda triggers are useful for adding functionality during certain lifecycles of the user's journey. Associate a Lambda trigger with an auth scenario, S3 bucket, DynamoDB table or Kinesis Stream managed through the Amplify CLI.",
      "subcategory": "Advanced workflows",
      "category": "Amplify CLI"
    },
    "filename": "/cli/usage/lambda-triggers"
  },
  {
    "searchableText": [
      {
        "heading": "Team workflows",
        "depth": 2,
        "text": "Amplify environments help you manage your local and cloud environments to mimic your team workflows. Common tasks include:"
      },
      {
        "heading": "Team workflows",
        "depth": 2,
        "text": "Manage environments to support development processes (e.g., development, staging, production)"
      },
      {
        "heading": "Team workflows",
        "depth": 2,
        "text": "Test new features safely"
      },
      {
        "heading": "Team workflows",
        "depth": 2,
        "text": "Share environments between team members"
      },
      {
        "heading": "Team workflows",
        "depth": 2,
        "text": "Support team workflows"
      },
      {
        "heading": "Team workflows",
        "depth": 2,
        "text": "To display all commands available for a new Amplify project, run the following command from the root directory."
      },
      {
        "heading": "Commands overview",
        "depth": 2,
        "text": "| Command  | Description  |\n|---|---|\n| amplify env add [--permissions-boundary <IAM Policy ARN>] | Adds a new environment |\n| amplify env pull [--restore] | Pulls the current environment from the cloud |\n| amplify env checkout <env-name> [--restore] | Switches to the selected environment |\n| amplify env list [--details] [--json] | Displays a list of all the environments |\n| amplify env get --name <env-name> | Displays the environment details |\n| amplify env update [--permissions-boundary <IAM Policy ARN>] | Updates the environment's IAM Permissions Boundary |\n| amplify env import --name <env-name> --config <provider-configs> [--awsInfo <aws-configs>] | Imports an environment |\n| amplify env remove <env-name> | Removes an environment |"
      },
      {
        "heading": "Add a new environment",
        "depth": 3,
        "text": "The add command goes through the following steps:"
      },
      {
        "heading": "Add a new environment",
        "depth": 3,
        "text": "Asks for a name for the new environment"
      },
      {
        "heading": "Add a new environment",
        "depth": 3,
        "text": "Creates IAM role for unauthenticated users"
      },
      {
        "heading": "Add a new environment",
        "depth": 3,
        "text": "Creates IAM role for authenticated users"
      },
      {
        "heading": "Add a new environment",
        "depth": 3,
        "text": "Creates S3 bucket for deployment"
      },
      {
        "heading": "Add a new environment",
        "depth": 3,
        "text": "Creates a new backend environment in AWS Amplify Console to view and manage resources."
      },
      {
        "heading": "Add a new environment",
        "depth": 3,
        "text": "Optionally, you can configure an IAM Permissions Boundary for all Amplify-generated roles via the --permissions-boundary parameter. For more information about configuring IAM Permissions Boundary, see IAM Permissions Boundary for Amplify-generated roles."
      },
      {
        "heading": "Pull the environment from the cloud",
        "depth": 3,
        "text": "Use this command to pull the current environment from the cloud. Add the --restore flag to overwrite your local changes like amplify pull command."
      },
      {
        "heading": "Checkout an environment",
        "depth": 3,
        "text": "Use this command to checkout the <env-name> environment. Add the --restore flag to overwrite your local changes."
      },
      {
        "heading": "List environments",
        "depth": 3,
        "text": "Use this command to list all the environments. Add the --details or --json flags to see more details and format the output. Details include the AWS Region, IAM roles, S3 bucket and stack information."
      },
      {
        "heading": "List environments",
        "depth": 3,
        "text": "See the output below for an Amplify project with dev and test environments. The active environment is preceded with an asterisk."
      },
      {
        "heading": "Show environment details",
        "depth": 3,
        "text": "Use this command to list all details for <env-name> environment. Details include the AWS Region, IAM roles, S3 bucket and stack information."
      },
      {
        "heading": "Import an environment",
        "depth": 3,
        "text": "Use this command to import an existing environment. Find below an example of a bash command."
      },
      {
        "heading": "Import an environment",
        "depth": 3,
        "text": "You can get the AWSCLOUDFORMATIONCONFIG from the team-provider-info.json file from your existing Amplify project."
      },
      {
        "heading": "Remove an environment",
        "depth": 3,
        "text": "Use this command to remove an environment. This will remove both the local and the cloud environments including all provisioned services and resources."
      }
    ],
    "source": "export const meta = {\n  title: `Commands`,\n  description: `Use these Amplify CLI commands to manage a team workflow with multiple environments.`,\n};\n\n \n## Team workflows\n\nAmplify environments help you manage your local and cloud environments to mimic your team workflows. Common tasks include:\n\n- Manage environments to support development processes (e.g., development, staging, production)\n- Test new features safely\n- Share environments between team members\n- Support team workflows\n\nTo display all commands available for a new Amplify project, run the following command from the root directory.\n\n```bash\namplify env\n```\n\n## Commands overview\n\n| Command  | Description  |\n|---|---|\n| [`amplify env add [--permissions-boundary <IAM Policy ARN>]`](#add-a-new-environment) | Adds a new environment |\n| [`amplify env pull [--restore]`](#pull-the-environment-from-the-cloud) | Pulls the current environment from the cloud |\n| [`amplify env checkout <env-name> [--restore]`](#checkout-an-environment) | Switches to the selected environment |\n| [`amplify env list [--details] [--json]`](#list-environments) | Displays a list of all the environments |\n| [`amplify env get --name <env-name>`](#show-environment-details) | Displays the environment details |\n| [`amplify env update [--permissions-boundary <IAM Policy ARN>]`](/cli/usage/permissions-boundary) | Updates the environment's IAM Permissions Boundary |\n| [`amplify env import --name <env-name> --config <provider-configs> [--awsInfo <aws-configs>]`](#import-an-environment) | Imports an environment |\n| [`amplify env remove <env-name>`](#remove-an-environment) | Removes an environment |\n\n## Environment CLI commands\n\n### Add a new environment\n\n```bash\namplify env add\n```\n\nThe `add` command goes through the following steps:\n\n- Asks for a name for the new environment\n- Creates IAM role for unauthenticated users\n- Creates IAM role for authenticated users\n- Creates S3 bucket for deployment\n- Creates a new backend environment in [AWS Amplify Console](https://console.aws.amazon.com/amplify) to view and manage resources.\n\nOptionally, you can configure an IAM Permissions Boundary for all Amplify-generated roles via the `--permissions-boundary` parameter. For more information about configuring IAM Permissions Boundary, see [IAM Permissions Boundary for Amplify-generated roles](/cli/usage/permissions-boundary).\n\n### Pull the environment from the cloud\n\n```bash\namplify env pull [--restore]\n```\n\nUse this command to pull the current environment from the cloud. Add the `--restore` flag to overwrite your local changes like `amplify pull` command.\n\n### Checkout an environment\n\n```bash\namplify env checkout <env-name> [--restore]\n```\n\nUse this command to checkout the &lt;env-name&gt; environment. Add the `--restore` flag to overwrite your local changes.\n\n### List environments\n\n```bash\namplify env list [--details] [--json]\n```\n\nUse this command to list all the environments. Add the `--details` or `--json` flags to see more details and format the output. Details include the AWS Region, IAM roles, S3 bucket and stack information.\n\nSee the output below for an Amplify project with `dev` and `test` environments. The active environment is preceded with an asterisk.\n\n```bash\namplify env list\n```\n\n```console\n| Environments |\n| ------------ |\n| *dev         |\n| test         |\n```\n\n### Show environment details\n\n```bash\namplify env get --name <env-name>\n```\n\nUse this command to list all details for &lt;env-name&gt; environment. Details include the AWS Region, IAM roles, S3 bucket and stack information.\n\n### Import an environment\n\n```bash\namplify env import --name <env-name> --config <provider-configs> [--awsInfo <aws-configs>]\n```\n\nUse this command to import an existing environment. Find below an example of a bash command.\n\n```bash\n#!/bin/bash\nset -e\nIFS='|'\n \nAWSCLOUDFORMATIONCONFIG=\"{\\\n\\\"Region\\\": \\\"us-east-1\\\",\\\n\\\"DeploymentBucketName\\\": \\\"mytestproject-20181106123241-deployment\\\",\\\n\\\"UnauthRoleName\\\": \\\"mytestproject-20181106123241-unauthRole\\\",\\\n\\\"StackName\\\": \\\"mytestproject-20181106123241\\\",\\\n\\\"StackId\\\": \\\"arn:aws:cloudformation:us-east-1:132393967379:stack/mytestproject67-20181106123241/1c03a3e0-e203-11e8-bea9-500c20ff1436\\\",\\\n\\\"AuthRoleName\\\": \\\"mytestproject67-20181106123241-authRole\\\",\\\n\\\"UnauthRoleArn\\\": \\\"arn:aws:iam::132393967379:role/mytestproject67-20181106123241-unauthRole\\\",\\\n\\\"AuthRoleArn\\\": \\\"arn:aws:iam::132393967379:role/mytestproject67-20181106123241-authRole\\\"\\\n}\"\nPROVIDER_CONFIG=\"{\\\n\\\"awscloudformation\\\":$AWSCLOUDFORMATIONCONFIG\\\n}\"\n \n \nAWS_CONFIG=\"{\\\n\\\"configLevel\\\":\\\"project\\\",\\\n\\\"useProfile\\\":true,\\\n\\\"profileName\\\":\\\"default\\\"\\\n}\"\n \namplify env import \\\n--name dev \\\n--config $PROVIDER_CONFIG \\\n--awsInfo $AWS_CONFIG \\\n--yes\n \n```\n\nYou can get the `AWSCLOUDFORMATIONCONFIG` from the `team-provider-info.json` file from your existing Amplify project.\n\n### Remove an environment\n\n```bash\namplify env remove <env-name>\n```\n\nUse this command to remove an environment. This will remove both the local and the cloud environments including all provisioned services and resources.\n",
    "meta": {
      "title": "Commands",
      "description": "Use these Amplify CLI commands to manage a team workflow with multiple environments.",
      "subcategory": "Team environments",
      "category": "Amplify CLI"
    },
    "filename": "/cli/teams/commands"
  },
  {
    "searchableText": [
      {
        "heading": "Using Amplify Console",
        "depth": 2,
        "text": "You can use the multi-environments feature with the Amplify Console for a fully managed web application hosting and continuous deployment solution. For more information please learn more in the official documentation."
      }
    ],
    "source": "export const meta = {\n  title: `Continuous deployment`,\n  description: `Use the multi-environments feature with the Amplify Console for a fully managed web application hosting and continuous deployment solution.`,\n};\n\n## Using Amplify Console\n\nYou can use the multi-environments feature with the Amplify Console for a fully managed web application hosting and continuous deployment solution. For more information please learn more in the [official documentation](https://docs.aws.amazon.com/amplify/latest/userguide/multi-environments.html).\n",
    "meta": {
      "title": "Continuous deployment",
      "description": "Use the multi-environments feature with the Amplify Console for a fully managed web application hosting and continuous deployment solution.",
      "subcategory": "Team environments",
      "category": "Amplify CLI"
    },
    "filename": "/cli/teams/cicd"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Use the amplify pull command to share the same Amplify backend across multiple frontends (e.g, a React and Android app). Users have an option to pull the entire backend definition (infrastructure templates and metadata) or only the metadata (e.g. the aws-exports.js or amplifyconfiguration.json file) required to connect to the backend. If you’re building a mobile and web app in separate repositories, the recommended workflow is to keep the backend definition (the amplify folder) in only one of the repositories and pull the metadata (the aws-exports.js or amplifyconfiguration.json file) in the second repository to connect to the same backend."
      },
      {
        "heading": "Workflow",
        "depth": 2,
        "text": "This workflow outlines the steps required to share a backend across two (or more) frontends. This example scenario is for a team building an Android and React app."
      },
      {
        "heading": "Workflow",
        "depth": 2,
        "text": ""
      },
      {
        "heading": "Workflow",
        "depth": 2,
        "text": "Initialize a backend for your React app. This will create an Amplify project and backend environment that is accessible in the Amplify Console (by running amplify console)."
      },
      {
        "heading": "Workflow",
        "depth": 2,
        "text": "Make your frontend changes and commit the code to Git. Your Git repository now stores the amplify folder which contains the definition of your infrastructure."
      },
      {
        "heading": "Workflow",
        "depth": 2,
        "text": "Reference the backend from your Android app using the amplify pull command. Choose 'No' when asked if you want to modify or add new categories to your backend. This will put the amplifyconfiguration to your src folder only. Choosing 'Yes' will work, however your backend definition will now be stored in two separate repositories leading to unintended consequences with multiple sources of truth."
      }
    ],
    "source": "export const meta = {\n  title: `Multiple frontends`,\n  description: `Learn how to share the same Amplify backend across multiple frontends (e.g, a React and Android app).`,\n};\n\nUse the `amplify pull` command to share the same Amplify backend across multiple frontends (e.g, a React and Android app). Users have an option to pull the entire backend definition (infrastructure templates and metadata) or only the metadata (e.g. the `aws-exports.js` or `amplifyconfiguration.json` file) required to connect to the backend. If you’re building a mobile and web app in separate repositories, the recommended workflow is to keep the backend definition (the amplify folder) in only one of the repositories and pull the metadata (the `aws-exports.js` or `amplifyconfiguration.json` file) in the second repository to connect to the same backend.\n\n## Workflow\n\nThis workflow outlines the steps required to share a backend across two (or more) frontends. This example scenario is for a team building an Android and React app.\n\n![Image](/images/multiple-frontends.png)\n\n1. Initialize a backend for your React app. This will create an Amplify project and backend environment that is accessible in the Amplify Console (by running `amplify console`).\n\n ```console\n     $ cd my-react-app\n     $ amplify init\n  ? Enter a name for the project: ecommerce\n  ? Choose the type of app that you're building: react\n     $ amplify add api\n     $ amplify push\n ```\n\n2. Make your frontend changes and commit the code to Git. Your Git repository now stores the `amplify` folder which contains the definition of your infrastructure.\n\n3. Reference the backend from your Android app using the `amplify pull` command. Choose 'No' when asked if you want to modify or add new categories to your backend. This will put the `amplifyconfiguration` to your src folder only. Choosing 'Yes' will work, however your backend definition will now be stored in two separate repositories leading to unintended consequences with multiple sources of truth.\n\n ```console\n   cd my-android-app\n   amplify pull\n  ? Which app are you working on?\n    > ecommerce\n      mysecretproject\n  ? Choose the type of app that you're building: #android\n  ? Do you plan on modifying this backend?: #n\n   Successfully pulled backend environment dev from the cloud.\n   Run 'amplify pull' to sync upstream changes.\n ```\n",
    "meta": {
      "title": "Multiple frontends",
      "description": "Learn how to share the same Amplify backend across multiple frontends (e.g, a React and Android app).",
      "subcategory": "Team environments",
      "category": "Amplify CLI"
    },
    "filename": "/cli/teams/multi-frontend"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Now you have two independent environments (main & dev) in the cloud and have corresponding git branches with your amplify backend infrastructure code on Git. Suppose a team member wants to work on the same Amplify project, add some features to it and then push changes to the dev environment to test some changes. They would perform the following steps:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Next, suppose the team-member wants to move these changes to dev and main environments/branches:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "After testing that everything works fine in the dev stage, you could now merge dev to the main git branch:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "In this approach, you can consider the git branches (dev & main) as the source of truth and all the team members should work off the branches and keep their workspaces in sync."
      }
    ],
    "source": "export const meta = {\n  title: `Sandbox environments`,\n  description: `Learn how to enable sandbox environments for your Amplify project.`,\n};\n\nNow you have two independent environments (main & dev) in the cloud and have corresponding git branches with your amplify backend infrastructure code on Git. Suppose a team member wants to work on the same Amplify project, add some features to it and then push changes to the dev environment to test some changes. They would perform the following steps:\n\n```console\n$ git clone <git-repo>\n$ cd <project-dir>\n$ git checkout -b mysandbox\n$ amplify env add\n? Do you want to use an existing environment? No\n? Enter a name for the environment mysandbox\n// Rest of init steps\n// Add/update any backend configurations using amplify add/update <category>\n$ amplify push\n$ git push -u origin mysandbox\n```\n\nNext, suppose the team-member wants to move these changes to dev and main environments/branches:\n\n```console\n$ git checkout dev\n$ amplify env checkout dev\n$ git merge mysandbox\n$ amplify push\n$ git push -u origin dev\n```\n\nAfter testing that everything works fine in the dev stage, you could now merge dev to the main git branch:\n\n```console\n$ git checkout main\n$ amplify env checkout main\n$ git merge dev\n$ amplify push\n$ git push -u origin main\n```\n\nIn this approach, you can consider the git branches (dev & main) as the source of truth and all the team members should work off the branches and keep their workspaces in sync.\n",
    "meta": {
      "title": "Sandbox environments",
      "description": "Learn how to enable sandbox environments for your Amplify project.",
      "subcategory": "Team environments",
      "category": "Amplify CLI"
    },
    "filename": "/cli/teams/sandbox"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "You have two independent environments (main & dev) in the cloud and have corresponding Git branches with your Amplify backend infrastructure code on Git. Suppose all team members want to work on the same Amplify project and push backend related changes to the same dev environment to test their changes. Each team member would run the following:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Ensure the root of your project has the amplify folder set up in order to be able to re-use existing environments."
      },
      {
        "heading": null,
        "depth": null,
        "text": "If the team-provider-info.json file is missing:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Backup and remove the amplify folder"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Pull the environment from the root of your project folder using the amplify pull --appId <app-id> --envName <env-name> command displayed in the Amplify Console for your application"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Since the team is sharing the same dev backend, periodically team members would need to pull in changes which their team members pushed for the dev environment to be in sync. Let's pull in the changes from the dev branch & environment."
      },
      {
        "heading": "Sharing projects within the team",
        "depth": 2,
        "text": "Team members will only be able to push to a stack only if they have the correct credentials (access key/secret keys) to do so."
      },
      {
        "heading": "Sharing projects within the team",
        "depth": 2,
        "text": "Inside the amplify directory file-structure, you will observe a team-provider-info.json file which contains a structure similar to the following:"
      },
      {
        "heading": "Sharing projects within the team",
        "depth": 2,
        "text": "This file is to be shared between team members, so that they have the ability to push/provision resources to the same CloudFormation stack and that way teams can work in a push/pull way and can always be in sync with the latest state of the project in the cloud."
      },
      {
        "heading": "Sharing projects within the team",
        "depth": 2,
        "text": "If you want to share a project publicly and open source your serverless infrastructure, you should remove or put the amplify/team-provider-info.json file in the .gitignore file."
      }
    ],
    "source": "export const meta = {\n  title: `Share single environment`,\n  description: `Learn the recommended workflow for multiple team members sharing a single Amplify environment.`,\n};\n\nYou have two independent environments (`main` & `dev`) in the cloud and have corresponding Git branches with your Amplify backend infrastructure code on Git. Suppose all team members want to work on the same Amplify project and push backend related changes to the same `dev` environment to test their changes. Each team member would run the following:\n\n```bash\ncd <project-dir>\namplify init\n```\n\n<Callout warning>\n\nEnsure the root of your project has the `amplify` folder set up in order to be able to re-use existing environments.\n\nIf the **team-provider-info.json** file is missing:\n\n1. Backup and remove the `amplify` folder\n2. Pull the environment from the root of your project folder using the `amplify pull --appId <app-id> --envName <env-name>` command displayed in the Amplify Console for your application\n\n</Callout>\n\n```console\nDo you want to use an existing environment? Yes\nChoose the environment you would like to use:\n❯ dev\nmain\n# The rest of init steps\n# amplify add/update \namplify push\n```\n\nSince the team is sharing the same `dev` backend, periodically team members would need to pull in changes which their team members pushed for the `dev` environment to be in sync. Let's pull in the changes from the `dev` branch & environment.\n\n```bash\namplify pull\n```\n\n## Sharing projects within the team\n\n<Callout warning>\n\nTeam members will only be able to push to a stack only if they have the [correct credentials (access key/secret keys)](https://docs.amplify.aws/cli/start/install#pre-requisites-for-installation) to do so.\n\n</Callout>\n\nInside the `amplify` directory file-structure, you will observe a **team-provider-info.json** file which contains a structure similar to the following:\n\n```json\n{\n  \"dev\": {\n    \"awscloudformation\": {\n      \"AuthRoleName\": \"multenvtest-20181115101929-authRole\",\n      \"UnauthRoleArn\": \"arn:aws:iam::132393967379:role/multenvtest-20181115101929-unauthRole\",\n      \"AuthRoleArn\": \"arn:aws:iam::132393967379:role/multenvtest-20181115101929-authRole\",\n      \"Region\": \"us-east-1\",\n      \"DeploymentBucketName\": \"multenvtest-20181115101929-deployment\",\n      \"UnauthRoleName\": \"multenvtest-20181115101929-unauthRole\",\n      \"StackName\": \"multenvtest-20181115101929\",\n      \"StackId\": \"arn:aws:cloudformation:us-east-1:132393967379:stack/multenvtest-20181115101929/fc7b1010-e902-11e8-a9bd-50fae97e0835\"\n    }\n  },\n  \"main\": {\n    \"awscloudformation\": {\n      \"AuthRoleName\": \"multenvtest-20181115102119-authRole\",\n      \"UnauthRoleArn\": \"arn:aws:iam::345090917734:role/multenvtest-20181115102119-unauthRole\",\n      \"AuthRoleArn\": \"arn:aws:iam::345090917734:role/multenvtest-20181115102119-authRole\",\n      \"Region\": \"us-east-1\",\n      \"DeploymentBucketName\": \"multenvtest-20181115102119-deployment\",\n      \"UnauthRoleName\": \"multenvtest-20181115102119-unauthRole\",\n      \"StackName\": \"multenvtest-20181115102119\",\n      \"StackId\": \"arn:aws:cloudformation:us-east-1:345090917734:stack/multenvtest-20181115102119/3e907b70-e903-11e8-a18b-503acac41e61\"\n    }\n  }\n}\n```\n\nThis file is to be shared between team members, so that they have the ability to push/provision resources to the same CloudFormation stack and that way teams can work in a push/pull way and can always be in sync with the latest state of the project in the cloud.\n\nIf you want to share a project publicly and open source your serverless infrastructure, you should remove or put the `amplify/team-provider-info.json` file in the `.gitignore` file.\n",
    "meta": {
      "title": "Share single environment",
      "description": "Learn the recommended workflow for multiple team members sharing a single Amplify environment.",
      "subcategory": "Team environments",
      "category": "Amplify CLI"
    },
    "filename": "/cli/teams/shared"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "When you initialize a project, you create an Amplify backend environment. Every Amplify backend environment is a container for the categories added to your project. To deploy updates to an environment, run amplify push. In teams where multiple members are working on the same backend, it is good practice to run amplify pull to fetch changes from upstream before beginning work on new backend features. View the list of backend environments in your cloud project by visiting the Amplify Console."
      },
      {
        "heading": null,
        "depth": null,
        "text": "For multiple environments, Amplify matches the standard Git workflow where you switch between different branches using the env checkout command -- similar to running git checkout BRANCHNAME, run amplify env checkout ENVIRONMENT_NAME to switch between environments. The diagram below shows a workflow of how to initialize new environments when creating new git branches."
      },
      {
        "heading": null,
        "depth": null,
        "text": ""
      },
      {
        "heading": null,
        "depth": null,
        "text": "You can independently add features to each environment which allows you to develop and test before moving them to different stages. Using the same example above of Dev being the base which Test and Prod were derived, you could add (or remove) features and merge & deploy accordingly once you are comfortable with your setup."
      },
      {
        "heading": null,
        "depth": null,
        "text": ""
      },
      {
        "heading": null,
        "depth": null,
        "text": "This can be done in an iterative manner as you work through your deployment pipeline:"
      },
      {
        "heading": null,
        "depth": null,
        "text": ""
      },
      {
        "heading": null,
        "depth": null,
        "text": "Multiple developers on a team can also share and manipulate the environment as well by using the credentials in the account. For instance suppose they wanted to test a change to the API without impacting the Test or Prod deployments. This will allow them to test the configured resources and, if they have been granted appropriate CloudFormation permissions, they can push resources as well to the backend with amplify push."
      },
      {
        "heading": null,
        "depth": null,
        "text": ""
      },
      {
        "heading": null,
        "depth": null,
        "text": "You can alternatively, have developers setup their own isolated replica of these environments in a different AWS account. To do this simply:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Clone the existing project"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Run amplify env add and set up a new environment (e.g. \"mydev\") with that developer's account and AWS profile"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Deploy with amplify push"
      },
      {
        "heading": null,
        "depth": null,
        "text": "This workflow can be used to share complete Amplify projects with people outside of your organization as well by committing the project into a Git repository. If you are doing this remove (or add to the .gitignore file) the team-provider-info.json which is located in the amplify directory. You can learn more about this file here."
      },
      {
        "heading": "Continuous deployment and Hosting",
        "depth": 3,
        "text": "The Amplify CLI supports basic web application hosting with Amazon S3 and CloudFront. You can use the multi-environments feature with the Amplify Console for a fully managed web application hosting and continuous deployment solution. For more information please learn more in the official documentation."
      },
      {
        "heading": "Setting up prod and dev environments",
        "depth": 3,
        "text": "Create a Git repository for your project if you haven't already. It is recommended managing separate Git branches for different environments (try to have the same branch name as your environment name to avoid confusion).\nFrom the root of your project, execute the following commands:"
      },
      {
        "heading": "Setting up prod and dev environments",
        "depth": 3,
        "text": "Note: When you initialize a project using the Amplify CLI, it appends (if a gitignore file exists at the root of the project) or creates one for you (if a gitignore file doesn't exist at the root of your project), with a list of recommended files to check in from the Amplify CLI generated list of files, into your Git repository. Amplify CLI will continue to manage the section of your .gitignore between the #amplify-do-not-edit-begin and #amplify-do-not-edit-end pragmas."
      },
      {
        "heading": "Setting up prod and dev environments",
        "depth": 3,
        "text": "Once you have your 'prod' branch setup in Git, set up a 'dev' environment in your Amplify project (which would be based on your 'prod' environment), and then walk through the following steps to create a corresponding git branch for it."
      },
      {
        "heading": "Setting up prod and dev environments",
        "depth": 3,
        "text": "This will set up another environment for the project in the cloud. The backend-configs and resources are now cloned from the 'prod' environment. Run amplify push to provision all the AWS resources for your new environment (dev)."
      },
      {
        "heading": "Setting up prod and dev environments",
        "depth": 3,
        "text": "Now push the changes to the 'prod' branch (you would just see changes to the team-provider-info.json file -- when running a git status command, which has cumulative stack information for all the project environments which are useful when you want to share the same backend within a team). After this, let's create a new git branch -- 'dev' corresponding to the new environment we just created."
      }
    ],
    "source": "export const meta = {\n  title: `Overview`,\n  description: `Every Amplify backend environment is a container for the categories added to your project. For multiple environments, Amplify matches the standard Git workflow where you switch between different branches using familiar commands.`,\n};\n\nWhen you initialize a project, you create an Amplify backend environment. Every Amplify backend environment is a container for the categories added to your project. To deploy updates to an environment, run `amplify push`. In teams where multiple members are working on the same backend, it is good practice to run `amplify pull` to fetch changes from upstream before beginning work on new backend features. View the list of backend environments in your cloud project by visiting the [Amplify Console](https://console.aws.amazon.com/amplify).\n\nFor multiple environments, Amplify matches the standard Git workflow where you switch between different branches using the `env checkout` command -- similar to running `git checkout BRANCHNAME`, run `amplify env checkout ENVIRONMENT_NAME` to switch between environments. The diagram below shows a workflow of how to initialize new environments when creating new git branches.\n\n![Image](/images/AmplifyEnvSwitching.jpg)\n\nYou can independently add features to each environment which allows you to develop and test before moving them to different stages. Using the same example above of **Dev** being the base which **Test** and **Prod** were derived, you could add (or remove) features and merge & deploy accordingly once you are comfortable with your setup.\n\n![Image](/images/AmplifyEnvAddDeploy.jpg)\n\nThis can be done in an iterative manner as you work through your deployment pipeline:\n\n![Image](/images/AmplifyEnvAddDeploySwitching.jpg)\n\nMultiple developers on a team can also share and manipulate the environment as well by using the credentials in the account. For instance suppose they wanted to test a change to the API without impacting the **Test** or **Prod** deployments. This will allow them to test the configured resources and, if they have been granted appropriate CloudFormation permissions, they can push resources as well to the backend with `amplify push`.\n\n![Image](/images/AmplifyEnvMultDevelopers.jpg)\n\nYou can alternatively, have developers setup their own isolated replica of these environments in a different AWS account. To do this simply:\n\n1. Clone the existing project\n2. Run `amplify env add` and set up a new environment (e.g. \"mydev\") with that developer's account and AWS profile\n3. Deploy with `amplify push`\n\nThis workflow can be used to share complete Amplify projects with people outside of your organization as well by committing the project into a Git repository. If you are doing this remove (or add to the `.gitignore` file) the **team-provider-info.json** which is located in the `amplify` directory. You can learn more about this file [here](/cli/teams/shared#sharing-projects-outside-the-team).\n\n### Continuous deployment and Hosting\n\nThe Amplify CLI supports basic web application hosting with Amazon S3 and CloudFront. You can use the multi-environments feature with the Amplify Console for a fully managed web application hosting and continuous deployment solution. For more information please learn more in the [official documentation](https://docs.aws.amazon.com/amplify/latest/userguide/multi-environments.html).\n\n### Setting up prod and dev environments\n\nCreate a Git repository for your project if you haven't already. It is recommended managing separate Git branches for different environments (try to have the same branch name as your environment name to avoid confusion).\nFrom the root of your project, execute the following commands:\n\n```console\n$ amplify init\n? Enter a name for the environment: prod\n// Provide AWS Profile info\n// Add amplify categories using `amplify add <category>`\n$ git init\n$ git add <all project related files>\n$ git commit -m \"Creation of a prod amplify environment\"\n$ git remote add origin git@github.com:<repo-name>\n$ git push -u origin prod\n```\n\n**Note:** When you initialize a project using the Amplify CLI, it appends (if a gitignore file exists at the root of the project) or creates one for you (if a gitignore file doesn't exist at the root of your project), with a list of recommended files to check in from the Amplify CLI generated list of files, into your Git repository. Amplify CLI will continue to manage the section of your .gitignore between the `#amplify-do-not-edit-begin` and `#amplify-do-not-edit-end` pragmas.\n\nOnce you have your 'prod' branch setup in Git, set up a 'dev' environment in your Amplify project (which would be based on your 'prod' environment), and then walk through the following steps to create a corresponding git branch for it.\n\n```console\n$ amplify env add\n? Do you want to use an existing environment? No\n? Enter a name for the environment dev\n// Provide AWS Profile info\n```\n\nThis will set up another environment for the project in the cloud. The backend-configs and resources are now cloned from the 'prod' environment. Run `amplify push` to provision all the AWS resources for your new environment (dev).\n\nNow push the changes to the 'prod' branch (you would just see changes to the team-provider-info.json file -- when running a `git status` command, which has cumulative stack information for all the project environments which are useful when you want to share the same backend within a team). After this, let's create a new git branch -- 'dev' corresponding to the new environment we just created.\n\n```console\n$ git add .\n$ git commit -m \"Creation of a dev amplify environment\"\n$ git push -u origin prod\n$ git checkout -b dev\n$ git push -u origin dev\n```\n",
    "meta": {
      "title": "Overview",
      "description": "Every Amplify backend environment is a container for the categories added to your project. For multiple environments, Amplify matches the standard Git workflow where you switch between different branches using familiar commands.",
      "subcategory": "Team environments",
      "category": "Amplify CLI"
    },
    "filename": "/cli/teams/overview"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "This troubleshooting guide provides guidance to developers to detect and correct common errors encountered during development, deployment, and migration of applications built using the Amplify CLI."
      },
      {
        "heading": "For all Amplify CLI projects",
        "depth": 3,
        "text": "To debug deployment issues, it's helpful to understand the file structure of your Amplify-generated project and the artifacts generated by the Amplify CLI."
      },
      {
        "heading": "For all Amplify CLI projects",
        "depth": 3,
        "text": "Amplify CloudFormation artifacts: The Amplify CLI provisions AWS resources using CloudFormation templates and the input parameters provided by the user during the CLI walkthrough. Starting with Amplify CLI version 7 and above, some categories (Storage, Auth, API) allow developers to override the Amplify-generated AWS resource configurations with the Amplify CLI Overrides feature."
      },
      {
        "heading": "For all Amplify CLI projects",
        "depth": 3,
        "text": "Amplify CLI walkthrough input parameters artifacts: All inputs provided by the user during a CLI walkthrough are stored in JSON files in the /amplify/backend folder. For example, cli-inputs.json or amplify-meta.json. These files let you inspect the configurations, both developer-provided and Amplify-generated, to root cause potential problems.\nRefer to Amplify backend files documentation to determine if a file is safe to edit manually."
      },
      {
        "heading": "For Amplify CLI projects with GraphQL API",
        "depth": 3,
        "text": "To debug deployment issues in projects with GraphQL API, it's helpful to understand the various artifacts generated by Amplify in a GraphQL project."
      },
      {
        "heading": "For Amplify CLI projects with GraphQL API",
        "depth": 3,
        "text": "GraphQL schema VTL generation: The Amplify CLI GraphQL workflow uses the AWS AppSync service to provision the GraphQL API. The amplify api gql-compile command transpiles the GraphQL schema provided by the developer and generates all the artifacts required to deploy the API in AWS."
      },
      {
        "heading": "For Amplify CLI projects with GraphQL API",
        "depth": 3,
        "text": "Directives like @model, @function, @auth, and @searchable in the GraphQL schema are used to generate CloudFormation and provision AWS resources."
      },
      {
        "heading": "For Amplify CLI projects with GraphQL API",
        "depth": 3,
        "text": "The GraphQL resolvers for Query, Mutation or Subscription are converted into VTL (Velocity Template Language) files. AWS AppSync uses VTL to translate GraphQL requests from clients into a request to your data source."
      },
      {
        "heading": "For Amplify CLI projects with GraphQL API",
        "depth": 3,
        "text": "GraphQL schema client-side code generation: The Amplify CLI GraphQL workflow allows developers to generate client-side code for web and mobile clients using the amplify codegen command.\nRead the Amplify code generation documentation prior to debugging any client-side code generation issues."
      },
      {
        "heading": "Troubleshooting \"amplify push\" failures",
        "depth": 2,
        "text": "Errors:"
      },
      {
        "heading": "Troubleshooting \"amplify push\" failures",
        "depth": 2,
        "text": "“An error occurred during the push operation”"
      },
      {
        "heading": "Troubleshooting \"amplify push\" failures",
        "depth": 2,
        "text": "The amplify push command performs the following steps:"
      },
      {
        "heading": "Troubleshooting \"amplify push\" failures",
        "depth": 2,
        "text": "It generates CloudFormation for deployment of resources to AWS."
      },
      {
        "heading": "Troubleshooting \"amplify push\" failures",
        "depth": 2,
        "text": "If the application contains a GraphQL API, the CLI runs amplify api gql-compile internally to compile the schema and generate VTL (Velocity Templates) for mapping resolvers and CloudFormation templates to allocate AWS resources."
      },
      {
        "heading": "Troubleshooting \"amplify push\" failures",
        "depth": 2,
        "text": "It builds, packages, and uploads the deployment artifacts into the application's deployment bucket."
      },
      {
        "heading": "Troubleshooting \"amplify push\" failures",
        "depth": 2,
        "text": "It uses the AWS CloudFormation SDK to deploy the CloudFormation stack into your AWS account."
      },
      {
        "heading": "Troubleshooting \"amplify push\" failures",
        "depth": 2,
        "text": "On a successful deployment of the resources to AWS, the Amplify CLI renames the deployment package in the deployment bucket to #current-cloud-backend.zip. This file is the source of truth for your deployment."
      },
      {
        "heading": "Troubleshooting \"amplify push\" failures",
        "depth": 2,
        "text": "If your local project is deleted or corrupted, you can always go back to your last successful deployment using amplify pull."
      },
      {
        "heading": "Troubleshooting \"amplify push\" failures",
        "depth": 2,
        "text": "** This table shows the important files and folders in the Amplify deployment bucket **"
      },
      {
        "heading": "Troubleshooting \"amplify push\" failures",
        "depth": 2,
        "text": "|Name|Type|Purpose|\n|-|-|-|\n|#current-cloud-backend.zip|zip file|Source of truth for the Amplify project.|\n|amplify-appsync-files/ |folder| GraphQL API deployment artifacts (VTL resolvers, CloudFormation) |\n|amplify-cfn-templates/ |folder| CloudFormation templates generated by Amplify for each resource category |\n|amplify-meta.json| file | Used by CLI core and the plugins to log internal information and to communicate with each other |\n|backend-config.json | file | Configuration about how your project's backend connects to AWS resources |\n|hooks/ | folder | User provided Amplify hooks scripts |\n|root-cloudformation-stack.json | file | The parent CloudFormation template for your application's nested stack |"
      },
      {
        "heading": "Troubleshooting \"amplify push\" failures",
        "depth": 2,
        "text": "** The following sections contain examples of different types of \"amplify push\" failures and suggested resolutions **"
      },
      {
        "heading": "Push failures from unmanaged changes to cloud resources - Drift",
        "depth": 3,
        "text": "Warning: Once an application is deployed to the cloud using Amplify CLI the cloud resources like DynamoDB tables, Cognito Roles, or IAM policies must never be updated outside of Amplify CLI or Amplify Studio."
      },
      {
        "heading": "Push failures from unmanaged changes to cloud resources - Drift",
        "depth": 3,
        "text": "A change to Amplify-generated resource from outside of Amplify, such as using the AWS console, is called an \"unmanaged change\".\nThe Amplify CLI cannot track such changes made outside of the Amplify-generated CloudFormation stack.\nThis difference between the expected configuration of the resource in the Cloudformation versus the actual configuration of the service is called a “CloudFormation drift”.\nCurrently there is no automated way to reverse a CloudFormation drift. Each resource must be inspected through the AWS console for drift in its CloudFormation stack and the drift has to be resolved manually."
      },
      {
        "heading": "Push failures from unmanaged changes to cloud resources - Drift",
        "depth": 3,
        "text": "Upon deployment, the Amplify-generated CloudFormation templates provision an AppSync GraphQL API and multiple DynamoDB tables with their GSIs."
      },
      {
        "heading": "Scenario 1: \"amplify push\" fails after manually updating DynamoDB tables and GSIs from the console.",
        "depth": 4,
        "text": "Assume you have an application with a GraphQL schema deployed to the cloud.\nAmplify creates DynamoDB tables for all @model types and GSIs for all @index fields in the GraphQL schema.\n\"Drift\" is introduced if you delete any of the GSIs using the DynamoDB console, instead of using the Amplify CLI.\nWith drift, future changes to the GraphQL schema may fail to deploy.\nAs an example, if you change the names of some @model types and @index fields in your GraphQL schema and perform the amplify push --allow-destructive-graphql-schema-updates command, Amplify will first remove all DynamoDB tables corresponding to the original model names.\nHowever if any of these tables' GSIs were already deleted manually from the console, then the deployment will fail. This is because Amplify’s CloudFormation stack is attempting to update the state of a resource (the GSI) which doesn’t exist."
      },
      {
        "heading": "Scenario 1: \"amplify push\" fails after manually updating DynamoDB tables and GSIs from the console.",
        "depth": 4,
        "text": "Suggested Resolution:\nTo fix deployment failures due to drift in DynamoDB tables, manually rollback the state of the drifted resource to match its state in CloudFormation. Then retry amplify push."
      },
      {
        "heading": "Scenario 1: \"amplify push\" fails after manually updating DynamoDB tables and GSIs from the console.",
        "depth": 4,
        "text": "You can view the drift in the DynamoDB CloudFormation Stack per instructions in the AWS drift detection documentation"
      },
      {
        "heading": "Scenario 1: \"amplify push\" fails after manually updating DynamoDB tables and GSIs from the console.",
        "depth": 4,
        "text": "Revert every drift manually through the AWS console. In this particular scenario, re-create the GSIs and manually undo any renaming changes."
      },
      {
        "heading": "Scenario 1: \"amplify push\" fails after manually updating DynamoDB tables and GSIs from the console.",
        "depth": 4,
        "text": "Perform an amplify push."
      },
      {
        "heading": "Scenario 2: \"amplify push\" fails after unmanaged updates to non-database resources in the cloud.",
        "depth": 4,
        "text": "Assume you have an application with a GraphQL schema deployed to the cloud using Amplify CLI.\nYou then have performed one or more of the following types of changes"
      },
      {
        "heading": "Scenario 2: \"amplify push\" fails after unmanaged updates to non-database resources in the cloud.",
        "depth": 4,
        "text": "Updated your GraphQL schema using the AppSync console, or"
      },
      {
        "heading": "Scenario 2: \"amplify push\" fails after unmanaged updates to non-database resources in the cloud.",
        "depth": 4,
        "text": "Deleted user pools created by Amplify from the Cognito console, or"
      },
      {
        "heading": "Scenario 2: \"amplify push\" fails after unmanaged updates to non-database resources in the cloud.",
        "depth": 4,
        "text": "Updated the code in Lambda functions which were originally deployed through Amplify.\nThese types of unmanaged changes will introduce a drift for the affected resources. Therefore subsequent updates to these resources using Amplify will most likely fail deployment."
      },
      {
        "heading": "Scenario 2: \"amplify push\" fails after unmanaged updates to non-database resources in the cloud.",
        "depth": 4,
        "text": "Suggested Resolution:\nThese types of drifts must be addressed on a case-by-case basis. In some cases, such as a Lambda code change, forcing a redeployment of the function by making a minor change to the code will likely work.\nIn other cases, like deleting a user pool or updates to GraphQL schema from the AppSync console, follow the steps below:"
      },
      {
        "heading": "Scenario 2: \"amplify push\" fails after unmanaged updates to non-database resources in the cloud.",
        "depth": 4,
        "text": "Force a new CloudFormation stack deployment - Run amplify push --force to force push the application's resources."
      },
      {
        "heading": "Scenario 2: \"amplify push\" fails after unmanaged updates to non-database resources in the cloud.",
        "depth": 4,
        "text": "Forcible deployment of CloudFormation stack from the Console - Fetch the CloudFormation stack from the \"amplify-cfn-templates\" folder in the application’s deployment bucket and selectively update the stack through the CloudFormation console as described in (AWS CloudFormation - updating stacks documentation)[https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks-direct.html]."
      },
      {
        "heading": "Scenario 2: \"amplify push\" fails after unmanaged updates to non-database resources in the cloud.",
        "depth": 4,
        "text": "Apply drift changes into code - If methods above failed, the other option is to inspect the manual changes and to update them in the CLI input files.\nFor example, you could update the GraphQL schema to reflect the same changes as performed manually in the cloud and then perform amplify push."
      },
      {
        "heading": "Push failures in a multi-account multi-environment project (CI/CD errors)",
        "depth": 3,
        "text": "Errors:"
      },
      {
        "heading": "Push failures in a multi-account multi-environment project (CI/CD errors)",
        "depth": 3,
        "text": "\"There was an error initializing your environment.”\"!!! Build failed\"\n\"!!! Non-Zero Exit Code detected\""
      },
      {
        "heading": "Push failures in a multi-account multi-environment project (CI/CD errors)",
        "depth": 3,
        "text": "In a multi-account project with CI/CD, you find that the application has deployed successfully in one account but has failed deployment in another account.\nThe following are some common causes:"
      },
      {
        "heading": "Push failures in a multi-account multi-environment project (CI/CD errors)",
        "depth": 3,
        "text": "Some resource being referenced in the Amplify-generated CloudFormation is missing from the failing account."
      },
      {
        "heading": "Push failures in a multi-account multi-environment project (CI/CD errors)",
        "depth": 3,
        "text": "The failing account is missing permissions to access a particular resource used in the CloudFormation."
      },
      {
        "heading": "Push failures in a multi-account multi-environment project (CI/CD errors)",
        "depth": 3,
        "text": "The application code relies on “secrets” that are not correctly created or copied in the failing environment."
      },
      {
        "heading": "Scenario 1: \"amplify push\" fails in one account/environment",
        "depth": 4,
        "text": "Assume you created a project in a “dev” account and you extend your deployment environment to a full CI/CD pipeline with dev, beta, and prod environments.\nYour project likely follows a pattern specified in the Amplify CLI team environments guide.\nOn completion of all steps, you observe that the Amplify Hosting console displays the “build” step of one of your environments, such as \"beta\", as failed and shows other environments as successfully deployed."
      },
      {
        "heading": "Scenario 1: \"amplify push\" fails in one account/environment",
        "depth": 4,
        "text": "Suggested Resolution:\nUsing Amplify CLI deploy the application in the failing account. In the above case, the dev environment has successfully deployed but the beta environment has failed.\nFirst, get the App ID from your dev environment. You can find your App ID under the \"Edit backend\" section of your application's dev environment in the Amplify console.\nPerform the following steps to fetch the app from the dev environment and deploy it into the beta environment."
      },
      {
        "heading": "Scenario 1: \"amplify push\" fails in one account/environment",
        "depth": 4,
        "text": "amplify pull --appId <YOUR_APP_ID> --envName dev"
      },
      {
        "heading": "Scenario 1: \"amplify push\" fails in one account/environment",
        "depth": 4,
        "text": "amplify env checkout beta"
      },
      {
        "heading": "Scenario 1: \"amplify push\" fails in one account/environment",
        "depth": 4,
        "text": "amplify push"
      },
      {
        "heading": "Scenario 1: \"amplify push\" fails in one account/environment",
        "depth": 4,
        "text": "If amplify push fails, check the CloudFormation event logs for the failing resource to get detailed information to fix the issues in the failing environment.\nIn the AWS CloudFormation console, search for your application's stack name. For instance, if your application was named \"lil\" and deployed in your \"dev\" environment,\nAmplify would have generated a CloudFormation stack named amplify-lil-dev-{random chars}.\nIn the CloudFormation console, click on the application's stack name and then click on the \"Resources\" tab.\nThe \"Resources\" tab displays the deployment status of all the resources in the stack. It will also show the deployment error reason.\nRefer to the CloudFormation troubleshooting document to gain insight into the error messages."
      },
      {
        "heading": "Scenario 1: \"amplify push\" fails in one account/environment",
        "depth": 4,
        "text": "Note:\nTo debug any issues related to secrets not being correctly copied across environments, refer to Multi-environment flows section in the Access secret values documentation."
      },
      {
        "heading": "Scenario 1: \"amplify push\" fails in one account/environment",
        "depth": 4,
        "text": ""
      },
      {
        "heading": "Push failures from resources exceeding AWS service quotas",
        "depth": 3,
        "text": "Errors:"
      },
      {
        "heading": "Push failures from resources exceeding AWS service quotas",
        "depth": 3,
        "text": "\"Limit on the number of resources in a single stack operation exceeded”\"Cannot exceed quota for PoliciesPerRole\""
      },
      {
        "heading": "Push failures from resources exceeding AWS service quotas",
        "depth": 3,
        "text": "AWS maintains service quotas for various AWS services. If your application contains many resources, such as large GraphQL schemas with many resolvers or many REST APIs, you may hit a service limit.\nTo identify if exceeding an AWS Service level quotas caused a deployment failure, check the AWS console for the CloudFormation deployment/failure logs."
      },
      {
        "heading": "Push failures from resources exceeding AWS service quotas",
        "depth": 3,
        "text": "Suggested Resolution:"
      },
      {
        "heading": "Push failures from resources exceeding AWS service quotas",
        "depth": 3,
        "text": "If your application's resource requirements are impaired by AWS service quotas, you can use the AWS Service Quotas console to view and request increases for most AWS quotas."
      },
      {
        "heading": "Push failures from resources exceeding AWS service quotas",
        "depth": 3,
        "text": "If you are using the Amplify DataStore, refer to Amplify DataStore Best Practices for insights into making the correct design decisions and optimize resource allocation in your application."
      },
      {
        "heading": "Push failures from resources exceeding AWS service quotas",
        "depth": 3,
        "text": "If the service quotas cannot be increased, then this may require you to redesign some aspects of your application for sustainable scaling in a serverless environment. Referring to AWS Knowledge Center may help understand the different prescribed design changes. For example, a complex GraphQL schema could be simplified to reduce the number of GraphQL resources in use e.g rewriting the schema to have less models. Using escape hatches like overrides and export may help to scale the application beyond the CLI generated architecture."
      },
      {
        "heading": "Scenario 1: Optimizing REST API schema for reducing policy count:",
        "depth": 4,
        "text": "Assume you have deployed a REST API using Amplify CLI with many routes and one Lambda to handle all routes.\nAmplify CLI in this case generates one policy per route and applies it to the Lambda execution role. Therefore in this configuration, the max number of allowed routes is limited by the “Max policies per role” limit in AWS IAM limits.\nThe following table shows the distribution of policies with regards to routes in such a configuration.\nNote: The term \"Resource\" represents an API Gateway resource allocated to service the \"Route\"."
      },
      {
        "heading": "Scenario 1: Optimizing REST API schema for reducing policy count:",
        "depth": 4,
        "text": "|Resources\t|Policies|\tRole|\tHandler|\n|-|-|-|-|\n|/items/rock|\tamplify generated policy1\t| | |\n|/items/paper| amplify generated policy2 |Lambda Execution Role | Lambda function |\n|/items/scissors|\tamplify generated policy3 || |"
      },
      {
        "heading": "Scenario 1: Optimizing REST API schema for reducing policy count:",
        "depth": 4,
        "text": "However, if your application has many routes, one way to reduce the number of policies generated is by creating a single route resource and to support additional paths as query parameters:\n/items?item=rock, /items?item=paper, /items?item=scissors\nIn this case the Amplify CLI creates only 1 policy for the /items resource."
      },
      {
        "heading": "Scenario 1: Optimizing REST API schema for reducing policy count:",
        "depth": 4,
        "text": "|Resources\t|Policies|\tRole|\tHandler|\n|-|-|-|-|\n|/items| amplify generated policy1\t| Lambda Execution Role | Lambda function |"
      },
      {
        "heading": "Push failures from GraphQL schema syntax errors",
        "depth": 3,
        "text": "Errors:"
      },
      {
        "heading": "Push failures from GraphQL schema syntax errors",
        "depth": 3,
        "text": "“Schema validation failed”, “Unknown directive\""
      },
      {
        "heading": "Push failures from GraphQL schema syntax errors",
        "depth": 3,
        "text": "After making any GraphQL schema changes, run amplify api gql-compile to ensure that the schema is valid and Amplify is able to generate correct CloudFormation templates from the GraphQL schema. Refer to the Amplify CLI GraphQL documentation to understand the latest Amplify GraphQL directives."
      },
      {
        "heading": "Scenario 1: GraphQL Schema errors",
        "depth": 4,
        "text": "Assume your GraphQL schema has an error where the directive \"@model\" is misspelled as \"@mode\":"
      },
      {
        "heading": "Scenario 1: GraphQL Schema errors",
        "depth": 4,
        "text": "When running amplify api gql-compile the transform step will fail with an invalid directive error."
      },
      {
        "heading": "Scenario 1: GraphQL Schema errors",
        "depth": 4,
        "text": ""
      },
      {
        "heading": "Troubleshooting other GraphQL schema related errors",
        "depth": 3,
        "text": "If amplify push fails while deploying any of the scenarios below, refer to the Amplify GraphQL Troubleshooting Guide."
      },
      {
        "heading": "Troubleshooting other GraphQL schema related errors",
        "depth": 3,
        "text": "Deploying multiple index changes in a single amplify push"
      },
      {
        "heading": "Troubleshooting other GraphQL schema related errors",
        "depth": 3,
        "text": "Backfill OpenSearch index from DynamoDB table"
      },
      {
        "heading": "Troubleshooting other GraphQL schema related errors",
        "depth": 3,
        "text": "Index with Multi-Sort Key Fields"
      },
      {
        "heading": "Deployment Best Practices",
        "depth": 2,
        "text": "This section describes the various best practices which help developers avoid deployment errors and scaling problems in their Amplify applications."
      },
      {
        "heading": "Overriding Amplify CLI default behavior",
        "depth": 3,
        "text": "Any changes to your application must be performed only through the Amplify CLI and the associated configuration files or through Amplify Studio. Never manually edit any resources directly from the AWS console or using the AWS CLI/SDK, unless explicitly noted. To override the Amplify-generated resources beyond the customizations available within an Amplify CLI command, you must follow the instructions in the Amplify extensibility documentation which details all the “escape hatches” available in the Amplify CLI."
      },
      {
        "heading": "Understanding the impact of changing model names in the GraphQL Schema",
        "depth": 3,
        "text": "Errors:"
      },
      {
        "heading": "Understanding the impact of changing model names in the GraphQL Schema",
        "depth": 3,
        "text": "“An error occurred during the push operation: Removing a model from the GraphQL schema will also remove the underlying DynamoDB table”\n“ALL EXISTING DATA IN THESE TABLES WILL BE LOST!”"
      },
      {
        "heading": "Understanding the impact of changing model names in the GraphQL Schema",
        "depth": 3,
        "text": "Amplify automatically creates DynamoDB database tables for GraphQL types annotated with the @model directive in your GraphQL schema.\nTherefore if you rename models in the GraphQL Schema, to protect the application data from accidental deletion, the Amplify CLI will block subsequent amplify push operations and prompt you to explicitly pass the --allow-destructive-graphql-schema-updates flag.\nThis flag grants Amplify CLI the ability to make destructive database changes, such as deleting the DynamoDB tables for the original model names and create new tables with the new model names specified in the schema.\nAmplify currently doesn't support automatic data migration. If the data in the original tables is required, then you will need to backup the DynamoDB tables and migrate the data after the destructive deployment of the new tables."
      },
      {
        "heading": "Understanding the impact of changing model names in the GraphQL Schema",
        "depth": 3,
        "text": ""
      },
      {
        "heading": "Migration from GraphQL transformer V1 to V2",
        "depth": 3,
        "text": "If you have previously deployed an application using GraphQL transformer V1 and have decided to migrate to GraphQL transformer V2, go through the GraphQL transformer migration documentation to understand the impact of the migration on the schema directives and limitations prior to updating.\nYou can confirm the version of the GraphQL transformer using the amplify status command. You can also inspect the transformerversion feature flag in ${project-root}/amplify/cli.json, to confirm."
      },
      {
        "heading": "Local testing",
        "depth": 3,
        "text": "Test schema changes and business logic as much as you can prior to deployment. The amplify mock command allows validation of your cloud dependencies locally. Follow the mock testing examples in Advanced workflows documentation to dive deeper."
      },
      {
        "heading": "Further reading",
        "depth": 2,
        "text": "|Amplify CLI troubleshooting Guides|Description|\n|-|-|\n|Amplify CLI GraphQL troubleshooting| Troubleshoot and fix issues encountered when deploying GraphQL Schema through Amplify CLI|\n|Amplify Console custom domain troubleshooting|Troubleshoot and fix issues encountered when adding Custom Domains to your Apps from the Amplify Console |\n|IAM troubleshooting|Troubleshoot and fix common issues encountered when working with Amplify and IAM.|\n|Amplify CLI extensibility | Learn about the different escape hatches provided by the Amplify CLI to extend your application and override default behavior |\n|Amplify DataStore best practices | Learn the best practices to build your applications 'Offline First' using Amplify DataStore |\n|AWS knowledge center | Learn about the most frequent questions and requests for your AWS services |\n|AWS CloudFormation drift | Detect and View CloudFormation Drift |"
      },
      {
        "heading": "Contacting support",
        "depth": 2,
        "text": "Search for similar issues or open new issues on Github"
      },
      {
        "heading": "Contacting support",
        "depth": 2,
        "text": "amplify-cli issues"
      },
      {
        "heading": "Contacting support",
        "depth": 2,
        "text": "amplify-codegen issues"
      },
      {
        "heading": "Contacting support",
        "depth": 2,
        "text": "amplify-console issues"
      },
      {
        "heading": "Contacting support",
        "depth": 2,
        "text": "Connect with AWS Enterprise support"
      },
      {
        "heading": "Contacting support",
        "depth": 2,
        "text": "Join our community Discord Channel"
      }
    ],
    "source": "export const meta = {\n  title: `Troubleshooting guide`,\n  description: `Information to troubleshoot common Amplify CLI project errors.`,\n};\n\nThis troubleshooting guide provides guidance to developers to detect and correct common errors encountered during development, deployment, and migration of applications built using the Amplify CLI.\n\n## Essential reading\n\n### For all Amplify CLI projects \nTo debug deployment issues, it's helpful to understand the [file structure of your Amplify-generated project](/cli/reference/files/) and the artifacts generated by the Amplify CLI.\n1. Amplify CloudFormation artifacts: The Amplify CLI provisions AWS resources using [CloudFormation templates](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/Welcome.html) and the input parameters provided by the user during the CLI walkthrough. Starting with Amplify CLI version 7 and above, some categories (Storage, Auth, API) allow developers to override the Amplify-generated AWS resource configurations with the [Amplify CLI Overrides feature](/cli/project/override/).\n\n1. Amplify CLI walkthrough input parameters artifacts: All inputs provided by the user during a CLI walkthrough are stored in JSON files in the `/amplify/backend` folder. For example, `cli-inputs.json` or `amplify-meta.json`. These files let you inspect the configurations, both developer-provided and Amplify-generated, to root cause potential problems. \n   Refer to [Amplify backend files documentation](/cli/reference/files/#backend-configjson) to determine if a file is safe to edit manually.\n\n### For Amplify CLI projects with GraphQL API\nTo debug deployment issues in projects with GraphQL API, it's helpful to understand the various artifacts generated by Amplify in a GraphQL project. \n1. GraphQL schema VTL generation: The Amplify CLI GraphQL workflow uses the [AWS AppSync service](https://docs.aws.amazon.com/appsync/latest/devguide/system-overview-and-architecture.html) to provision the GraphQL API. The `amplify api gql-compile` command transpiles the GraphQL schema provided by the developer and generates all the artifacts required to deploy the API in AWS. \n   * Directives like [@model](/cli/graphql/data-modeling/), [@function](/cli/graphql-transformer/function/), [@auth](/cli/graphql/authorization-rules/), and [@searchable](/cli/graphql/search-and-result-aggregations/) in the GraphQL schema are used to generate CloudFormation and provision AWS resources.\n   * The GraphQL resolvers for Query, Mutation or Subscription are converted into [VTL (Velocity Template Language)](https://docs.aws.amazon.com/appsync/latest/devguide/resolver-mapping-template-reference-programming-guide.html) files. AWS AppSync uses VTL to translate GraphQL requests from clients into a request to your data source.\n1. GraphQL schema client-side code generation: The Amplify CLI GraphQL workflow allows developers to generate client-side code for web and mobile clients using the `amplify codegen` command. \n   Read the [Amplify code generation documentation](/cli/graphql/client-code-generation/) prior to debugging any client-side code generation issues. \n\n## Troubleshooting \"amplify push\" failures\n<Callout>\n\n**Errors:**\n\n“An error occurred during the push operation”\n</Callout>\n\nThe [`amplify push`](/cli/start/workflows/#amplify-push) command performs the following steps:\n\n1. It generates CloudFormation for deployment of resources to AWS.\n1. If the application contains a GraphQL API, the CLI runs `amplify api gql-compile` internally to compile the schema and generate VTL (Velocity Templates) for mapping resolvers and CloudFormation templates to allocate AWS resources. \n1. It builds, packages, and uploads the deployment artifacts into the application's deployment bucket. \n1. It uses the AWS CloudFormation SDK to deploy the CloudFormation stack into your AWS account.\n1. On a successful deployment of the resources to AWS, the Amplify CLI renames the deployment package in the deployment bucket to `#current-cloud-backend.zip`. This file is the source of truth for your deployment.\n1. If your local project is deleted or corrupted, you can always go back to your last successful deployment using [`amplify pull`](/cli/start/workflows/#amplify-pull).\n\n** This table shows the important files and folders in the Amplify deployment bucket **\n\n|Name|Type|Purpose|\n|-|-|-|\n|#current-cloud-backend.zip|zip file|Source of truth for the Amplify project.|\n|amplify-appsync-files/ |folder| GraphQL API deployment artifacts (VTL resolvers, CloudFormation) |\n|amplify-cfn-templates/ |folder| CloudFormation templates generated by Amplify for each resource category |\n|amplify-meta.json| file | Used by CLI core and the plugins to log internal information and to communicate with each other |\n|backend-config.json | file | Configuration about how your project's backend connects to AWS resources | \n|hooks/ | folder | User provided Amplify hooks scripts |\n|root-cloudformation-stack.json | file | The parent CloudFormation template for your application's nested stack |\n\n\n** The following sections contain examples of different types of \"amplify push\" failures and suggested resolutions **\n\n### Push failures from unmanaged changes to cloud resources - Drift \n<Callout warning>\n\n**Warning:** Once an application is deployed to the cloud using Amplify CLI the cloud resources like DynamoDB tables, Cognito Roles, or IAM policies must never be updated outside of Amplify CLI or Amplify Studio.\n\n</Callout>\n\nA change to Amplify-generated resource from outside of Amplify, such as using the AWS console, is called an \"unmanaged change\".\nThe Amplify CLI cannot track such changes made outside of the Amplify-generated CloudFormation stack. \nThis difference between the expected configuration of the resource in the Cloudformation versus the actual configuration of the service is called a “CloudFormation drift”. \nCurrently there is no automated way to reverse a CloudFormation drift. Each resource must be inspected through the AWS console for drift in its CloudFormation stack and the drift has to be resolved manually.\n\nUpon deployment, the Amplify-generated CloudFormation templates provision an AppSync GraphQL API and multiple DynamoDB tables with their GSIs. \n\n#### Scenario 1: \"amplify push\" fails after manually updating DynamoDB tables and GSIs from the console.\nAssume you have an application with a GraphQL schema deployed to the cloud. \nAmplify creates DynamoDB tables for all [@model]((/cli/graphql/data-modeling/)) types and GSIs for all [@index]((/cli/graphql/data-modeling/)) fields in the GraphQL schema. \n\"Drift\" is introduced if you delete any of the GSIs using the DynamoDB console, instead of using the Amplify CLI.\nWith drift, future changes to the GraphQL schema may fail to deploy. \nAs an example, if you change the names of some `@model` types and `@index` fields in your GraphQL schema and perform the `amplify push --allow-destructive-graphql-schema-updates` command, Amplify will first remove all DynamoDB tables corresponding to the original model names. \nHowever if any of these tables' GSIs were already deleted manually from the console, then the deployment will fail. This is because Amplify’s CloudFormation stack is attempting to update the state of a resource (the GSI) which doesn’t exist. \n\n\n**Suggested Resolution:**\nTo fix deployment failures due to drift in DynamoDB tables, manually rollback the state of the drifted resource to match its state in CloudFormation. Then retry `amplify push`. \n1. You can view the drift in the DynamoDB CloudFormation Stack per instructions in the [AWS drift detection documentation](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/detect-drift-stack.html)\n1. Revert every drift manually through the AWS console. In this particular scenario, re-create the GSIs and manually undo any renaming changes.\n1. Perform an `amplify push`.\n\n#### Scenario 2: \"amplify push\" fails after unmanaged updates to non-database resources in the cloud.\n\nAssume you have an application with a GraphQL schema deployed to the cloud using Amplify CLI. \nYou then have performed one or more of the following types of changes  \n1. Updated your GraphQL schema using the AppSync console, or\n2. Deleted user pools created by Amplify from the Cognito console, or\n3. Updated the code in Lambda functions which were originally deployed through Amplify.\nThese types of unmanaged changes will introduce a drift for the affected resources. Therefore subsequent updates to these resources using Amplify will most likely fail deployment.\n\n**Suggested Resolution:** \nThese types of drifts must be addressed on a case-by-case basis. In some cases, such as a Lambda code change, forcing a redeployment of the function by making a minor change to the code will likely work. \nIn other cases, like deleting a user pool or updates to GraphQL schema from the AppSync console, follow the steps below:\n1. Force a new CloudFormation stack deployment - Run `amplify push --force` to force push the application's resources.\n1. Forcible deployment of CloudFormation stack from the Console - Fetch the CloudFormation stack from the \"amplify-cfn-templates\" folder in the application’s deployment bucket and selectively update the stack through the CloudFormation console as described in (AWS CloudFormation - updating stacks documentation)[https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks-direct.html].\n1. Apply drift changes into code - If methods above failed, the other option is to inspect the manual changes and to update them in the CLI input files. \nFor example, you could update the GraphQL schema to reflect the same changes as performed manually in the cloud and then perform `amplify push`.\n\n### Push failures in a multi-account multi-environment project (CI/CD errors)\n<Callout>\n\n**Errors:** \n\n\"There was an error initializing your environment.”  \n\"!!! Build failed\"\n\"!!! Non-Zero Exit Code detected\"\n</Callout>\n\nIn a multi-account project with CI/CD, you find that the application has deployed successfully in one account but has failed deployment in another account. \nThe following are some common causes:\n1. Some resource being referenced in the Amplify-generated CloudFormation is missing from the failing account. \n1. The failing account is missing permissions to access a particular resource used in the CloudFormation. \n1. The application code relies on “secrets” that are not correctly created or copied in the failing environment.\n\n#### Scenario 1: \"amplify push\" fails in one account/environment\nAssume you created a project in a “dev” account and you extend your deployment environment to a full CI/CD pipeline with dev, beta, and prod environments. \nYour project likely follows a pattern specified in the [Amplify CLI team environments guide](/cli/teams/overview/#setting-up-prod-and-dev-environments). \nOn completion of all steps, you observe that the Amplify Hosting console displays the “build” step of one of your environments, such as \"beta\", as failed and shows other environments as successfully deployed.\n\n**Suggested Resolution:** \nUsing Amplify CLI deploy the application in the failing account. In the above case, the dev environment has successfully deployed but the beta environment has failed. \nFirst, get the App ID from your dev environment. You can find your App ID under the \"Edit backend\" section of your application's dev environment in the Amplify console.\nPerform the following steps to fetch the app from the dev environment and deploy it into the beta environment.\n\n1. `amplify pull --appId <YOUR_APP_ID> --envName dev`\n1. `amplify env checkout beta`\n1. `amplify push` \n\nIf `amplify push` fails, check the CloudFormation event logs for the failing resource to get detailed information to fix the issues in the failing environment. \nIn the AWS CloudFormation console, search for your application's stack name. For instance, if your application was named \"lil\" and deployed in your \"dev\" environment, \nAmplify would have generated a CloudFormation stack named `amplify-lil-dev-{random chars}`.\nIn the CloudFormation console, click on the application's stack name and then click on the \"Resources\" tab. \nThe \"Resources\" tab displays the deployment status of all the resources in the stack. It will also show the deployment error reason. \nRefer to the [CloudFormation troubleshooting document](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/troubleshooting.html#basic-ts-guide) to gain insight into the error messages.\n\n**Note:**\nTo debug any issues related to secrets not being correctly copied across environments, refer to [Multi-environment flows](/cli/function/secrets/#multi-environment-flows) section in the [Access secret values](/cli/function/secrets) documentation. \n\n![CloudFormation status logs for a deployment failure of a resource](/images/ts-guide-cfn-error.png)\n\n### Push failures from resources exceeding AWS service quotas\n<Callout information>\n\n**Errors:** \n\n\"Limit on the number of resources in a single stack operation exceeded”  \n\"Cannot exceed quota for PoliciesPerRole\"\n</Callout>\n\nAWS maintains [service quotas](/general/latest/gr/aws-service-information.html) for various AWS services. If your application contains many resources, such as large GraphQL schemas with many resolvers or many REST APIs, you may hit a service limit.\nTo identify if exceeding an [AWS Service level quotas](/general/latest/gr/aws-service-information.html) caused a deployment failure, check the AWS console for the CloudFormation deployment/failure logs.\n\n**Suggested Resolution:** \n1. If your application's resource requirements are impaired by AWS service quotas, you can use the [AWS Service Quotas console](https://console.aws.amazon.com/servicequotas) to view and request increases for most AWS quotas.\n1. If you are using the Amplify DataStore, refer to [Amplify DataStore Best Practices](https://docs.aws.amazon.com/whitepapers/latest/amplify-datastore-implementation/amplify-datastore-best-practices.html) for insights into making the correct design decisions and optimize resource allocation in your application. \n1. If the service quotas cannot be increased, then this may require you to redesign some aspects of your application for sustainable scaling in a serverless environment. Referring to [AWS Knowledge Center](https://aws.amazon.com/premiumsupport/knowledge-center/) may help understand the different prescribed design changes. For example, a complex GraphQL schema could be simplified to reduce the number of GraphQL resources in use e.g rewriting the schema to have less models. Using escape hatches like [overrides](/cli/#extensibility) and [export](/cli/usage/export-to-cdk/) may help to scale the application beyond the CLI generated architecture. \n\n#### Scenario 1: Optimizing REST API schema for reducing policy count:\nAssume you have deployed a REST API using Amplify CLI with many routes and one Lambda to handle all routes. \nAmplify CLI in this case generates one policy per route and applies it to the Lambda execution role. Therefore in this configuration, the max number of allowed routes is limited by the “Max policies per role” limit in [AWS IAM limits](https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_iam-limits.html).\nThe following table shows the distribution of policies with regards to routes in such a configuration.\n**Note:** The term \"Resource\" represents an [API Gateway resource](https://docs.aws.amazon.com/apigateway/api-reference/resource/resource/) allocated to service the \"Route\". \n\n|Resources\t|Policies|\tRole|\tHandler|\n|-|-|-|-|\n|/items/rock|\tamplify generated policy1\t| | |\n|/items/paper| amplify generated policy2 |Lambda Execution Role | Lambda function |\n|/items/scissors|\tamplify generated policy3 || |\t\t\n\nHowever, if your application has many routes, one way to reduce the number of policies generated is by creating a single route resource and to support additional paths as query parameters:\n`/items?item=rock, /items?item=paper, /items?item=scissors` \nIn this case the Amplify CLI creates only 1 policy for the /items resource.\n\n|Resources\t|Policies|\tRole|\tHandler|\n|-|-|-|-|\n|/items| amplify generated policy1\t| Lambda Execution Role | Lambda function |\n\n### Push failures from GraphQL schema syntax errors\n<Callout>\n\n**Errors:** \n\n“Schema validation failed”, “Unknown directive\"\n</Callout>\nAfter making any GraphQL schema changes, run `amplify api gql-compile` to ensure that the schema is valid and Amplify is able to generate correct CloudFormation templates from the GraphQL schema. Refer to the [Amplify CLI GraphQL documentation](/cli/graphql/overview/) to understand the latest Amplify GraphQL directives.\n\n#### Scenario 1: GraphQL Schema errors\n\nAssume your GraphQL schema has an error where the directive \"@model\" is misspelled as \"@mode\":\n```graphql\ntype Tag @mode { /** @mode is an invalid directive **/\n  id : ID!\n  tag: String\n  topics: [Topic]\n}\n```\n\nWhen running `amplify api gql-compile` the transform step will fail with an invalid directive error. \n\n![Amplify GraphQL schema validation error](/images/ts-guide-gql-schema-validation-error.png)\n\n### Troubleshooting other GraphQL schema related errors \nIf `amplify push` fails while deploying any of the scenarios below, refer to the [Amplify GraphQL Troubleshooting Guide](/cli/graphql/troubleshooting/).\n1.\t[Deploying multiple index changes in a single `amplify push`](/cli/graphql/troubleshooting/#deploying-multiple-index-changes-at-once)\n1.\t[Backfill OpenSearch index from DynamoDB table](/cli/graphql/troubleshooting/#deploying-multiple-index-changes-at-once)\n1.\t[Index with Multi-Sort Key Fields](/cli/graphql/troubleshooting/#index-with-multiple-sort-key-fields)\n\n## Deployment Best Practices\nThis section describes the various best practices which help developers avoid deployment errors and scaling problems in their Amplify applications.\n\n### Overriding Amplify CLI default behavior \nAny changes to your application must be performed only through the Amplify CLI and the associated configuration files or through Amplify Studio. Never manually edit any resources directly from the AWS console or using the AWS CLI/SDK, unless explicitly noted. To override the Amplify-generated resources beyond the customizations available within an Amplify CLI command, you must follow the instructions in the [Amplify extensibility documentation](/cli/#extensibility) which details all the “escape hatches” available in the Amplify CLI. \n\n### Understanding the impact of changing model names in the GraphQL Schema \n<Callout>\n\n**Errors:** \n\n“An error occurred during the push operation: Removing a model from the GraphQL schema will also remove the underlying DynamoDB table” \n“ALL EXISTING DATA IN THESE TABLES WILL BE LOST!”\n</Callout>\n\nAmplify automatically creates DynamoDB database tables for GraphQL types annotated with the @model directive in your GraphQL schema. \nTherefore if you rename models in the GraphQL Schema, to protect the application data from accidental deletion, the Amplify CLI will block subsequent `amplify push` operations and prompt you to explicitly pass the `--allow-destructive-graphql-schema-updates` flag. \nThis flag grants Amplify CLI the ability to make destructive database changes, such as deleting the DynamoDB tables for the original model names and create new tables with the new model names specified in the schema. \nAmplify currently doesn't support automatic data migration. If the data in the original tables is required, then you will need to backup the DynamoDB tables and migrate the data after the destructive deployment of the new tables. \n\n![Amplify GraphQL model deletion warning](/images/ts-guide-model-deletion-warning.png)\n\n### Migration from GraphQL transformer V1 to V2\nIf you have previously deployed an application using GraphQL transformer V1 and have decided to migrate to GraphQL transformer V2, go through the [GraphQL transformer migration documentation](/cli/migration/transformer-migration/#changes-that-amplify-cli-will-auto-migrate-for-you) to understand the impact of the migration on the schema directives and limitations prior to updating. \nYou can confirm the version of the GraphQL transformer using the `amplify status` command. You can also inspect the `transformerversion` feature flag in `${project-root}/amplify/cli.json`, to confirm.\n\n### Local testing \nTest schema changes and business logic as much as you can prior to deployment. The `amplify mock` command allows validation of your cloud dependencies locally. Follow the mock testing examples in [Advanced workflows documentation](/cli/usage/mock/) to dive deeper.\n\n## Further reading\n|Amplify CLI troubleshooting Guides|Description|\n|-|-|\n|[Amplify CLI GraphQL troubleshooting](/cli/graphql/troubleshooting/)| Troubleshoot and fix issues encountered when deploying GraphQL Schema through Amplify CLI|\n|[Amplify Console custom domain troubleshooting](https://docs.aws.amazon.com/amplify/latest/userguide/custom-domain-troubleshoot-guide.html)|Troubleshoot and fix issues encountered when adding Custom Domains to your Apps from the Amplify Console |\n|[IAM troubleshooting](https://docs.aws.amazon.com/amplify/latest/userguide/security_iam_troubleshoot.html)|Troubleshoot and fix common issues encountered when working with Amplify and IAM.|\n|[Amplify CLI extensibility](/cli/#extensibility) | Learn about the different escape hatches provided by the Amplify CLI to extend your application and override default behavior |\n|[Amplify DataStore best practices](https://docs.aws.amazon.com/whitepapers/latest/amplify-datastore-implementation/amplify-datastore-best-practices.html) | Learn the best practices to build your applications 'Offline First' using Amplify DataStore |\n|[AWS knowledge center](https://aws.amazon.com/premiumsupport/knowledge-center/) | Learn about the most frequent questions and requests for your AWS services |\n|[AWS CloudFormation drift](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-stack-drift.html) | Detect and View CloudFormation Drift |\n\n## Contacting support\n\nSearch for similar issues or open new issues on Github \n* [amplify-cli issues](https://github.com/aws-amplify/amplify-cli/issues)\n* [amplify-codegen issues](https://github.com/aws-amplify/amplify-codegen/issues)\n* [amplify-console issues](https://github.com/aws-amplify/amplify-console)\n\nConnect with [AWS Enterprise support](https://aws.amazon.com/premiumsupport/)\n\nJoin our [community Discord Channel](https://discord.com/invite/amplify)\n\n",
    "meta": {
      "title": "Troubleshooting",
      "description": "Information to troubleshoot common Amplify CLI project errors.",
      "subcategory": "Project-level configurations",
      "category": "Amplify CLI"
    },
    "filename": "/cli/project/troubleshooting"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Run the command above to override Amplify-generated project-level resources, such as IAM roles for authenticated and unauthenticated."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Warning: Due to the deep dependencies on the authenticated and unauthenticated user roles, it is recommended to ONLY modify these resources at the beginning of your project, when no other resources are added yet."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The command creates a new overrides.ts file under amplify/backend/awscloudformation/ which provides you the Amplify-generated resources as CDK constructs."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Apply all the overrides in the override(...) function. For example to rename and add a path for authenticated users' IAM role:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "You can override the following project-level resources that Amplify generates:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "|Amplify-generated resource|Description|\n|-|-|\n|authRole|The IAM role for authenticated access to your app backend|\n|unauthRole|The IAM role for authenticated or guest access to your app backend|"
      },
      {
        "heading": "Example: Modify authRole's IAM policies",
        "depth": 2,
        "text": "For example, use amplify override project to further modify the authRole policy for Geo category beyond the default policy statements:"
      }
    ],
    "source": "export const meta = {\n  title: `Override Amplify-generated project-level IAM roles`,\n  description: `The \"amplify override project\" command generates a developer-configurable \"overrides\" TypeScript file which provides Amplify-generated IAM roles for authenticated and unauthenticated as CDK constructs. For example, developers can run \"amplify override project\" to change the authenticated and unauthenticated IAM role names to comply with organization-specific naming conventions.`,\n};\n\n```bash\namplify override project\n```\n\nRun the command above to override Amplify-generated project-level resources, such as IAM roles for authenticated and unauthenticated.\n\n<Callout warning>\n\n**Warning:** Due to the deep dependencies on the authenticated and unauthenticated user roles, it is recommended to ONLY modify these resources at the beginning of your project, when no other resources are added yet.\n</Callout>\n\nThe command creates a new `overrides.ts` file under `amplify/backend/awscloudformation/` which provides you the Amplify-generated resources as [CDK constructs](https://docs.aws.amazon.com/cdk/latest/guide/home.html).\n\nApply all the overrides in the `override(...)` function. For example to rename and add a path for authenticated users' IAM role:\n```ts\nimport { AmplifyRootStackTemplate } from '@aws-amplify/cli-extensibility-helper';\n\nexport function override(resources: AmplifyRootStackTemplate) {\n  resources.authRole.roleName = \"myCustomName\"\n  resources.authRole.path = \"/<my-organization>/\"\n  // Note: CloudFormation limits you from updating the path if you don't recreate the resource.\n  // Changing the role name will recreate the resource.\n}\n```\n\nYou can override the following project-level resources that Amplify generates:\n\n|Amplify-generated resource|Description|\n|-|-|\n|[authRole](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-role.html)|The IAM role for authenticated access to your app backend|\n|[unauthRole](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-role.html)|The IAM role for authenticated or guest access to your app backend|\n\n\n## Example: Modify authRole's IAM policies\n\nFor example, use `amplify override project` to further modify the authRole policy for Geo category beyond the default policy statements:\n\n```ts\nimport { AmplifyRootStackTemplate } from \"@aws-amplify/cli-extensibility-helper\";\n\nexport function override(resources: AmplifyRootStackTemplate) {\n  const authRole = resources.authRole;\n\n  const basePolicies = Array.isArray(authRole.policies)\n    ? authRole.policies\n    : [authRole.policies];\n\n  authRole.policies = [\n    ...basePolicies,\n    {\n      policyName: \"amplify-permissions-custom-resources\",\n      policyDocument: {\n        Version: \"2012-10-17\",\n        Statement: [\n          //? Route calculator\n          {\n            Resource: \"<ARN of Geo>\",\n            Action: [\"geo:CalculateRoute*\"],\n            Effect: \"Allow\",\n          },\n        ],\n      },\n    },\n  ];\n}\n\n```\n",
    "meta": {
      "title": "Override Amplify-generated project-level IAM resources",
      "description": "The \"amplify override project\" command generates a developer-configurable \"overrides\" TypeScript file which provides Amplify-generated IAM roles for authenticated and unauthenticated as CDK constructs. For example, developers can run \"amplify override project\" to change the authenticated and unauthenticated IAM role names to comply with organization-specific naming conventions.",
      "subcategory": "Project-level configurations",
      "category": "Amplify CLI"
    },
    "filename": "/cli/project/override"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "For a monorepo setup, it is recommended to have the Amplify CLI initialize a new backend at the root of one of your frontend projects. In a different frontend directory, you can run amplify pull and select the Amplify app you want to associate your frontend with."
      },
      {
        "heading": "Example",
        "depth": 2,
        "text": "In this guide, you will learn the recommended Amplify project setup for monorepo."
      },
      {
        "heading": "Step 1: Set up your monorepo project",
        "depth": 3,
        "text": "To get started, have a monorepo setup with a couple of frontends. For our example, we'll have a monorepo setup with a React and an Angular app."
      },
      {
        "heading": "Step 1: Set up your monorepo project",
        "depth": 3,
        "text": "This project contains the frontend code for an angular and react Todo app. The repository has the following structure:"
      },
      {
        "heading": "Step 2: Set up the Amplify backend",
        "depth": 3,
        "text": "To set up a backend on AWS, we are going to use the Amplify CLI. The Amplify CLI is a command-line toolchain that simplifies provisioning AWS services."
      },
      {
        "heading": "Step 2: Set up the Amplify backend",
        "depth": 3,
        "text": "First, configure the CLI on your machine. Once configured, initialize a new backend project at the root of one of your frontend projects. While we could also initialize the project at the root level, the Amplify is best used attached to one of your projects. This allows you to set up continuous deployment pipelines of the frontend and backend together."
      },
      {
        "heading": "Step 2: Set up the Amplify backend",
        "depth": 3,
        "text": "Add api and database"
      },
      {
        "heading": "Step 2: Set up the Amplify backend",
        "depth": 3,
        "text": "Deploy to cloud"
      },
      {
        "heading": "Step 3a: Integrate backend with React app",
        "depth": 3,
        "text": "Test the React app locally. Create a new to-do.."
      },
      {
        "heading": "Step 3a: Integrate backend with React app",
        "depth": 3,
        "text": "To verify the Todos got created, run amplify console. This will open up your backend env in the Amplify Console. Choose the API tab and under Data Sources click View on the Todotable. You should see the to-do record you just created."
      },
      {
        "heading": "Step 3b: Integrate backend with Angular app",
        "depth": 3,
        "text": "Now pivot to the Angular app."
      },
      {
        "heading": "Step 3b: Integrate backend with Angular app",
        "depth": 3,
        "text": "Let's reference the same backend in the Angular app. In order to do so, run the following commands"
      },
      {
        "heading": "Step 3b: Integrate backend with Angular app",
        "depth": 3,
        "text": "Generate client-side code for your other frontend"
      }
    ],
    "source": "export const meta = {\n  title: `Monorepo project structure`,\n  description: `Learn how to set up monorepo workflows with Amplify CLI`,\n};\n\nFor a monorepo setup, it is recommended to have the Amplify CLI initialize a new backend at the root of one of your frontend projects. In a different frontend directory, you can run `amplify pull` and select the Amplify app you want to associate your frontend with.\n\n## Example\n\nIn this guide, you will learn the recommended Amplify project setup for monorepo.\n\n### Step 1: Set up your monorepo project\n\nTo get started, have a monorepo setup with a couple of frontends. For our example, we'll have a monorepo setup with a React and an Angular app.\n\nThis project contains the frontend code for an angular and react Todo app. The repository has the following structure:\n\n```console\n> monorepo-amplify\n  > react\n  > angular\n```\n\n### Step 2: Set up the Amplify backend\n\nTo set up a backend on AWS, we are going to use the Amplify CLI. The Amplify CLI is a command-line toolchain that simplifies provisioning AWS services.\n\nimport all0 from \"/src/fragments/cli-install-block.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nFirst, [configure the CLI](/cli/start/install#configure-the-amplify-cli) on your machine. Once configured, initialize a new backend project at the root of one of your frontend projects. While we could also initialize the project at the root level, the Amplify is best used attached to one of your projects. This allows you to set up continuous deployment pipelines of the frontend and backend together.\n\n```console\n> cd monorepo-amplify/react\namplify init\n? Enter a name for the project todoreact\n? Enter a name for the environment dev\n? Choose your default editor: Visual Studio Code\n? Choose the type of app that you're building javascript\nPlease tell us about your project\n? What javascript framework are you using react\n? Source Directory Path:  src\n? Distribution Directory Path: build\n? Build Command:  npm run-script build\n? Start Command: npm run-script start\nUsing default provider  awscloudformation\n\nFor more information on AWS Profiles, see:\nhttps://docs.aws.amazon.com/cli/latest/userguide/cli-multiple-profiles.html\n\n? Do you want to use an AWS profile? Yes\n? Please choose the profile you want to use #enter the profile you created\n```\n\nAdd api and database\n\n```console\n> amplify add api\n? Please select from one of the below mentioned services:\n  > GraphQL\n? Here is the GraphQL API that we will create. Select a setting to edit or continue:\n  > Continue\n? Choose a schema template:\n  > Single object with fields (e.g., “Todo” with ID, name, description)\n? Do you want to edit the schema now?\n  > Yes\n```\n\nDeploy to cloud\n\n```console\namplify push\n✔ Successfully pulled backend environment dev from the cloud.\n\nCurrent Environment: dev\n\n| Category | Resource name | Operation | Provider plugin   |\n| -------- | ------------- | --------- | ----------------- |\n| Api      | todo          | Create    | awscloudformation |\n? Are you sure you want to continue? Yes\n\nThe following types do not have '@auth' enabled. Consider using @auth with @model\n  - Todo\nLearn more about @auth here: https://docs.amplify.aws/cli/graphql/authorization-rules\n\nGraphQL schema compiled successfully.\n\nEdit your schema at /Users/nsswamin/workspace/Experiments/monorepo-amplify/react/amplify/backend/api/todo/schema.graphql or place .graphql files in a directory at /Users/nsswamin/workspace/Experiments/monorepo-amplify/react/amplify/backend/api/todo/schema\n? Do you want to generate code for your newly created GraphQL API\n  > Yes\n? Choose the code generation language target\n  > javascript\n? Enter the file name pattern of graphql queries, mutations and subscriptions\n  > src/graphql/**/*.js\n? Do you want to generate/update all possible GraphQL operations - queries, mutations and subscriptions\n  > Yes\n? Enter maximum statement depth [increase from default if your schema is deeply nested]\n  > 2\n```\n\n### Step 3a: Integrate backend with React app\n\nTest the React app locally. Create a new to-do..\n\n```bash\nnpm start\n```\n\nTo verify the Todos got created, run `amplify console`. This will open up your backend env in the Amplify Console. Choose the **API** tab and under Data Sources click **View** on the Todotable. You should see the to-do record you just created.\n\n### Step 3b: Integrate backend with Angular app\n\nNow pivot to the Angular app.\n\n```bash\ncd ../angular\n```\n\nLet's reference the same backend in the Angular app. In order to do so, run the following commands\n\n```console\namplify pull\n? Do you want to use an AWS profile? Yes\n? Please choose the profile you want to use work-lhr\n? Which app are you working on? \n❯ todo \n  app2\n  app3\n\n(hit enter on all other options till the last question)\n\n? Do you plan on modifying this backend? No\n```\n\nGenerate client-side code for your other frontend\n\n```console\ncp ../react/src/graphql/schema.json .\namplify add codegen --apiId XXXXXXXXX\n? Choose the type of app that you're building javascript\n? What javascript framework are you using angular\n? Choose the code generation language target angular\n? Enter the file name pattern of graphql queries, mutations and subscriptions src/graphql/**/*.graphql\n? Do you want to generate/update all possible GraphQL operations - queries, mutations and subscriptions Yes\n? Enter maximum statement depth [increase from default if your schema is deeply nested] 2\n? Enter the file name for the generated code src/app/API.service.ts\n? Do you want to generate code for your newly created GraphQL API Yes\n```\n",
    "meta": {
      "title": "Monorepo project structure",
      "description": "Learn how to set up monorepo workflows with Amplify CLI",
      "subcategory": "Project-level configurations",
      "category": "Amplify CLI"
    },
    "filename": "/cli/project/monorepo"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Use Command Hooks to execute custom scripts before, during, and after Amplify CLI commands (“amplify push”, “amplify api gql-compile”, and more). This allows you to extend Amplify’s best-practice defaults to meet your organization’s specific security guidelines and operational requirements."
      },
      {
        "heading": "Adding a command hook",
        "depth": 2,
        "text": "Place your custom scripts in the amplify/hooks directory and set the script file name to the desired command with a pre or post designation. For example post-add-function.js will execute the script after amplify add function. For more information about the script naming convention, see How to name command hook scripts."
      },
      {
        "heading": "Adding a command hook",
        "depth": 2,
        "text": "For this example, let's create a hook to ensure that a minimum major Amplify CLI version is used before deployment (amplify push)."
      },
      {
        "heading": "Adding a command hook",
        "depth": 2,
        "text": "Let's add pre-push.js in the amplify/hooks directory with the following contents. Note: You need to create a amplify/hooks folder if your Amplify project was created prior to Amplify CLI version 5.5.0"
      },
      {
        "heading": "Adding a command hook",
        "depth": 2,
        "text": "Next, let's run amplify push:"
      },
      {
        "heading": "How to name command hook scripts",
        "depth": 2,
        "text": "To hook into a command, the script file in the amplify/hooks directory should be named with the following naming convention:"
      },
      {
        "heading": "How to name command hook scripts",
        "depth": 2,
        "text": "pre|post-<command>[-<sub-command>].extension"
      },
      {
        "heading": "How to name command hook scripts",
        "depth": 2,
        "text": "command (required) - Amplify command."
      },
      {
        "heading": "How to name command hook scripts",
        "depth": 2,
        "text": "extension (required) - by default .js and .sh are mapped to Node.js and Bash. To support more extensions or scripting runtimes, see Adding a custom scripting runtime."
      },
      {
        "heading": "How to name command hook scripts",
        "depth": 2,
        "text": "sub-command (optional) - Amplify sub-command. Can be used to increase hook specificity. Example: pre-add-auth and pre-mock-api."
      },
      {
        "heading": "How to name command hook scripts",
        "depth": 2,
        "text": "The following is an exhaustive list of all commands along with their subcommands that are supported by Amplify CLI:"
      },
      {
        "heading": "How to name command hook scripts",
        "depth": 2,
        "text": "commands                | sub-commands (optional)\n------------------------|------------------------\nadd                     |all categories (api, auth, etc.)codegenenv\nupdate                  |all categories (api, auth, etc.)env\nremove                  |all categories (api, auth, etc.)env\npush                    |analytics, api, auth, function, hosting, interactions, storage, xr\npull                    |env\npublish                 |-\ndelete                  |-\ncheckout                |env\nlist                    |env\nget                     |env\nmock                    |api, storage, function\nbuild                   |function\nstatus                  |notifications\nimport                  |auth, storage, env\ngqlcompile              |api\naddgraphqldatasource    |api\nstatements              |codegen\ntypes                  |codegen"
      },
      {
        "heading": "How to name command hook scripts",
        "depth": 2,
        "text": "Note: Multiple hook scripts with the same filename are not allowed"
      },
      {
        "heading": "Access parameters in hook scripts",
        "depth": 2,
        "text": "Command hooks receive two parameters, data and error. Amplify CLI passes parameters to hook scripts as a JSON string through standard input."
      },
      {
        "heading": "data parameter structure",
        "depth": 3,
        "text": "amplify"
      },
      {
        "heading": "data parameter structure",
        "depth": 3,
        "text": "version - current Amplify CLI version"
      },
      {
        "heading": "data parameter structure",
        "depth": 3,
        "text": "environment - current Amplify environment"
      },
      {
        "heading": "data parameter structure",
        "depth": 3,
        "text": "envName - current Amplify environment name"
      },
      {
        "heading": "data parameter structure",
        "depth": 3,
        "text": "projectPath - path to current Amplify project"
      },
      {
        "heading": "data parameter structure",
        "depth": 3,
        "text": "defaultEditor - chosen editor in init step. Example vscode"
      },
      {
        "heading": "data parameter structure",
        "depth": 3,
        "text": "command - hooked Amplify CLI command. Example: push"
      },
      {
        "heading": "data parameter structure",
        "depth": 3,
        "text": "subCommand - hooked Amplify CLI subcommand or plugin. Example auth, env."
      },
      {
        "heading": "data parameter structure",
        "depth": 3,
        "text": "argv - list containing the arguments passed to Amplify CLI through the command line"
      },
      {
        "heading": "error parameter structure",
        "depth": 3,
        "text": "error is undefined if no error is emitted. Otherwise, it has the following structure:"
      },
      {
        "heading": "error parameter structure",
        "depth": 3,
        "text": "message - the error message emitted by Amplify CLI"
      },
      {
        "heading": "error parameter structure",
        "depth": 3,
        "text": "stack - the error stack emitted by Amplify CLI"
      },
      {
        "heading": "How to access command hook parameters in Bash",
        "depth": 3,
        "text": "First, install a JSON parser like jq."
      },
      {
        "heading": "How to access command hook parameters in Bash",
        "depth": 3,
        "text": "Then, parse the parameters:"
      },
      {
        "heading": "How to conditionally stop an Amplify CLI command execution",
        "depth": 2,
        "text": "To stop the execution of Amplify CLI, the hook scripts can exit with a non-zero exit code."
      },
      {
        "heading": "Advanced command hook configurations",
        "depth": 2,
        "text": "You can optionally add hooks-config.json in amplify/hooks to configure custom scripting runtimes or manage external dependencies."
      },
      {
        "heading": "Adding a custom scripting runtime",
        "depth": 3,
        "text": "By default, Node.js and Bash are supported. To support additional runtimes, add extensions to the hooks-config.json file in the amplify/hooks folder."
      },
      {
        "heading": "Adding a custom scripting runtime",
        "depth": 3,
        "text": "An example showcasing python runtime support and different runtime settings based on operating system:"
      },
      {
        "heading": "Adding a custom scripting runtime",
        "depth": 3,
        "text": "The keys in the extensions ( js, py ) are values that will be used as extension in the naming convention used when naming the hook scripts."
      },
      {
        "heading": "Adding a custom scripting runtime",
        "depth": 3,
        "text": "runtime (required) - symlink (node, python, bash) or path to executable (~/.nvm/versions/node/v14.17.1/bin/node)."
      },
      {
        "heading": "Adding a custom scripting runtime",
        "depth": 3,
        "text": "runtime_windows (optional) - windows specific symlink or path to executable."
      },
      {
        "heading": "Managing third-party dependencies",
        "depth": 3,
        "text": "Packages from external package managers like npm can be used in command hooks scripts. In this example, we'll showcase how to install axios as a dependency for our Node.js hooks."
      },
      {
        "heading": "Managing third-party dependencies",
        "depth": 3,
        "text": "First, go to the hooks folder and install the axios dependency."
      },
      {
        "heading": "Managing third-party dependencies",
        "depth": 3,
        "text": "Note: If you use command hooks with Amplify Hosting CI/CD pipelines, you also need to have a preBuild step configured to install the hook dependencies:"
      },
      {
        "heading": "Managing third-party dependencies",
        "depth": 3,
        "text": "Dependency directories and files, such as node_modules, should be added to ignore in hooks-config.json."
      },
      {
        "heading": "Managing third-party dependencies",
        "depth": 3,
        "text": "Note: All entries in ignore should follow the .gitignore specification."
      },
      {
        "heading": "Managing third-party dependencies",
        "depth": 3,
        "text": "You can now use axios in your hook scripts placed in the amplify/hooks directory."
      },
      {
        "heading": "Using command hooks in Amplify's CI/CD pipeline",
        "depth": 2,
        "text": "Command hooks are executed when CI/CD builds are triggered on Amplify Console. To execute hook scripts in the Amplify Console, add the hook scripts to the amplify/hooks directory and run amplify push locally to upload the hooks."
      },
      {
        "heading": "Using command hooks in Amplify's CI/CD pipeline",
        "depth": 2,
        "text": "By default only pre-push and post-push hooks will be executed on builds in Amplify Console."
      },
      {
        "heading": "Using command hooks in Amplify's CI/CD pipeline",
        "depth": 2,
        "text": "To use scripting runtimes other than Node.js and Bash, see Adding a custom scripting runtime and also update the Build Settings in Amplify Console to include the runtime executable."
      },
      {
        "heading": "Using command hooks in Amplify's CI/CD pipeline",
        "depth": 2,
        "text": "In this example, we'll add a python hook script running in the Amplify Console's CI/CD pipeline:"
      },
      {
        "heading": "Using command hooks in Amplify's CI/CD pipeline",
        "depth": 2,
        "text": "Add the python hook script along with hooks-config.json to the hooks directory."
      },
      {
        "heading": "Using command hooks in Amplify's CI/CD pipeline",
        "depth": 2,
        "text": "Add python3 to hooks-config.json and run amplify push to upload the command hooks."
      },
      {
        "heading": "Using command hooks in Amplify's CI/CD pipeline",
        "depth": 2,
        "text": "Navigate to your app in the Amplify Console and select App settings > Build settings to update the preBuild phase to install python."
      },
      {
        "heading": "Using command hooks in Amplify's CI/CD pipeline",
        "depth": 2,
        "text": "You’re all set! The python command hooks will be executed in new CI/CD builds."
      },
      {
        "heading": "Command hook limitations with Amplify Studio",
        "depth": 2,
        "text": "Command Hooks are not executed when updating a backend via Amplify Studio."
      }
    ],
    "source": "export const meta = {\n  title: `Command Hooks`,\n  description: `Execute custom scripts before, during, and after Amplify CLI commands (“amplify push”, “amplify api gql-compile”, and more).`,\n};\n\nUse Command Hooks to execute custom scripts before, during, and after Amplify CLI commands (“amplify push”, “amplify api gql-compile”, and more). This allows you to extend Amplify’s best-practice defaults to meet your organization’s specific security guidelines and operational requirements. \n\n## Adding a command hook\nPlace your custom scripts in the `amplify/hooks` directory and set the script file name to the desired command with a pre or post designation. For example `post-add-function.js` will execute the script after `amplify add function`. For more information about the script naming convention, see [How to name command hook scripts](#how-to-name-command-hook-scripts). \n\nFor this example, let's create a hook to ensure that a minimum major Amplify CLI version is used before deployment (`amplify push`).\n\nLet's add `pre-push.js` in the `amplify/hooks` directory with the following contents. *Note: You need to create a `amplify/hooks` folder if your Amplify project was created prior to Amplify CLI version 5.5.0*\n\n```js\nconst fs = require('fs');\nconst parameters = JSON.parse(fs.readFileSync(0, { encoding: 'utf8' }));\n\n// Get the running Amplify CLI major version number\nconst currentCLIMajorVersion = parameters.data.amplify.version.split('.')[0]\nconsole.log('Amplify CLI major version: ', currentCLIMajorVersion)\n\nconst MINIMUM_MAJOR_AMPLIFY_CLI_VERSION = 5\nconsole.log('Minimum required Amplify CLI major version: ', MINIMUM_MAJOR_AMPLIFY_CLI_VERSION)\n\nif (currentCLIMajorVersion < MINIMUM_MAJOR_AMPLIFY_CLI_VERSION) {\n  // Non-zero exit code will stop the Amplify CLI command's execution\n  console.log('Minimum CLI version requirement not met.')\n  process.exit(1) \n} else {\n  console.log('Minimum CLI version requirement met.')\n  process.exit(0) \n}\n```\n\nNext, let's run `amplify push`:\n```bash\namplify push\n```\n```console\n----- 🪝 pre-push execution start -----\nAmplify CLI major version: 5\nMinimum required Amplify CLI major version: 5\nMinimum CLI version requirement met.\n----- 🪝 pre-push execution end -----\n```\n\n## How to name command hook scripts\nTo hook into a command, the script file in the `amplify/hooks` directory should be named with the following naming convention: \n\n`pre|post-<command>[-<sub-command>].extension` \n\n- `command` (required) - Amplify command.\n- `extension` (required) - by default `.js` and `.sh` are mapped to Node.js and Bash. To support more extensions or scripting runtimes, see [Adding a custom scripting runtime](#adding-a-custom-scripting-runtime).\n- `sub-command` (optional) - Amplify sub-command. Can be used to increase hook specificity. Example: `pre-add-auth` and `pre-mock-api`.\n\nThe following is an exhaustive list of all commands along with their subcommands that are supported by Amplify CLI: \n\ncommands                | sub-commands **(optional)**\n------------------------|------------------------\n`add`                     |all categories (`api`, `auth`, etc.)<br/>`codegen`<br/>`env`<br/>\n`update`                  |all categories (`api`, `auth`, etc.)<br/>`env`<br/>\n`remove`                  |all categories (`api`, `auth`, etc.)<br/>`env`<br/>\n`push`                    |`analytics`, `api`, `auth`, `function`, `hosting`, `interactions`, `storage`, `xr`\n`pull`                    |`env`<br/>\n`publish`                 |-\n`delete`                  |-\n`checkout`                |`env`\n`list`                    |`env`\n`get`                     |`env`\n`mock`                    |`api`, `storage`, `function`<br/>\n`build`                   |`function`<br/>\n`status`                  |`notifications`<br/>\n`import`                  |`auth`, `storage`, `env`<br/>\n`gqlcompile`              |`api`<br/>\n`addgraphqldatasource`    |`api`<br/>\n`statements`              |`codegen`<br/>\n`types`                  |`codegen`<br/>\n\n\n\n*Note: Multiple hook scripts with the same filename are not allowed*\n\n## Access parameters in hook scripts\n\nCommand hooks receive two parameters, `data` and `error`. Amplify CLI passes parameters to hook scripts as a JSON string through standard input.\n\n### **data** parameter structure\n```json\n{\n  \"amplify\": { \n    \"version\": String,\n    \"environment\": {\n      \"envName\": String,\n      \"projectPath\": String,\n      \"defaultEditor\": String\n    },\n    \"command\": String,\n    \"subCommand\": String,\n    \"argv\": [ String ]\n  }\n}\n```\n\n- amplify\n    - version - current Amplify CLI version\n    - environment - current Amplify environment\n        - envName - current Amplify environment name\n        - projectPath - path to current Amplify project\n        - defaultEditor - chosen editor in init step. Example `vscode`\n    - command - hooked Amplify CLI command. Example: `push`\n    - subCommand - hooked Amplify CLI subcommand or plugin. Example `auth`, `env`. \n    - argv - list containing the arguments passed to Amplify CLI through the command line\n\n### **error** parameter structure\n\n**error** is `undefined` if no error is emitted. Otherwise, it has the following structure:\n```json\n{\n  \"message\": String,\n  \"stack\": String\n}\n```\n- message - the error message emitted by Amplify CLI\n- stack - the error stack emitted by Amplify CLI\n\n### How to access command hook parameters in Node.js\n```javascript\nconst fs = require('fs');\nconst parameters = JSON.parse(fs.readFileSync(0, { encoding: 'utf8' }));\nconsole.log(parameters.data, parameters.error)\n```\n\n### How to access command hook parameters in Bash\n\nFirst, install a JSON parser like [`jq`](https://stedolan.github.io/jq/download/).\n\nThen, parse the parameters:\n```bash\nparameters=`cat`\ndata=$(jq -r '.data' <<< \"$parameters\")\nerror=$(jq -r '.error // empty' <<< \"$parameters\")\necho $data\necho $error\n```\n\n## How to conditionally stop an Amplify CLI command execution\nTo stop the execution of Amplify CLI, the hook scripts can exit with a non-zero exit code. \n\n<BlockSwitcher>\n\n<Block name=\"Node.js\">\n\n```js\nprocess.exit(1)\n```\n\n</Block>\n\n<Block name=\"Bash\">\n\n```bash\nexit 1\n```\n\n</Block>\n\n</BlockSwitcher>\n\n\n## Advanced command hook configurations\nYou can optionally add `hooks-config.json` in `amplify/hooks` to configure custom scripting runtimes or manage external dependencies.\n\n### Adding a custom scripting runtime \nBy default, Node.js and Bash are supported. To support additional runtimes, add `extensions` to the `hooks-config.json` file in the `amplify/hooks` folder.\n\nAn example showcasing python runtime support and different runtime settings based on operating system: \n```json\n{\n  \"extensions\": {\n    \"py\": {\n      \"runtime\": \"python3\"\n    },\n    \"js\": {\n      \"runtime\": \"~/.nvm/versions/node/v14.17.1/bin/node\",\n      \"runtime_windows\": \"node\"\n    }\n  }\n}\n```\n- The keys in the `extensions` ( js, py ) are values that will be used as `extension` in the [naming convention](#how-to-name-command-hook-scripts) used when naming the hook scripts.\n- `runtime` (required) - symlink (`node`, `python`, `bash`) or path to executable (`~/.nvm/versions/node/v14.17.1/bin/node`).\n- `runtime_windows` (optional) - windows specific symlink or path to executable.\n\n### Managing third-party dependencies\n\nPackages from external package managers like `npm` can be used in command hooks scripts. In this example, we'll showcase how to install `axios` as a dependency for our Node.js hooks.\n\nFirst, go to the hooks folder and install the `axios` dependency.\n```bash\ncd amplify/hooks\nnpm init\nnpm install axios\n```\n\n*Note*: If you use command hooks with Amplify Hosting CI/CD pipelines, you also need to have a `preBuild` step configured to install the hook dependencies:\n\n```yaml\nbackend:\n  phases:\n    preBuild:\n    commands:\n      - cd amplify/hooks\n      - npm install\nfrontend:\n...\n```\n\nDependency directories and files, such as `node_modules`, should be added to `ignore` in `hooks-config.json`. \n\n```json\n{\n  \"ignore\": [\"node_modules\", \"build\"]\n}\n```\n\n*Note*: All entries in `ignore` should follow the [.gitignore specification](http://git-scm.com/docs/gitignore).\n\nYou can now use `axios` in your hook scripts placed in the `amplify/hooks` directory.\n\n## Using command hooks in Amplify's CI/CD pipeline\nCommand hooks are executed when [CI/CD builds are triggered on Amplify Console](https://docs.aws.amazon.com/amplify/latest/userguide/multi-environments.html). To execute hook scripts in the Amplify Console, add the hook scripts to the `amplify/hooks` directory and run `amplify push` locally to upload the hooks.\n\nBy default only `pre-push` and `post-push` hooks will be executed on builds in Amplify Console.\n\nTo use scripting runtimes other than Node.js and Bash, see [Adding a custom scripting runtime](#adding-a-custom-scripting-runtime) and also update the **Build Settings** in Amplify Console to include the runtime executable.  \n\nIn this example, we'll add a `python` hook script running in the Amplify Console's CI/CD pipeline:\n\n1. Add the python hook script along with `hooks-config.json` to the hooks directory. \n    ```bash\n    touch amplify/hooks/hooks-config.json\n    ```\n\n2. Add `python3` to `hooks-config.json` and run `amplify push` to upload the command hooks.\n    ```json\n    {\n        \"extensions\": {\n            \"py\": { \"runtime\": \"python3\" }\n        }\n    }\n    ```\n    ```bash\n    amplify push\n    ```\n3. Navigate to your app in the Amplify Console and select **App settings** > **Build settings** to update the `preBuild` phase to install python.\n    ```yaml\n    ...\n    backend:\n    phases:\n        preBuild:\n        commands:\n            - yum install -y python3\n    frontend:\n    ...\n    ```\n\n4. You’re all set! The python command hooks will be executed in new CI/CD builds. \n\n## Command hook limitations with Amplify Studio\n\nCommand Hooks are not executed when updating a backend via Amplify Studio.\n",
    "meta": {
      "title": "Command Hooks",
      "description": "Execute custom scripts before, during, and after Amplify CLI commands (“amplify push”, “amplify api gql-compile”, and more).",
      "subcategory": "Project-level configurations",
      "category": "Amplify CLI"
    },
    "filename": "/cli/project/command-hooks"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "To set the maximum permissions that can be granted to IAM Roles created by Amplify CLI, configure a Permissions Boundary for the project. Then, Amplify-generated IAM roles can perform only the actions that are allowed by both the roles’ policies and Permissions Boundary. You can configure a different Permissions Boundary for each environment. For example, this enables you to deny a dev environment all access to a prod environment's resources."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The IAM Permissions Boundary will apply to all IAM Roles created by Amplify. This includes the \"auth role\" assumed by users that log into the app and the \"unauth role\" assumed by guest users. It also applies to Lambda execution roles, Cognito user group roles, and any role configured in a custom resource stack."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The IAM Policy, to be used as a Permissions Boundary, must be configured outside of Amplify CLI. A Permissions Boundary is an IAM Policy and can be created following the guide here. This is usually part of an AWS Organization rule or other corporate governance requirement. Once you have created an IAM Policy to use as a Permissions Boundary, copy the IAM Policy ARN for the next steps."
      },
      {
        "heading": "Set up a Permissions Boundary in a new project",
        "depth": 2,
        "text": "To initialize a project with a Permissions Boundary run:"
      },
      {
        "heading": "Set up a Permissions Boundary in a new environment",
        "depth": 2,
        "text": "When creating a new Amplify environment using amplify env add the Permissions Boundary from the current environment is automatically applied to the new environment."
      },
      {
        "heading": "Set up a Permissions Boundary in a new environment",
        "depth": 2,
        "text": "To specify a different Permissions Boundary for the new environment, run:"
      },
      {
        "heading": "Set up a Permissions Boundary in a new environment",
        "depth": 2,
        "text": "To explicitly specify that the new environment should NOT have a Permissions Boundary, run:"
      },
      {
        "heading": "Set up a Permissions Boundary in a new environment",
        "depth": 2,
        "text": "If Amplify CLI is not able to automatically apply the Permissions Boundary to the new environment and --permissions-boundary is not specified, it will prompt for a IAM Policy ARN as a Permissions Boundary."
      },
      {
        "heading": "Update an environment's Permissions Boundary",
        "depth": 2,
        "text": "To modify the Permissions Boundary of the current environment, run:"
      },
      {
        "heading": "Update an environment's Permissions Boundary",
        "depth": 2,
        "text": "In non-interactive shells use"
      },
      {
        "heading": "Update an environment's Permissions Boundary",
        "depth": 2,
        "text": "The IAM Permissions Boundary will be applied on the next amplify push."
      },
      {
        "heading": "Set up a Permissions Boundary in a cross-account Amplify project",
        "depth": 2,
        "text": "Amplify CLI cannot automatically apply the existing boundary to a new environment in a different AWS account if the --yes flag is used during amplify env add. In this case, a new Permissions Boundary must be specified using amplify env add --yes --permissions-boundary <IAM Policy ARN> or to explicitly remove the Permissions Boundary from the new environment use amplify env add --yes --permissions-boundary ''."
      }
    ],
    "source": "export const meta = {\n  title: `IAM Permissions Boundary for Amplify-generated roles`,\n  description: `Apply a Permissions Boundary to all IAM Roles created by Amplify CLI.`,\n};\n\nTo set the maximum permissions that can be granted to IAM Roles created by Amplify CLI, configure a [Permissions Boundary](https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_boundaries.html) for the project. Then, Amplify-generated IAM roles can perform only the actions that are allowed by both the roles’ policies and Permissions Boundary. You can configure a different Permissions Boundary for each environment. For example, this enables you to deny a dev environment all access to a prod environment's resources.\n\nThe IAM Permissions Boundary will apply to all IAM Roles created by Amplify. This includes the \"auth role\" assumed by users that log into the app and the \"unauth role\" assumed by guest users. It also applies to Lambda execution roles, Cognito user group roles, and any role configured in a [custom resource stack](/cli/usage/customcf).\n\nThe IAM Policy, to be used as a Permissions Boundary, must be configured outside of Amplify CLI. A Permissions Boundary is an IAM Policy and can be created following the guide [here](https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_create-console.html). This is usually part of an AWS Organization rule or other corporate governance requirement. Once you have created an IAM Policy to use as a Permissions Boundary, copy the IAM Policy ARN for the next steps.\n\n## Set up a Permissions Boundary in a new project\n\nTo initialize a project with a Permissions Boundary run: \n```\namplify init --permissions-boundary <IAM Policy ARN>\n```\n\n## Set up a Permissions Boundary in a new environment\n\nWhen creating a new Amplify environment using `amplify env add` the Permissions Boundary from the current environment is automatically applied to the new environment.\n\nTo specify a different Permissions Boundary for the new environment, run:\n```\namplify env add --permissions-boundary <IAM Policy ARN>\n```\n\nTo explicitly specify that the new environment should NOT have a Permissions Boundary, run:\n```\namplify env add --permissions-boundary ''\n```\n\nIf Amplify CLI is not able to automatically apply the Permissions Boundary to the new environment and `--permissions-boundary` is not specified, it will prompt for a IAM Policy ARN as a Permissions Boundary.\n\n## Update an environment's Permissions Boundary\n\nTo modify the Permissions Boundary of the current environment, run:\n```\namplify env update\n```\n\nIn non-interactive shells use \n```\namplify env update --permissions-boundary <IAM Policy ARN>\n```\n\nThe IAM Permissions Boundary will be applied on the next `amplify push`.\n\n## Set up a Permissions Boundary in a cross-account Amplify project\n\nAmplify CLI cannot automatically apply the existing boundary to a new environment in a different AWS account if the `--yes` flag is used during `amplify env add`. In this case, a new Permissions Boundary must be specified using `amplify env add --yes --permissions-boundary <IAM Policy ARN>` or to explicitly remove the Permissions Boundary from the new environment use `amplify env add --yes --permissions-boundary ''`.",
    "meta": {
      "title": "IAM Permissions Boundary for Amplify-generated roles",
      "description": "Apply a Permissions Boundary to all IAM Roles created by Amplify CLI.",
      "subcategory": "Project-level configurations",
      "category": "Amplify CLI"
    },
    "filename": "/cli/project/permissions-boundary"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Tags are labels consisting of key-value pairs that make it easier to manage, search for, and filter resources. Some popular use cases include:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Resource organization"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Cost allocation"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Operations support"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Access control"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Security risk management"
      },
      {
        "heading": null,
        "depth": null,
        "text": "You can learn more about how tags work here, as well as read about best practices for tagging here."
      },
      {
        "heading": "Setting up tags in a new project",
        "depth": 2,
        "text": "When running amplify init, a tags.json file is automatically generated in the amplify/backend/ directory, containing predefined tags."
      },
      {
        "heading": "Setting up tags in a new project",
        "depth": 2,
        "text": "The structure of the file is the following:"
      },
      {
        "heading": "Setting up tags in a new project",
        "depth": 2,
        "text": "Note: For projects created before CLI version 4.28.0. Creating a tags.json file under amplify/backend/ directory with the desired tags will ensure tags being applied to existing resources after invoking amplify push."
      },
      {
        "heading": "Setting up tags in a new project",
        "depth": 2,
        "text": "The tag configuration file is created, when you run \"amplify init\" and the initial Amplify project resources are deployed. You can optionally also pre-create the amplify/backend/tags.json configuration file before \"amplify init\". This allows you to tag the initial Amplify project resources with your designated tags as well."
      },
      {
        "heading": "Using predefined variables",
        "depth": 2,
        "text": "There are predefined tags that let you be more specific with information about the current project, while giving you the opportunity of structuring the tags according to what feels right to you."
      },
      {
        "heading": "Using predefined variables",
        "depth": 2,
        "text": "The 2 predefined tags are the following:"
      },
      {
        "heading": "Using predefined variables",
        "depth": 2,
        "text": " - Refers to the project environment (e.g., prod, env, etc)"
      },
      {
        "heading": "Using predefined variables",
        "depth": 2,
        "text": " - Refers to the current project name (e.g., mytestproject)"
      },
      {
        "heading": "Using predefined variables",
        "depth": 2,
        "text": "There are many different cases in which these tag variables can be used. This is an example of how they can be used together and what the output would be:"
      },
      {
        "heading": "Using predefined variables",
        "depth": 2,
        "text": "When getting pushed, the resources would transform into:"
      },
      {
        "heading": "Using predefined variables",
        "depth": 2,
        "text": "Tag values are not required, thus they can be empty."
      },
      {
        "heading": "Adding and updating tags",
        "depth": 2,
        "text": "You can update or add any additional tags in the tags.json file inside the amplify/backend/ folder by editing the file itself. The file must in a JSON format and should follow this structure:"
      },
      {
        "heading": "Adding and updating tags",
        "depth": 2,
        "text": "To update the AWS resources from your Amplify project just run amplify push."
      },
      {
        "heading": "Restrictions",
        "depth": 2,
        "text": "You can only add up to 50 tags to the amplify/backend/tags.json file."
      },
      {
        "heading": "Restrictions",
        "depth": 2,
        "text": "Tag keys and values are case sensitive."
      },
      {
        "heading": "Restrictions",
        "depth": 2,
        "text": "Duplicate tag keys are not allowed."
      },
      {
        "heading": "Restrictions",
        "depth": 2,
        "text": "For more information on limits and restrictions with tagging conventions, please visit this link."
      }
    ],
    "source": "export const meta = {\n  title: `Apply tags to generated resources`,\n  description: `Learn how to stay organized with your Amplify-generated AWS resources by tagging them through the CLI`,\n};\n\nTags are labels consisting of key-value pairs that make it easier to manage, search for, and filter resources. Some popular use cases include:\n\n- Resource organization\n- Cost allocation\n- Operations support\n- Access control\n- Security risk management\n\nYou can learn more about how tags work [here](https://docs.aws.amazon.com/general/latest/gr/aws_tagging.html), as well as read about best practices for tagging [here](https://d1.awsstatic.com/whitepapers/aws-tagging-best-practices.pdf).\n\n## Setting up tags in a new project\n\nWhen running `amplify init`, a `tags.json` file is automatically generated in the `amplify/backend/` directory, containing predefined tags.\n\nThe structure of the file is the following:\n\n```json\n[\n  {\n    \"Key\": \"user:Stack\",\n    \"Value\": \"{project-env}\"\n  },\n  {\n    \"Key\": \"user:Application\",\n    \"Value\": \"{project-name}\"\n  }\n]\n```\n\n**Note:** For projects created before CLI version 4.28.0. Creating a `tags.json` file under `amplify/backend/` directory with the desired tags will ensure tags being applied to existing resources after invoking `amplify push`.\n\n> The tag configuration file is created, when you run \"amplify init\" and the initial Amplify project resources are deployed. You can optionally also pre-create the `amplify/backend/tags.json` configuration file before \"amplify init\". This allows you to tag the initial Amplify project resources with your designated tags as well. \n\n## Using predefined variables\n\nThere are predefined tags that let you be more specific with information about the current project, while giving you the opportunity of structuring the tags according to what feels right to you.\n\nThe 2 predefined tags are the following:\n\n- {project-env} - Refers to the project environment (e.g., prod, env, etc)\n- {project-name} - Refers to the current project name (e.g., mytestproject)\n\nThere are many different cases in which these tag variables can be used. This is an example of how they can be used together and what the output would be:\n\n```json\n[{\n  \"Key\": \"myawesomekey\",\n  \"Value\": \"myvalue-{project-name}-{project-env}\"\n}]\n```\n\nWhen getting pushed, the resources would transform into:\n\n```json\n[{\n  \"Key\": \"myawesomekey\",\n  \"Value\": \"myvalue-myamplifyproject-dev\"\n}]\n```\n\nTag values are not required, thus they can be empty.\n\n```json\n[{\n  \"Key\": \"MY_TAG_KEY\",\n  \"Value\": \"\"\n}]\n```\n\n## Adding and updating tags\n\nYou can update or add any additional tags in the `tags.json` file inside the `amplify/backend/` folder by editing the file itself. The file must in a JSON format and should follow this structure:\n\n```json\n[{\n  \"Key\": “MY_TAG_KEY”,\n  \"Value\": “MY_TAG_VALUE\"\n}]\n```\n\nTo update the AWS resources from your Amplify project just run `amplify push`.\n\n## Restrictions\n\n- You can only add up to 50 tags to the `amplify/backend/tags.json` file.\n- Tag keys and values are case sensitive.\n- Duplicate tag keys are not allowed.\n\n<Callout>\n\nFor more information on limits and restrictions with tagging conventions, please visit [this link](https://docs.aws.amazon.com/general/latest/gr/aws_tagging.html).\n\n</Callout>\n",
    "meta": {
      "title": "Apply tags to generated resources",
      "description": "Learn how to stay organized with your Amplify-generated AWS resources by tagging them through the CLI",
      "subcategory": "Project-level configurations",
      "category": "Amplify CLI"
    },
    "filename": "/cli/project/tags"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "The Amplify CLI provides the ability to add custom AWS resources with AWS CloudFormation. Running the amplify add custom command in your Amplify project provides CloudFormation starter templates along with mechanisms to reference other Amplify-generated resources."
      },
      {
        "heading": null,
        "depth": null,
        "text": "To add custom AWS resources using AWS CloudFormation, run the following command:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "A skeleton CloudFormation template is generated in the amplify/backend/custom/<resource-name> directory. The additional AWS resources can be defined in the <resource-name>-cloudformation-template.json CloudFormation template file."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Note: Always append the Amplify environment name (env parameter) to a resource name to ensure correct behavior with Amplify's multi-environment workflows."
      },
      {
        "heading": "Reference Amplify backend name",
        "depth": 2,
        "text": "Amplify CLI will automatically populate the env parameter in the top of your CloudFormation template."
      },
      {
        "heading": "Reference Amplify backend name",
        "depth": 2,
        "text": "To reference the parameter use the Ref intrinsic function:"
      },
      {
        "heading": "Reference Amplify-generated resources",
        "depth": 2,
        "text": "The CloudFormation template for custom AWS resources can reference Amplify-generated resources' CloudFormation outputs. To reference another resource's output, run:"
      },
      {
        "heading": "Reference Amplify-generated resources",
        "depth": 2,
        "text": "Once the resources are selected, you can reference the resources' output listed as parameters on the top of your CloudFormation template. To reference the parameter use the Ref intrinsic function:"
      }
    ],
    "source": "export const meta = {\n  title: `Use CloudFormation to add custom AWS resources`,\n  description: 'The Amplify CLI provides the ability to add custom AWS resources with AWS CloudFormation. Running the `amplify add custom` command in your Amplify project provides CloudFormation starter templates along with mechanisms to reference other Amplify-generated resources.',\n};\n\nThe Amplify CLI provides the ability to add custom AWS resources with AWS CloudFormation. Running the `amplify add custom` command in your Amplify project provides CloudFormation starter templates along with mechanisms to reference other Amplify-generated resources.\n\nTo add custom AWS resources using AWS CloudFormation, run the following command:\n\n```bash\namplify add custom\n```\n```console\n? How do you want to define this custom resource? …  (Use arrow keys or type to filter)\n  AWS CDK\n❯ AWS CloudFormation\n```\n\nA skeleton CloudFormation template is generated in the `amplify/backend/custom/<resource-name>` directory. The additional AWS resources can be defined in the `<resource-name>-cloudformation-template.json` CloudFormation template file.\n\n```json\n{\n  \"AWSTemplateFormatVersion\": \"2010-09-09\",\n  \"Parameters\": {\n    \"env\": {\n      \"Type\": \"String\"\n    }\n  },\n  \"Resources\": {\n    \"snstopic1234\": {\n      \"Type\": \"AWS::SNS::Topic\",\n      \"Properties\": {\n        \"TopicName\": {\n          \"Fn::Join\": [ \"\", [ \"sns-topic-1234-\", { \"Ref\": \"env\" } ] ]\n        }\n      }\n    },\n    \"snstopicemailsub1234\": {\n      \"Type\": \"AWS::SNS::Subscription\",\n      \"Properties\": {\n        \"Protocol\": \"email\",\n        \"TopicArn\": {\n          \"Ref\": \"snstopic1234\"\n        },\n        \"Endpoint\": \"<your-email-address>\"\n      }\n    }\n  },\n  \"Outputs\": {}\n}\n```\n\n> Note: Always append the Amplify environment name (`env` parameter) to a resource name to ensure correct behavior with Amplify's multi-environment workflows.\n\n## Reference Amplify backend name\n\nAmplify CLI will automatically populate the `env` parameter in the top of your CloudFormation template. \n\n```json\n...\n  \"Parameters\": {\n    \"env\": {\n      \"Type\": \"String\"\n    }\n  },\n...\n```\n\nTo reference the parameter use the [`Ref`](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/parameters-section-structure.html) intrinsic function:\n\n```json\n...\n  \"Resources\": {\n    \"snstopic1234\": {\n      \"Type\": \"AWS::SNS::Topic\",\n      \"Properties\": {\n        \"TopicName\": {\n          \"Fn::Join\": [ \"\", [ \"sns-topic-1234-\", { \"Ref\": \"env\" } ] ]\n        }\n      }\n    }\n  }\n...\n```\n\n## Reference Amplify-generated resources\n\nThe CloudFormation template for custom AWS resources can reference Amplify-generated resources' CloudFormation outputs. To reference another resource's output, run:\n\n```bash\namplify update custom\n```\n```console\n✔ Do you want to access Amplify generated resources in your custom CloudFormation file? (y/N) · yes\n? Select the categories you want this custom resource to have access to:\n❯ <category>\n? Function has 2 resources in this project. Select the one you would like your custom resource to access\n❯ ...\n```\n\nOnce the resources are selected, you can reference the resources' output listed as parameters on the top of your CloudFormation template. To reference the parameter use the [`Ref`](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/parameters-section-structure.html) intrinsic function:\n\n```json\n...\n  \"Parameters\": {\n    ...,\n    \"myFunctionArn\": {\n      \"Type\": \"String\"\n    }\n  },\n  \"Resources\": {\n    ...: {\n      \"Type\": ...,\n      \"Properties\": {\n        ...: { \"Ref\": \"myFunctionArn\"}\n      }\n    }\n  }\n...\n```",
    "meta": {
      "title": "Use CloudFormation to add custom AWS resources",
      "description": "The Amplify CLI provides the ability to add custom AWS resources with AWS CloudFormation. Running the `amplify add custom` command in your Amplify project provides CloudFormation starter templates along with mechanisms to reference other Amplify-generated resources.",
      "subcategory": "Custom AWS resources",
      "category": "Amplify CLI"
    },
    "filename": "/cli/custom/cloudformation"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "The Amplify CLI provides the ability to add custom AWS resources with AWS Cloud Development Kit (CDK). Running the amplify add custom command in your Amplify project provides CDK starter stacks along with mechanisms to reference other Amplify-generated resources."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The AWS Cloud Development Kit (AWS CDK) is an open source software development framework to define your cloud application resources using familiar programming languages, such as Typescript."
      },
      {
        "heading": null,
        "depth": null,
        "text": "A skeleton CDK stack is generated in the amplify/backend/custom/<resource-name> directory. Edit the cdk-stack.ts file to define the additional AWS resources. Add additional CDK constructs using the package.json. Run amplify build to download all NPM dependencies for this custom resource and synthesize the CDK stack."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The following example creates an SNS topic whose notification messages are forwarded via email:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Note: Always append the Amplify environment name to a resource name to ensure correct behavior with Amplify's multi-environment workflows."
      },
      {
        "heading": null,
        "depth": null,
        "text": "When creating custom resources using Amplify CLI, the CLI may require additional permissions outside the Amplify managed policy, AdministratorAccess-Amplify.\nPlease refer to the Amplify IAM Policy documentation for additional information regarding the necessary permissions for Amplify CLI and for more information on providing additional permissions to your Amplify CLI IAM user refer to AWS IAM User documentation."
      },
      {
        "heading": "Reference Amplify project and environment name",
        "depth": 2,
        "text": "Amplify provides you helper functions to get Amplify project information such as the project name and the current Amplify environment name."
      },
      {
        "heading": "Reference Amplify project name",
        "depth": 3,
        "text": "Use the AmplifyHelpers.getProjectInfo() function to retrieve the project name:"
      },
      {
        "heading": "Reference Amplify environment name",
        "depth": 3,
        "text": "There are two access patterns for the environment for two different use cases. Using the right access mechanism for the right use case is critical to ensure multi-environment workflows function properly."
      },
      {
        "heading": "Reference Amplify environment name",
        "depth": 3,
        "text": "If you want to use the environment name as a variable for a resource, use cdk.Fn.ref('env'):"
      },
      {
        "heading": "Reference Amplify environment name",
        "depth": 3,
        "text": "If you want to apply conditional logic based on the current environment name, use AmplifyHelpers.projectInfo():"
      },
      {
        "heading": "Reference Amplify-generated resources",
        "depth": 2,
        "text": "The CDK stack for custom AWS resources can reference Amplify-generated resources' CloudFormation outputs. To reference another resource, first add the resource as a dependency."
      },
      {
        "heading": "Reference Amplify-generated resources",
        "depth": 2,
        "text": "Then use the cdk.Fn.ref function to create a dynamic reference of the dependencies' outputs."
      },
      {
        "heading": "Reference Amplify-generated resources",
        "depth": 2,
        "text": "The dependencies variable has the auto-generated AmplifyDependentResourcesAttributes type which includes all Amplify-generated resource output. Run amplify build to regenerate AmplifyDependentResourcesAttributes if you don't see your category, resource, or parameters."
      }
    ],
    "source": "export const meta = {\n  title: `Use CDK to add custom AWS resources`,\n  description: 'The Amplify CLI provides the ability to add custom AWS resources with AWS Cloud Development Kit (CDK). Running the `amplify add custom` command in your Amplify project provides CDK starter stacks along with mechanisms to reference other Amplify-generated resources.',\n};\n\nThe Amplify CLI provides the ability to add custom AWS resources with AWS Cloud Development Kit (CDK). Running the `amplify add custom` command in your Amplify project provides CDK starter stacks along with mechanisms to reference other Amplify-generated resources.\n\n> The [AWS Cloud Development Kit (AWS CDK)](https://docs.aws.amazon.com/cdk/latest/guide/home.html) is an open source software development framework to define your cloud application resources using familiar programming languages, such as Typescript.\n\n```bash\namplify add custom\n```\n```console\n? How do you want to define this custom resource? …  (Use arrow keys or type to filter)\n❯ AWS CDK\n  AWS CloudFormation\n```\n\nA skeleton CDK stack is generated in the `amplify/backend/custom/<resource-name>` directory. Edit the `cdk-stack.ts` file to define the additional AWS resources. Add additional CDK constructs using the `package.json`. Run `amplify build` to download all NPM dependencies for this custom resource and synthesize the CDK stack.\n\nThe following example creates an SNS topic whose notification messages are forwarded via email:\n\n```ts\nimport * as cdk from '@aws-cdk/core';\nimport * as AmplifyHelpers from '@aws-amplify/cli-extensibility-helper';\nimport * as sns from '@aws-cdk/aws-sns';\nimport * as subs from '@aws-cdk/aws-sns-subscriptions';\n\nexport class cdkStack extends cdk.Stack {\n  constructor(scope: cdk.Construct, id: string, props?: cdk.StackProps, amplifyResourceProps?: AmplifyHelpers.AmplifyResourceProps) {\n    super(scope, id, props);\n\n    /* Do not remove - Amplify CLI automatically injects the current deployment environment in this input parameter */\n    new cdk.CfnParameter(this, 'env', {\n      type: 'String',\n      description: 'Current Amplify CLI env name',\n    });\n\n    const projectName = AmplifyHelpers.getProjectInfo().projectName;\n    \n    const topic = new sns.Topic(this, 'sns-topic', {\n      topicName: `sns-topic-${projectName}-${cdk.Fn.ref('env')}`\n    });\n\n    topic.addSubscription(new subs.EmailSubscription(\"<your-email-address>\"));\n  }\n}\n```\n\n> Note: Always append the Amplify environment name to a resource name to ensure correct behavior with Amplify's multi-environment workflows.\n\n<Callout warning>\n\nWhen creating custom resources using Amplify CLI, the CLI may require additional permissions outside the Amplify managed policy, [`AdministratorAccess-Amplify`](https://console.aws.amazon.com/iam/home#policies/arn:aws:iam::aws:policy/AdministratorAccess-Amplify).\nPlease refer to the Amplify [IAM Policy](/cli/reference/iam) documentation for additional information regarding the necessary permissions for Amplify CLI and for more information on providing additional permissions to your Amplify CLI IAM user refer to [AWS IAM User](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_users_change-permissions.html#users_change_permissions-add-directly-console) documentation.\n\n</Callout>\n\n## Reference Amplify project and environment name\n\nAmplify provides you helper functions to get Amplify project information such as the project name and the current Amplify environment name.\n\n### Reference Amplify project name\n\nUse the `AmplifyHelpers.getProjectInfo()` function to retrieve the project name:\n\n```ts\nimport * as AmplifyHelpers from '@aws-amplify/cli-extensibility-helper';\n\n// ...\n\nconst projectName = AmplifyHelpers.getProjectInfo().projectName;\n```\n\n### Reference Amplify environment name\n\nThere are two access patterns for the environment for two different use cases. Using the right access mechanism for the right use case is critical to ensure multi-environment workflows function properly.\n\nIf you want to use the environment name as a variable for a resource, use `cdk.Fn.ref('env')`:\n\n```ts\nconst role = new iam.Role(this, 'CustomRole', {\n  assumedBy: new iam.AccountRootPrincipal(),\n  roleName: `${roleResourceNamePrefix}-${cdk.Fn.ref('env')}` // Reference to Amplify \"env\" name\n})\n```\n\nIf you want to apply conditional logic based on the current environment name, use `AmplifyHelpers.projectInfo()`:\n\n```ts\nimport * as AmplifyHelpers from '@aws-amplify/cli-extensibility-helper';\n\n// ...\n\nconst envName = AmplifyHelpers.getProjectInfo().envName;\n\nif (envName === \"prod\") {\n  // ...\n} else {\n  // ...\n}\n```\n\n## Reference Amplify-generated resources\n\nThe CDK stack for custom AWS resources can reference Amplify-generated resources' CloudFormation outputs. To reference another resource, first add the resource as a dependency.\n\n```ts\nconst dependencies: AmplifyDependentResourcesAttributes = AmplifyHelpers.addResourceDependency(this,\n  amplifyResourceProps.category,\n  amplifyResourceProps.resourceName,\n  [{\n    category: \"function\", // api, auth, storage, function, etc.\n    resourceName: \"<resource-name>\" // find the resource at \"amplify/backend/<category>/<resourceName>\"\n  } /* add more dependencies as needed */] \n);\n```\n\nThen use the `cdk.Fn.ref` function to create a dynamic reference of the dependencies' outputs.\n\n```ts\nconst myFunctionArn = cdk.Fn.ref(dependencies.function.<resource-name>.Arn)\n```\n\nThe `dependencies` variable has the auto-generated `AmplifyDependentResourcesAttributes` type which includes all Amplify-generated resource output. Run `amplify build` to regenerate `AmplifyDependentResourcesAttributes` if you don't see your category, resource, or parameters.\n",
    "meta": {
      "title": "Use CDK to add custom AWS resources",
      "description": "The Amplify CLI provides the ability to add custom AWS resources with AWS Cloud Development Kit (CDK). Running the `amplify add custom` command in your Amplify project provides CDK starter stacks along with mechanisms to reference other Amplify-generated resources.",
      "subcategory": "Custom AWS resources",
      "category": "Amplify CLI"
    },
    "filename": "/cli/custom/cdk"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Deploy and host your app using either Amplify Console or Amazon CloudFront/S3. The Amplify Console offers fully managed hosting with features such as instant cache invalidation and atomic deploys. For more control with setting up a CDN and hosting buckets, use CloudFront and S3."
      },
      {
        "heading": "Workflow",
        "depth": 2,
        "text": "amplify add hosting\nThis adds the hosting resources to the backend. The command will first prompt for environment selection, either DEV or PROD. Upon completion, the CloudFormation template for the resources is placed in the amplify/backend/hosting directory. "
      },
      {
        "heading": "Workflow",
        "depth": 2,
        "text": "amplify configure hosting\nThis command walks through the steps to configure the different sections of the resources used in hosting, including S3, CloudFront, and publish ignore. See below for more details."
      },
      {
        "heading": "Workflow",
        "depth": 2,
        "text": "amplify publish\nThe amplify publish command is designed to build and publish both the backend and the frontend of the project. In the current implementation, the frontend publish functionality is only available for a JavaScript project for static web hosting."
      },
      {
        "heading": "Workflow",
        "depth": 2,
        "text": "amplify remove hosting\nThis removes the hosting resources locally from the backend. On your next amplify push the provisioned hosting resources will get removed from the cloud. "
      },
      {
        "heading": "Using AWS Amplify Console",
        "depth": 2,
        "text": "The AWS Amplify Console is a continuous deployment and hosting service for Amplify web apps. Learn more."
      },
      {
        "heading": "Using AWS Amplify Console",
        "depth": 2,
        "text": "The AWS Amplify Console provides a Git-based workflow for building, deploying, and hosting your Amplify web app — both the frontend and backend — from source control. Once you connect a feature branch, all code commits are automatically deployed to an amplifyapp.com subdomain or your custom domain. Get Started"
      },
      {
        "heading": "Using AWS Amplify Console",
        "depth": 2,
        "text": "Following are the concepts you would encounter when adding Amplify console as a hosting option for your Amplify app."
      },
      {
        "heading": "Type of deployments",
        "depth": 3,
        "text": "If you select Amplify Console for hosting your Amplify App in the amplify add hosting flow, there are two stages you can select from as a part of the flow:"
      },
      {
        "heading": "Type of deployments",
        "depth": 3,
        "text": "Continuous deployment allows you to publish changes on every code commit by connecting your GitHub, Bitbucket, GitLab, or AWS CodeCommit repositories. Selecting this option would open up your AWS Amplify console where you can connect your Git  repository. Once your repository is connected, run git push to deploy changes to both your backend and frontend in a single workflow."
      },
      {
        "heading": "Type of deployments",
        "depth": 3,
        "text": "Manual deployment allows you to publish your web app to the Amplify Console without connecting a Git provider. If you select this option, you will have to run the amplify publish command every time you would like to see your changes reflected in the cloud."
      },
      {
        "heading": "Type of deployments",
        "depth": 3,
        "text": "In order to change deployment types, you need to run amplify remove hosting and then amplify add hosting to choose your new preferred deployment type."
      },
      {
        "heading": "Custom domain, redirects, and more",
        "depth": 3,
        "text": "The amplify configure hosting command for the Amplify Console option, opens up the AWS Amplify Console browser tab for you where you can configure settings such as rewrite/redirect URL's, password protection, custom domain.\nThese settings do not get replicated or cloned between environments and you'd have to configure them on a per-environment basis."
      },
      {
        "heading": "Custom domain, redirects, and more",
        "depth": 3,
        "text": "Note:"
      },
      {
        "heading": "Custom domain, redirects, and more",
        "depth": 3,
        "text": "Amplify Console automatically handles cache invalidation and there is no additional configurations or commands/command-line parameters required for it."
      },
      {
        "heading": "Custom domain, redirects, and more",
        "depth": 3,
        "text": "If you start from the Amplify Console's home page and connect your project's code repository (by clicking Connect app button), the frontend environment is created for your project once the workflow successfully completes. After setting up hosting in the Amplify Console, you cannot run the amplify hosting add command from your local installation of the Amplify CLI. To disable hosting, please visit the Amplify Console and disconnect the branch from the App settings > General page."
      },
      {
        "heading": "Custom domain, redirects, and more",
        "depth": 3,
        "text": "If you're hosting a Single Page Web App (SPA) with routing such as react-router, you'll need to add a redirect in the Amplify console."
      },
      {
        "heading": "Custom domain, redirects, and more",
        "depth": 3,
        "text": ""
      },
      {
        "heading": "Custom domain, redirects, and more",
        "depth": 3,
        "text": "The redirect address should be consistent with the redirect documentation."
      },
      {
        "heading": "Amazon S3 and Amazon Cloudfront",
        "depth": 2,
        "text": "The Amplify CLI provides you the option to manage the hosting of your static website using Amazon S3 and Amazon Cloudfront directly as well. Following are the concepts you would encounter when adding S3 & Cloudfront as a hosting option for your Amplify app."
      },
      {
        "heading": "Stages",
        "depth": 3,
        "text": "If you select Amazon S3 & Amazon Cloudfront for hosting your Amplify App in the amplify add hosting flow, there are two stages you can select from as a part of the flow:"
      },
      {
        "heading": "Stages",
        "depth": 3,
        "text": "DEV:  S3 static web hosting"
      },
      {
        "heading": "Stages",
        "depth": 3,
        "text": "PROD: S3 and CloudFront"
      },
      {
        "heading": "Stages",
        "depth": 3,
        "text": "It can take time to provision a CloudFront Distribution across the global CDN footprint, in some cases 15 minutes or more. Therefore the Amplify CLI provides a DEV configuration with an S3 static site only when prototyping your application; and a PROD configuration when you are ready to deploy in production. Note that the DEV stage using S3, your static site would not have HTTPS support and hence only recommended for prototyping your app."
      },
      {
        "heading": "Stages",
        "depth": 3,
        "text": "Amazon CloudFront service can also be added or removed in your Amplify project later on top of your Amazon S3 bucket by using the amplify hosting configure command. Note that if the hosting S3 bucket is newly created in regions other than us-east-1, you might get the HTTP 307 Temporary Redirect error in the beginning when you access your published application through CloudFront. This is because CloudFront forwards requests to the default S3 endpoint (s3.amazonaws.com), which is in the us-east-1 region, and it can take up to 24 hours for the new hosting bucket name to propagate globally."
      },
      {
        "heading": "Stages",
        "depth": 3,
        "text": "For more  information of the Amazon S3 and Amazon CloudFront, check their docs:\nS3 static web hosting\nCloudFront DEV Guide"
      },
      {
        "heading": "Cache Invalidation",
        "depth": 3,
        "text": "If you select Amazon S3 & Amazon Cloudfront for hosting your Amplify App in the amplify add hosting flow, the frontend build artifacts will be uploaded to the S3 hosting bucket, and then if Amazon CloudFront is enabled along with it, the amplify publish command executed with the --invalidateCloudFront or -c flag will send an invalidation request to the Amazon CloudFront service to invalidate its cache."
      },
      {
        "heading": "Advanced Configurations",
        "depth": 3,
        "text": "The amplify configure hosting command walks through the steps to configure the different sections of the resources used when hosting through Amazon S3 & Amazon Cloudfront. Following are the available configurable options:"
      },
      {
        "heading": "Advanced Configurations",
        "depth": 3,
        "text": "Website\nConfigures the S3 bucket for static web hosting. You can set the index doc and error doc references by configuring this option. Both are set to be index.html by default."
      },
      {
        "heading": "Advanced Configurations",
        "depth": 3,
        "text": "CloudFront\nConfigures the CloudFront content delivery network (CDN). You can configure TTLs (Time To Live) for the default cache behavior, and configure custom error responses."
      },
      {
        "heading": "Advanced Configurations",
        "depth": 3,
        "text": "Publish\nConfigures the publish ignore patterns (similar to a .gitignore file in your git based project) for the publish command. The publish command will ignore these set of directories and files in the distribution folder that have names matching the patterns."
      }
    ],
    "source": "export const meta = {\n  title: `Overview`,\n  description: `Deploy and host your app using either Amplify Console or Amazon CloudFront/S3. The Amplify Console offers fully managed hosting with features such as instant cache invalidation and atomic deploys.`,\n};\n\nDeploy and host your app using either Amplify Console or Amazon CloudFront/S3. The Amplify Console offers fully managed hosting with features such as instant cache invalidation and atomic deploys. For more control with setting up a CDN and hosting buckets, use CloudFront and S3.\n\n## Workflow\n\n- `amplify add hosting`<br/>\nThis adds the hosting resources to the backend. The command will first prompt for environment selection, either DEV or PROD. Upon completion, the CloudFormation template for the resources is placed in the amplify/backend/hosting directory. <br/><br/>\n- `amplify configure hosting`<br/>\nThis command walks through the steps to configure the different sections of the resources used in hosting, including S3, CloudFront, and publish ignore. See below for more details.<br/><br/>\n- `amplify publish`<br/>\nThe `amplify publish` command is designed to build and publish both the backend and the frontend of the project. In the current implementation, the frontend publish functionality is only available for a JavaScript project for static web hosting.<br/><br/>\n- `amplify remove hosting`<br/>\nThis removes the hosting resources locally from the backend. On your next `amplify push` the provisioned hosting resources will get removed from the cloud. <br/><br/>\n\n## Using AWS Amplify Console\n\n<Callout>\n\nThe AWS Amplify Console is a continuous deployment and hosting service for Amplify web apps. [Learn more](https://console.amplify.aws).\n\n</Callout>\n\nThe AWS Amplify Console provides a Git-based workflow for building, deploying, and hosting your Amplify web app — both the frontend and backend — from source control. Once you connect a feature branch, all code commits are automatically deployed to an `amplifyapp.com` subdomain or your custom domain. [Get Started](https://docs.aws.amazon.com/amplify/latest/userguide/getting-started.html)\n\nFollowing are the concepts you would encounter when adding Amplify console as a hosting option for your Amplify app.\n\n### Type of deployments\n\nIf you select Amplify Console for hosting your Amplify App in the `amplify add hosting` flow, there are two stages you can select from as a part of the flow:\n\n- **Continuous deployment** allows you to publish changes on every code commit by connecting your GitHub, Bitbucket, GitLab, or AWS CodeCommit repositories. Selecting this option would open up your AWS Amplify console where you can connect your Git  repository. Once your repository is connected, run `git push` to deploy changes to both your backend and frontend in a single workflow.\n- **Manual deployment** allows you to publish your web app to the Amplify Console without connecting a Git provider. If you select this option, you will have to run the `amplify publish` command every time you would like to see your changes reflected in the cloud.\n\nIn order to change deployment types, you need to run `amplify remove hosting` and then `amplify add hosting` to choose your new preferred deployment type.\n\n### Custom domain, redirects, and more\n\nThe `amplify configure hosting` command for the Amplify Console option, opens up the AWS Amplify Console browser tab for you where you can configure settings such as rewrite/redirect URL's, password protection, custom domain.\nThese settings do not get replicated or cloned between environments and you'd have to configure them on a per-environment basis.\n\n**Note:**\n\nAmplify Console automatically handles cache invalidation and there is no additional configurations or commands/command-line parameters required for it.\n\nIf you start from the Amplify Console's home page and connect your project's code repository (by clicking `Connect app` button), the frontend environment is created for your project once the workflow successfully completes. After setting up hosting in the Amplify Console, you cannot run the `amplify hosting add` command from your local installation of the Amplify CLI. To disable hosting, please visit the Amplify Console and disconnect the branch from the `App settings > General` page.\n\nIf you're hosting a Single Page Web App (SPA) with routing such as [`react-router`](https://reactrouter.com/web/guides/quick-start), you'll need to add a [redirect](https://docs.aws.amazon.com/amplify/latest/userguide/redirects.html#redirects-for-single-page-web-apps-spa) in the Amplify console.\n\n![SPA redirect](/images/hosting/spa-redirect.png)\n\n[The redirect address should be consistent with the redirect documentation.](https://docs.aws.amazon.com/amplify/latest/userguide/redirects.html#redirects-for-single-page-web-apps-spa)\n\n## Amazon S3 and Amazon Cloudfront\n\nThe Amplify CLI provides you the option to manage the hosting of your static website using Amazon S3 and Amazon Cloudfront directly as well. Following are the concepts you would encounter when adding S3 & Cloudfront as a hosting option for your Amplify app.\n\n### Stages\n\nIf you select Amazon S3 & Amazon Cloudfront for hosting your Amplify App in the `amplify add hosting` flow, there are two stages you can select from as a part of the flow:\n\n- DEV:  S3 static web hosting\n- PROD: S3 and CloudFront\n\nIt can take time to provision a CloudFront Distribution across the global CDN footprint, in some cases 15 minutes or more. Therefore the Amplify CLI provides a DEV configuration with an S3 static site only when prototyping your application; and a PROD configuration when you are ready to deploy in production. Note that the DEV stage using S3, your static site would not have HTTPS support and hence **only recommended for prototyping your app**.\n\nAmazon CloudFront service can also be added or removed in your Amplify project later on top of your Amazon S3 bucket by using the `amplify hosting configure` command. Note that if the hosting S3 bucket is newly created in regions other than us-east-1, you might get the `HTTP 307 Temporary Redirect` error in the beginning when you access your published application through CloudFront. This is because CloudFront forwards requests to the default S3 endpoint (s3.amazonaws.com), which is in the us-east-1 region, and it can take up to 24 hours for the new hosting bucket name to propagate globally.\n\nFor more  information of the Amazon S3 and Amazon CloudFront, check their docs:\n[S3 static web hosting](https://docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteHosting.html)\n[CloudFront DEV Guide](https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Introduction.html)\n\n### Cache Invalidation\n\nIf you select Amazon S3 & Amazon Cloudfront for hosting your Amplify App in the `amplify add hosting` flow, the frontend build artifacts will be uploaded to the S3 hosting bucket, and then if Amazon CloudFront is enabled along with it, the `amplify publish` command executed with the `--invalidateCloudFront` or `-c` flag will send an invalidation request to the Amazon CloudFront service to invalidate its cache.\n\n### Advanced Configurations\n\nThe `amplify configure hosting` command walks through the steps to configure the different sections of the resources used when hosting through Amazon S3 & Amazon Cloudfront. Following are the available configurable options:\n\n- `Website`<br/>\nConfigures the S3 bucket for static web hosting. You can set the index doc and error doc references by configuring this option. Both are set to be `index.html` by default.<br/><br/>\n- `CloudFront`<br/>\nConfigures the CloudFront content delivery network (CDN). You can configure TTLs (Time To Live) for the default cache behavior, and configure custom error responses.<br/><br/>\n- `Publish`<br/>\nConfigures the publish ignore patterns (similar to a .gitignore file in your git based project) for the publish command. The publish command will ignore these set of directories and files in the distribution folder that have names matching the patterns.\n",
    "meta": {
      "title": "Overview",
      "description": "Deploy and host your app using either Amplify Console or Amazon CloudFront/S3. The Amplify Console offers fully managed hosting with features such as instant cache invalidation and atomic deploys.",
      "subcategory": "Hosting",
      "category": "Amplify CLI"
    },
    "filename": "/cli/hosting/hosting"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "A Geofence is a virtual perimeter for a real-world geographic area. A Geofence contains points or vertices that form a closed boundary, defining an area of interest.\nGeofence collections store one or multiple Geofences.\nAmplify's geo category enables you to create and manage Geofence collections used to setup virtual geographic perimeters."
      },
      {
        "heading": "Setup a new Geofence Collection",
        "depth": 2,
        "text": "Before you add a new Geofence Collection to your application, you need to have at least one Cognito User Pool group added to your project.\nThe permissions to perform CRUD operations on Geofences in the collection will be granted only to users belonging to a Cognito User Pool group that is responsible for managing these Geofences."
      },
      {
        "heading": "Setup a new Geofence Collection",
        "depth": 2,
        "text": "If you haven't set up the auth category already, you can do so by running:"
      },
      {
        "heading": "Setup a new Geofence Collection",
        "depth": 2,
        "text": "When you have auth category set up, you can add the Cognito User Pool groups using:"
      },
      {
        "heading": "Setup a new Geofence Collection",
        "depth": 2,
        "text": "If you want to grant access to previously created geo resources to the users of the Cognito group added above,\nfollow the instructions as mentioned in the section below."
      },
      {
        "heading": "Setup a new Geofence Collection",
        "depth": 2,
        "text": "Additionally, if you want to add existing users to the Cognito group,\nfollow the instructions as mentioned in the section below."
      },
      {
        "heading": "Setup a new Geofence Collection",
        "depth": 2,
        "text": "When you have at least one Cognito User Pool group added, you can now provision a new Geofence Collection using:"
      },
      {
        "heading": "Setup a new Geofence Collection",
        "depth": 2,
        "text": "Next, set a name for the Geofence Collection:"
      },
      {
        "heading": "Geofence Collection Access permissions",
        "depth": 2,
        "text": "Next, configure the access permissions for your geofence collection resource and authorize users of desired Cognito User Pool groups to perform CRUD operations on Geofences in the collection."
      },
      {
        "heading": "Geofence Collection Access permissions",
        "depth": 2,
        "text": "The above chosen permissions are granted to the users belonging the specified Cognito User Pool group.\nPlease note that these permissions apply to ALL Geofences in a collection. For example, If you chose Read geofence permission for say storesInWashingtonGeofenceCollectionAdmin\nCognito group, ALL users added to that group will be able to read the properties of ALL Geofences in that Geofence collection."
      },
      {
        "heading": "Geofence Collection Pricing Plan",
        "depth": 2,
        "text": "The pricing plan for the Geofence Collection will be set to RequestBasedUsage.\nWe advice you to go through the location service pricing along with the location service terms (82.5 section) to learn more about the pricing plan."
      },
      {
        "heading": "Set a default Geofence Collection",
        "depth": 2,
        "text": "If you added more than one geofence collection via amplify add geo, the geofence collection that was added last will be the default.\nHowever, you can choose if the current geofence collection should be the default for your application:"
      },
      {
        "heading": "Set a default Geofence Collection",
        "depth": 2,
        "text": "Answering No will retain the previously set default."
      },
      {
        "heading": "Set a default Geofence Collection",
        "depth": 2,
        "text": "That's it! You can now create virtual perimeters around points of interest in your application. Follow the library documentation as listed here."
      },
      {
        "heading": "Granting Maps and Search permissions to a group of users",
        "depth": 2,
        "text": "If you want to grant permissions to render a Map or Search for places to the users of a Cognito group,\nyou can do so as shown below:"
      },
      {
        "heading": "Auth/Guest Users access",
        "depth": 4,
        "text": "Select Auth/Guest Users, to scope permissions based on an individual user's authentication status.\nOn the next question you'll be able to select if only authenticated users can access resources, or authenticated and guest users:"
      },
      {
        "heading": "Auth/Guest Users access",
        "depth": 4,
        "text": "Select Authorized users only if only authenticated users are allowed to render the map."
      },
      {
        "heading": "Auth/Guest Users access",
        "depth": 4,
        "text": "Select Authorized and Guest users if both authenticated and unauthenticated users are allowed to render the map."
      },
      {
        "heading": "Auth/Guest Users access",
        "depth": 4,
        "text": "For more information, refer link to location service page."
      },
      {
        "heading": "Individual Group access",
        "depth": 4,
        "text": "Select Individual Groups to scope access permissions based on Cognito User Groups"
      },
      {
        "heading": "Individual Group access",
        "depth": 4,
        "text": "Note: If you combine Auth/Guest user access and Individual Group access, users who are members of a group will only be granted the permissions of the group, and not the authenticated user permissions."
      },
      {
        "heading": "Adding users to a Cognito User Pool Group",
        "depth": 2,
        "text": "In order to add users to an existing Cognito user pool group created using Amplify CLI, follow the steps mentioned below:"
      },
      {
        "heading": "Using the AWS console",
        "depth": 4,
        "text": "Open the AWS console page corresponding to the user pool that is provisioned by Amplify CLI using"
      },
      {
        "heading": "Using the AWS console",
        "depth": 4,
        "text": "From the Cognito user pool console page that opened in your default browser, choose Users and groups tab in General settings.\nThen, choose the corresponding Cognito group from the Groups tab on the right as shown\n"
      },
      {
        "heading": "Using the AWS console",
        "depth": 4,
        "text": "Then click on the Add users button that displays a window to select the users by their username, email etc. that you intend to add to the Cognito group. Note: the user(s) added to the Cognito User Pool Group may need to be re-authenticated by signing out and signing in again.\n"
      },
      {
        "heading": "Using the AWS SDK for Javascript",
        "depth": 4,
        "text": "Alternatively, if you want to add users to an existing Cognito user pool group programmatically, you can use the AWS SDK for Javascript. Refer to the API documentation."
      },
      {
        "heading": "Upload your own GeoJSON file to geofence collection",
        "depth": 2,
        "text": "After you have added geofence collection and provisioned the resource, you will be able to upload your own GeoJSON file that defines the Geofences in a collection via the command:"
      },
      {
        "heading": "Upload your own GeoJSON file to geofence collection",
        "depth": 2,
        "text": "You can refer to GeoJSON.IO where you can draw your own geofences and have GeoJSON file auto generated. After you get the GeoJSON file, you can provide the file path:"
      },
      {
        "heading": "Upload your own GeoJSON file to geofence collection",
        "depth": 2,
        "text": "For each geofence feature, it requires a unique identifier. According to the RFC7946, There are two options for applying identifiers:"
      },
      {
        "heading": "Root level ID",
        "depth": 3,
        "text": "This option will use auto-generated id field in the root level of Feature object as identifier."
      },
      {
        "heading": "Root level ID",
        "depth": 3,
        "text": "Note: This option will UPDATE your GeoJSON file"
      },
      {
        "heading": "Custom properties",
        "depth": 3,
        "text": "This option allows you to choose your own fields inside properties of Feature object. Amplify CLI will help scan the candidate properties and provide them as options in the walkthrough. The candidate properties are chosen based on the existence of all feature objects. The identifier field should have unique values among geofences and will be validated after being selected."
      },
      {
        "heading": "Custom properties",
        "depth": 3,
        "text": "A validation of the GeoJSON file will be executed afterwards. The upload of geofences will be triggered upon the success of validation. For the regulation of GeoJSON, please refer to RFC7946"
      },
      {
        "heading": "Custom properties",
        "depth": 3,
        "text": "Note: After you have provisioned the Geofence Collection using Amplify CLI, depending on your application's use-case, you can also add Geofences to\nthe provisioned Geofence Collection programmatically. Refer this API documentation for more information."
      }
    ],
    "source": "export const meta = {\n  title: `Geofencing`,\n  description: `Use Amplify CLI to create and manage collections of Geofences`,\n};\n\nA Geofence is a virtual perimeter for a real-world geographic area. A Geofence contains points or vertices that form a closed boundary, defining an area of interest. \nGeofence collections store one or multiple Geofences.\nAmplify's `geo` category enables you to create and manage Geofence collections used to setup virtual geographic perimeters.\n\n## Setup a new Geofence Collection\nBefore you add a new Geofence Collection to your application, you need to have at least one Cognito User Pool group added to your project.\nThe permissions to perform `CRUD` operations on Geofences in the collection will be granted only to users belonging to a Cognito User Pool group that is responsible for managing these Geofences.\n\nIf you haven't set up the `auth` category already, you can do so by running:\n```bash\namplify add auth\n```\n\nWhen you have `auth` category set up, you can add the Cognito User Pool groups using:\n```bash\namplify update auth\n```\n```console\n? What do you want to do? \n  Apply default configuration with Social Provider (Federation) \n  Walkthrough all the auth configurations \n❯ Create or update Cognito user pool groups \n  Create or update Admin queries API \n\n? Provide a name for your user pool group: storesInWashingtonGeofenceCollectionAdmin\n\n? Do you want to add another User Pool Group No\n\n? Sort the user pool groups in order of preference\n  storesInWashingtonGeofenceCollectionAdmin\n\n```\n\nIf you want to grant access to previously created geo resources to the users of the Cognito group added above, \nfollow the instructions as mentioned [in the section below](#granting-maps-and-search-permissions-to-a-group-of-users).\n\nAdditionally, if you want to add existing users to the Cognito group, \nfollow the instructions as mentioned [in the section below](#adding-users-to-a-cognito-user-pool-group).\n\nWhen you have at least one Cognito User Pool group added, you can now provision a new Geofence Collection using:\n```bash\namplify add geo\n```\n```console\n? Select which capability you want to add: \n  Map (visualize the geospatial data) \n  Location search (search by places, addresses, coordinates) \n❯ Geofencing (visualize virtual perimeters)\n```\n\nNext, set a name for the Geofence Collection: \n\n```console\n? Provide a name for the Geofence Collection: storesInWashington\n```\n\n## Geofence Collection Access permissions\n\nNext, configure the access permissions for your geofence collection resource and authorize users of desired Cognito User Pool groups to perform `CRUD` operations on Geofences in the collection.\n\n```console\n? Select one or more cognito groups to give access:\n✔ storesInWashingtonGeofenceCollectionAdmin\n\n? What kind of access do you want for storesInWashingtonGeofenceCollectionAdmin users? Select ALL that apply:\n ✔ Read geofence\n ✔ Create/Update geofence\n   Delete geofence\n ✔ List geofences\n```\n\nThe above chosen permissions are granted to the users belonging the specified Cognito User Pool group. \nPlease note that these permissions apply to ALL Geofences in a collection. For example, If you chose `Read geofence` permission for say `storesInWashingtonGeofenceCollectionAdmin`\nCognito group, ALL users added to that group will be able to read the properties of ALL Geofences in that Geofence collection.\n\n## Geofence Collection Pricing Plan\n\nThe pricing plan for the Geofence Collection will be set to `RequestBasedUsage`.\nWe advice you to go through the [location service pricing](https://aws.amazon.com/location/pricing/) along with the [location service terms](https://aws.amazon.com/service-terms/) (_82.5 section_) to learn more about the pricing plan.\n\n## Set a default Geofence Collection\nIf you added more than one geofence collection via `amplify add geo`, the geofence collection that was added last will be the default. \nHowever, you can choose if the current geofence collection should be the default for your application:\n\n```console\n? Set this geofence collection as the default? It will be used in Amplify geofence collection API calls if no explicit reference is provided. (Y/n)\n> No\n```\nAnswering `No` will retain the previously set default.\n\nThat's it! You can now create virtual perimeters around points of interest in your application. Follow the library documentation as listed [here](/lib/geo/geofences).\n\n## Granting Maps and Search permissions to a group of users\nIf you want to grant permissions to render a Map or Search for places to the users of a Cognito group,\nyou can do so as shown below:\n\n```bash\namplify update geo\n```\n\n```console\n? Select which capability you want to update: (Use arrow keys)\n❯ Map (visualize the geospatial data) \n  Location search (search by places, addresses, coordinates) \n  Geofencing (visualize virtual perimeters)\n\n? Select the Map you want to update:\n❯ EsriDarkCanvasMap\n\n? Restrict access by?\n  Auth/Guest Users\n  Individual Groups\n❯ Both\n  Learn more\n```\n\n#### Auth/Guest Users access\n\nSelect `Auth/Guest Users`, to scope permissions based on an individual user's authentication status. \nOn the next question you'll be able to select if only authenticated users can access resources, or authenticated and guest users:\n\n```\n? Who can access this Map?\n❯ Authorized users only\n  Authorized and Guest users\n```\n\nSelect `Authorized users only` if only authenticated users are allowed to render the map.\n\nSelect `Authorized and Guest users` if both authenticated and unauthenticated users are allowed to render the map.\n\nFor more information, refer [link to location service page](https://docs.aws.amazon.com/location/latest/developerguide/security_iam_id-based-policy-examples.html#security_iam_id-based-policy-examples-get-map-tiles).\n\n#### Individual Group access\nSelect `Individual Groups` to scope access permissions based on [Cognito User Groups](/cli/auth/groups)\n\n```console\n? Select one or more cognito groups to give access:\n  ✔ storesInWashingtonGeofenceCollectionAdmin\n```\n\n> Note: If you combine `Auth/Guest user access` and `Individual Group access`, users who are members of a group will only be granted the permissions of the group, and not the authenticated user permissions.\n\n## Adding users to a Cognito User Pool Group\nIn order to add users to an existing Cognito user pool group created using Amplify CLI, follow the steps mentioned below:\n\n#### Using the AWS console\nOpen the AWS console page corresponding to the user pool that is provisioned by Amplify CLI using\n```console\namplify auth console\n\n? Which console \n❯ User Pool \n  Identity Pool \n  User Pool and Identity Pool\n```\n\nFrom the Cognito user pool console page that opened in your default browser, choose `Users and groups` tab in `General settings`.\nThen, choose the corresponding Cognito group from the `Groups` tab on the right as shown \n![cognito user pool console groups tab](/images/cli/geo/geo-cognito-groups-1.png)\n\nThen click on the `Add users` button that displays a window to select the users by their `username`, `email` etc. that you intend to add to the Cognito group. _Note: the user(s) added to the Cognito User Pool Group may need to be re-authenticated by signing out and signing in again._\n![cognito group add users button](/images/cli/geo/geo-cognito-groups-2.png)\n\n#### Using the AWS SDK for Javascript\nAlternatively, if you want to add users to an existing Cognito user pool group programmatically, you can use the AWS SDK for Javascript. Refer to the [API documentation](https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/CognitoIdentityServiceProvider.html#adminAddUserToGroup).\n\n## Upload your own GeoJSON file to geofence collection\nAfter you have added geofence collection and provisioned the resource, you will be able to upload your own GeoJSON file that defines the Geofences in a collection via the command: \n```bash\namplify geo import\n```\nYou can refer to [GeoJSON.IO](https://geojson.io/) where you can draw your own geofences and have GeoJSON file auto generated. After you get the GeoJSON file, you can provide the file path:\n```console\n? Provide the path to GeoJSON file containing the Geofences for ${your_geofence_collection} collection:\n> ${your_input_geojson_file_path}\n```\nFor each geofence feature, it requires a unique identifier. According to the [RFC7946](https://datatracker.ietf.org/doc/html/rfc7946#section-3.2), There are two options for applying identifiers:\n\n### Root level ID\n\nThis option will use auto-generated `id` field in the root level of Feature object as identifier.\n<Callout>\n\n**Note:** This option will UPDATE your GeoJSON file\n\n</Callout>\n\n```console\n? Select the property to use as the Geofence feature identifier:\n> Use root-level \"id\" field. (Auto-assigned if missing)\n```\n\n### Custom properties\n\nThis option allows you to choose your own fields inside `properties` of Feature object. Amplify CLI will help scan the candidate properties and provide them as options in the walkthrough. The candidate properties are chosen based on the existence of all feature objects. The identifier field should have unique values among geofences and will be validated after being selected.\n```console\n? Select the property to use as the Geofence feature identifier:\n  Use root-level \"id\" field. (Auto-assigned if missing)\n> ${scanned_candidate_property_1}\n  ${scanned_candidate_property_2}\n```\n\nA validation of the GeoJSON file will be executed afterwards. The upload of geofences will be triggered upon the success of validation. For the regulation of GeoJSON, please refer to [RFC7946](https://datatracker.ietf.org/doc/html/rfc7946)\n```console\n✅ Successfully validated GeoJSON file.\n✅ Successfully added/updated Geofences in your collection\n```\n\n<Callout>\n\n**Note:** After you have provisioned the Geofence Collection using Amplify CLI, depending on your application's use-case, you can also add Geofences to\nthe provisioned Geofence Collection programmatically. Refer this [API documentation](/lib/geo/geofences#savegeofences) for more information.\n\n</Callout>\n",
    "meta": {
      "title": "Geofencing",
      "description": "Use Amplify CLI to create and manage collections of Geofences",
      "subcategory": "Geo",
      "category": "Amplify CLI"
    },
    "filename": "/cli/geo/geofencing"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Amplify's geo category enables you to search by places, addresses, and coordinates in your app with \"place index\" resources."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Note: Please reach out to us for any feedback and/or issues here"
      },
      {
        "heading": "Setup a new Location Search Index",
        "depth": 2,
        "text": "You can add a new location search index by running the following command from your project's root folder:"
      },
      {
        "heading": "Setup a new Location Search Index",
        "depth": 2,
        "text": "If you haven't set up the auth category already, the Amplify CLI will guide you to enable the auth category.\nThe auth category is required in your application so that the appropriate permissions to search for places can be given to Authorized and/or Guest users as described below."
      },
      {
        "heading": "Setup a new Location Search Index",
        "depth": 2,
        "text": "Next, set a name for the location search index:"
      },
      {
        "heading": "Location Search Access permissions",
        "depth": 2,
        "text": "Next, configure the access permissions for your location search index and authorize users to search for places. You can scope permissions based on an individual user's authentication status."
      },
      {
        "heading": "Location Search Access permissions",
        "depth": 2,
        "text": "Select Authorized users only if only authenticated users can search for places."
      },
      {
        "heading": "Location Search Access permissions",
        "depth": 2,
        "text": "Select Authorized and Guest users if both authenticated and unauthenticated users can can search for places."
      },
      {
        "heading": "Location Search Access permissions",
        "depth": 2,
        "text": "For more information, refer link to location service page."
      },
      {
        "heading": "Location Search Access permissions",
        "depth": 2,
        "text": "Note:\nIf you are using Amplify CLI version 7.6.19 or older and have a Search Index added to your application, please follow these instructions to get the auto-complete suggestions for search:"
      },
      {
        "heading": "Location Search Access permissions",
        "depth": 2,
        "text": "Upgrade the Amplify CLI to version 7.6.20 or later using npm i -g @aws-amplify/cli."
      },
      {
        "heading": "Location Search Access permissions",
        "depth": 2,
        "text": "Run amplify update geo and select the existing Search Index. Choose the same configuration for the Search Index that you already have."
      },
      {
        "heading": "Location Search Access permissions",
        "depth": 2,
        "text": "Run amplify push to update the backend resource."
      },
      {
        "heading": "Location Search Index Pricing Plan",
        "depth": 2,
        "text": "The pricing plan for Search Index will be set to RequestBasedUsage.\nWe advice you to go through the location service pricing along with the location service terms (82.5 section) to learn more about the pricing plan."
      },
      {
        "heading": "Update Location Search Index pricing plan to RequestBasedUsage",
        "depth": 3,
        "text": "You can check the pricing plan for your Search Index from geo/<searchIndexID>/pricingPlan attribute in your project metadata file located at amplify/backend/amplify-meta.json in your project."
      },
      {
        "heading": "Update Location Search Index pricing plan to RequestBasedUsage",
        "depth": 3,
        "text": "You can check your Amplify CLI version using amplify -v."
      },
      {
        "heading": "Update Location Search Index pricing plan to RequestBasedUsage",
        "depth": 3,
        "text": "Note:\nIf you are using Amplify CLI version 7.6.8 or older and have a Search Index added to your application with the pricing plan set to MobileAssetTracking or MobileAssetManagement,\nplease follow these instructions to update the pricing plan:"
      },
      {
        "heading": "Update Location Search Index pricing plan to RequestBasedUsage",
        "depth": 3,
        "text": "Upgrade the Amplify CLI to version 7.6.9 or later using npm i -g @aws-amplify/cli."
      },
      {
        "heading": "Update Location Search Index pricing plan to RequestBasedUsage",
        "depth": 3,
        "text": "Run amplify update geo and select the Search Index with Asset based pricing plan. Choose the same configuration for the Search Index that you already have."
      },
      {
        "heading": "Update Location Search Index pricing plan to RequestBasedUsage",
        "depth": 3,
        "text": "Run amplify push to update the backend resource."
      },
      {
        "heading": "Advanced Settings",
        "depth": 2,
        "text": "You can optionally configure the data provider and result storage location for your location search index."
      },
      {
        "heading": "Location Search data provider",
        "depth": 3,
        "text": "You can select a data provider as the source for geocoding, reverse geocoding and searches.\nEach provider gathers and curates their data using different means. They may also have varying expertise in different regions of the world.\nThe available data providers of geospatial data are shown. To learn more about data providers, please refer this location service doc."
      },
      {
        "heading": "Location Search data provider",
        "depth": 3,
        "text": "Note: If your application is tracking or routing assets you use in your business (such as delivery vehicles or employees), you may only use HERE as your geolocation provider.\nSee section 82 of the AWS service terms for more details."
      },
      {
        "heading": "Location Search data provider",
        "depth": 3,
        "text": "HERE will be set as default data provider for the location search index, if you do not want to explicitly set this property."
      },
      {
        "heading": "Location Search result storage location",
        "depth": 3,
        "text": "You can specify how the results of a search operation will be stored by the caller."
      },
      {
        "heading": "Location Search result storage location",
        "depth": 3,
        "text": "No will be chosen as default if the developer does not want to explicitly set this property."
      },
      {
        "heading": "Location Search result storage location",
        "depth": 3,
        "text": "Refer this location service doc for more information."
      },
      {
        "heading": "Set a default Location Search Index",
        "depth": 2,
        "text": "If you added more than one location search index via amplify add geo, the index that was added last will be the default.\nHowever, you can choose if the current search index should be the default one used in your application:"
      },
      {
        "heading": "Set a default Location Search Index",
        "depth": 2,
        "text": "Answering No will retain the previously set default."
      },
      {
        "heading": "Set a default Location Search Index",
        "depth": 2,
        "text": "That's it! You can now render maps in your application. Follow the library documentation as listed here."
      }
    ],
    "source": "export const meta = {\n  title: `Location Search`,\n  description: `Use Amplify CLI to create and manage location search indices or place indices that are used to search for places in your application.`,\n};\n\nAmplify's `geo` category enables you to search by places, addresses, and coordinates in your app with \"place index\" resources.\n\n<Callout>\n\n**Note:** Please reach out to us for any feedback and/or issues [here](https://github.com/aws-amplify/amplify-cli/issues)\n\n</Callout>\n\n## Setup a new Location Search Index\n\nYou can add a new location search index by running the following command from your project's root folder:\n\n```bash\namplify add geo\n```\n```console\n? Select which capability you want to add:\n  Map (visualize the geospatial data)\n> Location search (search by places, addresses, coordinates)\n```\nIf you haven't set up the `auth` category already, the Amplify CLI will guide you to enable the auth category.\nThe `auth` category is required in your application so that the appropriate permissions to search for places can be given to Authorized and/or Guest users as described below.\n\nNext, set a name for the location search index:\n\n```console\n? Provide a name for the location search index (place index):\n> MyPlaceIndex\n```\n\n## Location Search Access permissions\n\nNext, configure the access permissions for your location search index and authorize users to search for places. You can scope permissions based on an individual user's authentication status.\n\n```console\n? Who can access this Search Index?\n❯ Authorized users only\n  Authorized and Guest users\n```\n\nSelect `Authorized users only` if only authenticated users can search for places.\n\nSelect `Authorized and Guest users` if both authenticated and unauthenticated users can can search for places.\n\nFor more information, refer [link to location service page](https://docs.aws.amazon.com/location/latest/developerguide/security_iam_id-based-policy-examples.html#security_iam_id-based-policy-examples-search-for-place).\n\n<Callout>\n\n**Note:** \nIf you are using Amplify CLI version `7.6.19` or older and have a Search Index added to your application, please follow these instructions to get the auto-complete suggestions for search:\n1. Upgrade the Amplify CLI to version `7.6.20` or later using `npm i -g @aws-amplify/cli`.\n2. Run `amplify update geo` and select the existing Search Index. Choose the same configuration for the Search Index that you already have.\n3. Run `amplify push` to update the backend resource.\n\n</Callout>\n\n## Location Search Index Pricing Plan\nThe pricing plan for Search Index will be set to `RequestBasedUsage`.\nWe advice you to go through the [location service pricing](https://aws.amazon.com/location/pricing/) along with the [location service terms](https://aws.amazon.com/service-terms/) (_82.5 section_) to learn more about the pricing plan.\n\n### Update Location Search Index pricing plan to `RequestBasedUsage`\nYou can check the pricing plan for your Search Index from `geo/<searchIndexID>/pricingPlan` attribute in your project metadata file located at `amplify/backend/amplify-meta.json` in your project.\n```bash\n\"geo\": {\n    \"MyPlaceIndex\": {\n      \"isDefault\": true,\n      \"providerPlugin\": \"awscloudformation\",\n      \"service\": \"PlaceIndex\",\n      \"dataProvider\": \"Esri\",\n      \"dataSourceIntendedUse\": \"SingleUse\",\n      \"pricingPlan\": \"MobileAssetManagement\",\n      \"accessType\": \"AuthorizedUsers\"\n    }\n}\n```\n\nYou can check your Amplify CLI version using `amplify -v`.\n\n\n<Callout>\n\n**Note:** \nIf you are using Amplify CLI version `7.6.8` or older and have a Search Index added to your application with the pricing plan set to `MobileAssetTracking` or `MobileAssetManagement`,\nplease follow these instructions to update the pricing plan:\n1. Upgrade the Amplify CLI to version `7.6.9` or later using `npm i -g @aws-amplify/cli`.\n2. Run `amplify update geo` and select the Search Index with Asset based pricing plan. Choose the same configuration for the Search Index that you already have.\n3. Run `amplify push` to update the backend resource.\n\n</Callout>\n\n## Advanced Settings\nYou can optionally configure the data provider and result storage location for your location search index.\n\n### Location Search data provider\nYou can select a data provider as the source for geocoding, reverse geocoding and searches.\nEach provider gathers and curates their data using different means. They may also have varying expertise in different regions of the world.\nThe available data providers of geospatial data are shown. To learn more about data providers, please refer this [location service doc](https://docs.aws.amazon.com/location/latest/developerguide/what-is-data-provider.html).\n\n```console\n? Specify the data provider of geospatial data for this Search Index:\n  Esri\n❯ HERE\n```\n\n<Callout>\n\n**Note:** If your application is tracking or routing assets you use in your business (such as delivery vehicles or employees), you may only use `HERE` as your geolocation provider. \nSee section 82 of the [AWS service terms](https://aws.amazon.com/service-terms/) for more details.\n\n</Callout>\n\n`HERE` will be set as default data provider for the location search index, if you do not want to explicitly set this property.\n\n### Location Search result storage location\nYou can specify how the results of a search operation will be stored by the caller.\n\n```console\n? Do you want to cache or store the results of search operations?\n> No\n```\n\n`No` will be chosen as default if the developer does not want to explicitly set this property.\n\nRefer [this location service doc](https://docs.aws.amazon.com/location-places/latest/APIReference/API_DataSourceConfiguration.html#locationplaces-Type-DataSourceConfiguration-IntendedUse) for more information. \n\n## Set a default Location Search Index\nIf you added more than one location search index via `amplify add geo`, the index that was added last will be the default. \nHowever, you can choose if the current search index should be the default one used in your application:\n\n```console\nSet this search index as the default? It will be used in Amplify Search API calls if no explicit reference is provided.\n> No\n```\n\nAnswering `No` will retain the previously set default.\n\nThat's it! You can now render maps in your application. Follow the library documentation as listed [here](/lib/geo/search).\n",
    "meta": {
      "title": "Location Search",
      "description": "Use Amplify CLI to create and manage location search indices or place indices that are used to search for places in your application.",
      "subcategory": "Geo",
      "category": "Amplify CLI"
    },
    "filename": "/cli/geo/search"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Amplify's geo category enables you to create and manage map resources used to visualize geospatial data in your application."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Note: Please reach out to us for any feedback and/or issues here"
      },
      {
        "heading": "Setup a new Map",
        "depth": 2,
        "text": "You can add a new map by running the following command from your project's root folder:"
      },
      {
        "heading": "Setup a new Map",
        "depth": 2,
        "text": "If you haven't set up the auth category already, the Amplify CLI will guide you to enable the auth category.\nThe auth category is required in your application so that the appropriate permissions to render the map can be given to Authorized and/or Guest users as described below."
      },
      {
        "heading": "Setup a new Map",
        "depth": 2,
        "text": "Next, set a name for the map:"
      },
      {
        "heading": "Map Access permissions",
        "depth": 2,
        "text": "Next, configure the access permissions for your Map resource and authorize users to render the map.\nYou can scope permissions based on an individual user's authentication status."
      },
      {
        "heading": "Map Access permissions",
        "depth": 2,
        "text": "Select Authorized users only if only authenticated users are allowed to render the map."
      },
      {
        "heading": "Map Access permissions",
        "depth": 2,
        "text": "Select Authorized and Guest users if both authenticated and unauthenticated users are allowed to render the map."
      },
      {
        "heading": "Map Access permissions",
        "depth": 2,
        "text": "For more information, refer link to location service page."
      },
      {
        "heading": "Map Pricing Plan",
        "depth": 2,
        "text": "The pricing plan for Map will be set to RequestBasedUsage.\nWe advice you to go through the location service pricing along with the location service terms (82.5 section) to learn more about the pricing plan."
      },
      {
        "heading": "Update Map pricing plan to RequestBasedUsage",
        "depth": 3,
        "text": "You can check the pricing plan for your Map from geo/<mapID>/pricingPlan attribute in your project metadata file located at amplify/backend/amplify-meta.json in your project."
      },
      {
        "heading": "Update Map pricing plan to RequestBasedUsage",
        "depth": 3,
        "text": "You can check your Amplify CLI version using amplify -v."
      },
      {
        "heading": "Update Map pricing plan to RequestBasedUsage",
        "depth": 3,
        "text": "Note:\nIf you are using Amplify CLI version 7.6.8 or older and have a Map added to your application with the pricing plan set to MobileAssetTracking or MobileAssetManagement,\nplease follow these instructions to update the pricing plan:"
      },
      {
        "heading": "Update Map pricing plan to RequestBasedUsage",
        "depth": 3,
        "text": "Upgrade the Amplify CLI to version 7.6.9 or later using npm i -g @aws-amplify/cli."
      },
      {
        "heading": "Update Map pricing plan to RequestBasedUsage",
        "depth": 3,
        "text": "Run amplify update geo and select the Map with Asset based pricing plan. Choose the same configuration for the Map that you already have."
      },
      {
        "heading": "Update Map pricing plan to RequestBasedUsage",
        "depth": 3,
        "text": "Run amplify push to update the backend resource."
      },
      {
        "heading": "Advanced Settings",
        "depth": 2,
        "text": "You can optionally configure the style and data provider for the map."
      },
      {
        "heading": "Map style & Map data provider",
        "depth": 3,
        "text": "You can pick a style for the map resource. The available map styles along with the data provider of geospatial data are shown. To learn more about each of these map styles, please refer this location service doc."
      },
      {
        "heading": "Map style & Map data provider",
        "depth": 3,
        "text": "Note: If your application is tracking or routing assets you use in your business (such as delivery vehicles or employees), you may only use HERE as your geolocation provider.\nSee section 82 of the AWS service terms for more details."
      },
      {
        "heading": "Map style & Map data provider",
        "depth": 3,
        "text": "Streets (data provided by Esri)  will be the default option that will be used to set Map style, if you do not want to explicitly set this property."
      },
      {
        "heading": "Set a default Map",
        "depth": 3,
        "text": "If you added more than one map via amplify add geo, the map that was added last will be the default.\nHowever, you can choose if the current Map should be the default for your application:"
      },
      {
        "heading": "Set a default Map",
        "depth": 3,
        "text": "Answering No will retain the previously set default."
      },
      {
        "heading": "Set a default Map",
        "depth": 3,
        "text": "That's it! You can now render maps in your application. Follow the library documentation as listed here."
      }
    ],
    "source": "export const meta = {\n  title: `Maps`,\n  description: `Use Amplify CLI to create and manage maps to visualize geospatial data in your app.`,\n};\n\nAmplify's `geo` category enables you to create and manage map resources used to visualize geospatial data in your application.\n\n<Callout>\n\n**Note:** Please reach out to us for any feedback and/or issues [here](https://github.com/aws-amplify/amplify-cli/issues)\n\n</Callout>\n\n## Setup a new Map\n\nYou can add a new map by running the following command from your project's root folder:\n\n```bash\namplify add geo\n```\n```console\n? Select which capability you want to add:\n> Map (visualize the geospatial data)\n  Location search (search by places, addresses, coordinates)\n```\nIf you haven't set up the `auth` category already, the Amplify CLI will guide you to enable the auth category.\nThe `auth` category is required in your application so that the appropriate permissions to render the map can be given to Authorized and/or Guest users as described below.\n\nNext, set a name for the map:\n\n```console\n? Provide a name for the Map:\n> StreetsMap\n```\n\n## Map Access permissions\n\nNext, configure the access permissions for your Map resource and authorize users to render the map.\nYou can scope permissions based on an individual user's authentication status.\n\n```console\n? Who can access this Map?\n❯ Authorized users only\n  Authorized and Guest users\n```\n\nSelect `Authorized users only` if only authenticated users are allowed to render the map.\n\nSelect `Authorized and Guest users` if both authenticated and unauthenticated users are allowed to render the map.\n\nFor more information, refer [link to location service page](https://docs.aws.amazon.com/location/latest/developerguide/security_iam_id-based-policy-examples.html#security_iam_id-based-policy-examples-get-map-tiles).\n\n## Map Pricing Plan\nThe pricing plan for Map will be set to `RequestBasedUsage`.\nWe advice you to go through the [location service pricing](https://aws.amazon.com/location/pricing/) along with the [location service terms](https://aws.amazon.com/service-terms/) (_82.5 section_) to learn more about the pricing plan.\n\n### Update Map pricing plan to `RequestBasedUsage`\nYou can check the pricing plan for your Map from `geo/<mapID>/pricingPlan` attribute in your project metadata file located at `amplify/backend/amplify-meta.json` in your project.\n```bash\n\"geo\": {\n    \"StreetsMap\": {\n      \"isDefault\": true,\n      \"providerPlugin\": \"awscloudformation\",\n      \"service\": \"Map\",\n      \"mapStyle\": \"VectorEsriStreets\",\n      \"pricingPlan\": \"MobileAssetManagement\",\n      \"accessType\": \"AuthorizedUsers\"\n    }\n}\n```\n\nYou can check your Amplify CLI version using `amplify -v`.\n\n<Callout>\n\n**Note:**\nIf you are using Amplify CLI version `7.6.8` or older and have a Map added to your application with the pricing plan set to `MobileAssetTracking` or `MobileAssetManagement`,\nplease follow these instructions to update the pricing plan:\n1. Upgrade the Amplify CLI to version `7.6.9` or later using `npm i -g @aws-amplify/cli`.\n2. Run `amplify update geo` and select the Map with Asset based pricing plan. Choose the same configuration for the Map that you already have.\n3. Run `amplify push` to update the backend resource.\n\n</Callout>\n\n## Advanced Settings\nYou can optionally configure the style and data provider for the map.\n\n### Map style & Map data provider\nYou can pick a style for the map resource. The available map styles along with the data provider of geospatial data are shown. To learn more about each of these map styles, please refer this [location service doc](https://docs.aws.amazon.com/location-maps/latest/APIReference/API_MapConfiguration.html).\n\n<Callout>\n\n**Note:** If your application is tracking or routing assets you use in your business (such as delivery vehicles or employees), you may only use `HERE` as your geolocation provider.\nSee section 82 of the [AWS service terms](https://aws.amazon.com/service-terms/) for more details.\n\n</Callout>\n\n```console\n? Specify the map style:\n❯ Streets (data provided by Esri)\n  Berlin (data provided by HERE)\n  Explore (data provided by HERE)\n  ExploreTruck (data provided by HERE)\n  Topographic (data provided by Esri)\n  Navigation (data provided by Esri)\n  LightGrayCanvas (data provided by Esri)\n  DarkGrayCanvas (data provided by Esri)\n  Imagery (data provided by Esri)\n```\n\n`Streets (data provided by Esri) ` will be the default option that will be used to set Map style, if you do not want to explicitly set this property.\n\n### Set a default Map\nIf you added more than one map via `amplify add geo`, the map that was added last will be the default.\nHowever, you can choose if the current Map should be the default for your application:\n\n```console\n? Set this Map as the default? It will be used in Amplify Map API calls if no explicit reference is provided.\n> No\n```\nAnswering `No` will retain the previously set default.\n\nThat's it! You can now render maps in your application. Follow the library documentation as listed [here](/lib/geo/maps).\n",
    "meta": {
      "title": "Maps",
      "description": "Use Amplify CLI to create and manage maps to visualize geospatial data in your app.",
      "subcategory": "Geo",
      "category": "Amplify CLI"
    },
    "filename": "/cli/geo/maps"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "In some cases, it might be necessary to execute a script before a function is deployed, e.g. to transpile Typescript or ES6 with Babel or with tsc into a format that is supported by the AWS Lambda's node runtime. amplify push will look for a script definition in the project root's package.json with the name amplify:<resource_name> and run it right after npm install is canned in the function resource's src directory."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Example: Transpiling Typescript code with TSC"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Make sure you have the tsc command installed globally by running npm install -g typescript or locally by running npm install --save-dev typescript"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Let's say, a function resource has been created with amplify function add and it is called generateReport. The ES6 source code for this function is located in amplify/backend/function/generateReport/lib and the resource's src directory only contains the auto-generated package.json for this function. In order to compile TypeScript, you have to add the following script definition to your project root's package.json:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Navigate into amplify/backend/function/generateReport and create tsconfig.json then add the following to it:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Note: It is important to note that if you are using aws-sdk in your TypeScript file, you will get a timeout if you attempt to import it with the following:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Change to this:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Once you run amplify push, the amplify:generateReport script will be executed, either by yarn or by npm depending on the existence of a yarn.lock file in the project root directory."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Example: Transpiling ES6 code with Babel"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Let's say, a function resource has been created with amplify function add and it is called generateReport. The ES6 source code for this function is located in amplify/backend/function/generateReport/lib and the resource's src directory only contains the auto-generated package.json for this function. In order to run Babel, you have to add the following script definition and dev dependencies to your project root's package.json:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Babel needs to be configured properly so that the transpiled code can be run on AWS Lambda. This can be done by adding a .babelrc file to the resource folder (amplify/backend/function/generateReport/.babelrc in this case):"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Once you run amplify push, the amplify:generateReport script will be executed, either by yarn or by npm depending on the existence of a yarn.lock file in the project root directory."
      },
      {
        "heading": null,
        "depth": null,
        "text": "There are no existing build options for Python functions. The process of building and packaging Python functions is in line with Amazon's existing documentation for manually creating a Lambda deployment package which depends on a virtual environment."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify will run pipenv install in your function's source directory during builds using either Pipenv's default virtual environment, or whichever virtual environment happens to be active. Then, during the packaging stage, the contents of the site-packages directory for that virtual environment will be zipped up along with the function-specific files."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The contents of the Python build can include local development dependencies (e.g. for testing) in addition to those necessary for your function to run. Packages installed as \"editable\" (using the -e flag) will not be  packaged, as they are represented as an .egg-link file pointing to the local, editable code of the dependency."
      }
    ],
    "source": "export const meta = {\n  title: `Build options`,\n  description: `Use build options for Amplify's function category to execute a script before a function is deployed, e.g. to transpile Typescript or ES6 with Babel into a format that is supported by the AWS Lambda's node runtime.`,\n};\n\n<BlockSwitcher>\n\n<Block name=\"NodeJS\">\n\nIn some cases, it might be necessary to execute a script before a function is deployed, e.g. to transpile Typescript or ES6 with Babel or with `tsc` into a format that is supported by the AWS Lambda's node runtime. `amplify push` will look for a `script` definition in the project root's `package.json` with the name `amplify:<resource_name>` and run it right after `npm install` is canned in the function resource's `src` directory.\n\n**Example: Transpiling Typescript code with TSC**\n\nMake sure you have the `tsc` command installed globally by running `npm install -g typescript` or locally by running `npm install --save-dev typescript`\n\nLet's say, a function resource has been created with `amplify function add` and it is called `generateReport`. The ES6 source code for this function is located in `amplify/backend/function/generateReport/lib` and the resource's `src` directory only contains the auto-generated `package.json` for this function. In order to compile TypeScript, you have to add the following script definition to your project root's `package.json`:\n\n```json\n{\n  \"scripts\": {\n    \"amplify:generateReport\": \"cd amplify/backend/function/generateReport && tsc -p ./tsconfig.json && cd -\"\n  },\n}\n```\n\nNavigate into `amplify/backend/function/generateReport` and create `tsconfig.json` then add the following to it:\n\n```json\n{\n  \"compilerOptions\": {\n    \"allowSyntheticDefaultImports\": true,\n    \"lib\": [\"dom\", \"esnext\"],\n    \"module\": \"commonjs\",\n    \"moduleResolution\": \"node\",\n    \"skipLibCheck\": true,\n    \"resolveJsonModule\": true,\n    \"outDir\": \"./src\",\n    \"baseUrl\": \"./\",\n    \"rootDir\": \"./lib\",\n    \"paths\": {\n      \"src\": [\"./lib\"]\n    }\n  }\n}\n```\n\n**Note:** It is important to note that if you are using `aws-sdk` in your TypeScript file, you will get a timeout if you attempt to import it with the following:\n\n```js\nimport AWS from 'aws-sdk';\n```\n\nChange to this:\n\n```js\nimport * as AWS from 'aws-sdk';\n```\n\nOnce you run `amplify push`, the `amplify:generateReport` script will be executed, either by `yarn` or by `npm` depending on the existence of a `yarn.lock` file in the project root directory.\n\n**Example: Transpiling ES6 code with Babel**\n\nLet's say, a function resource has been created with `amplify function add` and it is called `generateReport`. The ES6 source code for this function is located in `amplify/backend/function/generateReport/lib` and the resource's `src` directory only contains the auto-generated `package.json` for this function. In order to run Babel, you have to add the following script definition and dev dependencies to your project root's `package.json`:\n\n```json\n{\n  \"scripts\": {\n    \"amplify:generateReport\": \"cd amplify/backend/function/generateReport && babel lib -d src && cd -\"\n  },\n  \"devDependencies\": {\n    \"@babel/cli\": \"^7.5.5\",\n    \"@babel/preset-env\": \"^7.5.5\",\n  }\n}\n```\n\nBabel needs to be configured properly so that the transpiled code can be run on AWS Lambda. This can be done by adding a `.babelrc` file to the resource folder (`amplify/backend/function/generateReport/.babelrc` in this case):\n\n```json\n{\n  \"presets\": [\n    [\n      \"env\",\n      {\n        \"exclude\": [\"transform-regenerator\"],\n        \"targets\": {\n          \"node\": \"10.18\"\n        }\n      }\n    ]\n  ],\n  \"plugins\": [\n    \"transform-async-to-generator\",\n    \"transform-exponentiation-operator\",\n    \"transform-object-rest-spread\"\n  ]\n}\n```\n\nOnce you run `amplify push`, the `amplify:generateReport` script will be executed, either by `yarn` or by `npm` depending on the existence of a `yarn.lock` file in the project root directory.\n\n</Block>\n\n<Block name=\"Python\">\n\nThere are no existing build options for Python functions. The process of building and packaging Python functions is in line with Amazon's [existing documentation](https://docs.aws.amazon.com/lambda/latest/dg/python-package.html#python-package-venv) for manually creating a Lambda deployment package which depends on a virtual environment.\n\nAmplify will run `pipenv install` in your function's source directory during builds using either Pipenv's default virtual environment, or whichever virtual environment happens to be active. Then, during the packaging stage, the contents of the `site-packages` directory for that virtual environment will be zipped up along with the function-specific files.\n\nThe contents of the Python build can include local development dependencies (e.g. for testing) in addition to those necessary for your function to run. Packages installed as \"editable\" (using the `-e` flag) will not be  packaged, as they are represented as an `.egg-link` file pointing to the local, editable code of the dependency.\n\n</Block>\n\n</BlockSwitcher>\n",
    "meta": {
      "title": "Build options",
      "description": "Use build options for Amplify's function category to execute a script before a function is deployed, e.g. to transpile Typescript or ES6 with Babel into a format that is supported by the AWS Lambda's node runtime.",
      "subcategory": "Functions",
      "category": "Amplify CLI"
    },
    "filename": "/cli/function/build-options"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Amplify CLI allows you to configure secret values that can be securely accessed from a Lambda function. Each Amplify environment can have a different secret value. This enables use cases such as different API keys for a dev and prod environment. Secrets should be used for values such as database passwords, API keys, and access tokens."
      },
      {
        "heading": null,
        "depth": null,
        "text": "To access non-sensitive configuration values in a Lambda function, use environment variables."
      },
      {
        "heading": "Configuring secret values",
        "depth": 2,
        "text": "To configure a new function with secret values, run amplify add function, select yes to the advanced settings prompt and select yes to the secrets configuration prompt. From there, you can specify the name and value of the secret."
      },
      {
        "heading": "Configuring secret values",
        "depth": 2,
        "text": "To configure secrets for an existing function, run amplify update function, and select Secret values configuration. You can then add, update and remove secret values."
      },
      {
        "heading": "Configuring secret values",
        "depth": 2,
        "text": "Note: Amplify CLI never stores secrets locally. All secret values are immediately stored in AWS Parameter Store using the SecureString parameter type."
      },
      {
        "heading": "Accessing the values in your function",
        "depth": 2,
        "text": "To access the secret values in your Lambda function, use the AWS SSM GetParameter API. Amplify CLI will automatically supply the SSM parameter name of the secret as an environment variable to the function. This value can be passed into the API call as the \"Name\" to retrieve the value. Ensure that the API call has \"WithDecryption\" specified as true."
      },
      {
        "heading": "Accessing the values in your function",
        "depth": 2,
        "text": "If your Lambda function is using the Node.js runtime, a comment block will be placed at the top of your index.js file with example code to retrieve the secret values."
      },
      {
        "heading": "Multi-environment flows",
        "depth": 2,
        "text": "When creating a new Amplify environment using amplify env add, Amplify CLI asks if you want to apply all secret values to the new environment or modify them. If you choose to apply the existing values, you can still make edits anytime using amplify update function."
      },
      {
        "heading": "Multi-environment flows",
        "depth": 2,
        "text": "When creating a new Amplify environment using amplify env add --envName <new env name> --yes, Amplify CLI will apply all secret values from the current environment to the new environment."
      },
      {
        "heading": "Multi-environment flows",
        "depth": 2,
        "text": "In multi-environment workflows, you may have added a new secret in one Amplify environment and then checked out a different Amplify environment. In this case, on the next amplify push. Amplify CLI will detect that there is a new secret that does not have a value specified in the current environment and prompt for one. Running amplify push --yes in this case will fail with a message explaining the missing secret values."
      },
      {
        "heading": "Multi-environment flows",
        "depth": 2,
        "text": "In git-based multi-environment workflows, you may run into errors during deployment. For example, this happens when you add a secret in envA (corresponding to a git branch branchA), then amplify env checkout envB and git checkout branchB and git merge branchA into branchB. Upon pushing envB, Amplify CLI detects that a new secret has been added but can't infer a value for it. To resolve this issue, run the following commands in the terminal:"
      },
      {
        "heading": "Multi-environment flows",
        "depth": 2,
        "text": "amplify env checkout <failing env name>"
      },
      {
        "heading": "Multi-environment flows",
        "depth": 2,
        "text": "amplify push - when prompted, enter a new value for the secret(s)"
      },
      {
        "heading": "Multi-environment flows",
        "depth": 2,
        "text": "git commit"
      },
      {
        "heading": "Multi-environment flows",
        "depth": 2,
        "text": "git push"
      }
    ],
    "source": "export const meta = {\n  title: `Access secret values`,\n  description: `Configure Lambda functions to securely access secret values`,\n};\n\nAmplify CLI allows you to configure secret values that can be securely accessed from a Lambda function. Each Amplify environment can have a different secret value. This enables use cases such as different API keys for a dev and prod environment. Secrets should be used for values such as database passwords, API keys, and access tokens.\n\n> To access non-sensitive configuration values in a Lambda function, use [environment variables](/cli/function/env-vars).\n\n## Configuring secret values\nTo configure a new function with secret values, run `amplify add function`, select `yes` to the advanced settings prompt and select `yes` to the secrets configuration prompt. From there, you can specify the name and value of the secret.\n\n```console\n$ amplify add function\n...\n? Do you want to configure advanced settings? Yes\n...\n? Do you want to configure secret values this function can access? Yes\n? Enter a secret name (this is the key used to look up the secret value): API_KEY\n? Enter the value for API_KEY: [hidden]\n? What do you want to do? (Use arrow keys)\n  Add a secret\n  Update a secret\n  Remove secrets\n> I'm done\n```\n\nTo configure secrets for an existing function, run `amplify update function`, and select `Secret values configuration`. You can then add, update and remove secret values.\n\n```console\n$ amplify update function\n...\n? Which setting do you want to update?\n  Resource access permissions\n  Scheduled recurring invocation\n  Lambda layers configuration\n  Environment variables configuration\n> Secret values configuration\n? What do you want to do?\n> Add a secret\n  Update a secret\n  Remove secrets\n  I'm done\n```\n\n> Note: Amplify CLI never stores secrets locally. All secret values are immediately stored in [AWS Parameter Store](https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-parameter-store.html) using the SecureString parameter type.\n\n## Accessing the values in your function\nTo access the secret values in your Lambda function, use the [AWS SSM GetParameter API](https://docs.aws.amazon.com/systems-manager/latest/APIReference/API_GetParameter.html). Amplify CLI will automatically supply the SSM parameter name of the secret as an environment variable to the function. This value can be passed into the API call as the \"Name\" to retrieve the value. Ensure that the API call has \"WithDecryption\" specified as `true`.\n\nIf your Lambda function is using the Node.js runtime, a comment block will be placed at the top of your `index.js` file with example code to retrieve the secret values.\n\n```js\nconst aws = require('aws-sdk');\n\nconst { Parameters } = await (new aws.SSM())\n  .getParameters({\n    Names: [\"EXAMPLE_SECRET_1\", \"EXAMPLE_SECRET_2\"].map(secretName => process.env[secretName]),\n    WithDecryption: true,\n  })\n  .promise();\n\n// Parameters will be of the form { Name: 'secretName', Value: 'secretValue', ... }[]\n```\n\n## Multi-environment flows\nWhen creating a new Amplify environment using `amplify env add`, Amplify CLI asks if you want to apply all secret values to the new environment or modify them. If you choose to apply the existing values, you can still make edits anytime using `amplify update function`.\n\nWhen creating a new Amplify environment using `amplify env add --envName <new env name> --yes`, Amplify CLI will apply all secret values from the current environment to the new environment.\n\nIn multi-environment workflows, you may have added a new secret in one Amplify environment and then checked out a different Amplify environment. In this case, on the next `amplify push`. Amplify CLI will detect that there is a new secret that does not have a value specified in the current environment and prompt for one. Running `amplify push --yes` in this case will fail with a message explaining the missing secret values.\n\nIn [**git-based** multi-environment workflows](/cli/teams/overview), you may run into errors during deployment. For example, this happens when you add a secret in `envA` (corresponding to a git branch `branchA`), then `amplify env checkout envB` and `git checkout branchB` and `git merge` branchA into branchB. Upon pushing `envB`, Amplify CLI detects that a new secret has been added but can't infer a value for it. To resolve this issue, run the following commands in the terminal:\n\n1. `amplify env checkout <failing env name>`\n2. `amplify push` - when prompted, enter a new value for the secret(s)\n3. `git commit`\n4. `git push`\n",
    "meta": {
      "title": "Access secret values",
      "description": "Configure Lambda functions to securely access secret values",
      "subcategory": "Functions",
      "category": "Amplify CLI"
    },
    "filename": "/cli/function/secrets"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Amplify CLI allows you to configure environment variables for your Lambda functions. Each Amplify environment can have a different environment variable value. This enables use cases such as switching between dev and prod URLs depending on the environment."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Environment variables should NOT be used for storing sensitive configuration values such as database passwords, API keys, or access tokens. Use function secrets configuration instead!"
      },
      {
        "heading": "Configuring environment variables",
        "depth": 2,
        "text": "To configure a new function with environment variables, run amplify add function, select yes to the advanced settings prompt and select yes to the environment variables configuration prompt. From there, you will be able to specify a key and value for the environment variable."
      },
      {
        "heading": "Configuring environment variables",
        "depth": 2,
        "text": "To configure environment variables for an existing function, run amplify update function, and select Environment variables configuration. You can then add, update, or remove environment variables."
      },
      {
        "heading": "Multi-environment flows",
        "depth": 2,
        "text": "When creating a new Amplify environment using amplify env add, Amplify CLI asks if you want to apply all environment variable values to the new environment or modify them. If you choose to apply the existing values, you can still make edits anytime by running amplify update function."
      },
      {
        "heading": "Multi-environment flows",
        "depth": 2,
        "text": "When creating a new Amplify environment using amplify env add --yes, Amplify CLI will apply all environment variable values from the current environment to the new environment."
      },
      {
        "heading": "Multi-environment flows",
        "depth": 2,
        "text": "In multi-environment workflows, you may have added a new environment variable in one Amplify environment and then checked out a different Amplify environment. In this case, on the next amplify push, Amplify CLI will detect that there is a new environment variable that does not have a value specified in the current environment and prompt for one.\nRunning amplify push --yes in this case will fail with a message explaining the missing environment variable values."
      },
      {
        "heading": "Multi-environment flows",
        "depth": 2,
        "text": "In git-based multi-environment workflows, you may run into errors during deployment. For example, this happens when you add an environment variable in envA (corresponding to a git branch branchA), then amplify checkout envB and git checkout branchB and git merge branchA into branchB. Upon pushing envB, Amplify CLI detects that a new environment variable has been added but can't infer a value for it. To resolve this issue, run the following commands in the terminal:"
      },
      {
        "heading": "Multi-environment flows",
        "depth": 2,
        "text": "amplify env checkout <failing env name>"
      },
      {
        "heading": "Multi-environment flows",
        "depth": 2,
        "text": "amplify push - when prompted, enter a new value for the environment variable(s)"
      },
      {
        "heading": "Multi-environment flows",
        "depth": 2,
        "text": "git commit"
      },
      {
        "heading": "Multi-environment flows",
        "depth": 2,
        "text": "git push"
      }
    ],
    "source": "export const meta = {\n  title: `Environment variables`,\n  description: `Configure environment variables for AWS Lambda functions`,\n};\n\nAmplify CLI allows you to configure environment variables for your Lambda functions. Each Amplify environment can have a different environment variable value. This enables use cases such as switching between dev and prod URLs depending on the environment.\n\n> Environment variables should NOT be used for storing sensitive configuration values such as database passwords, API keys, or access tokens. Use [function secrets configuration](/cli/function/secrets) instead!\n\n## Configuring environment variables\nTo configure a new function with environment variables, run `amplify add function`, select `yes` to the advanced settings prompt and select `yes` to the environment variables configuration prompt. From there, you will be able to specify a key and value for the environment variable.\n\n```console\n$ amplify add function\n...\n? Do you want to configure advanced settings? Yes\n...\n? Do you want to configure environment variables for this function? Yes\n? Enter the environment variable name: API_URL\n? Enter the environment variable value: https://example.com/test\n? Select what you want to do with environment variables: (Use arrow keys)\n  Add new environment variable\n  Update existing environment variables\n  Remove existing environment variables\n> I'm done\n```\n\nTo configure environment variables for an existing function, run `amplify update function`, and select `Environment variables configuration`. You can then add, update, or remove environment variables.\n\n```console\n$ amplify update function\n...\n? Which setting do you want to update?\n  Resource access permissions\n  Scheduled recurring invocation\n  Lambda layers configuration\n> Environment variables configuration\n  Secret values configuration\n? Select what you want to do with environment variables:\n> Add new environment variable\n  Update existing environment variables\n  Remove existing environment variables\n  I'm done\n```\n\n## Multi-environment flows\nWhen creating a new Amplify environment using `amplify env add`, Amplify CLI asks if you want to apply all environment variable values to the new environment or modify them. If you choose to apply the existing values, you can still make edits anytime by running `amplify update function`.\n\nWhen creating a new Amplify environment using `amplify env add --yes`, Amplify CLI will apply all environment variable values from the current environment to the new environment.\n\nIn multi-environment workflows, you may have added a new environment variable in one Amplify environment and then checked out a different Amplify environment. In this case, on the next `amplify push`, Amplify CLI will detect that there is a new environment variable that does not have a value specified in the current environment and prompt for one.\nRunning `amplify push --yes` in this case will fail with a message explaining the missing environment variable values.\n\nIn [**git-based** multi-environment workflows](/cli/teams/overview), you may run into errors during deployment. For example, this happens when you add an environment variable in `envA` (corresponding to a git branch `branchA`), then `amplify checkout envB` and `git checkout branchB` and `git merge` branchA into branchB. Upon pushing `envB`, Amplify CLI detects that a new environment variable has been added but can't infer a value for it. To resolve this issue, run the following commands in the terminal:\n\n1. `amplify env checkout <failing env name>`\n2. `amplify push` - when prompted, enter a new value for the environment variable(s)\n3. `git commit`\n4. `git push`\n",
    "meta": {
      "title": "Environment variables",
      "description": "Configure environment variables for AWS Lambda functions",
      "subcategory": "Functions",
      "category": "Amplify CLI"
    },
    "filename": "/cli/function/env-vars"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Lambda layers allow you to pull common code & assets for your Lambda function into a centralized location. With Lambda layers you can:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Re-use your code & assets: Your Lambda functions can leverage these layers to reuse shared code & assets across functions"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Speed up function deployments: Iterating on your Lambda function will be significantly faster because it can be independently updated from the layer which usually contains the bulk of large static content"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Known limitation: Functions using a layer can't be mocked locally using amplify mock. We recommend you to create a dev environment and test the functions inside the AWS Lambda console."
      },
      {
        "heading": null,
        "depth": null,
        "text": ""
      },
      {
        "heading": null,
        "depth": null,
        "text": "The general workflow breaks down into the following steps:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Create a Lambda layer"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Add shared code & assets to the layer"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Add the Lambda layer to a function"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Deploy the layer & function"
      },
      {
        "heading": "Create a Lambda Layer",
        "depth": 2,
        "text": "To create a layer, run the following command within your Amplify project:"
      },
      {
        "heading": "Create a Lambda Layer",
        "depth": 2,
        "text": "Select Lambda layer as the capability to add"
      },
      {
        "heading": "Create a Lambda Layer",
        "depth": 2,
        "text": "Next, you'll be guided through a workflow to provide a layer name, and select a supported runtime. Currently Amplify CLI provides NodeJS or Python runtime support for layers."
      },
      {
        "heading": "Create a Lambda Layer",
        "depth": 2,
        "text": "After that, you'll be asked to configure your layer's permission."
      },
      {
        "heading": "Create a Lambda Layer",
        "depth": 2,
        "text": "The current AWS account will always have access to this layer.\nIn addition, the customer can configure access for:"
      },
      {
        "heading": "Create a Lambda Layer",
        "depth": 2,
        "text": "Specific AWS accounts: provide a comma-separated list of AWS Account IDs to provide access to them."
      },
      {
        "heading": "Create a Lambda Layer",
        "depth": 2,
        "text": "Specific AWS organizations: provide a comma-separated list of AWS Organization IDs to provide access to them. AWS Organization IDs start with o-."
      },
      {
        "heading": "Create a Lambda Layer",
        "depth": 2,
        "text": "Public: make this layer available for everyone AWS. Anyone in AWS can reference this layer using its ARN."
      },
      {
        "heading": "Create a Lambda Layer",
        "depth": 2,
        "text": "Your Lambda layer is ready to use after the permissions are set up."
      },
      {
        "heading": "Add shared code & assets",
        "depth": 2,
        "text": "Now that your layer is set up, you'll see a new folder with the layer-name added to amplify/backend/function/. The respective runtime's folder structure is autogenerated."
      },
      {
        "heading": "Add shared code",
        "depth": 3,
        "text": "A nodejs folder is auto-generated for you. In there you'll find an empty package.json file and a node_modules folder. If you want to offload other node_modules you can either:"
      },
      {
        "heading": "Add shared code",
        "depth": 3,
        "text": "cd into the nodejs folder and add the dependencies into the package.json file, or"
      },
      {
        "heading": "Add shared code",
        "depth": 3,
        "text": "move all your existing function's node_modules content into the layer's node_modules folder"
      },
      {
        "heading": "Add shared code",
        "depth": 3,
        "text": "Any dependency listed within the layer's package.json file will be installed and packaged during amplify push."
      },
      {
        "heading": "Add shared code",
        "depth": 3,
        "text": "Any node module that is in the layer's node_modules folder can be accessed from the function as if the node module is in the function's node_modules folder."
      },
      {
        "heading": "Add shared code",
        "depth": 3,
        "text": "In order to take advantage of Lambda layer's for your NodeJS function, you don't even need to update your function's code!"
      },
      {
        "heading": "Add shared code",
        "depth": 3,
        "text": "A python folder is auto-generated for you. In there you'll find an empty Pipfile file. Any packages listed within the layer's Pipfile file will be installed and packaged during amplify push. You can import these packages from within your Python function just like any other package within your Python function."
      },
      {
        "heading": "Add shared assets",
        "depth": 3,
        "text": "Any assets like large images or other files that you want to share across various functions can be placed in the amplify/backend/function/<layer-name>/opt/ folder. Your function's code can import any assets by looking for files in the /opt/ path."
      },
      {
        "heading": "Lambda layer versions",
        "depth": 3,
        "text": "Every time amplify push or amplify update function is run, Amplify CLI checks if a layer's content has changed and automatically creates a new layer version. Layer versions are immutable and functions always use a specific layer version."
      },
      {
        "heading": "Lambda layer versions",
        "depth": 3,
        "text": "In order to speed up deployments when vast amount of node_modules exist, Amplify CLI scans only for changes within each module's package.json file. If you don't see Amplify CLI detect your latest changes, verify that at least of your node module's package.json content has changed."
      },
      {
        "heading": "Add a layer to a function",
        "depth": 2,
        "text": "You can either create a new function and add Lambda layers by running amplify add function or add layers to an existing function using amplify update function. Select Lambda function when prompted and you'll be presented the following question during the guided flow:"
      },
      {
        "heading": "Add a layer to a function",
        "depth": 2,
        "text": "You can either add an existing layer in AWS by referencing its ARN or select a layer from your Amplify project that's listed below."
      },
      {
        "heading": "Add a layer to a function",
        "depth": 2,
        "text": "When adding a layer from your Amplify project, you'll also be able to select a specific layer version or always choose the latest layer version. The largest layer version number represents the most recent changes."
      },
      {
        "heading": "Add a layer to a function",
        "depth": 2,
        "text": "Given that layers can have overlapping contents, the order of the layer matters. You can adjust the layer's order if needed in the next step."
      },
      {
        "heading": "Add a layer to a function",
        "depth": 2,
        "text": "Now, you've successfully added a layer to your function."
      },
      {
        "heading": "Deploy Lambda layers & functions with Lambda layers",
        "depth": 2,
        "text": "Once you're ready with your changes in your layer and functions, you can deploy them by running amplify push."
      },
      {
        "heading": "Deploy Lambda layers & functions with Lambda layers",
        "depth": 2,
        "text": "If a layer’s content has been updated and it has permissions associated, Amplify CLI will prompt you whether you want to carry the permissions forward to a newer version."
      },
      {
        "heading": "Deploy Lambda layers & functions with Lambda layers",
        "depth": 2,
        "text": "During amplify push, you get to modify the layer version description. By default, Amplify CLI will populate the description as Updated layer version <timestamp>."
      },
      {
        "heading": "Update layer content",
        "depth": 2,
        "text": "Any file changes within a layer's folder are automatically tracked by Amplify CLI. If there are changes available, the Amplify CLI will create a new layer version with the changes."
      },
      {
        "heading": "Update layer settings",
        "depth": 2,
        "text": "You can update any of the layer's settings like its name, runtimes, or permissions by running amplify update function and selecting Lambda layer."
      },
      {
        "heading": "Update layer settings",
        "depth": 2,
        "text": "Next, you'll be prompted to select the layer for which you want to update the settings for."
      },
      {
        "heading": "Note: Update Layer Permissions from Public to Specific",
        "depth": 4,
        "text": "To update a lambda layer from Public access to Specific (Account/Organization) access, please remember to remove Public access by un-selecting the option in the 'amplify update' CLI flow before selecting a specific AWS account/organization."
      },
      {
        "heading": "Note: Update Layer Permissions from Public to Specific",
        "depth": 4,
        "text": "If you have already selected 'Public' access, just adding additional 'specific' AWS accounts/organizations will not have any effect on the Lambda Layer configuration. It will not automatically remove Public access."
      },
      {
        "heading": "Remove a layer",
        "depth": 2,
        "text": "To remove a Lambda layer, run the amplify function remove command and select Lambda layers. Next, you'll be prompted to select which layer to remove. You can delete specific layer versions or all of them."
      },
      {
        "heading": "Remove a layer",
        "depth": 2,
        "text": "Warning: When you delete a layer, you can no longer configure functions to use it. However, any function that already uses the layer continues to have access to it."
      }
    ],
    "source": "export const meta = {\n  title: `Reuse code & assets using layers`,\n  description: `Use Amplify CLI's Lambda layer capability to reuse code & assets across functions.`,\n};\n\nLambda layers allow you to pull common code & assets for your Lambda function into a centralized location. With Lambda layers you can:\n\n1. _*Re-use your code & assets*_: Your Lambda functions can leverage these layers to reuse shared code & assets across functions\n2. _*Speed up function deployments*_: Iterating on your Lambda function will be significantly faster because it can be independently updated from the layer which usually contains the bulk of large static content\n\n> **Known limitation**: Functions using a layer can't be mocked locally using `amplify mock`. We recommend you to create a dev environment and test the functions inside the AWS Lambda console.\n\n![Lambda layer architecture diagram](/images/layers-architecture.gif)\n\nThe general workflow breaks down into the following steps:\n\n1. Create a Lambda layer\n2. Add shared code & assets to the layer\n3. Add the Lambda layer to a function\n4. Deploy the layer & function\n\n## Create a Lambda Layer\n\nTo create a layer, run the following command within your Amplify project:\n\n```bash\namplify add function\n```\n\nSelect `Lambda layer` as the capability to add\n\n```console\n? Select which capability you want to add:\n> Lambda layer (shared code & resource used across functions)\n```\n\n```console\n? Provide a name for your Lambda layer: (layer-name)\n? Choose the runtime that you want to use: (Use arrow keys)\n❯ NodeJS\n  Python\n```\n\nNext, you'll be guided through a workflow to provide a **layer name**, and select a **supported runtime**. Currently Amplify CLI provides NodeJS or Python runtime support for layers.\n\n```console\n? The current AWS account will always have access to this layer.\n  Optionally, configure who else can access this layer. (Hit <Enter> to skip)\n◯ Specific AWS accounts\n◯ Specific AWS organization\n◯ Public (everyone on AWS can use this layer)\n```\n\nAfter that, you'll be asked to configure your **layer's permission**.\n\nThe **current AWS account will always have access to this layer**.\nIn addition, the customer can configure access for:\n\n- **Specific AWS accounts**: provide a comma-separated list of AWS Account IDs to provide access to them.\n- **Specific AWS organizations**: provide a comma-separated list of AWS Organization IDs to provide access to them. *AWS Organization IDs start with `o-`.*\n- **Public**: make this layer available for everyone AWS. Anyone in AWS can reference this layer using its ARN.\n \n```console\nNext steps:\nMove your libraries to the following folder:\n[NodeJS]: amplify/backend/function/<lambda-layer-name>/lib/nodejs\n\nInclude any files you want to share across runtimes in this folder:\namplify/backend/function/<lambda-layer-name>/opt\n\n\"amplify function update <function-name>\" - configure a function with this Lambda layer\n\"amplify push\" - builds all of your local backend resources and provisions them in the cloud\n```\n\nYour Lambda layer is ready to use after the permissions are set up.\n\n## Add shared code & assets\n\nNow that your layer is set up, you'll see a new folder with the `layer-name` added to `amplify/backend/function/`. The respective runtime's folder structure is autogenerated.\n\n### Add shared code\n\n<BlockSwitcher>\n\n<Block name=\"NodeJS\">\n\nA `nodejs` folder is auto-generated for you. In there you'll find an empty `package.json` file and a `node_modules` folder. If you want to offload other node_modules you can either:\n\n1. `cd` into the `nodejs` folder and add the dependencies into the `package.json` file, or\n2. move all your existing function's `node_modules` content into the layer's `node_modules` folder\n\nAny dependency listed within the layer's `package.json` file will be installed and packaged during `amplify push`.\n\nAny node module that is in the layer's `node_modules` folder can be accessed from the function as if the node module is in the function's `node_modules` folder. \n\n*In order to take advantage of Lambda layer's for your NodeJS function, you don't even need to update your function's code!*\n\n</Block>\n\n<Block name=\"Python\">\n\nA `python` folder is auto-generated for you. In there you'll find an empty `Pipfile` file. Any packages listed within the layer's `Pipfile` file will be installed and packaged during `amplify push`. You can `import` these packages from within your Python function just like any other package within your Python function.\n\n</Block>\n\n</BlockSwitcher>\n\n### Add shared assets\n\nAny assets like large images or other files that you want to share across various functions can be placed in the `amplify/backend/function/<layer-name>/opt/` folder. Your function's code can import any assets by looking for files in the `/opt/` path.\n\n### Lambda layer versions\n\nEvery time `amplify push` or `amplify update function` is run, Amplify CLI checks if a layer's content has changed and automatically creates a new *layer version*. Layer versions are immutable and functions always use a specific layer version. \n\nIn order to speed up deployments when vast amount of node_modules exist, Amplify CLI scans only for changes within each module's `package.json` file. If you don't see Amplify CLI detect your latest changes, verify that at least of your node module's `package.json` content has changed.\n\n## Add a layer to a function\n\nYou can either create a new function and add Lambda layers by running `amplify add function` or add layers to an existing function using `amplify update function`. Select `Lambda function` when prompted and you'll be presented the following question during the guided flow:\n\n```console\n...\n? Do you want to enable Lambda layers for this function? Yes\n? Provide existing layers or select layers in this project to access from this function (pick up to 5):\n ◯ Provide existing Lambda layer ARNs\n❯◉ myamplifylayer1\n ◯ myamplifylayer2\n```\n\nYou can either add an existing layer in AWS by referencing its ARN or select a layer from your Amplify project that's listed below.\n\n```console\n? Select a version for myamplifylayer1:\n❯ Always choose latest version\n  2: Updated layer version 2021-06-08T05:33:42.651Z\n  1: Updated layer version 2021-06-08T05:30:43.101Z\n```\n\nWhen adding a layer from your Amplify project, you'll also be able to select a specific layer version or always choose the latest layer version. The largest layer version number represents the most recent changes.\n\n```console\n? Modify the layer order:\n(Layers with conflicting files will overwrite contents of layers earlier in the list):\n- layer2\n- layer3\n- layer6\n- <ARN1>\n- <ARN2>\n```\n\nGiven that layers can have overlapping contents, the order of the layer matters. You can adjust the layer's order if needed in the next step.\n\nNow, you've successfully added a layer to your function.\n\n## Deploy Lambda layers & functions with Lambda layers\n\nOnce you're ready with your changes in your layer and functions, you can deploy them by running `amplify push`.\n\nIf a layer’s content has been updated and it has permissions associated, Amplify CLI will prompt you whether you want to carry the permissions forward to a newer version.\n\n```console\nContent changes in Lambda layers detected.\nSuggested configuration for new layer versions:\n\nmyamplifylayer1\n  - Description: Updated layer version  2021-06-08T05:33:42.651Z\n\n? Accept the suggested layer version configurations? (Y/n)\n```\n\nDuring `amplify push`, you get to modify the layer version description. By default, Amplify CLI will populate the description as `Updated layer version <timestamp>`.\n\n## Update layer content\n\nAny file changes within a layer's folder are automatically tracked by Amplify CLI. If there are changes available, the Amplify CLI will create a new layer version with the changes.\n\n## Update layer settings\n\nYou can update any of the layer's settings like its name, runtimes, or permissions by running `amplify update function` and selecting `Lambda layer`.\n\nNext, you'll be prompted to select the layer for which you want to update the settings for.\n\n#### Note: Update Layer Permissions from Public to Specific\n  - To update a lambda layer from Public access to Specific (Account/Organization) access, please remember to remove Public access by **un-selecting** the option in the 'amplify update' CLI flow before selecting a specific AWS account/organization.\n  - If you have already selected 'Public' access, just adding additional 'specific' AWS accounts/organizations will not have any effect on the Lambda Layer configuration. It will not automatically remove Public access. \n\n## Remove a layer\n\nTo remove a Lambda layer, run the `amplify function remove` command and select `Lambda layers`. Next, you'll be prompted to select which layer to remove. You can delete specific layer versions or all of them.\n\n> Warning: When you delete a layer, you can no longer configure functions to use it. However, any function that already uses the layer continues to have access to it.\n\n```console\n? Choose the resource you would want to remove <lambda-layer-name> (layer)\nWhen you delete a layer version, you can no longer configure functions to use it.\nHowever, any function that already uses the layer version continues to have access to it.\n? Choose the Layer versions you want to remove.\n❯◯ 1: Updated layer version 2021-06-08T05:30:43.101Z\n ◯ 2: Updated layer version 2021-06-08T05:33:42.651Z\n? Are you sure you want to delete the resource? This action deletes all files related to this resource from the backend directory. (Y/n)\n```\n",
    "meta": {
      "title": "Reuse code & assets using layers",
      "description": "Use Amplify CLI's Lambda layer capability to reuse code & assets across functions.",
      "subcategory": "Functions",
      "category": "Amplify CLI"
    },
    "filename": "/cli/function/layers"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Run the command above to override Amplify-generated storage resources including the S3 bucket, DynamoDB tables, and more."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The command creates a new overrides.ts file under amplify/backend/storage/<resource-name>/ which provides you the Amplify-generated resources as CDK constructs."
      },
      {
        "heading": "Customize Amplify-generated S3 resources",
        "depth": 2,
        "text": "Apply all the overrides in the override(...) function. For example to enable versioning on your S3 bucket:"
      },
      {
        "heading": "Customize Amplify-generated S3 resources",
        "depth": 2,
        "text": "You can override the following S3-related resources that Amplify generates:"
      },
      {
        "heading": "Customize Amplify-generated S3 resources",
        "depth": 2,
        "text": "| Amplify-generated resource | Description |\n| --- | --- |\n| s3Bucket | The S3 bucket that Amplify generates for file storage upon amplify add storage |\n| s3AuthPublicPolicy | The IAM policy for authenticated users' write access to public/* prefix |\n| s3AuthProtectedPolicy | The IAM policy for authenticated users' write access to protected/* prefix |\n| s3AuthPrivatePolicy | The IAM policy for authenticated users' write access to private/* prefix |\n| s3AuthUploadPolicy | The IAM policy for authenticated users' write access to uploads/* prefix |\n| s3AuthReadPolicy | The IAM policy for authenticated users' read access |\n| s3GuestPublicPolicy | The IAM policy for guest users' write access to public/* prefix |\n| s3GuestUploadPolicy | The IAM policy for guest users' write access to uploads/* prefix |\n| s3GuestReadPolicy | The IAM policy for guest users' read access |"
      },
      {
        "heading": "Customize Amplify-generated S3 resources",
        "depth": 2,
        "text": "For example, you can use amplify override storage to add additional PUT and GET access IAM policy statements to the S3 bucket's default public Auth policy:"
      },
      {
        "heading": "Customize Amplify-generated S3 resources",
        "depth": 2,
        "text": "Please refer to the IAM documentation for more information on actions, resources, and condition keys for Amazon S3."
      },
      {
        "heading": "Customize Amplify-generated DynamoDB tables",
        "depth": 2,
        "text": "Apply all the overrides in the override(...) function. For example to enable time-to-live specification on your DynamoDB table:"
      },
      {
        "heading": "Customize Amplify-generated DynamoDB tables",
        "depth": 2,
        "text": "You can override the following DynamoDB resources that Amplify generates:"
      },
      {
        "heading": "Customize Amplify-generated DynamoDB tables",
        "depth": 2,
        "text": "| Amplify-generated resource | Description |\n| --- | --- |\n| dynamoDBTable | The DynamoDB table that Amplify creates upon amplify add storage |"
      }
    ],
    "source": "export const meta = {\n  title: `Override Amplify-generated S3 and DynamoDB resources`,\n  description:\n    'The \"amplify override storage\" command generates a developer-configurable \"overrides\" TypeScript file which provides Amplify-generated S3 and DynamoDB resources as CDK constructs. For example, developers can run the “amplify override storage” command to enable Transfer Acceleration for Amplify-generated S3 buckets.'\n};\n\n```bash\namplify override storage\n```\n\nRun the command above to override Amplify-generated storage resources including the S3 bucket, DynamoDB tables, and more.\n\nThe command creates a new `overrides.ts` file under `amplify/backend/storage/<resource-name>/` which provides you the Amplify-generated resources as [CDK constructs](https://docs.aws.amazon.com/cdk/latest/guide/home.html).\n\n## Customize Amplify-generated S3 resources\n\nApply all the overrides in the `override(...)` function. For example to enable versioning on your S3 bucket:\n\n```ts\nimport { AmplifyS3ResourceTemplate } from '@aws-amplify/cli-extensibility-helper';\n\nexport function override(resources: AmplifyS3ResourceTemplate) {\n  resources.s3Bucket.versioningConfiguration = {\n    status: 'Enabled'\n  };\n}\n```\n\nYou can override the following S3-related resources that Amplify generates:\n\n| Amplify-generated resource | Description |\n| --- | --- |\n| [s3Bucket](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-s3-bucket.html) | The S3 bucket that Amplify generates for file storage upon `amplify add storage` |\n| [s3AuthPublicPolicy](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html) | The IAM policy for authenticated users' write access to `public/*` prefix |\n| [s3AuthProtectedPolicy](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html) | The IAM policy for authenticated users' write access to `protected/*` prefix |\n| [s3AuthPrivatePolicy](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html) | The IAM policy for authenticated users' write access to `private/*` prefix |\n| [s3AuthUploadPolicy](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html) | The IAM policy for authenticated users' write access to `uploads/*` prefix |\n| [s3AuthReadPolicy](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html) | The IAM policy for authenticated users' read access |\n| [s3GuestPublicPolicy](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html) | The IAM policy for guest users' write access to `public/*` prefix |\n| [s3GuestUploadPolicy](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html) | The IAM policy for guest users' write access to `uploads/*` prefix |\n| [s3GuestReadPolicy](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html) | The IAM policy for guest users' read access |\n\n<br />\n\nFor example, you can use `amplify override storage` to add additional PUT and GET access IAM policy statements to the S3 bucket's default public Auth policy:\n\n```ts\nimport { AmplifyS3ResourceTemplate } from '@aws-amplify/cli-extensibility-helper';\n\nexport function override(resources: AmplifyS3ResourceTemplate) {\n  resources.s3AuthPublicPolicy.policyDocument.Statement =  [\n    ...resources.s3AuthPublicPolicy.policyDocument.Statement, \n    {\n      Effect: \"Allow\",\n      Action: [ \"s3:PutObject\",\"s3:PutObjectAcl\",\"s3:GetObject\"], \n      Resource: \"<ARN of the S3 resource>\"\n    }\n  ]\n}\n\n```\n\nPlease refer to the [IAM documentation](https://docs.aws.amazon.com/service-authorization/latest/reference/list_amazons3.html) for more information on actions, resources, and condition keys for Amazon S3.\n\n## Customize Amplify-generated DynamoDB tables\n\nApply all the overrides in the `override(...)` function. For example to enable time-to-live specification on your DynamoDB table:\n\n```ts\nimport { AmplifyDDBResourceTemplate } from '@aws-amplify/cli-extensibility-helper';\n\nexport function override(resources: AmplifyDDBResourceTemplate) {\n  resources.dynamoDBTable.timeToLiveSpecification = {\n    attributeName: 'ttl',\n    enabled: true\n  };\n}\n```\n\nYou can override the following DynamoDB resources that Amplify generates:\n\n| Amplify-generated resource | Description |\n| --- | --- |\n| [dynamoDBTable](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-dynamodb-table.html) | The DynamoDB table that Amplify creates upon `amplify add storage` |\n",
    "meta": {
      "title": "Override Amplify-generated S3 and DynamoDB resources",
      "description": "The \"amplify override storage\" command generates a developer-configurable \"overrides\" TypeScript file which provides Amplify-generated S3 and DynamoDB resources as CDK constructs. For example, developers can run the “amplify override storage” command to enable Transfer Acceleration for Amplify-generated S3 buckets.",
      "subcategory": "Storage",
      "category": "Amplify CLI"
    },
    "filename": "/cli/storage/override"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Import an existing S3 bucket or DynamoDB tables into your Amplify project. Get started by running amplify import storage command to search for & import an S3 or DynamoDB resource from your account."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Make sure to run amplify push to complete the import process and deploy this backend change to the cloud."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The amplify import storage command will:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "automatically populate your Amplify Library configuration files (aws-exports.js, amplifyconfiguration.json) with your chosen S3 bucket information"
      },
      {
        "heading": null,
        "depth": null,
        "text": "provide your designated S3 bucket or DynamoDB table as a storage mechanism for all storage-dependent categories (API, Function, Predictions, and more)"
      },
      {
        "heading": null,
        "depth": null,
        "text": "enable Lambda functions to access the chosen S3 or DynamoDB resource if you permit it"
      },
      {
        "heading": null,
        "depth": null,
        "text": "This feature is particularly useful if you're trying to:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "enable Amplify categories (such as API and Function) to access your existing storage resources;"
      },
      {
        "heading": null,
        "depth": null,
        "text": "incrementally adopt Amplify for your application stack;"
      },
      {
        "heading": null,
        "depth": null,
        "text": "independently manage S3 and DynamoDB resources while working with Amplify."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Note: Amplify does not manage the lifecycle of an imported resource."
      },
      {
        "heading": "Import an existing S3 bucket",
        "depth": 2,
        "text": "Select the \"S3 bucket - Content (Images, audio, video, etc.)\" option when you've run amplify import storage."
      },
      {
        "heading": "Import an existing S3 bucket",
        "depth": 2,
        "text": "Run amplify push to complete the import procedure."
      },
      {
        "heading": "Import an existing S3 bucket",
        "depth": 2,
        "text": "Amplify projects are limited to exactly one S3 bucket."
      },
      {
        "heading": "Connect to an imported S3 bucket with Amplify Libraries",
        "depth": 3,
        "text": "By default, Amplify Libraries assumes that S3 buckets are configured with the following access patterns:"
      },
      {
        "heading": "Connect to an imported S3 bucket with Amplify Libraries",
        "depth": 3,
        "text": "public/ - Accessible by all users of your app"
      },
      {
        "heading": "Connect to an imported S3 bucket with Amplify Libraries",
        "depth": 3,
        "text": "protected/{user_identity_id}/ - Readable by all users, but writable only by the creating user"
      },
      {
        "heading": "Connect to an imported S3 bucket with Amplify Libraries",
        "depth": 3,
        "text": "private/{user_identity_id}/ - Only accessible for the individual user"
      },
      {
        "heading": "Connect to an imported S3 bucket with Amplify Libraries",
        "depth": 3,
        "text": "You can either configure your IAM role to use the Amplify-recommended policies or in your Amplify libraries configuration overwrite the default storage path behavior."
      },
      {
        "heading": "Connect to an imported S3 bucket with Amplify Libraries",
        "depth": 3,
        "text": "It is highly recommended to review your S3 bucket's CORS settings. Review the recommendation guide here."
      },
      {
        "heading": "Configuring IAM role to use Amplify-recommended policies",
        "depth": 3,
        "text": "If you're using an imported S3 bucket with an imported Cognito resource, then you'll need to update the policy of your Cognito Identity Pool's authenticated and unauthenticated role. Create new managed policies (not inline policies) for these roles with the following statements:"
      },
      {
        "heading": "Configuring IAM role to use Amplify-recommended policies",
        "depth": 3,
        "text": "Make sure to replace {YOUR_S3_BUCKET_NAME} with your S3 bucket's name."
      },
      {
        "heading": "Unauthenticated role policies",
        "depth": 4,
        "text": "IAM policy statement for public/:"
      },
      {
        "heading": "Unauthenticated role policies",
        "depth": 4,
        "text": "IAM policy statement for read access to public/, protected/, and private/:"
      },
      {
        "heading": "Authenticated role policies",
        "depth": 4,
        "text": "IAM policy statement for public/:"
      },
      {
        "heading": "Authenticated role policies",
        "depth": 4,
        "text": "IAM policy statement for protected/:"
      },
      {
        "heading": "Authenticated role policies",
        "depth": 4,
        "text": "IAM policy statement for private/:"
      },
      {
        "heading": "Authenticated role policies",
        "depth": 4,
        "text": "IAM policy statement for read access to public/, protected/, and private/:"
      },
      {
        "heading": "Import an existing DynamoDB table",
        "depth": 2,
        "text": "Select the \"DynamoDB table - NoSQL Database\" option when you've run amplify import storage. In order to successfully import your DynamoDB table, your DynamoDB table needs to be located within the same region as your Amplify project."
      },
      {
        "heading": "Import an existing DynamoDB table",
        "depth": 2,
        "text": "Run amplify push to complete the import procedure."
      },
      {
        "heading": "Import an existing DynamoDB table",
        "depth": 2,
        "text": "Amplify projects can contain multiple DynamoDB tables."
      },
      {
        "heading": "Multi-environment support",
        "depth": 2,
        "text": "When you create a new environment through amplify env add, Amplify CLI will assume by default that you're managing your app's storage resources outside of an Amplify project. You'll be asked to either import a different S3 bucket or DynamoDB tables or maintain the same imported storage resource."
      },
      {
        "heading": "Multi-environment support",
        "depth": 2,
        "text": "If you want to have Amplify manage your storage resources in a new environment, run amplify remove storage to unlink the imported storage resources and amplify add storage to create new Amplify-managed S3 buckets and DynamoDB tables in the new environment."
      },
      {
        "heading": "Unlink an existing S3 bucket or DynamoDB table",
        "depth": 2,
        "text": "In order to unlink your existing Cognito resource run amplify remove storage. This will only unlink the S3 bucket or DynamoDB table referenced from the Amplify project. It will not delete the S3 bucket or DynamoDB table itself."
      },
      {
        "heading": "Unlink an existing S3 bucket or DynamoDB table",
        "depth": 2,
        "text": "Run amplify push to complete the unlink procedure."
      },
      {
        "heading": "Configure environment variables for Amplify Hosting builds",
        "depth": 2,
        "text": "In order to successfully build your application with Amplify Hosting add the following environment variables to your build environment:"
      },
      {
        "heading": "Configure environment variables for Amplify Hosting builds",
        "depth": 2,
        "text": "|Environment Variable|Description|Imported Resource|Required\n|-|-|-|-|\n|AMPLIFY_STORAGE_BUCKET_NAME|The name of the S3 bucket being imported for storage|S3 bucket|Yes\n|AMPLIFY_STORAGE_REGION|The AWS region in which the S3 bucket or the DynamoDB table is located (for example: us-east-1, us-west-2, etc.)|S3 bucket or DynamoDB table|Yes\n|AMPLIFY_STORAGE_TABLES|The name of the storage resource and DynamoDB table being imported for storage|DynamoDB table|Yes"
      },
      {
        "heading": "Configure environment variables for Amplify Hosting builds",
        "depth": 2,
        "text": "The value of the AMPLIFY_STORAGE_TABLES environment variable needs to be in a json format such as:"
      },
      {
        "heading": "Configure environment variables for Amplify Hosting builds",
        "depth": 2,
        "text": "The values for the STORAGE_RESOURCE_NAME and DDB_TABLE_NAME fields can be retrieved from the amplify/team-provider-info.json file."
      }
    ],
    "source": "export const meta = {\n  title: `Use an existing S3 bucket or DynamoDB table`,\n  description: `Configure the Amplify CLI to use existing S3 bucket or DynamoDB table resources as a storage resource for other Amplify categories. (API, Function, and more)`,\n};\n\nImport an existing S3 bucket or DynamoDB tables into your Amplify project. Get started by running `amplify import storage` command to search for & import an S3 or DynamoDB resource from your account.\n\n```bash\namplify import storage\n```\n\nMake sure to run `amplify push` to complete the import process and deploy this backend change to the cloud.\n\nThe `amplify import storage` command will:\n\n- automatically populate your Amplify Library configuration files (aws-exports.js, amplifyconfiguration.json) with your chosen S3 bucket information\n- provide your designated S3 bucket or DynamoDB table as a storage mechanism for all storage-dependent categories (API, Function, Predictions, and more)\n- enable Lambda functions to access the chosen S3 or DynamoDB resource if you permit it\n\nThis feature is particularly useful if you're trying to:\n\n- enable Amplify categories (such as API and Function) to access your existing storage resources;\n- incrementally adopt Amplify for your application stack;\n- independently manage S3 and DynamoDB resources while working with Amplify.\n\n> Note: Amplify does not manage the lifecycle of an imported resource.\n\n## Import an existing S3 bucket\n\nSelect the \"S3 bucket - Content (Images, audio, video, etc.)\" option when you've run `amplify import storage`.\n\nRun `amplify push` to complete the import procedure.\n\n> Amplify projects are limited to exactly one S3 bucket.\n\n### Connect to an imported S3 bucket with Amplify Libraries\n\nBy default, Amplify Libraries assumes that S3 buckets are configured with the following access patterns:\n\n- `public/` - Accessible by all users of your app\n- `protected/{user_identity_id}/` - Readable by all users, but writable only by the creating user\n- `private/{user_identity_id}/` - Only accessible for the individual user\n\nYou can either configure your IAM role to use the Amplify-recommended policies or in your Amplify libraries configuration [overwrite the default storage path behavior](https://docs.amplify.aws/lib/storage/configureaccess/q/platform/js#customize-object-key-path).\n\nIt is highly recommended to review your S3 bucket's CORS settings. Review the [recommendation guide here](https://docs.amplify.aws/lib/storage/getting-started/q/platform/js#amazon-s3-bucket-cors-policy-setup).\n\n### Configuring IAM role to use Amplify-recommended policies\n\nIf you're using an imported S3 bucket with an imported Cognito resource, then you'll need to update the policy of your Cognito Identity Pool's authenticated and unauthenticated role. Create new __managed policies__ (not *inline policies*) for these roles with the following statements:\n\n> Make sure to replace `{YOUR_S3_BUCKET_NAME}` with your S3 bucket's name.\n\n#### Unauthenticated role policies\n\n- IAM policy statement for `public/`:\n\n```json\n{\n  \"Action\": [\n    \"s3:PutObject\",\n    \"s3:GetObject\",\n    \"s3:DeleteObject\"\n  ],\n  \"Resource\": [\n    \"arn:aws:s3:::{YOUR_S3_BUCKET_NAME}/public/*\"\n  ],\n  \"Effect\": \"Allow\"\n}\n```\n\n- IAM policy statement for read access to `public/`, `protected/`, and `private/`:\n\n```json\n{\n  \"Action\": [\n    \"s3:GetObject\"\n  ],\n  \"Resource\": [\n    \"arn:aws:s3:::{YOUR_S3_BUCKET_NAME}/protected/*\"\n  ],\n  \"Effect\": \"Allow\"\n},\n{\n  \"Condition\": {\n    \"StringLike\": {\n      \"s3:prefix\": [\n        \"public/\",\n        \"public/*\",\n        \"protected/\",\n        \"protected/*\"\n      ]\n    }\n  },\n  \"Action\": [\n    \"s3:ListBucket\"\n  ],\n  \"Resource\": [\n    \"arn:aws:s3:::{YOUR_S3_BUCKET_NAME}\"\n  ],\n  \"Effect\": \"Allow\"\n}\n```\n\n#### Authenticated role policies\n\n- IAM policy statement for `public/`:\n\n```json\n{\n  \"Action\": [\n    \"s3:PutObject\",\n    \"s3:GetObject\",\n    \"s3:DeleteObject\"\n  ],\n  \"Resource\": [\n    \"arn:aws:s3:::{YOUR_S3_BUCKET_NAME}/public/*\"\n  ],\n  \"Effect\": \"Allow\"\n}\n```\n\n- IAM policy statement for `protected/`:\n\n```json\n{\n  \"Action\": [\n    \"s3:PutObject\",\n    \"s3:GetObject\",\n    \"s3:DeleteObject\"\n  ],\n  \"Resource\": [\n    \"arn:aws:s3:::{YOUR_S3_BUCKET_NAME}/protected/${cognito-identity.amazonaws.com:sub}/*\"\n  ],\n  \"Effect\": \"Allow\"\n}\n```\n\n- IAM policy statement for `private/`:\n\n```json\n{\n  \"Action\": [\n    \"s3:PutObject\",\n    \"s3:GetObject\",\n    \"s3:DeleteObject\"\n  ],\n  \"Resource\": [\n    \"arn:aws:s3:::{YOUR_S3_BUCKET_NAME}/private/${cognito-identity.amazonaws.com:sub}/*\"\n  ],\n  \"Effect\": \"Allow\"\n}\n```\n\n- IAM policy statement for read access to `public/`, `protected/`, and `private/`:\n\n```json\n{\n  \"Action\": [\n    \"s3:GetObject\"\n  ],\n  \"Resource\": [\n    \"arn:aws:s3:::{YOUR_S3_BUCKET_NAME}/protected/*\"\n  ],\n  \"Effect\": \"Allow\"\n},\n{\n  \"Condition\": {\n    \"StringLike\": {\n      \"s3:prefix\": [\n        \"public/\",\n        \"public/*\",\n        \"protected/\",\n        \"protected/*\",\n        \"private/${cognito-identity.amazonaws.com:sub}/\",\n        \"private/${cognito-identity.amazonaws.com:sub}/*\"\n      ]\n    }\n  },\n  \"Action\": [\n    \"s3:ListBucket\"\n  ],\n  \"Resource\": [\n    \"arn:aws:s3:::{YOUR_S3_BUCKET_NAME}\"\n  ],\n  \"Effect\": \"Allow\"\n}\n```\n\n## Import an existing DynamoDB table\n\nSelect the \"DynamoDB table - NoSQL Database\" option when you've run `amplify import storage`. In order to successfully import your DynamoDB table, your DynamoDB table needs to be located within the same region as your Amplify project.\n\nRun `amplify push` to complete the import procedure.\n\n> Amplify projects can contain multiple DynamoDB tables.\n\n## Multi-environment support\n\nWhen you create a new environment through `amplify env add`, Amplify CLI will assume by default that you're managing your app's storage resources outside of an Amplify project. You'll be asked to either import a different S3 bucket or DynamoDB tables or maintain the same imported storage resource.\n\nIf you want to have Amplify manage your storage resources in a new environment, run `amplify remove storage` to unlink the imported storage resources and `amplify add storage` to create new Amplify-managed S3 buckets and DynamoDB tables in the new environment.\n\n## Unlink an existing S3 bucket or DynamoDB table\n\nIn order to unlink your existing Cognito resource run `amplify remove storage`. This will only unlink the S3 bucket or DynamoDB table referenced from the Amplify project. It will not delete the S3 bucket or DynamoDB table itself.\n\nRun `amplify push` to complete the unlink procedure.\n\n## Configure environment variables for Amplify Hosting builds\n\nIn order to successfully build your application with Amplify Hosting add the following environment variables to your build environment:\n\n|Environment Variable|Description|Imported Resource|Required\n|-|-|-|-|\n|AMPLIFY_STORAGE_BUCKET_NAME|The name of the S3 bucket being imported for storage|S3 bucket|Yes\n|AMPLIFY_STORAGE_REGION|The AWS region in which the S3 bucket or the DynamoDB table is located (for example: us-east-1, us-west-2, etc.)|S3 bucket or DynamoDB table|Yes\n|AMPLIFY_STORAGE_TABLES|The name of the storage resource and DynamoDB table being imported for storage|DynamoDB table|Yes\n\n<Callout warning>\nThe value of the AMPLIFY_STORAGE_TABLES environment variable needs to be in a json format such as: \n\n```\n{\n  \"STORAGE_RESOURCE_NAME_1\":\"DDB_TABLE_NAME_1\",\n  \"STORAGE_RESOURCE_NAME_2\":\"DDB_TABLE_NAME_2\"  // If you are importing more than a single DynamoDB table\n}\n```\nThe values for the `STORAGE_RESOURCE_NAME` and `DDB_TABLE_NAME` fields can be retrieved from the amplify/team-provider-info.json file.\n</Callout>\n",
    "meta": {
      "title": "Use an existing S3 bucket or DynamoDB table",
      "description": "Configure the Amplify CLI to use existing S3 bucket or DynamoDB table resources as a storage resource for other Amplify categories. (API, Function, and more)",
      "subcategory": "Storage",
      "category": "Amplify CLI"
    },
    "filename": "/cli/storage/import"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Amplify CLI's storage category enables you to create and manage cloud-connected file & data storage. Use the storage category when you need to store:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "app content (images, audio, video etc.) in an public, protected or private storage bucket or"
      },
      {
        "heading": null,
        "depth": null,
        "text": "app data in a NoSQL database and access it with a REST API + Lambda"
      },
      {
        "heading": "Setup a new storage resource",
        "depth": 2,
        "text": "You can setup a new storage resource by running the following command:"
      },
      {
        "heading": "Setup a new storage resource",
        "depth": 2,
        "text": "Amplify allows you to either setup a app content storage (images, audio, video etc.) backed by Amazon S3 or a NoSQL database backed by Amazon DynamoDB."
      },
      {
        "heading": "Adding S3 storage",
        "depth": 3,
        "text": "Follow the prompts to provide your content storage's resource name."
      },
      {
        "heading": "S3 Access permissions",
        "depth": 3,
        "text": "Next, configure the access permissions for your Amazon S3 bucket. If you haven't set up the auth category already, the Amplify CLI will guide you through a workflow to enable the auth category."
      },
      {
        "heading": "S3 Access permissions",
        "depth": 3,
        "text": "NOTE: Run amplify update storage to change the access permissions for your Amazon S3 bucket"
      },
      {
        "heading": "Auth/Guest Users access",
        "depth": 4,
        "text": "Select Auth/Guest Users, to scope permissions based on an individual user's authentication status. On the next question you'll be able to select if only authenticated users can access resources, or authenticated and guest users:"
      },
      {
        "heading": "Auth/Guest Users access",
        "depth": 4,
        "text": "Then you'll be prompted to set the access scopes for your authenticated and (if selected prior) unauthenticated users."
      },
      {
        "heading": "Auth/Guest Users access",
        "depth": 4,
        "text": "Granting access to authenticated users will allow the specified CRUD operations on objects in the bucket starting with the prefix /public/, /protected/{cognito:sub}/, and /private/{cognito:sub}/. {cognito:sub} is the sub of the Cognito identity of the authenticated user."
      },
      {
        "heading": "Auth/Guest Users access",
        "depth": 4,
        "text": "Granting access to guest users will allow the specified CRUD operations on objects in the bucket starting with the prefix /public/."
      },
      {
        "heading": "Individual Group access",
        "depth": 4,
        "text": "Select Individual Groups to scope access permissions based on Cognito User Groups"
      },
      {
        "heading": "Individual Group access",
        "depth": 4,
        "text": "Then select the CRUD operations you want to permit for each selected Cognito user group"
      },
      {
        "heading": "Individual Group access",
        "depth": 4,
        "text": "Note: CRUD operations selected here will apply to ALL objects in the bucket, not just objects under a particular prefix."
      },
      {
        "heading": "Individual Group access",
        "depth": 4,
        "text": "Note: If you combine Auth/Guest user access and Individual Group access, users who are members of a group will only be granted the permissions of the group, and not the authenticated user permissions."
      },
      {
        "heading": "S3 Lambda trigger",
        "depth": 3,
        "text": "Lastly, you have the option of configuring a Lambda function that can execute in response to S3 events."
      },
      {
        "heading": "S3 Lambda trigger",
        "depth": 3,
        "text": "Learn more about this workflow here."
      },
      {
        "heading": "S3 Lambda trigger",
        "depth": 3,
        "text": "That's it! Your content storage is set up! Head to the library's storage docs to integrate this newly created S3 bucket into your app."
      },
      {
        "heading": "Adding a NoSQL database",
        "depth": 3,
        "text": "Follow the prompts to provide your NoSQL Database's resource name. Next, you'll go through a table-creation wizard. First, you'll create the columns of your table:"
      },
      {
        "heading": "Adding a NoSQL database",
        "depth": 3,
        "text": "Then, you'll need to specify your indexes. The concept behind \"indexes\", \"partition key\", \"sort key\" and \"global secondary indexes\" are explained in-depth here."
      },
      {
        "heading": "Adding a NoSQL database",
        "depth": 3,
        "text": "If you want to configure a Lambda trigger for your Table, you'll have the option. Learn more about this workflow here."
      },
      {
        "heading": "Adding a NoSQL database",
        "depth": 3,
        "text": "That's it! Your NoSQL Database is set up!"
      }
    ],
    "source": "export const meta = {\n  title: `Overview`,\n  description: `Use Amplify CLI to create and manage cloud-connected file & data storage for your app.`\n};\n\nAmplify CLI's `storage` category enables you to create and manage cloud-connected file & data storage. Use the `storage` category when you need to store:\n\n1. app content (images, audio, video etc.) in an public, protected or private storage bucket or\n2. app data in a NoSQL database and access it with a REST API + Lambda\n\n## Setup a new storage resource\n\nYou can setup a new storage resource by running the following command:\n\n```bash\namplify add storage\n```\n\nAmplify allows you to either setup a app content storage (images, audio, video etc.) backed by Amazon S3 or a NoSQL database backed by Amazon DynamoDB.\n\n### Adding S3 storage\n\n```console\n? Please select from one of the below mentioned services:\n> Content (Images, audio, video, etc.)\n  NoSQL Database\n? Please provide a friendly name for your resource that will be used to label this category in the project:\n> mystorage\n? Please provide bucket name:\n> mybucket\n```\n\nFollow the prompts to provide your content storage's resource name.\n\n### S3 Access permissions\n\nNext, configure the access permissions for your Amazon S3 bucket. If you haven't set up the `auth` category already, the Amplify CLI will guide you through a workflow to enable the auth category.\n\n```console\n? Restrict access by?\n> Auth/Guest Users\n  Individual Groups\n  Both\n  Learn more\n```\n\n<Callout>\n\n**NOTE:** Run `amplify update storage` to change the access permissions for your Amazon S3 bucket\n\n</Callout>\n\n#### Auth/Guest Users access\n\nSelect `Auth/Guest Users`, to scope permissions based on an individual user's authentication status. On the next question you'll be able to select if only authenticated users can access resources, or authenticated and guest users:\n\n```\n? Who should have access:\n❯ Auth users only\n  Auth and guest users\n```\n\nThen you'll be prompted to set the access scopes for your authenticated and (if selected prior) unauthenticated users.\n\n```console\n? What kind of access do you want for Authenticated users?\n> ◉ create/update\n  ◯ read\n  ◯ delete\n? What kind of access do you want for Guest users?\n  ◯ create/update\n> ◉ read\n  ◯ delete\n```\n\nGranting access to authenticated users will allow the specified CRUD operations on objects in the bucket starting with the prefix `/public/`, `/protected/{cognito:sub}/`, and `/private/{cognito:sub}/`. `{cognito:sub}` is the sub of the Cognito identity of the authenticated user.\n\nGranting access to guest users will allow the specified CRUD operations on objects in the bucket starting with the prefix `/public/`.\n\n#### Individual Group access\n\nSelect `Individual Groups` to scope access permissions based on [Cognito User Groups](/cli/auth/groups)\n\n```console\n? Select groups:\n  ◉ EMPLOYEE\n> ◉ MANAGER\n```\n\nThen select the CRUD operations you want to permit for each selected Cognito user group\n\n```console\n? What kind of access do you want for EMPLOYEE users?\n  ◯ create/update\n> ◉ read\n  ◯ delete\n? What kind of access do you want for MANAGER users?\n  ◉ create/update\n  ◯ read\n> ◉ delete\n```\n\n> Note: CRUD operations selected here will apply to ALL objects in the bucket, not just objects under a particular prefix.\n\n> Note: If you combine `Auth/Guest user access` and `Individual Group access`, users who are members of a group will only be granted the permissions of the group, and not the authenticated user permissions.\n\n### S3 Lambda trigger\n\nLastly, you have the option of configuring a Lambda function that can execute in response to S3 events.\n\n```console\n? Do you want to add a Lambda Trigger for your S3 Bucket? (y/N)\n```\n\nLearn more about this workflow [here](/cli/usage/lambda-triggers#s3-lambda-triggers).\n\nThat's it! Your content storage is set up! Head to the [library's storage docs](/lib/storage/getting-started) to integrate this newly created S3 bucket into your app.\n\n### Adding a NoSQL database\n\n```console\n? Please select from one of the below mentioned services:\n> Content (Images, audio, video, etc.)\n  NoSQL Database\n? Please provide a friendly name for your resource that will be used to label this category in the project:\n> dynamo2e1dc4eb\n? Please provide table name:\n> dynamo2e1dc4eb\n```\n\nFollow the prompts to provide your NoSQL Database's resource name. Next, you'll go through a table-creation wizard. First, you'll create the columns of your table:\n\n```console\nYou can now add columns to the table.\n\n? What would you like to name this column: id\n? Please choose the data type: string\n? Would you like to add another column? Yes\n```\n\nThen, you'll need to specify your indexes. The concept behind \"indexes\", \"partition key\", \"sort key\" and \"global secondary indexes\" are explained in-depth [here](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.CoreComponents.html#HowItWorks.CoreComponents.PrimaryKey).\n\n```console\n? Please choose partition key for the table: id\n? Do you want to add a sort key to your table? (y/N)\n```\n\n```console\n? Do you want to add a Lambda Trigger for your Table? (y/N)\n```\n\nIf you want to configure a Lambda trigger for your Table, you'll have the option. Learn more about this workflow [here](/cli/usage/lambda-triggers#dynamodb-lambda-triggers).\n\nThat's it! Your NoSQL Database is set up!\n",
    "meta": {
      "title": "Overview",
      "description": "Use Amplify CLI to create and manage cloud-connected file & data storage for your app.",
      "subcategory": "Storage",
      "category": "Amplify CLI"
    },
    "filename": "/cli/storage/overview"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Run the command above to override Amplify-generated auth resources including Amazon Cognito user pool, identity pool, user pool groups, and more."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The command creates a new overrides.ts file under amplify/backend/auth/<resource-name>/ which provides you the Amplify-generated resources as CDK constructs."
      },
      {
        "heading": "Customize Amplify-generated Cognito auth resources",
        "depth": 2,
        "text": "Apply all the overrides in the override(...) function. For example, to update the temporary password validity days for your Cognito user pool:"
      },
      {
        "heading": "Customize Amplify-generated Cognito auth resources",
        "depth": 2,
        "text": "Or add a custom attribute to your Cognito user pool:"
      },
      {
        "heading": "Customize Amplify-generated Cognito auth resources",
        "depth": 2,
        "text": "You can override the following auth resources that Amplify generates:"
      },
      {
        "heading": "Customize Amplify-generated Cognito auth resources",
        "depth": 2,
        "text": "|Amplify-generated resource|Description|\n|-|-|\n|customMessageConfirmationBucket|S3 bucket used for custom message triggers|\n|snsRole|SNS role for sending authentication-related messages|\n|userPool|The Cognito user pool that enables user sign-up and sign-in|\n|userPoolClientWeb|A Cognito user pool client for web apps|\n|userPoolClient|A Cognito user pool client for mobile apps|\n|identityPool|A Cognito identity pool to federate identities|\n|identityPoolRoleMap|Role mapping for authenticated and unauthenticated user roles|\n|lambdaConfigPermissions|Permissions for Lambda function to access Cognito user pool and identity pool |\n|lambdaTriggerPermissions|IAM policy attached to Cognito Lambda triggers|\n|userPoolClientLambda|Lambda function to fetch app client secret from user pool client|\n|userPoolClientRole|IAM Role for Lambda function to fetch app client secret from user pool client|\n|userPoolClientLambdaPolicy|IAM Policy for Lambda function to fetch app client secret from user pool client|\n|userPoolClientLogPolicy|IAM Policy to enable CloudWatch logging for Lambda function to fetch app client secret from user pool client|\n|userPoolClientInputs|Custom CloudFormation resource to fetch app client secret from user pool client|\n|hostedUICustomResource|Lambda function to enable Cognito user pool Hosted UI login|\n|hostedUICustomResourcePolicy|IAM Policy for Lambda function to enable Cognito user pool Hosted UI login|\n|hostedUICustomResourceLogPolicy|IAM Policy to enable CloudWatch logging for Lambda function to enable Cognito user pool Hosted UI login|\n|hostedUICustomResourceInputs|Custom CloudFormation resource to enable Cognito user pool Hosted UI login|\n|hostedUIProvidersCustomResource|Lambda function to configure Hosted UI with 3rd party identity providers|\n|hostedUIProvidersCustomResourcePolicy|IAM Policy for Lambda function to configure Hosted UI with 3rd party identity provider|\n|hostedUIProvidersCustomResourceLogPolicy|IAM Policy to enable CloudWatch logging for Lambda function to configure Hosted UI with 3rd party identity provider|\n|hostedUIProvidersCustomResourceInputs|Custom CloudFormation resource to configure Hosted UI with 3rd party identity provider|\n|oAuthCustomResource|Lambda function to enable OAuth|\n|oAuthCustomResourcePolicy|IAM Policy for OAuth custom CloudFormation resource|\n|oAuthCustomResourceLogPolicy|IAM Policy to enable CloudWatch logging for OAuth Lambda function|\n|oAuthCustomResourceInputs|Custom CloudFormation resource to enable OAuth|\n|mfaLambda|Lambda function to enable multi-factor authentication function|\n|mfaLogPolicy|IAM Policy to enable CloudWatch logging for multi-factor authentication Lambda function|\n|mfaLambdaPolicy|IAM Policy for multi-factor authentication Lambda function|\n|mfaLambdaInputs|Custom CloudFormation resource to enable multi-factor authentication|\n|mfaLambdaRole|IAM Execution Role for multi-factor authentication Lambda function|\n|openIdLambda|Lambda function to enable OpenID Connect|\n|openIdLogPolicy|IAM Policy to enable CloudWatch logging for OpenID Connect Lambda function|\n|openIdLambdaIAMPolicy|IAM Policy to enable OpenID Connect Lambda function|\n|openIdLambdaInputs|Custom CloudFormation resource to enable OpenID Connect|\n|openIdLambdaRole|Lambda Execution Role for OpenID Connect Lambda function|"
      },
      {
        "heading": "Customize Amplify-generated Cognito user group resources",
        "depth": 2,
        "text": "Apply all the overrides in the override(...) function. For example to add a path to the lambda execution role that facilitates the user pool group to role mapping:"
      },
      {
        "heading": "Customize Amplify-generated Cognito user group resources",
        "depth": 2,
        "text": "You can override the following user pool group resources that Amplify generates:"
      },
      {
        "heading": "Customize Amplify-generated Cognito user group resources",
        "depth": 2,
        "text": "|Amplify-generated resource|Description|\n|-|-|\n|userPoolGroup|The map of user pool groups|\n|userPoolGroupRole|The map of user pool group roles|\n|roleMapCustomResource|A custom CloudFormation resource to map user pool groups to their roles|\n|lambdaExecutionRole|Lambda execution role for the \"user pool group\"-to-role mapping function|\n|roleMapLambdaFunction|The Lambda function that facilitates the user pool group to role mapping|"
      },
      {
        "heading": "Customize Amplify-generated Cognito auth resources with social providers",
        "depth": 2,
        "text": "Apply all the overrides in the override(...) function. For example to add social providers to your Cognito user pool:"
      }
    ],
    "source": "export const meta = {\n  title: `Override Amplify-generated Cognito resources`,\n  description: 'The \"amplify override auth\" command generates a developer-configurable \"overrides\" TypeScript file which provides Amplify-generated Cognito resources as CDK constructs. For example, developers can set auth settings that are not directly available in the Amplify CLI workflow, such as the number of valid days for a temporary password.',\n};\n\n```bash\namplify override auth\n```\n\nRun the command above to override Amplify-generated auth resources including Amazon Cognito user pool, identity pool, user pool groups, and more.\n\nThe command creates a new `overrides.ts` file under `amplify/backend/auth/<resource-name>/` which provides you the Amplify-generated resources as [CDK constructs](https://docs.aws.amazon.com/cdk/latest/guide/home.html).\n\n## Customize Amplify-generated Cognito auth resources\n\nApply all the overrides in the `override(...)` function. For example, to update the temporary password validity days for your Cognito user pool:\n\n```ts\nimport { AmplifyAuthCognitoStackTemplate } from '@aws-amplify/cli-extensibility-helper';\n\nexport function override(resources: AmplifyAuthCognitoStackTemplate) {\n  resources.userPool.policies = { // Set the user pool policies\n    passwordPolicy: {\n      ...resources.userPool.policies[\"passwordPolicy\"], // Carry over existing settings\n      temporaryPasswordValidityDays: 3 // Add new setting not provided Amplify's default\n    }\n  }\n}\n```\n\nOr add a custom attribute to your Cognito user pool:\n\n```ts\nimport { AmplifyAuthCognitoStackTemplate } from '@aws-amplify/cli-extensibility-helper'\n\nexport function override(resources: AmplifyAuthCognitoStackTemplate) {\n  const myCustomAttribute = {\n    attributeDataType: 'String',\n    developerOnlyAttribute: false,\n    mutable: true,\n    name: 'my_custom_attribute',\n    required: false,\n  }\n  resources.userPool.schema = [\n    ...(resources.userPool.schema as any[]), // Carry over existing attributes (example: email)\n    myCustomAttribute,\n  ]\n}\n```\n\nYou can override the following auth resources that Amplify generates:\n\n|Amplify-generated resource|Description|\n|-|-|\n|[customMessageConfirmationBucket](http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-s3-bucket.html)|S3 bucket used for custom message triggers|\n|[snsRole](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-role.html)|SNS role for sending authentication-related messages|\n|[userPool](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-cognito-userpool.html)|The Cognito user pool that enables user sign-up and sign-in|\n|[userPoolClientWeb](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-cognito-userpoolclient.html)|A Cognito user pool client for web apps|\n|[userPoolClient](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-cognito-userpoolclient.html)|A Cognito user pool client for mobile apps|\n|[identityPool](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-cognito-identitypool.html)|A Cognito identity pool to federate identities|\n|[identityPoolRoleMap](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-cognito-identitypoolroleattachment.html)|Role mapping for authenticated and unauthenticated user roles|\n|[lambdaConfigPermissions](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-lambda-permission.html)|Permissions for Lambda function to access Cognito user pool and identity pool |\n|[lambdaTriggerPermissions](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html)|IAM policy attached to Cognito Lambda triggers|\n|[userPoolClientLambda](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-lambda-function.html)|Lambda function to fetch app client secret from user pool client|\n|[userPoolClientRole](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-role.html)|IAM Role for Lambda function to fetch app client secret from user pool client|\n|[userPoolClientLambdaPolicy](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html)|IAM Policy for Lambda function to fetch app client secret from user pool client|\n|[userPoolClientLogPolicy](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html)|IAM Policy to enable CloudWatch logging for Lambda function to fetch app client secret from user pool client|\n|[userPoolClientInputs](https://docs.aws.amazon.com/cdk/api/latest/docs/@aws-cdk_aws-cloudformation.CustomResource.html)|Custom CloudFormation resource to fetch app client secret from user pool client|\n|[hostedUICustomResource](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-lambda-function.html)|Lambda function to enable Cognito user pool Hosted UI login|\n|[hostedUICustomResourcePolicy](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html)|IAM Policy for Lambda function to enable Cognito user pool Hosted UI login|\n|[hostedUICustomResourceLogPolicy](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html)|IAM Policy to enable CloudWatch logging for Lambda function to enable Cognito user pool Hosted UI login|\n|[hostedUICustomResourceInputs](https://docs.aws.amazon.com/cdk/api/latest/docs/@aws-cdk_aws-cloudformation.CustomResource.html)|Custom CloudFormation resource to enable Cognito user pool Hosted UI login|\n|[hostedUIProvidersCustomResource](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-lambda-function.html)|Lambda function to configure Hosted UI with 3rd party identity providers|\n|[hostedUIProvidersCustomResourcePolicy](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html)|IAM Policy for Lambda function to configure Hosted UI with 3rd party identity provider|\n|[hostedUIProvidersCustomResourceLogPolicy](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html)|IAM Policy to enable CloudWatch logging for Lambda function to configure Hosted UI with 3rd party identity provider|\n|[hostedUIProvidersCustomResourceInputs](https://docs.aws.amazon.com/cdk/api/latest/docs/@aws-cdk_aws-cloudformation.CustomResource.html)|Custom CloudFormation resource to configure Hosted UI with 3rd party identity provider|\n|[oAuthCustomResource](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-lambda-function.html)|Lambda function to enable OAuth|\n|[oAuthCustomResourcePolicy](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html)|IAM Policy for OAuth custom CloudFormation resource|\n|[oAuthCustomResourceLogPolicy](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html)|IAM Policy to enable CloudWatch logging for OAuth Lambda function|\n|[oAuthCustomResourceInputs](https://docs.aws.amazon.com/cdk/api/latest/docs/@aws-cdk_aws-cloudformation.CustomResource.html)|Custom CloudFormation resource to enable OAuth|\n|[mfaLambda](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-lambda-function.html)|Lambda function to enable multi-factor authentication function|\n|[mfaLogPolicy](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html)|IAM Policy to enable CloudWatch logging for multi-factor authentication Lambda function|\n|[mfaLambdaPolicy](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html)|IAM Policy for multi-factor authentication Lambda function|\n|[mfaLambdaInputs](https://docs.aws.amazon.com/cdk/api/latest/docs/@aws-cdk_aws-cloudformation.CustomResource.html)|Custom CloudFormation resource to enable multi-factor authentication|\n|[mfaLambdaRole](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-role.html)|IAM Execution Role for multi-factor authentication Lambda function|\n|[openIdLambda](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-lambda-function.html)|Lambda function to enable OpenID Connect|\n|[openIdLogPolicy](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html)|IAM Policy to enable CloudWatch logging for OpenID Connect Lambda function|\n|[openIdLambdaIAMPolicy](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html)|IAM Policy to enable OpenID Connect Lambda function|\n|[openIdLambdaInputs](https://docs.aws.amazon.com/cdk/api/latest/docs/@aws-cdk_aws-cloudformation.CustomResource.html)|Custom CloudFormation resource to enable OpenID Connect|\n|[openIdLambdaRole](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-role.html)|Lambda Execution Role for OpenID Connect Lambda function|\n\n## Customize Amplify-generated Cognito user group resources\n\nApply all the overrides in the `override(...)` function. For example to add a path to the lambda execution role that facilitates the user pool group to role mapping:\n```ts\nimport { AmplifyUserPoolGroupStackTemplate } from '@aws-amplify/cli-extensibility-helper';\n\nexport function override(resources: AmplifyUserPoolGroupStackTemplate) {\n  resources.lambdaExecutionRole.path = \"/<my-path>/\" // Note: CFN does not allow you to modify the path after creation\n}\n```\n\nYou can override the following user pool group resources that Amplify generates:\n\n|Amplify-generated resource|Description|\n|-|-|\n|[userPoolGroup](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-cognito-userpoolgroup.html)|The map of user pool groups|\n|[userPoolGroupRole](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-role.html)|The map of user pool group roles|\n|[roleMapCustomResource](https://docs.aws.amazon.com/cdk/api/latest/docs/@aws-cdk_aws-cloudformation.CustomResource.html)|A custom CloudFormation resource to map user pool groups to their roles|\n|[lambdaExecutionRole](iam.CfnRole)|Lambda execution role for the \"user pool group\"-to-role mapping function|\n|[roleMapLambdaFunction](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-lambda-function.html)|The Lambda function that facilitates the user pool group to role mapping|\n\n\n## Customize Amplify-generated Cognito auth resources with social providers\n\nApply all the overrides in the `override(...)` function. For example to add social providers to your Cognito user pool:\n\n```ts\nimport { AmplifyAuthCognitoStackTemplate } from \"@aws-amplify/cli-extensibility-helper\";\n\nexport function override(resources: AmplifyAuthCognitoStackTemplate) {\n  resources.addCfnResource(\n    {\n      type: \"AWS::Cognito::UserPoolIdentityProvider\",\n      properties: {\n        AttributeMapping: {\n          preferredUsername: \"email\",\n          email: \"email\"\n        },\n        ProviderDetails: {\n          client_id: \"test\",\n          client_secret: \"test\",\n          authorize_scopes: \"test\",\n        },\n        ProviderName: \"LoginWithAmazon\",\n        ProviderType: \"LoginWithAmazon\",\n        UserPoolId: {\n          Ref: \"UserPool\",\n        },\n      },\n    },\n    \"amazon-social-provider\"\n  );\n}\n```",
    "meta": {
      "title": "Override Amplify-generated Cognito resources",
      "description": "The \"amplify override auth\" command generates a developer-configurable \"overrides\" TypeScript file which provides Amplify-generated Cognito resources as CDK constructs. For example, developers can set auth settings that are not directly available in the Amplify CLI workflow, such as the number of valid days for a temporary password.",
      "subcategory": "Authentication",
      "category": "Amplify CLI"
    },
    "filename": "/cli/auth/override"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Import existing Amazon Cognito resources into your Amplify project. Get started by running amplify import auth command to search for & import an existing Cognito User Pool & Identity Pool in your account."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The amplify import auth command will:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "automatically populate your Amplify Library configuration files (aws-exports.js, amplifyconfiguration.json) with your chosen Amazon Cognito resource information"
      },
      {
        "heading": null,
        "depth": null,
        "text": "provide your designated existing Cognito resource as the authentication & authorization mechanism for all auth-dependent categories (API, Storage and more)"
      },
      {
        "heading": null,
        "depth": null,
        "text": "enable Lambda functions to access the chosen Cognito resource if you permit it"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Make sure to run amplify push to complete the import process and deploy this backend change to the cloud."
      },
      {
        "heading": null,
        "depth": null,
        "text": "This feature is particularly useful if you're trying to:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "enable Amplify categories (such as API, Storage, and function) for your existing user base;"
      },
      {
        "heading": null,
        "depth": null,
        "text": "incrementally adopt Amplify for your application stack;"
      },
      {
        "heading": null,
        "depth": null,
        "text": "independently manage Cognito resources while working with Amplify."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Note: Amplify does not manage the lifecycle of an imported resource."
      },
      {
        "heading": "Import an existing Cognito User Pool",
        "depth": 2,
        "text": "Select the \"Cognito User Pool only\" option when you've run amplify import auth. In order to successfully import your User Pool, your User Pools require at least one app client with the following conditions:"
      },
      {
        "heading": "Import an existing Cognito User Pool",
        "depth": 2,
        "text": "A \"Web app client\": an app client without a client secret"
      },
      {
        "heading": "Import an existing Cognito User Pool",
        "depth": 2,
        "text": "Run amplify push to complete the import procedure."
      },
      {
        "heading": "Import an existing Identity Pool",
        "depth": 2,
        "text": "Select the \"Cognito User Pool and Identity Pool\" option when you've run amplify import auth. In order to successfully import your Identity Pool, it must have both of the User Pool app clients fulfilling these requirements associated as an authentication provider."
      },
      {
        "heading": "Import an existing Identity Pool",
        "depth": 2,
        "text": "Your Identity Pool needs:"
      },
      {
        "heading": "Import an existing Identity Pool",
        "depth": 2,
        "text": "an Authenticated Role with a trust relationship to your Identity Pool"
      },
      {
        "heading": "Import an existing Identity Pool",
        "depth": 2,
        "text": "an optional Unauthenticated Role if you want to use any guest user access for your Amplify categories. (Example: Guest access for your S3 buckets or REST API endpoints)"
      },
      {
        "heading": "Import an existing Identity Pool",
        "depth": 2,
        "text": "These roles are usually automatically configured when you create a new Identity Pool enabling \"Unauthenticated\" access and have a Cognito User Pool as an authentication provider."
      },
      {
        "heading": "Import an existing Identity Pool",
        "depth": 2,
        "text": "Amplify CLI will update the policies attached to the roles to ensure Amplify categories function correctly. For example, enabling Storage for authenticated & guest users will add private, protected, public, read and upload permissions for the S3 bucket to the unauthenticated & authenticated role."
      },
      {
        "heading": "Import an existing Identity Pool",
        "depth": 2,
        "text": "Run amplify push to complete the import procedure."
      },
      {
        "heading": "Multi-environment support",
        "depth": 2,
        "text": "When you create a new environment through amplify env add, Amplify CLI will assume by default that you're managing your app's Cognito resources outside of an Amplify project. You'll be asked to either import a different Cognito resource or maintain the same Cognito resource for your app's auth category."
      },
      {
        "heading": "Multi-environment support",
        "depth": 2,
        "text": "If you want to have Amplify manage your auth resources in a new environment, run amplify remove auth to unlink the imported Cognito resource and amplify add auth to create new Amplify-managed auth resources in the new environment."
      },
      {
        "heading": "Unlink an existing Cognito User Pool or Identity Pool",
        "depth": 2,
        "text": "In order to unlink your existing Cognito resource run amplify remove auth. This will only unlink the Cognito resource referenced from the Amplify project. It will not delete the Cognito resource itself."
      },
      {
        "heading": "Unlink an existing Cognito User Pool or Identity Pool",
        "depth": 2,
        "text": "Run amplify push to complete the unlink procedure."
      },
      {
        "heading": "Add Environmental Variables to Amplify Console Build",
        "depth": 2,
        "text": "In order to successfully build your application with Amplify Console add the following environmental variables to your build environment:"
      },
      {
        "heading": "Add Environmental Variables to Amplify Console Build",
        "depth": 2,
        "text": "|Environment Variable|Description|\n|-|-|\n|AMPLIFY_USERPOOL_ID|The ID for the Amazon Cognito user pool imported for auth|\n|AMPLIFY_WEBCLIENT_ID|The ID for the app client to be used by web applications. The app client must be configured with access to the Amazon Cognito user pool specified by the AMPLIFY_USERPOOL_ID environment variable.|\n|AMPLIFY_NATIVECLIENT_ID|The ID for the app client to be used by native applications. The app client must be configured with access to the Amazon Cognito user pool specified by the AMPLIFY_USERPOOL_ID environment variable.|\n|AMPLIFY_IDENTITYPOOL_ID|The ID for the Amazon Cognito identity pool|"
      }
    ],
    "source": "export const meta = {\n  title: `Use an existing Cognito User Pool and Identity Pool`,\n  description: `Configure the Amplify CLI to use existing Amazon Cognito User Pool and Identity Pool resources as an authentication & authorization mechanism for other Amplify categories. (API, Storage, and more)`,\n};\n\nImport existing Amazon Cognito resources into your Amplify project. Get started by running `amplify import auth` command to search for & import an existing Cognito User Pool & Identity Pool in your account.\n\n```bash\namplify import auth\n```\n\nThe `amplify import auth` command will:\n\n- automatically populate your Amplify Library configuration files (aws-exports.js, amplifyconfiguration.json) with your chosen Amazon Cognito resource information\n- provide your designated existing Cognito resource as the authentication & authorization mechanism for all auth-dependent categories (API, Storage and more)\n- enable Lambda functions to access the chosen Cognito resource if you permit it\n\nMake sure to run `amplify push` to complete the import process and deploy this backend change to the cloud.\n\nThis feature is particularly useful if you're trying to:\n\n- enable Amplify categories (such as API, Storage, and function) for your existing user base;\n- incrementally adopt Amplify for your application stack;\n- independently manage Cognito resources while working with Amplify.\n\n> Note: Amplify does not manage the lifecycle of an imported resource.\n\n## Import an existing Cognito User Pool\n\nSelect the \"Cognito User Pool only\" option when you've run `amplify import auth`. In order to successfully import your User Pool, your User Pools require at least one app client with the following conditions:\n\n- *A \"Web app client\"*: an app client **without** a client secret\n\nRun `amplify push` to complete the import procedure.\n\n## Import an existing Identity Pool\n\nSelect the \"Cognito User Pool and Identity Pool\" option when you've run `amplify import auth`. In order to successfully import your Identity Pool, it must have both of the User Pool app clients fulfilling [these requirements](#import-an-existing-cognito-user-pool) associated as an authentication provider.\n\nYour Identity Pool needs:\n\n- an Authenticated Role with a trust relationship to your Identity Pool\n- an **optional** Unauthenticated Role if you want to use any guest user access for your Amplify categories. (Example: Guest access for your S3 buckets or REST API endpoints)\n\nThese roles are usually automatically configured when you create a new Identity Pool enabling \"Unauthenticated\" access and have a Cognito User Pool as an authentication provider.\n\nAmplify CLI will update the policies attached to the roles to ensure Amplify categories function correctly. For example, enabling Storage for authenticated & guest users will add private, protected, public, read and upload permissions for the S3 bucket to the unauthenticated & authenticated role.\n\nRun `amplify push` to complete the import procedure.\n\n## Multi-environment support\n\nWhen you create a new environment through `amplify env add`, Amplify CLI will assume by default that you're managing your app's Cognito resources outside of an Amplify project. You'll be asked to either import a different Cognito resource or maintain the same Cognito resource for your app's auth category.\n\nIf you want to have Amplify manage your auth resources in a new environment, run `amplify remove auth` to unlink the imported Cognito resource and `amplify add auth` to create new Amplify-managed auth resources in the new environment.\n\n## Unlink an existing Cognito User Pool or Identity Pool\n\nIn order to unlink your existing Cognito resource run `amplify remove auth`. This will only unlink the Cognito resource referenced from the Amplify project. It will not delete the Cognito resource itself.\n\nRun `amplify push` to complete the unlink procedure.\n\n## Add Environmental Variables to Amplify Console Build\n\nIn order to successfully build your application with Amplify Console add the following environmental variables to your build environment:\n\n|Environment Variable|Description|\n|-|-|\n|AMPLIFY_USERPOOL_ID|The ID for the Amazon Cognito user pool imported for auth|\n|AMPLIFY_WEBCLIENT_ID|The ID for the app client to be used by web applications. The app client must be configured with access to the Amazon Cognito user pool specified by the AMPLIFY_USERPOOL_ID environment variable.|\n|AMPLIFY_NATIVECLIENT_ID|The ID for the app client to be used by native applications. The app client must be configured with access to the Amazon Cognito user pool specified by the AMPLIFY_USERPOOL_ID environment variable.|\n|AMPLIFY_IDENTITYPOOL_ID|The ID for the Amazon Cognito identity pool|\n",
    "meta": {
      "title": "Use an existing Cognito User Pool and Identity Pool",
      "description": "Configure the Amplify CLI to use existing Amazon Cognito User Pool and Identity Pool resources as an authentication & authorization mechanism for other Amplify categories. (API, Storage, and more)",
      "subcategory": "Authentication",
      "category": "Amplify CLI"
    },
    "filename": "/cli/auth/import"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Admin Actions allow you to execute queries and operations against users and groups in your Cognito user pool."
      },
      {
        "heading": null,
        "depth": null,
        "text": "For example, the ability to list all users in a Cognito User Pool may provide useful for the administrative panel of an app if the logged-in user is a member of a specific Group called \"Admins\"."
      },
      {
        "heading": null,
        "depth": null,
        "text": "This is an advanced feature that is not recommended without an understanding of the underlying architecture. The associated infrastructure which is created is a base designed for you to customize for your specific business needs. We recommend removing any functionality which your app does not require."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The Amplify CLI can setup a REST endpoint with secure access to a Lambda function running with limited permissions to the User Pool if you wish to have these capabilities in your application, and you can choose to expose the actions to all users with a valid account or restrict to a specific User Pool Group."
      },
      {
        "heading": "Enable Admin Queries",
        "depth": 2,
        "text": "This will configure an API Gateway endpoint with a Cognito Authorizer that accepts an Access Token, which is used by a Lambda function to perform actions against the User Pool. The function is example code which you can use to remove, add, or alter functionality based on your business case by editing it in the amplify/backend/function/AdminQueriesXXX/src directory and running an amplify push to deploy your changes. If you choose to restrict actions to a specific Group, custom middleware in the function will prevent any actions unless the user is a member of that Group."
      },
      {
        "heading": "Admin Queries API",
        "depth": 2,
        "text": "The default routes and their functions, HTTP methods, and expected parameters are below"
      },
      {
        "heading": "Admin Queries API",
        "depth": 2,
        "text": "addUserToGroup: Adds a user to a specific Group. Expects username and groupname in the POST body."
      },
      {
        "heading": "Admin Queries API",
        "depth": 2,
        "text": "removeUserFromGroup: Removes a user from a specific Group. Expects username and groupname in the POST body."
      },
      {
        "heading": "Admin Queries API",
        "depth": 2,
        "text": "confirmUserSignUp: Confirms a users signup. Expects username in the POST body."
      },
      {
        "heading": "Admin Queries API",
        "depth": 2,
        "text": "disableUser: Disables a user. Expects username in the POST body."
      },
      {
        "heading": "Admin Queries API",
        "depth": 2,
        "text": "enableUser: Enables a user. Expects username in the POST body."
      },
      {
        "heading": "Admin Queries API",
        "depth": 2,
        "text": "getUser: Gets specific user details. Expects username as a GET query string."
      },
      {
        "heading": "Admin Queries API",
        "depth": 2,
        "text": "listUsers: Lists all users in the current Cognito User Pool. You can provide an OPTIONAL limit (between 0 and 60) as a GET query string, which returns a NextToken that can be provided as a token query string for pagination."
      },
      {
        "heading": "Admin Queries API",
        "depth": 2,
        "text": "listGroups: Lists all groups in the current Cognito User Pool. You can provide an OPTIONAL limit (between 0 and 60) as a GET query string, which returns a NextToken that can be provided as a token query string for pagination."
      },
      {
        "heading": "Admin Queries API",
        "depth": 2,
        "text": "listGroupsForUser: Lists groups to which current user belongs to. Expects username as a GET query string. You can provide an OPTIONAL limit (between 0 and 60) as a GET query string, which returns a NextToken that can be provided as a token query string for pagination."
      },
      {
        "heading": "Admin Queries API",
        "depth": 2,
        "text": "listUsersInGroup: Lists users that belong to a specific group. Expects groupname as a GET query string. You can provide an OPTIONAL limit (between 0 and 60) as a GET query string, which returns a NextToken that can be provided as a token query string for pagination."
      },
      {
        "heading": "Admin Queries API",
        "depth": 2,
        "text": "signUserOut: Signs a user out from User Pools, but only if the call is originating from that user. Expects username in the POST body."
      },
      {
        "heading": "Example",
        "depth": 2,
        "text": "To leverage this functionality in your app you would call the appropriate route from Amplify.API after signing in. The following example adds the user \"richard\" to the Editors Group and then list all members of the Editors Group with a pagination limit of 10:"
      },
      {
        "heading": "Example",
        "depth": 2,
        "text": "Initialize Amplify API. Refer to Getting Started with Amplify.API for REST for more details."
      },
      {
        "heading": "Example",
        "depth": 2,
        "text": "You should have the initialization code including the imports:"
      },
      {
        "heading": "Example",
        "depth": 2,
        "text": "and code that adds AWSCognitoAuthPlugin, AWSAPIPlugin, and configures it."
      },
      {
        "heading": "Example",
        "depth": 2,
        "text": "Sign in using Amplify.Auth. See Amplify.Auth to learn more about signing up and signing in a user."
      },
      {
        "heading": "Example",
        "depth": 2,
        "text": "Use the following in your app to add a user to the Group."
      },
      {
        "heading": "Example",
        "depth": 2,
        "text": "Use the following to list the users in the Group."
      },
      {
        "heading": "Example",
        "depth": 2,
        "text": "Note: Cognito User Pool with HostedUI"
      },
      {
        "heading": "Example",
        "depth": 2,
        "text": "The Admin Queries API configuration in amplifyconfiguration.json will have the endpoint's authorization type set to AMAZON_COGNITO_USER_POOLS. With this authorization type, Amplify.API will perform the request with the access token. However, when using HostedUI, the app may get unauthorized responses despite being signed in, and will require using the ID Token. Set the authorizationType to \"NONE\" and add a custom interceptor to return the ID Token."
      },
      {
        "heading": "Example",
        "depth": 2,
        "text": "If you perform additional updates to your resources using Amplify CLI, the authorizationType will be reverted back to AMAZON_COGNITO_USER_POOLS. Make sure to update this back to NONE."
      },
      {
        "heading": "Example",
        "depth": 2,
        "text": "Add a custom interceptor to the API"
      },
      {
        "heading": "Example",
        "depth": 2,
        "text": "Set up the custom interceptor to return the ID token for the request."
      }
    ],
    "source": "export const meta = {\n  title: `Admin actions`,\n  description: `Learn how to expose Administrative actions for your Cognito User Pool to your end user applications.`,\n};\n\nAdmin Actions allow you to execute queries and operations against users and groups in your Cognito user pool.\n\nFor example, the ability to list all users in a Cognito User Pool may provide useful for the administrative panel of an app if the logged-in user is a member of a specific Group called \"Admins\".\n\n> This is an advanced feature that is not recommended without an understanding of the underlying architecture. The associated infrastructure which is created is a base designed for you to customize for your specific business needs. We recommend removing any functionality which your app does not require.\n\nThe Amplify CLI can setup a REST endpoint with secure access to a Lambda function running with limited permissions to the User Pool if you wish to have these capabilities in your application, and you can choose to expose the actions to all users with a valid account or restrict to a specific User Pool Group.\n\n## Enable Admin Queries\n\n```bash\namplify add auth\n```\n\n```console\n? Do you want to add an admin queries API? Yes\n? Do you want to restrict access to a specific Group Yes\n? Select the group to restrict access with: (Use arrow keys)\n❯ Admins \n  Editors \n  Enter a custom group \n```\n\nThis will configure an API Gateway endpoint with a Cognito Authorizer that accepts an Access Token, which is used by a Lambda function to perform actions against the User Pool. The function is example code which you can use to remove, add, or alter functionality based on your business case by editing it in the `amplify/backend/function/AdminQueriesXXX/src` directory and running an `amplify push` to deploy your changes. If you choose to restrict actions to a specific Group, custom middleware in the function will prevent any actions unless the user is a member of that Group.\n\n## Admin Queries API\n\nThe default routes and their functions, HTTP methods, and expected parameters are below\n\n- `addUserToGroup`: Adds a user to a specific Group. Expects `username` and `groupname` in the POST body.\n- `removeUserFromGroup`: Removes a user from a specific Group. Expects `username` and `groupname` in the POST body.\n- `confirmUserSignUp`: Confirms a users signup. Expects `username` in the POST body.\n- `disableUser`: Disables a user. Expects `username` in the POST body.\n- `enableUser`: Enables a user. Expects `username` in the POST body.\n- `getUser`: Gets specific user details. Expects `username` as a GET query string.\n- `listUsers`: Lists all users in the current Cognito User Pool. You can provide an OPTIONAL `limit` (between 0 and 60) as a GET query string, which returns a `NextToken` that can be provided as a `token` query string for pagination.\n- `listGroups`: Lists all groups in the current Cognito User Pool. You can provide an OPTIONAL `limit` (between 0 and 60) as a GET query string, which returns a `NextToken` that can be provided as a `token` query string for pagination.\n- `listGroupsForUser`: Lists groups to which current user belongs to. Expects `username` as a GET query string. You can provide an OPTIONAL `limit` (between 0 and 60) as a GET query string, which returns a `NextToken` that can be provided as a `token` query string for pagination.\n- `listUsersInGroup`: Lists users that belong to a specific group. Expects `groupname` as a GET query string. You can provide an OPTIONAL `limit` (between 0 and 60) as a GET query string, which returns a `NextToken` that can be provided as a `token` query string for pagination.\n- `signUserOut`: Signs a user out from User Pools, but only if the call is originating from that user. Expects `username` in the POST body.\n\n## Example\n\nTo leverage this functionality in your app you would call the appropriate route from `Amplify.API` after signing in. The following example adds the user \"richard\" to the Editors Group and then list all members of the Editors Group with a pagination limit of 10:\n\n<BlockSwitcher>\n\n<Block name=\"JS (React)\">\n\n```js\nimport React from 'react'\nimport { Amplify, Auth, API } from 'aws-amplify';\nimport { withAuthenticator } from 'aws-amplify-react';\nimport awsconfig from './aws-exports';\nAmplify.configure(awsconfig);\n\nasync function addToGroup() { \n  let apiName = 'AdminQueries';\n  let path = '/addUserToGroup';\n  let myInit = {\n      body: {\n        \"username\" : \"richard\",\n        \"groupname\": \"Editors\"\n      }, \n      headers: {\n        'Content-Type' : 'application/json',\n        Authorization: `${(await Auth.currentSession()).getAccessToken().getJwtToken()}`\n      } \n  }\n  return await API.post(apiName, path, myInit);\n}\n\nlet nextToken;\n\nasync function listEditors(limit){\n  let apiName = 'AdminQueries';\n  let path = '/listUsersInGroup';\n  let myInit = { \n      queryStringParameters: {\n        \"groupname\": \"Editors\",\n        \"limit\": limit,\n        \"token\": nextToken\n      },\n      headers: {\n        'Content-Type' : 'application/json',\n        Authorization: `${(await Auth.currentSession()).getAccessToken().getJwtToken()}`\n      }\n  }\n  const { NextToken, ...rest } =  await API.get(apiName, path, myInit);\n  nextToken = NextToken;\n  return rest;\n}\n\nfunction App() {\n  return (\n    <div className=\"App\">\n      <button onClick={addToGroup}>Add to Group</button>\n      <button onClick={() => listEditors(10)}>List Editors</button>\n    </div>\n  );\n}\n\nexport default withAuthenticator(App, true);\n```\n\n</Block>\n\n<Block name=\"iOS\">\n\n1. Initialize Amplify API. Refer to [Getting Started with Amplify.API for REST](/lib/restapi/getting-started) for more details. \n\nYou should have the initialization code including the imports:\n\n```swift\nimport Amplify\n// If you are using Swift Package Manager\nimport AWSAPIPlugin\n// or if you are using Cocoapods\nimport AmplifyPlugins\n```\n\nand code that adds `AWSCognitoAuthPlugin`, `AWSAPIPlugin`, and configures it.\n\n```swift\ntry Amplify.add(plugin: AWSCognitoAuthPlugin())\ntry Amplify.add(plugin: AWSAPIPlugin())\ntry Amplify.configure()\n```\n\n2. Sign in using `Amplify.Auth`. See [Amplify.Auth](/lib/auth/getting-started) to learn more about signing up and signing in a user.\n\n3. Use the following in your app to add a user to the Group.\n\n```swift\nfunc addToGroup(username: String, groupName: String) {\n    let path = \"/addUserToGroup\"\n    let body = \"{\\\"username\\\":\\\"\\(username)\\\",\\\"groupname\\\":\\\"\\(groupName)\\\"}\".data(using: .utf8)\n    let request = RESTRequest(path: path, body: body)\n    Amplify.API.post(request: request) { result in\n        switch result {\n        case .success(let data):\n            print(\"Response Body: \\(String(decoding: data, as: UTF8.self))\")\n        case .failure(let error):\n            if case let .httpStatusError(statusCode, response) = error,\n                let awsResponse = response as? AWSHTTPURLResponse,\n                let responseBody = awsResponse.body\n            {\n                print(\"StatusCode: \\(statusCode) Response Body: \\(String(decoding: responseBody, as: UTF8.self))\")\n            }\n        }\n    }\n}\n\naddToGroup(username: \"richard\", groupName:  \"Editors\")\n```\n\n4. Use the following to list the users in the Group.\n\n```swift\nfunc listEditors(groupName: String, limit: Int, nextToken: String? = nil) {\n    let path = \"/listUsersInGroup\"\n    var query = [\"groupname\": groupName,\n                  \"limit\": String(limit)]\n    if let nextToken = nextToken {\n        query[\"token\"] = nextToken\n    }\n    \n    let request = RESTRequest(path: path, queryParameters: query, body: nil)\n    Amplify.API.get(request: request) { result in\n        switch result {\n        case .success(let data):\n            print(\"Response Body: \\(String(decoding: data, as: UTF8.self))\")\n        case .failure(let error):\n            if case let .httpStatusError(statusCode, response) = error,\n                let awsResponse = response as? AWSHTTPURLResponse,\n                let responseBody = awsResponse.body\n            {\n                print(\"StatusCode: \\(statusCode) Response Body: \\(String(decoding: responseBody, as: UTF8.self))\")\n            }\n        }\n    }\n}\n\nlistEditors(groupName: \"Editors\", limit: 10)\n```\n\n**Note: Cognito User Pool with HostedUI** \n\nThe Admin Queries API configuration in **amplifyconfiguration.json** will have the endpoint's authorization type set to `AMAZON_COGNITO_USER_POOLS`. With this authorization type, `Amplify.API` will perform the request with the access token. However, when using HostedUI, the app may get unauthorized responses despite being signed in, and will require using the ID Token. Set the authorizationType to \"NONE\" and add a custom interceptor to return the ID Token. \n\n```json\n{\n    \"awsAPIPlugin\": {\n        \"[YOUR-RESTENDPOINT-NAME]\": {\n            \"endpointType\": \"REST\",\n            \"endpoint\": \"[YOUR-REST-ENDPOINT]\",\n            \"region\": \"[REGION]\",\n            \"authorizationType\": \"NONE\"\n        }\n    }\n}\n```\n<Callout warning>\n\nIf you perform additional updates to your resources using Amplify CLI, the authorizationType will be reverted back to `AMAZON_COGNITO_USER_POOLS`. Make sure to update this back to `NONE`.\n\n</Callout>\n\nAdd a custom interceptor to the API\n```swift\ntry Amplify.configure()\ntry Amplify.API.add(interceptor: MyCustomInterceptor(), for: \"[YOUR-RESTENDPOINT-NAME]\")\n```\n\nSet up the custom interceptor to return the ID token for the request.\n\n```swift\n// `URLRequestInterceptor` comes from AWSAPIPlugin, add the following imports\nimport Amplify\n// If you are using Swift Package Manager\nimport AWSAPIPlugin\n// or if you are using Cocoapods\nimport AmplifyPlugins\n\nclass MyCustomInterceptor: URLRequestInterceptor {\n    func getLatestAuthToken() -> Result<String, Error> {\n        let semaphore = DispatchSemaphore(value: 0)\n        var result: Result<String, Error> = .failure(AuthError.unknown(\"Could not retrieve Cognito token\"))\n        Amplify.Auth.fetchAuthSession { (event) in\n            do {\n                defer {\n                    semaphore.signal()\n                }\n                let session = try event.get()\n                if let tokens = try (session as? AuthCognitoTokensProvider)?.getCognitoTokens().get() {\n                    result = .success(tokens.idToken)\n                }\n            } catch {\n                result = .failure(error)\n            }\n        }\n        semaphore.wait()\n        return result\n    }\n    \n    func intercept(_ request: URLRequest) throws -> URLRequest {\n        guard let mutableRequest = (request as NSURLRequest).mutableCopy() as? NSMutableURLRequest else {\n            throw APIError.unknown(\"Could not get mutable request\", \"\")\n        }\n        \n        let tokenResult = getLatestAuthToken()\n        switch tokenResult {\n        case .success(let token):\n            mutableRequest.setValue(token, forHTTPHeaderField: \"authorization\")\n        case .failure(let error):\n            throw APIError.operationError(\"Failed to retrieve Cognito UserPool token.\", \"\", error)\n        }\n        return mutableRequest as URLRequest\n    }\n}\n```\n</Block>\n</BlockSwitcher>",
    "meta": {
      "title": "Admin actions",
      "description": "Learn how to expose Administrative actions for your Cognito User Pool to your end user applications.",
      "subcategory": "Authentication",
      "category": "Amplify CLI"
    },
    "filename": "/cli/auth/admin"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "You can create logical groups in Cognito User Pools and assign permissions to access resources in Amplify categories with the CLI, as well as define the relative precedence of one group to another. This can be useful for defining which users should be part of \"Admins\" vs \"Editors\", and if the users in a Group should be able to just write or write & read to a resource (AppSync, API Gateway, S3 bucket, etc). You can also use these with @auth Static Groups in the GraphQL Transformer. Precedence helps remove any ambiguity on permissions if a user is in multiple Groups."
      },
      {
        "heading": "Create user groups",
        "depth": 2,
        "text": "When asked as in the example above, you can press Shift on your keyboard along with the LEFT and RIGHT arrows to move a Group higher or lower in precedence. Once complete you can open amplify/backend/auth/userPoolGroups/user-pool-group-precedence.json to manually set the precedence."
      },
      {
        "heading": "Group access controls",
        "depth": 2,
        "text": "For certain Amplify categories you can restrict access with CRUD (Create, Read, Update, and Delete) permissions, setting different access controls for authenticated users vs Guests (e.g. Authenticated users can read & write to S3 buckets while Guests can only read). You can further restrict this to apply different permissions conditionally depending on if a logged-in user is part of a specific User Pool Group."
      },
      {
        "heading": "Group access controls",
        "depth": 2,
        "text": "The above example uses a combination of permissions where users in the \"Admins\" Group have full access, \"Guest\" users can only read, and \"Authenticated\" users who are not a part of any group have create, update, and read access. Amplify will configure the corresponding IAM policy on your behalf. Advanced users can additionally set permissions by adding a customPolicies key to amplify/backend/auth/userPoolGroups/user-pool-group-precedence.json with custom IAM policy for a Group. This will attach an inline policy on the IAM role associated to this Group during deployment. Note  this is an advanced feature and only suitable if you have an understanding of AWS resources. For instance perhaps you wanted users in the \"Admins\" group to have the ability to Create an S3 bucket:"
      }
    ],
    "source": "export const meta = {\n  title: `User groups`,\n  description: `Create logical groups in Cognito User Pools and assign permissions to access resources in Amplify categories with the Amplify CLI.`,\n};\n\nYou can create logical groups in Cognito User Pools and assign permissions to access resources in Amplify categories with the CLI, as well as define the relative precedence of one group to another. This can be useful for defining which users should be part of \"Admins\" vs \"Editors\", and if the users in a Group should be able to just write or write & read to a resource (AppSync, API Gateway, S3 bucket, etc). [You can also use these with `@auth` Static Groups in the GraphQL Transformer](/cli/graphql/authorization-rules#static-group-authorization). Precedence helps remove any ambiguity on permissions if a user is in multiple Groups.\n\n## Create user groups\n\n```bash\namplify add auth\n```\n\n```console\n❯ Manual configuration\n\nDo you want to add User Pool Groups? (Use arrow keys)\n❯ Yes\n\n? Provide a name for your user pool group: Admins\n? Do you want to add another User Pool Group Yes\n? Provide a name for your user pool group: Editors\n? Do you want to add another User Pool Group No\n? Sort the user pool groups in order of preference …  (Use <shift>+<right/left> to change the order)\n  Admins\n  Editors\n```\n\nWhen asked as in the example above, you can press `Shift` on your keyboard along with the **LEFT** and **RIGHT** arrows to move a Group higher or lower in precedence. Once complete you can open `amplify/backend/auth/userPoolGroups/user-pool-group-precedence.json` to manually set the precedence.\n\n## Group access controls\n\nFor certain Amplify categories you can restrict access with CRUD (Create, Read, Update, and Delete) permissions, setting different access controls for authenticated users vs Guests (e.g. Authenticated users can read & write to S3 buckets while Guests can only read). You can further restrict this to apply different permissions conditionally depending on if a logged-in user is part of a specific User Pool Group.\n\n```bash\namplify add storage  # Select content\n```\n\n```console\n? Restrict access by? (Use arrow keys)\n  Auth/Guest Users\n  Individual Groups\n❯ Both\n  Learn more\n\nWho should have access?\n❯ Auth and guest users\n\nWhat kind of access do you want for Authenticated users?\n❯ create/update, read\n\nWhat kind of access do you want for Guest users?\n❯ read\n\nSelect groups:\n❯ Admins\n\nWhat kind of access do you want for Admins users?\n❯ create/update, read, delete\n```\n\nThe above example uses a combination of permissions where users in the \"Admins\" Group have full access, \"Guest\" users can only read, and \"Authenticated\" users who are not a part of any group have create, update, and read access. Amplify will configure the corresponding IAM policy on your behalf. Advanced users can additionally set permissions by adding a `customPolicies` key to `amplify/backend/auth/userPoolGroups/user-pool-group-precedence.json` with custom IAM policy for a Group. This will attach an inline policy on the IAM role associated to this Group during deployment. **Note**  this is an advanced feature and only suitable if you have an understanding of AWS resources. For instance perhaps you wanted users in the \"Admins\" group to have the ability to Create an S3 bucket:\n\n```json\n[\n  {\n    \"groupName\": \"Admins\",\n    \"precedence\": 1,\n    \"customPolicies\": [\n      {\n        \"PolicyName\": \"admin-group-policy\",\n        \"PolicyDocument\": {\n          \"Version\": \"2012-10-17\",\n          \"Statement\": [\n            {\n              \"Sid\": \"statement1\",\n              \"Effect\": \"Allow\",\n              \"Action\": [\"s3:CreateBucket\"],\n              \"Resource\": [\"arn:aws:s3:::*\"]\n            }\n          ]\n        }\n      }\n    ]\n  },\n  {\n    \"groupName\": \"Editors\",\n    \"precedence\": 2\n  }\n]\n```\n",
    "meta": {
      "title": "User groups",
      "description": "Create logical groups in Cognito User Pools and assign permissions to access resources in Amplify categories with the Amplify CLI.",
      "subcategory": "Authentication",
      "category": "Amplify CLI"
    },
    "filename": "/cli/auth/groups"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "The Amplify CLI supports configuring many different Authentication and Authorization workflows, including simple and advanced configurations of the login options, triggering Lambda functions during different lifecycle events, and administrative actions which you can optionally expose to your applications."
      },
      {
        "heading": "Configuring auth without social providers",
        "depth": 2,
        "text": "The easiest way to get started is to leverage the default configuration which is optimized for the most common use cases and choices."
      },
      {
        "heading": "Configuring auth with social providers",
        "depth": 2,
        "text": "Once your User Pool is functioning, you can enable more configurations such as federation with Facebook, Google, or Login with Amazon. You can also configure more advanced settings by selecting Manual Configuration."
      },
      {
        "heading": "Configuring auth with social providers",
        "depth": 2,
        "text": "Select Default configuration with Social Provider (Federation):"
      },
      {
        "heading": "Configuring auth with social providers",
        "depth": 2,
        "text": "You can find more documentation on adding each social provider in the Libraries section of the docs."
      },
      {
        "heading": "Re-use an existing Cognito User Pool and Identity Pool",
        "depth": 2,
        "text": "Instead of letting Amplify CLI create a new set of auth resources, you can also import your existing Cognito resources. These resources can be used to auto-generate the Amplify library configuration files, used as an auth dependency for other categories and provided access permissions from within Lambda functions."
      },
      {
        "heading": "Re-use an existing Cognito User Pool and Identity Pool",
        "depth": 2,
        "text": "Run amplify import auth or read the guide on how to import existing Cognito resources."
      }
    ],
    "source": "export const meta = {\n  title: `Overview`,\n  description: `The Amplify CLI supports configuring many different Authentication and Authorization workflows, including simple and advanced configurations of the login options, triggering Lambda functions during different lifecycle events, and administrative actions which you can optionally expose to your applications.`,\n};\n\nThe Amplify CLI supports configuring many different Authentication and Authorization workflows, including simple and advanced configurations of the login options, triggering Lambda functions during different lifecycle events, and administrative actions which you can optionally expose to your applications.\n\n## Configuring auth without social providers\n\nThe easiest way to get started is to leverage the default configuration which is optimized for the most common use cases and choices.\n\n```bash\namplify add auth  ## \"amplify update auth\" if already configured\n```\n\n```console\nDo you want to use the default authentication and security configuration? \n❯ Default configuration \n  Default configuration with Social Provider (Federation) \n  Manual configuration \n  I want to learn more.\n```\n\n## Configuring auth with social providers\n\nOnce your User Pool is functioning, you can enable more configurations such as federation with Facebook, Google, or Login with Amazon. You can also configure more advanced settings by selecting *Manual Configuration*.\n\n```bash\namplify add auth  ## \"amplify update auth\" if already configured\n```\n\nSelect Default configuration with Social Provider (Federation):\n\n```console\nDo you want to use the default authentication and security configuration?\n  Default configuration\n❯ Default configuration with Social Provider (Federation)\n  Manual configuration\n  I want to learn more.\n```\n\nYou can find [more documentation on adding each social provider in the Libraries section](https://docs.amplify.aws/lib/auth/social/q/platform/js#setup-your-auth-provider) of the docs.\n\n## Re-use an existing Cognito User Pool and Identity Pool\n\nInstead of letting Amplify CLI create a new set of auth resources, you can also import your existing Cognito resources. These resources can be used to auto-generate the Amplify library configuration files, used as an auth dependency for other categories and provided access permissions from within Lambda functions.\n\nRun `amplify import auth` or read the [guide on how to import existing Cognito resources](/cli/auth/import).\n",
    "meta": {
      "title": "Overview",
      "description": "The Amplify CLI supports configuring many different Authentication and Authorization workflows, including simple and advanced configurations of the login options, triggering Lambda functions during different lifecycle events, and administrative actions which you can optionally expose to your applications.",
      "subcategory": "Authentication",
      "category": "Amplify CLI"
    },
    "filename": "/cli/auth/overview"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Run the command above to override Amplify-generated Amazon API Gateway resources."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The command creates a new overrides.ts file under amplify/backend/api/<resource-name>/ which provides you the Amplify-generated resources as CDK constructs."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Apply all the overrides in the override(...) function. For example:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "To change a field on a particular path, use resources.restApi.body.paths[\\<route-path\\>]:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "You can override the following REST API resources that Amplify generates:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "|Amplify-generated resource|Description|\n|-|-|\n|restApi|The Amazon API Gateway REST API created by amplify add api|\n|deploymentResource|The deployment resource that deploys the REST API above to a stage.|\n|policies|User pool group-related IAM policy. Example: resources.policies[\"/items\"].groups[\"Admin\"]"
      },
      {
        "heading": "Add a Cognito User Pool authorizer to your REST API",
        "depth": 2,
        "text": "Amazon Cognito User Pools is a common service to use alongside API Gateway when\nadding user Sign-Up and Sign-In to your application. If your application needs to\ninteract with other AWS services, such as S3, on behalf of the user who invoked\nan endpoint, you will need to use IAM credentials with Cognito Identity Pools."
      },
      {
        "heading": "Add a Cognito User Pool authorizer to your REST API",
        "depth": 2,
        "text": "Amplify CLI does not support Cognito User Pool authorizers out of the box. To\nimplement this functionality, you must override your REST API and add a Cognito\nUser Pool authorizer yourself by adding the following code into the\noverride(...) function, in order."
      },
      {
        "heading": "Add a Cognito User Pool authorizer to your REST API",
        "depth": 2,
        "text": "First, assuming the Cognito User Pool you would like to use as an authorizer is\nthe Auth resource configured with your Amplify Project, create a parameter that resolves\nto its User Pool ID:"
      },
      {
        "heading": "Add a Cognito User Pool authorizer to your REST API",
        "depth": 2,
        "text": "Make sure to replace <your auth name here> with the name of your auth resource.\nThis is the name of the folder in amplify/backend/auth that was created when\nyou added an Auth resource to your Amplify project."
      },
      {
        "heading": "Add a Cognito User Pool authorizer to your REST API",
        "depth": 2,
        "text": "Now, create a Cognito User Pool Authorizer corresponding to the User Pool\nby modifying the security definition of your REST API:"
      },
      {
        "heading": "Add a Cognito User Pool authorizer to your REST API",
        "depth": 2,
        "text": "Finally, update the security methods for all of the paths in your REST API to\nuse this new Cognito User Pool authorizer. We also add the Authorization header\nas a parameter on incoming requests for these paths as a place for users to provide\ntheir Cognito User ID Tokens."
      },
      {
        "heading": "Add a Cognito User Pool authorizer to your REST API",
        "depth": 2,
        "text": "Note that you can add more advanced logic to only use the Cognito User Pool authorizer\nwith some paths or methods."
      },
      {
        "heading": "Add a Cognito User Pool authorizer to your REST API",
        "depth": 2,
        "text": "When performing requests to your REST API, make sure to add the Authorization\nheader with an ID Token provided by Cognito."
      },
      {
        "heading": "Add a Cognito User Pool authorizer to your REST API",
        "depth": 2,
        "text": "Requests to endpoints are now populated with information from Cognito about the\nuser who is invoking the\nendpoint, and you can reuse the verified ID Token in your endpoint resolvers to assume\nthe identity of the user for accessing other services like AWS AppSync or S3."
      }
    ],
    "source": "export const meta = {\n  title: `Override Amplify-generated API Gateway resources`,\n  description: `The \"amplify override api\" command generates a developer-configurable \"overrides\" TypeScript file which provides Amplify-generated API Gateway resources as CDK constructs. For example, developers can configure a custom description or the minimum compression size of their REST API.`,\n};\n\n```bash\namplify override api\n```\n\nRun the command above to override Amplify-generated Amazon API Gateway resources.\n\nThe command creates a new `overrides.ts` file under `amplify/backend/api/<resource-name>/` which provides you the Amplify-generated resources as [CDK constructs](https://docs.aws.amazon.com/cdk/latest/guide/home.html).\n\nApply all the overrides in the `override(...)` function. For example:\n\n```ts\n// This file is used to override the REST API resources configuration\nimport { AmplifyApiRestResourceStackTemplate } from '@aws-amplify/cli-extensibility-helper';\n\nexport function override(resources: AmplifyApiRestResourceStackTemplate) {\n  resources.restApi.description = \"Custom description\";\n  resources.restApi.minimumCompressionSize = 1024;\n}\n```\n\nTo change a field on a particular path, use `resources.restApi.body.paths[\\<route-path\\>]`:\n\n```ts\nexport function override(resources: AmplifyApiRestResourceStackTemplate) {\n  // Change the default CORS response header Access-Control-Allow-Origin from \"'*'\" to the API's domain\n  resources.restApi.body.paths['/items'].options['x-amazon-apigateway-integration'].responses.default.responseParameters['method.response.header.Access-Control-Allow-Origin'] = { 'Fn::Sub': \"'https://${ApiId}.execute-api.${AWS::Region}.amazonaws.com'\" };\n}\n```\n\nYou can override the following REST API resources that Amplify generates:\n\n<div class=\"table-wrapper\" markdown=\"block\">\n\n|Amplify-generated resource|Description|\n|-|-|\n|[restApi](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-apigateway-restapi.html)|The Amazon API Gateway REST API created by `amplify add api`|\n|[deploymentResource](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-apigateway-deployment.html)|The deployment resource that deploys the REST API above to a stage.|\n|[policies](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html)|User pool group-related IAM policy. Example: `resources.policies[\"/items\"].groups[\"Admin\"]`\n\n\n</div>\n\n## Add a Cognito User Pool authorizer to your REST API\n\nAmazon Cognito User Pools is a common service to use alongside API Gateway when\nadding user Sign-Up and Sign-In to your application. If your application needs to\ninteract with other AWS services, such as S3, on behalf of the user who invoked\nan endpoint, you will need to use IAM credentials with Cognito Identity Pools.\n\nAmplify CLI does not support Cognito User Pool authorizers out of the box. To\nimplement this functionality, you must override your REST API and add a Cognito \nUser Pool authorizer yourself by adding the following code into the\n`override(...)` function, in order.\n\nFirst, assuming the Cognito User Pool you would like to use as an authorizer is\nthe Auth resource configured with your Amplify Project, create a parameter that resolves\nto its User Pool ID:\n\n```ts\n// Add a parameter to your Cloud Formation Template for the User Pool's ID\nresources.addCfnParameter({\n    type: \"String\",\n    description: \"The id of an existing User Pool to connect. If this is changed, a user pool will not be created for you.\",\n    default: \"NONE\",\n  },\n  \"AuthCognitoUserPoolId\",\n  { \"Fn::GetAtt\": [\"auth<your auth name here>\", \"Outputs.UserPoolId\"], }\n);\n```\n\n<Callout warning>\n\nMake sure to replace `<your auth name here>` with the name of your auth resource.\nThis is the name of the folder in `amplify/backend/auth` that was created when\nyou added an Auth resource to your Amplify project.\n\n</Callout>\n\nNow, create a Cognito User Pool Authorizer corresponding to the User Pool\nby modifying the security definition of your REST API:\n\n```ts\n// Create the authorizer using the AuthCognitoUserPoolId parameter defined above\nresources.restApi.addPropertyOverride(\"Body.securityDefinitions\", {\n  Cognito: {\n    type: \"apiKey\",\n    name: \"Authorization\",\n    in: \"header\",\n    \"x-amazon-apigateway-authtype\": \"cognito_user_pools\",\n    \"x-amazon-apigateway-authorizer\": {\n      type: \"cognito_user_pools\",\n      providerARNs: [\n        { 'Fn::Sub': 'arn:aws:cognito-idp:${AWS::Region}:${AWS::AccountId}:userpool/${AuthCognitoUserPoolId}' },\n      ],\n    },\n  },\n});\n```\n\nFinally, update the security methods for all of the paths in your REST API to\nuse this new Cognito User Pool authorizer. We also add the `Authorization` header\nas a parameter on incoming requests for these paths as a place for users to provide\ntheir Cognito User ID Tokens. \n\n```ts\n// For every path in our REST API\nfor (const path in resources.restApi.body.paths) {\n  // Add the Authorization header as a parameter to requests\n  resources.restApi.addPropertyOverride(\n    `Body.paths.${path}.x-amazon-apigateway-any-method.parameters`,\n    [\n      ...resources.restApi.body.paths[path][\"x-amazon-apigateway-any-method\"]\n        .parameters,\n      {\n        name: \"Authorization\",\n        in: \"header\",\n        required: false,\n        type: \"string\",\n      },\n    ]\n  );\n  // Use our new Cognito User Pool authorizer for security\n  resources.restApi.addPropertyOverride(\n    `Body.paths.${path}.x-amazon-apigateway-any-method.security`,\n    [ { Cognito: [], }, ]\n  );\n}\n```\n\n<Callout>\n\nNote that you can add more advanced logic to only use the Cognito User Pool authorizer\nwith some paths or methods.\n\n</Callout>\n\nWhen performing requests to your REST API, make sure to add the `Authorization`\nheader with an ID Token provided by Cognito.\n\nRequests to endpoints are now populated with information from Cognito about the\nuser who is invoking the\nendpoint, and you can reuse the verified ID Token in your endpoint resolvers to assume\nthe identity of the user for accessing other services like AWS AppSync or S3.\n\n",
    "meta": {
      "title": "Override Amplify-generated API Gateway resources",
      "description": "The \"amplify override api\" command generates a developer-configurable \"overrides\" TypeScript file which provides Amplify-generated API Gateway resources as CDK constructs. For example, developers can configure a custom description or the minimum compression size of their REST API.",
      "subcategory": "API (REST)",
      "category": "Amplify CLI"
    },
    "filename": "/cli/restapi/override"
  },
  {
    "searchableText": [
      {
        "heading": "Test the API from the terminal",
        "depth": 2,
        "text": "If Guest users have access to your REST API you can test it from the terminal using Curl."
      },
      {
        "heading": "Test the API from the terminal",
        "depth": 2,
        "text": "Curl is a command-line tool that lets you transfer data to and from a server using various protocols."
      },
      {
        "heading": "Test the API from the terminal",
        "depth": 2,
        "text": "Curl is available in many distributions including Mac, Windows and Linux. Follow the install instructions in the docs."
      },
      {
        "heading": "POST method example",
        "depth": 3,
        "text": "Important! Testing methods using production endpoints may result in changes to resources that cannot be undone."
      },
      {
        "heading": "Test the API with Amplify Mock",
        "depth": 2,
        "text": "Amplify CLI allows you to quickly test your REST APIs by using the amplify mock function command."
      },
      {
        "heading": "Test the API with Amplify Mock",
        "depth": 2,
        "text": "Let's test your new REST API using the route below with HTTP Method GET and path /todos?limit=10 which includes a limit query string parameter."
      },
      {
        "heading": "Test the API with Amplify Mock",
        "depth": 2,
        "text": "Important! Testing methods using production endpoints may result in changes to resources that cannot be undone."
      },
      {
        "heading": "Test the API with Amplify Mock",
        "depth": 2,
        "text": "Before you continue, edit the file at {project}/amplify/backend/function/todosLambda/src/event.json and replace its content for the purpose of the test."
      },
      {
        "heading": "Test the API with Amplify Mock",
        "depth": 2,
        "text": "Make sure you have saved the changes and run"
      },
      {
        "heading": "Test the API with Amplify Mock",
        "depth": 2,
        "text": "Select the following options:"
      },
      {
        "heading": "Test the API with Amplify Mock",
        "depth": 2,
        "text": "Provide the path to the event JSON object relative to {project}/amplify/backend/function/todosLambda src/event.json"
      },
      {
        "heading": "Test the API with API Gateway console",
        "depth": 2,
        "text": "Let's test your new REST API using the route below with HTTP Method GET and path /todos?limit=10 which includes a limit query string parameter."
      },
      {
        "heading": "Test the API with API Gateway console",
        "depth": 2,
        "text": "Important! Testing methods with the API Gateway console may result in changes to resources that cannot be undone."
      },
      {
        "heading": "Test the API with API Gateway console",
        "depth": 2,
        "text": "Sign in to the API Gateway console at https://console.aws.amazon.com/apigateway."
      },
      {
        "heading": "Test the API with API Gateway console",
        "depth": 2,
        "text": "Choose the todosApi REST API."
      },
      {
        "heading": "Test the API with API Gateway console",
        "depth": 2,
        "text": "In the Resources pane, choose the method you want to test. Pick ANY right under /todos."
      },
      {
        "heading": "Test the API with API Gateway console",
        "depth": 2,
        "text": "In the Method Execution pane, in the Client box, choose TEST. Choose the GET method. Add limit=10 to the Query String {todos} field."
      },
      {
        "heading": "Test the API with API Gateway console",
        "depth": 2,
        "text": "Choose Test to run the test for GET /todos?limit=10. The following information will be displayed: request, status, latency, response body, response headers and logs."
      }
    ],
    "source": "export const meta = {\n  title: `Test`,\n  description: `Testing the REST API.`,\n};\n\n## Test the API from the terminal\n\nIf Guest users have access to your REST API you can test it from the terminal using Curl.\n\n[Curl](https://github.com/curl/curl) is a command-line tool that lets you transfer data to and from a server using various protocols.\n\n> Curl is available in many distributions including Mac, Windows and Linux. Follow the install instructions in the [docs](https://curl.haxx.se/docs/install.html).\n\n<BlockSwitcher>\n<Block name=\"Mac and Linux\">\n\n### GET method example\n\n```bash\ncurl https://a5b4c3d2e1.execute-api.eu-west-2.amazonaws.com/dev/todos\n```\n\n### POST method example\n\n```bash\ncurl -H \"Content-Type: application/json\" -d '{\"name\":\"todo-1\"}' https://a5b4c3d2e1.execute-api.eu-west-2.amazonaws.com/dev/todos\n```\n\n</Block>\n<Block name=\"Windows\">\n\n### GET method example\n\n```bash\ncurl https://a5b4c3d2e1.execute-api.eu-west-2.amazonaws.com/dev/todos\n```\n\n### POST method example\n\n```bash\ncurl -H \"Content-Type: application/json\" -d {\\\"name\\\":\\\"todo-1\\\"} https://a5b4c3d2e1.execute-api.eu-west-2.amazonaws.com/dev/todos\n```\n\n</Block>\n</BlockSwitcher>\n\n> Important! Testing methods using production endpoints may result in changes to resources that cannot be undone.\n\n## Test the API with Amplify Mock\n\nAmplify CLI allows you to quickly test your REST APIs by using the `amplify mock function` command.\n\nLet's test your new REST API using the route below with HTTP Method `GET` and path `/todos?limit=10` which includes a `limit` query string parameter.\n\n```console\nGET /todos?limit=10\n```\n\n> Important! Testing methods using production endpoints may result in changes to resources that cannot be undone.\n\nBefore you continue, edit the file at `{project}/amplify/backend/function/todosLambda/src/event.json` and replace its content for the purpose of the test.\n\n```json\n{\n  \"httpMethod\": \"GET\",\n  \"path\": \"/todos\",\n  \"queryStringParameters\": {\n    \"limit\": \"10\"\n  }\n}\n```\n\nMake sure you have saved the changes and run\n\n```bash\namplify mock function todosLambda\n```\n\nSelect the following options:\n\n- Provide the path to the event JSON object relative to `{project}/amplify/backend/function/todosLambda` __src/event.json__\n\n```console\nStarting execution...\nEVENT: {\"httpMethod\":\"GET\",\"path\":\"/todos\",\"queryStringParameters\":{\"limit\":\"10\"}}\nApp started\n\nResult:\n{\"statusCode\":200,\"body\":\"{\\\"success\\\":\\\"get call succeed!\\\",\\\"url\\\":\\\"/todos?limit=10\\\"}\",\"headers\":{\"x-powered-by\":\"Express\",\"access-control-allow-origin\":\"*\",\"access-control-allow-headers\":\"Origin, X-Requested-With, Content-Type, Accept\",\"content-type\":\"application/json; charset=utf-8\",\"content-length\":\"55\", \"date\":\"Tue, 18 Aug 2020 16:50:53 GMT\",\"connection\":\"close\"},\"isBase64Encoded\":false}\nFinished execution.\n```\n\n## Test the API with API Gateway console\n\nLet's test your new REST API using the route below with HTTP Method `GET` and path `/todos?limit=10` which includes a `limit` query string parameter.\n\n```console\nGET /todos?limit=10\n```\n\n> Important! Testing methods with the API Gateway console may result in changes to resources that cannot be undone.\n\n- Sign in to the API Gateway console at [https://console.aws.amazon.com/apigateway](https://console.aws.amazon.com/apigateway).\n- Choose the `todosApi` REST API.\n- In the Resources pane, choose the method you want to test. Pick `ANY` right under `/todos`.\n\n```console\n/                        \n |_ /todos               Main resource. Eg: /todos\n   ANY                   Includes methods: DELETE, GET, HEAD, OPTIONS, PATCH, POST, PUT\n   OPTIONS               Allow pre-flight requests in CORS by browser\n    |_ /{proxy+}         Proxy resource. Eg: /todos/, /todos/id, todos/object/{id}\n    ANY                  Includes methods: DELETE, GET, HEAD, OPTIONS, PATCH, POST, PUT\n    OPTIONS              Allow pre-flight requests in CORS by browser\n```\n\n- In the Method Execution pane, in the Client box, choose TEST. Choose the `GET` method. Add `limit=10` to the Query String `{todos}` field.\n\n- Choose Test to run the test for `GET /todos?limit=10`. The following information will be displayed: request, status, latency, response body, response headers and logs.\n\n```bash\nRequest: /todos?limit=10\nStatus: 200\nLatency: 139 ms\nResponse Body\n{\n  \"success\": \"get call succeed!\",\n  \"url\": \"/todos?limit=10\"\n}\nResponse Headers\n{\"access-control-allow-origin\":\"*\",\"date\":\"Tue, 18 Aug 2020 17:36:14 GMT\",\"content-length\":\"55\",\"access-control-allow-headers\":\"Origin, X-Requested-With, Content-Type, Accept\",\"x-powered-by\":\"Express\",\"content-type\":\"application/json; charset=utf-8\",\"connection\":\"close\"}\nLogs\nExecution log for request 4fc3c0c7-6f9f-4ac3-84d7-205500f39b5f\nTue Aug 18 17:36:14 UTC 2020 : Starting execution for request: 4fc3c0c7-6f9f-4ac3-84d7-205500f39b5f\nTue Aug 18 17:36:14 UTC 2020 : HTTP Method: GET, Resource Path: /todos\nTue Aug 18 17:36:14 UTC 2020 : Method request path: {}\nTue Aug 18 17:36:14 UTC 2020 : Method request query string: {limit=10}\nTue Aug 18 17:36:14 UTC 2020 : Method request headers: {}\nTue Aug 18 17:36:14 UTC 2020 : Method request body before transformations: \nTue Aug 18 17:36:14 UTC 2020 : Endpoint request URI: https://lambda.eu-west-2.amazonaws.com/2015-03-31/functions/arn:aws:lambda:eu-west-2:664371068953:function:expressLambda-dev/invocations\nTue Aug 18 17:36:14 UTC 2020 : Endpoint request headers: { X-Amz-Date=20200818T173614Z, X-Amz-Source-Arn=arn:aws:execute-api:eu-west-2:664371068953:s3zmw6fqy5/test-invoke-stage/GET/todos, Accept=application/json, User-Agent=AmazonAPIGateway_s3zmw6fqy5, X-Amz-Security-Token=IQoJb3JpZ2luX2VjEDEaCWV1LXdlc3QtMiJGMEQCIC3KIeR66WhaCBw+eJ+GPhF7y4hz9xC2nN+ARb7T3psyAiBdsoaD9yMfiw2dHWjQM5x7vM11XmToNSGu64mckUQdzSq0AwgaEAEaDDU0NDM4ODgxNjY2MyIMIzObNbCd6QtYwb0IKpEDpHXEzkM2OYq7JfL0U/WbF09KNamodfnifRYwZd/GNOwykykc/zHiU9X0XZPRd+QTnQe/9eoy8DaxBkDgRzQQjTThQWJWadtcfjryTLRKpVeo1UueL+f6DTUDf+URjb0P9CN1gPm+ntZD3LSyAXGwACKG7YMA5/HyeEk [TRUNCATED]\nTue Aug 18 17:36:14 UTC 2020 : Endpoint request body after transformations: {\"resource\":\"/todos\",\"path\":\"/todos\",\"httpMethod\":\"GET\",\"headers\":null,\"multiValueHeaders\":null,\"queryStringParameters\":{\"limit\":\"10\"},\"multiValueQueryStringParameters\":{\"limit\":[\"10\"]},\"pathParameters\":null,\"stageVariables\":null,\"requestContext\":{\"resourcePath\":\"/todos\",\"httpMethod\":\"GET\",\"requestTime\":\"18/Aug/2020:17:36:14 +0000\",\"path\":\"/todos\",\"accountId\":\"EXAMPLE_ID\",\"protocol\":\"HTTP/1.1\",\"stage\":\"test-invoke-stage\",\"domainPrefix\":\"testPrefix\",\"requestTimeEpoch\":1597772174890,\"requestId\":\"4fc3c0c7-6f9f-4ac3-84d7-205500f39b5f\",\"identity\":{\"cognitoIdentityPoolId\":null,\"cognitoIdentityId\":null,\"apiKey\":\"test-invoke-api-key\",\"principalOrgId\":null,\"cognitoAuthenticationType\":null,\"userArn\":\"arn:aws:iam::664371068953:root\",\"apiKeyId\":\"test-invoke-api-key-id\",\"userAgent\":\"aws-internal/3 aws-sdk-java/1.11.820 Linux/4.9.217-0.1.ac.205.84.332.metal1.x86_64 OpenJDK_64-Bit_Server_VM/25.252-b09 java/1.8.0_252 v [TRUNCATED]\nTue Aug 18 17:36:14 UTC 2020 : Sending request to https://lambda.eu-west-2.amazonaws.com/2015-03-31/functions/arn:aws:lambda:eu-west-2:664371068953:function:expressLambda-dev/invocations\nTue Aug 18 17:36:15 UTC 2020 : Received response. Status: 200, Integration latency: 137 ms\nTue Aug 18 17:36:15 UTC 2020 : Endpoint response headers: {Date=Tue, 18 Aug 2020 17:36:15 GMT, Content-Type=application/json, Content-Length=443, Connection=keep-alive, sampled=0}\nTue Aug 18 17:36:15 UTC 2020 : Endpoint response body before transformations: {\"statusCode\":200,\"body\":\"{\\\"success\\\":\\\"get call succeed!\\\",\\\"url\\\":\\\"/todos?limit=10\\\"}\",\"headers\":{\"x-powered-by\":\"Express\",\"access-control-allow-origin\":\"*\",\"access-control-allow-headers\":\"Origin, X-Requested-With, Content-Type, Accept\",\"content-type\":\"application/json; charset=utf-8\",\"content-length\":\"55\",\"date\":\"Tue, 18 Aug 2020 17:36:14 GMT\",\"connection\":\"close\"},\"isBase64Encoded\":false}\nTue Aug 18 17:36:15 UTC 2020 : Method response body after transformations: {\"success\":\"get call succeed!\",\"url\":\"/todos?limit=10\"}\nTue Aug 18 17:36:15 UTC 2020 : Method response headers: {x-powered-by=Express, access-control-allow-origin=*, access-control-allow-headers=Origin, X-Requested-With, Content-Type, Accept, content-type=application/json; charset=utf-8, content-length=55, date=Tue, 18 Aug 2020 17:36:14 GMT, connection=close, Sampled=0}\nTue Aug 18 17:36:15 UTC 2020 : Successfully completed execution\nTue Aug 18 17:36:15 UTC 2020 : Method completed with status: 200\n```\n",
    "meta": {
      "title": "Test",
      "description": "Testing the REST API.",
      "subcategory": "API (REST)",
      "category": "Amplify CLI"
    },
    "filename": "/cli/restapi/testing"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "The Amplify CLI provides a guided workflow to easily add, develop, test and manage REST APIs to access your AWS resources from your web and mobile applications."
      },
      {
        "heading": null,
        "depth": null,
        "text": "A REST API or HTTP endpoint will be composed by one or more paths. Eg: /items. Each path will use a Lambda function to handle HTTP requests and responses. Amplify CLI creates a single resource in Amazon API Gateway so you can handle all routes, HTTP Methods and paths, with a single Lambda function via a Lambda Proxy integration. HTTP proxy integrations forward all requests and responses directly through to your HTTP endpoint."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify CLI let's you choose either an existing Lambda function or create a new one. To kickstart your implementation, you can choose between the following templates:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Serverless ExpressJS function"
      },
      {
        "heading": null,
        "depth": null,
        "text": "CRUD function for DynamoDB"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Lambda templates use serverless-express and provide the building blocks to start your REST API development."
      },
      {
        "heading": null,
        "depth": null,
        "text": "See the list of all supported Lambda runtimes."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify CLI allows you to restrict REST API access to"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Only authenticated users; or"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Authenticated and Guest users"
      },
      {
        "heading": null,
        "depth": null,
        "text": "User Pool Groups"
      },
      {
        "heading": null,
        "depth": null,
        "text": "See a description of these user types below"
      },
      {
        "heading": null,
        "depth": null,
        "text": "| User type | Description |\n|---|---|\n| Authenticated user | User needs to sign in to use the REST API |\n| Guest user | User doesn't need to sign in to use the REST API |\n| User Pool Group | User needs to sign in and belong to the User Pool Group to use the REST API|"
      },
      {
        "heading": null,
        "depth": null,
        "text": "For each user type you can further specify what actions it has access to."
      },
      {
        "heading": null,
        "depth": null,
        "text": "| User type  | Actions | Http Method | Authentication Provider  |\n|---|---|---|---|\n| Authenticated user | create, read, update, delete | POST, GET, PUT, PATCH, DELETE | Amazon Cognito |\n| Guest user | create, read, update, delete | POST, GET, PUT, PATCH, DELETE | Amazon Cognito |\n| User Pool Group | create, read, update, delete | POST, GET, PUT, PATCH, DELETE | Amazon Cognito |"
      },
      {
        "heading": null,
        "depth": null,
        "text": "REST APIs have support for multiple environments (e.g. dev, qa, and prod). This means that you can easily isolate different versions of your REST API by using different Amplify environments."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Because Amplify environments could be in separate AWS accounts, we cannot use the environment feature of API Gateway. Each Amplify environment will have a separate API Gateway resource associated with it. For example:"
      },
      {
        "heading": "Create a REST API",
        "depth": 2,
        "text": "Navigate into the root of a JavaScript, iOS, or Android project and run:"
      },
      {
        "heading": "Create a REST API",
        "depth": 2,
        "text": "Follow the wizard to create a new app. After finishing the wizard run:"
      },
      {
        "heading": "Create a REST API",
        "depth": 2,
        "text": "Select the following options:"
      },
      {
        "heading": "Create a REST API",
        "depth": 2,
        "text": "Please select from one of the below mentioned services: REST"
      },
      {
        "heading": "Create a REST API",
        "depth": 2,
        "text": "Provide a friendly name for your resource to be used as a label for this category in the project: itemsApi"
      },
      {
        "heading": "Create a REST API",
        "depth": 2,
        "text": "Provide a path (e.g., /book/): /items"
      },
      {
        "heading": "Create a REST API",
        "depth": 2,
        "text": "This will be the configuration for /items path in API Gateway:"
      },
      {
        "heading": "Create a REST API",
        "depth": 2,
        "text": "By default Amplify CLI creates a greedy path variable /items/{proxy+} that catches all child resources for a path and forwards them to your Lambda. This will match all child routes including /items/id and /items/object/id."
      },
      {
        "heading": "Create a REST API",
        "depth": 2,
        "text": "Choose a Lambda source Create a new Lambda function"
      },
      {
        "heading": "Create a REST API",
        "depth": 2,
        "text": "Provide a friendly name for your resource to be used as a label for this category in the project: itemsLambda"
      },
      {
        "heading": "Create a REST API",
        "depth": 2,
        "text": "Provide the AWS Lambda function name: itemsLambda"
      },
      {
        "heading": "Create a REST API",
        "depth": 2,
        "text": "Choose the runtime that you want to use: NodeJS"
      },
      {
        "heading": "Create a REST API",
        "depth": 2,
        "text": "Choose the function template that you want to use: Serverless ExpressJS function"
      },
      {
        "heading": "Create a REST API",
        "depth": 2,
        "text": "The Lambda function template Serverless ExpressJS function implements route handlers for GET, POST, PUT and DELETE Http Methods and paths for /items and /items/*. Some possible routes examples include:"
      },
      {
        "heading": "Create a REST API",
        "depth": 2,
        "text": "Do you want to access other resources in this project from your Lambda function? No"
      },
      {
        "heading": "Create a REST API",
        "depth": 2,
        "text": "Do you want to invoke this function on a recurring schedule? No"
      },
      {
        "heading": "Create a REST API",
        "depth": 2,
        "text": "Do you want to configure Lambda layers for this function? No"
      },
      {
        "heading": "Create a REST API",
        "depth": 2,
        "text": "Do you want to edit the local lambda function now? Yes"
      },
      {
        "heading": "Create a REST API",
        "depth": 2,
        "text": "We are not going to change this template but it's good that you have it open as you follow the next steps."
      },
      {
        "heading": "Create a REST API",
        "depth": 2,
        "text": "Press enter to continue"
      },
      {
        "heading": "Create a REST API",
        "depth": 2,
        "text": "Restrict API access Yes"
      },
      {
        "heading": "Create a REST API",
        "depth": 2,
        "text": "Who should have access? Authenticated and Guest users"
      },
      {
        "heading": "Create a REST API",
        "depth": 2,
        "text": "What kind of access do you want for Authenticated users? create, read, update, delete"
      },
      {
        "heading": "Create a REST API",
        "depth": 2,
        "text": "What kind of access do you want for Guest users? read"
      },
      {
        "heading": "Create a REST API",
        "depth": 2,
        "text": "When configuration of your API is complete, the CLI displays a message confirming that you have configured local CLI metadata for this category. You can confirm this by running amplify status. Finally deploy your changes to the cloud:"
      },
      {
        "heading": "Create a REST API",
        "depth": 2,
        "text": "Amplify CLI restricts API access combining Amazon Cognito for authentication and AWS IAM (Identity and Access Management) for granting execution permissions on routes."
      },
      {
        "heading": "Create a REST API",
        "depth": 2,
        "text": "Do you want to add another path? No"
      },
      {
        "heading": "Create a REST API",
        "depth": 2,
        "text": "Deploy your new API."
      },
      {
        "heading": "Create a REST API",
        "depth": 2,
        "text": "At the end of this command you can take note of your new REST API url."
      },
      {
        "heading": "Create a REST API",
        "depth": 2,
        "text": "REST APIs follow this pattern https://{restapi-id}.execute-api.{region}.amazonaws.com/{environment}/{path}."
      },
      {
        "heading": "Create a REST API",
        "depth": 2,
        "text": "Let's see an overview of all the resources created by Amplify CLI."
      },
      {
        "heading": "Create REST API and restrict specific routes to specific User Pool Groups",
        "depth": 2,
        "text": "If your app uses User Pool Groups to manage different user types and would like to restrict access of specific routes to specific User Pool Groups. We can accomplish this by the following flow:"
      },
      {
        "heading": "Create REST API and restrict specific routes to specific User Pool Groups",
        "depth": 2,
        "text": "Create API route."
      },
      {
        "heading": "Create REST API and restrict specific routes to specific User Pool Groups",
        "depth": 2,
        "text": "Add API route handler function."
      },
      {
        "heading": "Create REST API and restrict specific routes to specific User Pool Groups",
        "depth": 2,
        "text": "Restrict-access to the API route to the User Pool Group."
      },
      {
        "heading": "Create REST API and restrict specific routes to specific User Pool Groups",
        "depth": 2,
        "text": "The following example flow assumes the existence of two User Pool Groups : AdminUsers and GuestUsers for a Book store.\nThe app would like to limit admin functionality like updating book records to the AdminUsers User Pool Group,\nwhile borrowing and returning books would be limited to the GuestUsers User Pool Group."
      },
      {
        "heading": "Create REST API and restrict specific routes to specific User Pool Groups",
        "depth": 2,
        "text": "Path : /book/admin is restricted to AdminUsers and commands are handled by the bookAdminHandler lambda function"
      },
      {
        "heading": "Create REST API and restrict specific routes to specific User Pool Groups",
        "depth": 2,
        "text": "Path : /book/guest is restricted to GuestUsers and commands are handled by the bookGuestHandler lambda function"
      },
      {
        "heading": "Create REST API and restrict specific routes to specific User Pool Groups",
        "depth": 2,
        "text": "At the end of this command you can verify the routes and their respective User Pool Group restrictions in the cli-inputs.json file at the following path."
      },
      {
        "heading": "REST endpoint that triggers new Lambda functions",
        "depth": 2,
        "text": "During the CLI setup, you'll be guided through to create a new Lambda function with a predefined serverless-express template with routing enabled for your REST API paths."
      },
      {
        "heading": "REST endpoint that triggers existing Lambda functions",
        "depth": 2,
        "text": "During the CLI setup, you'll be guided through to use your own Lambda functions which you've initialized as a part of your CLI project using the amplify add function command. This would allow you to have custom logic in your Lambda function and not use the predefined serverless-express templates generated by the CLI as in the examples above."
      },
      {
        "heading": "Set up a REST API with Amazon DynamoDB",
        "depth": 2,
        "text": "During the CLI setup, you'll be guided through to create a new Lambda function with a predefined serverless-express template with routing enabled for your REST API paths with support for CRUD operations to DynamoDB tables (which you can create by following the CLI prompts or use the tables which you've already configured using the amplify add storage command)."
      },
      {
        "heading": "Set up a REST API with Amazon DynamoDB",
        "depth": 2,
        "text": "In the example above with /items path, the following API will be created for you:"
      },
      {
        "heading": "Set up a REST API with Amazon DynamoDB",
        "depth": 2,
        "text": "GET /items/[ID] will return a list containing the item at the [ID]. If the item does not exist then an empty array is returned."
      },
      {
        "heading": "Set up a REST API with Amazon DynamoDB",
        "depth": 2,
        "text": "GET /items/object/[ID] will return a single item at [ID]. If the item does not exist then an empty object is returned."
      },
      {
        "heading": "Set up a REST API with Amazon DynamoDB",
        "depth": 2,
        "text": "PUT /items with your item in the request body will create or update the item."
      },
      {
        "heading": "Set up a REST API with Amazon DynamoDB",
        "depth": 2,
        "text": "POST /items with your item in the request body will create or update the item."
      },
      {
        "heading": "Set up a REST API with Amazon DynamoDB",
        "depth": 2,
        "text": "DELETE /items/object/[ID] will delete the item."
      },
      {
        "heading": "Set up a REST API with Amazon DynamoDB",
        "depth": 2,
        "text": "When you have a sort key, you can append it to the end of the path, for example: GET /items/object/[ID]/[SORT_KEY_ID]"
      }
    ],
    "source": "export const meta = {\n  title: `Overview`,\n  description: `Use Amplify CLI's simple guided workflow to add REST APIs to cloud-based web and mobile apps.`,\n};\n\nThe Amplify CLI provides a guided workflow to easily add, develop, test and manage REST APIs to access your AWS resources from your web and mobile applications.\n\nA REST API or HTTP endpoint will be composed by one or more paths. Eg: `/items`. Each path will use a Lambda function to handle HTTP requests and responses. Amplify CLI creates a single resource in Amazon API Gateway so you can handle all routes, HTTP Methods and paths, with a single Lambda function via a Lambda Proxy integration. HTTP proxy integrations forward all requests and responses directly through to your HTTP endpoint.\n\nAmplify CLI let's you choose either an existing Lambda function or create a new one. To kickstart your implementation, you can choose between the following templates:\n\n- Serverless ExpressJS function\n- CRUD function for DynamoDB\n\n> Lambda templates use [serverless-express](https://github.com/awslabs/aws-serverless-express) and provide the building blocks to start your REST API development.\n\n> See the list of all [supported Lambda runtimes](/cli/function/function).\n\nAmplify CLI allows you to restrict REST API access to\n\n- Only authenticated users; or\n- Authenticated and Guest users\n- User Pool Groups \n\nSee a description of these user types below\n\n| User type | Description |\n|---|---|\n| Authenticated user | User needs to sign in to use the REST API |\n| Guest user | User doesn't need to sign in to use the REST API |\n| User Pool Group | User needs to sign in and belong to the User Pool Group to use the REST API|\n\n\nFor each user type you can further specify what actions it has access to.\n\n| User type  | Actions | Http Method | Authentication Provider  |\n|---|---|---|---|\n| Authenticated user | create, read, update, delete | POST, GET, PUT, PATCH, DELETE | Amazon Cognito |\n| Guest user | create, read, update, delete | POST, GET, PUT, PATCH, DELETE | Amazon Cognito |\n| User Pool Group | create, read, update, delete | POST, GET, PUT, PATCH, DELETE | Amazon Cognito |\n\nREST APIs have support for [multiple environments](/cli/teams/overview) (e.g. dev, qa, and prod). This means that you can easily isolate different versions of your REST API by using different Amplify environments.\n\nBecause Amplify environments could be in separate AWS accounts, we cannot use the environment feature of API Gateway. Each Amplify environment will have a separate API Gateway resource associated with it. For example:\n\n```console\nhttps://<API ID 1>.execute-api.eu-west-2.amazonaws.com/dev/items\nhttps://<API ID 2>.execute-api.eu-west-2.amazonaws.com/prod/items\n```\n\n## Create a REST API\n\nNavigate into the root of a JavaScript, iOS, or Android project and run:\n\n```bash\namplify init\n```\n\nFollow the wizard to create a new app. After finishing the wizard run:\n\n```bash\namplify add api\n```\n\nSelect the following options:\n\n- Please select from one of the below mentioned services: __REST__\n- Provide a friendly name for your resource to be used as a label for this category in the project: __itemsApi__\n- Provide a path (e.g., /book/{isbn}): __/items__\n\nThis will be the configuration for `/items` path in API Gateway:\n\n```console\n/                        \n |_ /items               Main resource. Eg: /items\n    ANY                    Includes methods: DELETE, GET, HEAD, OPTIONS, PATCH, POST, PUT\n    OPTIONS                Allow pre-flight requests in CORS by browser\n    |_ /{proxy+}         Proxy resource. Eg: /items/, /items/id, items/object/{id}\n       ANY                  Includes methods: DELETE, GET, HEAD, OPTIONS, PATCH, POST, PUT\n       OPTIONS              Allow pre-flight requests in CORS by browser\n```\n\nBy default Amplify CLI creates a greedy path variable `/items/{proxy+}` that catches all child resources for a path and forwards them to your Lambda. This will match all child routes including `/items/id` and `/items/object/id`.\n\n- Choose a Lambda source __Create a new Lambda function__\n- Provide a friendly name for your resource to be used as a label for this category in the project: __itemsLambda__\n- Provide the AWS Lambda function name: __itemsLambda__\n- Choose the runtime that you want to use: __NodeJS__\n- Choose the function template that you want to use: __Serverless ExpressJS function__\n\nThe Lambda function template __Serverless ExpressJS function__ implements route handlers for `GET`, `POST`, `PUT` and `DELETE` Http Methods and paths for `/items` and `/items/*`. Some possible routes examples include:\n\n```console\nGET /items         List all items\nGET /items/1       Load an item by id\nPOST /items        Create an item\nPUT /items         Update an item\nDELETE /items/1    Delete an item by id\n```\n\n- Do you want to access other resources in this project from your Lambda function? __No__\n- Do you want to invoke this function on a recurring schedule? __No__\n- Do you want to configure Lambda layers for this function? __No__\n- Do you want to edit the local lambda function now? __Yes__\n\n> We are not going to change this template but it's good that you have it open as you follow the next steps.\n\n- Press enter to continue\n- Restrict API access __Yes__\n- Who should have access? __Authenticated and Guest users__\n- What kind of access do you want for Authenticated users? __create, read, update, delete__\n- What kind of access do you want for Guest users? __read__\n\nWhen configuration of your API is complete, the CLI displays a message confirming that you have configured local CLI metadata for this category. You can confirm this by running `amplify status`. Finally deploy your changes to the cloud:\n\nAmplify CLI restricts API access combining Amazon Cognito for authentication and AWS IAM (Identity and Access Management) for granting execution permissions on routes.\n\n- Do you want to add another path? __No__\n\nDeploy your new API.\n\n```bash\namplify push\n```\n\nAt the end of this command you can take note of your new REST API url.\n\n```console\nREST API endpoint: https://a5b4c3d2e1.execute-api.eu-west-2.amazonaws.com/dev\n```\n\n> REST APIs follow this pattern `https://{restapi-id}.execute-api.{region}.amazonaws.com/{environment}/{path}`.\n\nLet's see an overview of all the resources created by Amplify CLI.\n\n```console\nREST\n |_ /items (path)\n    |_ itemsApi (Amazon API Gateway) \n       |_ itemsLambda (AWS Lambda)\n          |_ Logs (Amazon CloudWatch)\n```\n\n## Create REST API and restrict specific routes to specific User Pool Groups\nIf your app uses User Pool Groups to manage different user types and would like to restrict access of specific routes to specific User Pool Groups. We can accomplish this by the following flow: \n- Create API route. \n- Add API route handler function.\n- Restrict-access to the API route to the User Pool Group.\n\n>\n> The following example flow assumes the existence of two User Pool Groups : AdminUsers and GuestUsers for a Book store.\n> The app would like to limit admin functionality like updating book records to the AdminUsers User Pool Group, \n> while borrowing and returning books would be limited to the GuestUsers User Pool Group. \n> - Path : /book/admin is restricted to AdminUsers and commands are handled by the bookAdminHandler lambda function\n> - Path : /book/guest is restricted to GuestUsers and commands are handled by the bookGuestHandler lambda function\n\n```bash\namplify add api\n$> ? Select from one of the below mentioned services: REST\n$> ✔ Provide a friendly name for your resource to be used as a label for this category in the project: · mybookapi\n$> ✔ Provide a path (e.g., /book/{isbn}): · /book/admin\n$> ✔ Choose a Lambda source · Create a new Lambda function\n$> ? Provide an AWS Lambda function name: bookAdminHandler\n$> ? Choose the runtime that you want to use: NodeJS\n$> ? Choose the function template that you want to use: Hello World\n$> ? Do you want to configure advanced settings? No\n$> ? Do you want to edit the local lambda function now? No\nSuccessfully added resource bookAdminHandler locally.\n$> ✔ Restrict API access? (Y/n) · yes\n$> ✔ Restrict access by: · Individual Groups\n$> ✔ Select groups: AdminUsers\n$> ✔ What permissions do you want to grant to AdminUsers users? · create, read, update, delete\n$> ✔ Do you want to add another path? (y/N) · yes\n$> ✔ Provide a path (e.g., /book/{isbn}): · /book/guest\n$> ✔ Choose a Lambda source · Create a new Lambda function\n$> ? Provide an AWS Lambda function name: bookGuestHandler\n$> ? Choose the runtime that you want to use: NodeJS\n$> ? Choose the function template that you want to use: Hello World\n$> ? Do you want to configure advanced settings? No\n$> ? Do you want to edit the local lambda function now? No\nSuccessfully added resource bookGuestHandler locally.\n$> ✔ Restrict API access? (Y/n) · yes\n$> ✔ Restrict access by: Individual Groups\n$> ✔ Select groups: GuestUsers\n$> ✔ What permissions do you want to grant to GuestUsers users?  create, read, update\n$> ✔ Do you want to add another path? (y/N) No\n✅ Successfully added resource mybookapi locally\n```\nAt the end of this command you can verify the routes and their respective User Pool Group restrictions in the `cli-inputs.json` file at the following path.\n```bash\n <project-root>/amplify/backend/api/<api-resource-name>/cli-inputs.json\n```\n\n## REST endpoint that triggers new Lambda functions\n\nDuring the CLI setup, you'll be guided through to create a new Lambda function with a predefined [serverless-express](https://github.com/awslabs/aws-serverless-express) template with routing enabled for your REST API paths.\n\n```bash\namplify add api\n```\n\n```console\n? Please select from one of the below mentioned services REST\n? Provide a friendly name for your resource to be used as a label for this category in the project: itemsApi\n? Provide a path (e.g., /book/{isbn}) /items\n? Choose a Lambda source Create a new Lambda function\n? Provide a friendly name for your resource to be used as a label for this category in the project: itemsLambda\n? Provide the AWS Lambda function name: itemsLambda\n? Choose the function template that you want to use:\n  CRUD function for Amazon DynamoDB\n❯ Serverless ExpressJS function\n```\n\n## REST endpoint that triggers existing Lambda functions\n\nDuring the CLI setup, you'll be guided through to use your own Lambda functions which you've initialized as a part of your CLI project using the `amplify add function` command. This would allow you to have custom logic in your Lambda function and not use the predefined [serverless-express](https://github.com/awslabs/aws-serverless-express) templates generated by the CLI as in the examples above.\n\n```bash\namplify add api\n```\n\n```console\n? Please select from one of the below mentioned services REST\n? Provide a friendly name for your resource to be used as a label for this category in the project: itemsApi\n? Provide a path (e.g., /book/{isbn}) /items\n? Choose a Lambda source\n  Create a new Lambda function\n❯ Use a Lambda function already added in the current Amplify project\n```\n\n## Set up a REST API with Amazon DynamoDB\n\nDuring the CLI setup, you'll be guided through to create a new Lambda function with a predefined [serverless-express](https://github.com/awslabs/aws-serverless-express) template with routing enabled for your REST API paths with support for CRUD operations to DynamoDB tables (which you can create by following the CLI prompts or use the tables which you've already configured using the `amplify add storage` command).\n\n```bash\namplify add api\n```\n\n```console\n? Please select from one of the below mentioned services REST\n? Provide a friendly name for your resource to be used as a label for this category in the project: itemsApi\n? Provide a path (e.g., /book/{isbn}) /items\n? Choose a Lambda source Create a new Lambda function\n? Provide a friendly name for your resource to be used as a label for this category in the project: itemsLambda\n? Provide the AWS Lambda function name: itemsLambda\n? Choose the function template that you want to use:\n❯ CRUD function for Amazon DynamoDB\n  Serverless ExpressJS function\n```\n\nIn the example above with `/items` path, the following API will be created for you:\n\n1. GET /items/[ID] will return a list containing the item at the [ID]. If the item does not exist then an empty array is returned.\n2. GET /items/object/[ID] will return a single item at [ID]. If the item does not exist then an empty object is returned.\n3. PUT /items with your item in the request body will create or update the item.\n4. POST /items with your item in the request body will create or update the item.\n5. DELETE /items/object/[ID] will delete the item.\n\nWhen you have a sort key, you can append it to the end of the path, for example: `GET /items/object/[ID]/[SORT_KEY_ID]`\n",
    "meta": {
      "title": "Overview",
      "description": "Use Amplify CLI's simple guided workflow to add REST APIs to cloud-based web and mobile apps.",
      "subcategory": "API (REST)",
      "category": "Amplify CLI"
    },
    "filename": "/cli/restapi/restapi"
  },
  {
    "searchableText": [
      {
        "heading": "Warehouse Management System",
        "depth": 2,
        "text": "In this \"Warehouse management system\" example, you will learn how to configure common access patterns for your app. This example has the following types:"
      },
      {
        "heading": "Warehouse Management System",
        "depth": 2,
        "text": "Warehouse"
      },
      {
        "heading": "Warehouse Management System",
        "depth": 2,
        "text": "Product"
      },
      {
        "heading": "Warehouse Management System",
        "depth": 2,
        "text": "Inventory"
      },
      {
        "heading": "Warehouse Management System",
        "depth": 2,
        "text": "Employee"
      },
      {
        "heading": "Warehouse Management System",
        "depth": 2,
        "text": "AccountRepresentative"
      },
      {
        "heading": "Warehouse Management System",
        "depth": 2,
        "text": "Customer"
      },
      {
        "heading": "Warehouse Management System",
        "depth": 2,
        "text": "These types have the following common access patterns:"
      },
      {
        "heading": "Warehouse Management System",
        "depth": 2,
        "text": "Look up employee details by employee ID"
      },
      {
        "heading": "Warehouse Management System",
        "depth": 2,
        "text": "Query employee details by employee name"
      },
      {
        "heading": "Warehouse Management System",
        "depth": 2,
        "text": "Find an employee's phone number(s)"
      },
      {
        "heading": "Warehouse Management System",
        "depth": 2,
        "text": "Find a customer's phone number(s)"
      },
      {
        "heading": "Warehouse Management System",
        "depth": 2,
        "text": "Get orders for a given customer within a given date range"
      },
      {
        "heading": "Warehouse Management System",
        "depth": 2,
        "text": "Show all open orders within a given date range across all customers"
      },
      {
        "heading": "Warehouse Management System",
        "depth": 2,
        "text": "See all employees recently hired"
      },
      {
        "heading": "Warehouse Management System",
        "depth": 2,
        "text": "Find all employees working in a given warehouse"
      },
      {
        "heading": "Warehouse Management System",
        "depth": 2,
        "text": "Get all items on order for a given product"
      },
      {
        "heading": "Warehouse Management System",
        "depth": 2,
        "text": "Get current inventories for a given product at all warehouses"
      },
      {
        "heading": "Warehouse Management System",
        "depth": 2,
        "text": "Get customers by account representative"
      },
      {
        "heading": "Warehouse Management System",
        "depth": 2,
        "text": "Get orders by account representative and date"
      },
      {
        "heading": "Warehouse Management System",
        "depth": 2,
        "text": "Get all items on order for a given product"
      },
      {
        "heading": "Warehouse Management System",
        "depth": 2,
        "text": "Get all employees with a given job title"
      },
      {
        "heading": "Warehouse Management System",
        "depth": 2,
        "text": "Get inventory by product and warehouse"
      },
      {
        "heading": "Warehouse Management System",
        "depth": 2,
        "text": "Get total product inventory"
      },
      {
        "heading": "Warehouse Management System",
        "depth": 2,
        "text": "Get account representatives ranked by order total and sales period"
      },
      {
        "heading": "Warehouse Management System",
        "depth": 2,
        "text": "The following schema introduces the required indexes and relationships so that we can support these access patterns:"
      },
      {
        "heading": "Warehouse Management System",
        "depth": 2,
        "text": "Now that we have the schema created, let's create the items in the database that we will be operating against:"
      },
      {
        "heading": "1. Look up employee details by employee ID",
        "depth": 3,
        "text": "This can simply be done by querying the employee model with an employee ID, no @primaryKey or @index need to be explicitly specified to make this work."
      },
      {
        "heading": "2. Query employee details by employee name",
        "depth": 3,
        "text": "The @index byName on the Employee type makes this access-pattern feasible because under the hood an index is created and a query is used to match against the name field. We can use this query:"
      },
      {
        "heading": "3. Find an Employee’s phone number",
        "depth": 3,
        "text": "Either one of the previous queries would work to find an employee’s phone number as long as one has their ID or name."
      },
      {
        "heading": "4. Find a customer’s phone number",
        "depth": 3,
        "text": "A similar query to those given above but on the Customer model would give you a customer’s phone number."
      },
      {
        "heading": "5. Get orders for a given customer within a given date range",
        "depth": 3,
        "text": "There is a one-to-many relation that lets all the orders of a customer be queried."
      },
      {
        "heading": "5. Get orders for a given customer within a given date range",
        "depth": 3,
        "text": "This relationship is created by having the @index name byCustomerByDate on the Order model that is queried by the @hasMany relationship on the orders field of the Customer model."
      },
      {
        "heading": "5. Get orders for a given customer within a given date range",
        "depth": 3,
        "text": "A sort key with the date is used. What this means is that the GraphQL resolver can use predicates like Between to efficiently search the date range rather than scanning all records in the database and then filtering them out."
      },
      {
        "heading": "5. Get orders for a given customer within a given date range",
        "depth": 3,
        "text": "The query one would need to get the orders to a customer within a date range would be:"
      },
      {
        "heading": "6. Show all open orders within a given date range across all customers",
        "depth": 3,
        "text": "The @index byCustomerByStatusByDate enables you to run a query that would work for this access pattern."
      },
      {
        "heading": "6. Show all open orders within a given date range across all customers",
        "depth": 3,
        "text": "In this example, a composite sort key (combination of two or more keys) with the status and date is used. What this means is that the unique identifier of a record in the database is created by concatenating these two fields (status and date) together, and then the GraphQL resolver can use predicates like Between or Contains to efficiently search the unique identifier for matches rather than scanning all records in the database and then filtering them out."
      },
      {
        "heading": "7. See all employees hired recently",
        "depth": 3,
        "text": "Having @index(name: \"newHire\", fields: [\"newHire\", \"id\"]) on the Employee model allows one to query by whether an employee has been hired recently."
      },
      {
        "heading": "7. See all employees hired recently",
        "depth": 3,
        "text": "We can also query and have the results returned by start date by using the employeesNewHireByStartDate query:"
      },
      {
        "heading": "8. Find all employees working in a given warehouse",
        "depth": 3,
        "text": "This needs a one to many relationship from warehouses to employees. As can be seen from the @hasMany relationship in the Warehouse model, this relationship uses the byWarehouse index on the Employee model. The relevant query would look like this:"
      },
      {
        "heading": "9. Get all items on order for a given product",
        "depth": 3,
        "text": "This access-pattern would use a one-to-many relation from products to orders. With this query we can get all orders of a given product:"
      },
      {
        "heading": "10. Get current inventories for a product at all warehouses",
        "depth": 3,
        "text": "The query needed to get the inventories of a product in all warehouses would be:"
      },
      {
        "heading": "11. Get customers by account representative",
        "depth": 3,
        "text": "This uses a has-many relationship between account representatives and customers:"
      },
      {
        "heading": "11. Get customers by account representative",
        "depth": 3,
        "text": "The query needed would look like this:"
      },
      {
        "heading": "12. Get orders by account representative and date",
        "depth": 3,
        "text": "As can be seen in the AccountRepresentative model this relationship uses the byRepresentativebyDate field on the Order model to create the connection needed. The query needed would look like this:"
      },
      {
        "heading": "13. Get all items on order for a given product",
        "depth": 3,
        "text": "This is the same as number 9."
      },
      {
        "heading": "14. Get all employees with a given job title",
        "depth": 3,
        "text": "Using the byTitle @index makes this access pattern quite easy."
      },
      {
        "heading": "15. Get inventory by product by warehouse",
        "depth": 3,
        "text": "Here having the inventories be held in a separate model is particularly useful since this model can have its own partition key and sort key such that the inventories themselves can be queried as is needed for this access-pattern."
      },
      {
        "heading": "15. Get inventory by product by warehouse",
        "depth": 3,
        "text": "A query on this model would look like this:"
      },
      {
        "heading": "15. Get inventory by product by warehouse",
        "depth": 3,
        "text": "We can also get all inventory from an individual warehouse by using the itemsByWarehouseID query created by the byWarehouseID key:"
      },
      {
        "heading": "16. Get total product inventory",
        "depth": 3,
        "text": "How this would be done depends on the use case. If one just wants a list of all inventories in all warehouses, one could just run a list inventories on the Inventory model:"
      },
      {
        "heading": "17. Get sales representatives ranked by order total and sales period",
        "depth": 3,
        "text": "The sales period is either a date range or maybe even a month or week. Therefore we can set the sales period as a string and query using the combination of salesPeriod and orderTotal. We can also set the sortDirection in order to get the return values from largest to smallest:"
      },
      {
        "heading": "Batch Put Custom Resolver",
        "depth": 3,
        "text": "Sometimes you need to create objects in bulk, rather than creating individual objects sequentially and waiting for all the requests to complete."
      },
      {
        "heading": "Batch Put Custom Resolver",
        "depth": 3,
        "text": "Define your schema with a custom mutation. The custom mutation should not be deployed to AppSync beforehand if following these steps, the CLI will attach its own resolver preventing you from attaching a custom resource this way."
      },
      {
        "heading": "Batch Put Custom Resolver",
        "depth": 3,
        "text": "Create a custom resource for your resolver and use the following code snippets as a guide to get started"
      },
      {
        "heading": "Batch Put Custom Resolver",
        "depth": 3,
        "text": "Follow the steps for creating a custom resolver:"
      },
      {
        "heading": "Batch Put Custom Resolver",
        "depth": 3,
        "text": "Next, install the AppSync dependencies for your custom resource:"
      },
      {
        "heading": "Batch Put Custom Resolver",
        "depth": 3,
        "text": "Use the following template as a starting point for your custom CDK stack, the resolvers must be templated with environment references"
      },
      {
        "heading": "Batch Put Custom Resolver",
        "depth": 3,
        "text": "By using CloudFormation parameters, you contextualize your custom resolvers to the environment you're working with."
      },
      {
        "heading": "Batch Put Custom Resolver",
        "depth": 3,
        "text": "Run amplify push and deploy your API"
      },
      {
        "heading": "Batch Put Custom Resolver",
        "depth": 3,
        "text": "The full documentation for custom resolvers is available here"
      }
    ],
    "source": "export const meta = {\n  title: `Overview`,\n  description: `Add authorization rules to your GraphQL schema to control access to your data.`,\n};\n\n<MigrationAlert url={\"/cli-legacy/graphql-transformer/examples\"}/>\n\n## Todo\n\n```graphql\ntype Todo @model @auth(rules: [{allow: owner}]) {\n  id: ID!\n  name: String!\n  description: String\n}\n```\n\n## Blog\n```graphql\ntype Blog @model @auth(rules: [\n  { allow: groups, groups: [\"Admins\"] },\n  { allow: public, operations: [read] }\n  ]) {\n  id: ID!\n  name: String!\n  posts: [Post] @hasMany\n}\ntype Post @model @auth(rules: [\n  { allow: groups, groups: [\"Admins\"] },\n  { allow: public, operations: [read] }\n  ]) {\n  id: ID!\n  title: String!\n  blog: Blog @belongsTo\n  comments: [Comment] @hasMany\n}\ntype Comment @model @auth(rules: [\n  { allow: groups, groups: [\"Admins\"], operations: [delete] },\n  { allow: owner },\n  { allow: public, operations: [read] }\n  ]) {\n  id: ID!\n  content: String\n  post: Post @belongsTo\n}\n```\n\n## Warehouse Management System\nIn this \"Warehouse management system\" example, you will learn how to configure common access patterns for your app. This example has the following types:\n\n- Warehouse\n- Product\n- Inventory\n- Employee\n- AccountRepresentative\n- Customer\n\nThese types have the following common access patterns:\n\n1. [Look up employee details by employee ID](#1-look-up-employee-details-by-employee-id)\n2. [Query employee details by employee name](#2-query-employee-details-by-employee-name)\n3. [Find an employee's phone number(s)](#3-find-an-employees-phone-number)\n4. [Find a customer's phone number(s)](#4-find-a-customers-phone-number)\n5. [Get orders for a given customer within a given date range](#5-get-orders-for-a-given-customer-within-a-given-date-range)\n6. [Show all open orders within a given date range across all customers](#6-show-all-open-orders-within-a-given-date-range-across-all-customers)\n7. [See all employees recently hired](#7-see-all-employees-hired-recently)\n8. [Find all employees working in a given warehouse](#8-find-all-employees-working-in-a-given-warehouse)\n9. [Get all items on order for a given product](#9-get-all-items-on-order-for-a-given-product)\n10. [Get current inventories for a given product at all warehouses](#10-get-current-inventories-for-a-product-at-all-warehouses)\n11. [Get customers by account representative](#11-get-customers-by-account-representative)\n12. [Get orders by account representative and date](#12-get-orders-by-account-representative-and-date)\n13. [Get all items on order for a given product](#13-get-all-items-on-order-for-a-given-product)\n14. [Get all employees with a given job title](#14-get-all-employees-with-a-given-job-title)\n15. [Get inventory by product and warehouse](#15-get-inventory-by-product-by-warehouse)\n16. [Get total product inventory](#16-get-total-product-inventory)\n17. [Get account representatives ranked by order total and sales period](#17-get-sales-representatives-ranked-by-order-total-and-sales-period)\n\nThe following schema introduces the required indexes and relationships so that we can support these access patterns:\n\n```graphql\n# This \"input\" configures a global authorization rule to enable public access to\n# all models in this schema. Learn more about authorization rules here: https://docs.amplify.aws/cli/graphql/auth\ninput AMPLIFY { globalAuthRule: AuthRule = { allow: public } } # FOR TESTING ONLY!\n\ntype Order @model {\n  id: ID!\n  customerID: ID! @index(name: \"byCustomerByStatusByDate\", sortKeyFields: [\"status\", \"date\"]) @index(name: \"byCustomerByDate\", sortKeyFields: [\"date\"])\n  accountRepresentativeID: ID! @index(name: \"byRepresentativebyDate\", sortKeyFields: [\"date\"])\n  productID: ID! @index(name: \"byProduct\", sortKeyFields: [\"id\"])\n  status: String!\n  amount: Int!\n  date: String!\n}\n\ntype Customer @model {\n  id: ID!\n  name: String!\n  phoneNumber: String\n  accountRepresentativeID: ID! @index(name: \"byRepresentative\", sortKeyFields: [\"id\"])\n  ordersByDate: [Order] @hasMany(indexName: \"byCustomerByDate\", fields: [\"id\"])\n  ordersByStatusDate: [Order] @hasMany(indexName: \"byCustomerByStatusByDate\", fields: [\"id\"])\n}\n\ntype Employee @model {\n  id: ID!\n  name: String! @index(name: \"byName\", queryField: \"employeeByName\", sortKeyFields: [\"id\"])\n  startDate: String!\n  phoneNumber: String!\n  warehouseID: ID! @index(name: \"byWarehouse\", sortKeyFields: [\"id\"])\n  jobTitle: String! @index(name: \"byTitle\", queryField: \"employeesByJobTitle\", sortKeyFields: [\"id\"])\n  newHire: String! @index(name: \"newHire\", queryField: \"employeesNewHire\", sortKeyFields: [\"id\"]) @index(name: \"newHireByStartDate\", queryField: \"employeesNewHireByStartDate\", sortKeyFields: [\"startDate\"])\n}\n\ntype Warehouse @model {\n  id: ID!\n  employees: [Employee] @hasMany(indexName: \"byWarehouse\", fields: [\"id\"])\n}\n\ntype AccountRepresentative @model {\n  id: ID!\n  customers: [Customer] @hasMany(indexName: \"byRepresentative\", fields: [\"id\"])\n  orders: [Order] @hasMany(indexName: \"byRepresentativebyDate\", fields: [\"id\"])\n  orderTotal: Int\n  salesPeriod: String @index(name: \"bySalesPeriodByOrderTotal\", queryField: \"repsByPeriodAndTotal\", sortKeyFields: [\"orderTotal\"])\n}\n\ntype Inventory @model {\n  productID: ID! @primaryKey(sortKeyFields: [\"warehouseID\"])\n  warehouseID: ID! @index(name: \"byWarehouseID\", queryField: \"itemsByWarehouseID\")\n  inventoryAmount: Int!\n}\n\ntype Product @model {\n  id: ID!\n  name: String!\n  orders: [Order] @hasMany(indexName: \"byProduct\", fields: [\"id\"])\n  inventories: [Inventory] @hasMany(fields: [\"id\"])\n}\n```\n\nNow that we have the schema created, let's create the items in the database that we will be operating against:\n\n```graphql\n# first\nmutation createWarehouse {\n  createWarehouse(input: {id: \"1\"}) {\n    id\n  }\n}\n\n# second\nmutation createEmployee {\n  createEmployee(input: {\n    id: \"amanda\"\n    name: \"Amanda\",\n    startDate: \"2018-05-22\",\n    phoneNumber: \"6015555555\",\n    warehouseID: \"1\",\n    jobTitle: \"Manager\",\n    newHire: \"true\"}\n  ) {\n    id\n    jobTitle\n    name\n    newHire\n    phoneNumber\n    startDate\n    warehouseID\n  }\n}\n\n# third\nmutation createAccountRepresentative {\n  createAccountRepresentative(input: {\n    id: \"dabit\"\n    orderTotal: 400000\n    salesPeriod: \"January 2019\"\n  }) {\n    id\n    orderTotal\n    salesPeriod\n  }\n}\n\n# fourth\nmutation createCustomer {\n  createCustomer(input: {\n    id: \"jennifer_thomas\"\n    accountRepresentativeID: \"dabit\"\n    name: \"Jennifer Thomas\"\n    phoneNumber: \"+16015555555\"\n  }) {\n    id\n    name\n    accountRepresentativeID\n    phoneNumber\n  }\n}\n\n# fifth\nmutation createProduct {\n  createProduct(input: {\n    id: \"yeezyboost\"\n    name: \"Yeezy Boost\"\n  }) {\n    id\n    name\n  }\n}\n\n# sixth\nmutation createInventory {\n  createInventory(input: {\n    productID: \"yeezyboost\"\n    warehouseID: \"1\"\n    inventoryAmount: 300\n  }) {\n    productID\n    inventoryAmount\n    warehouseID\n  }\n}\n\n# seventh\nmutation createOrder {\n  createOrder(input: {\n    amount: 300\n    date: \"2018-07-12\"\n    status: \"pending\"\n    accountRepresentativeID: \"dabit\"\n    customerID: \"jennifer_thomas\"\n    productID: \"yeezyboost\"\n  }) {\n    id\n    customerID\n    accountRepresentativeID\n    amount\n    date\n    customerID\n    productID\n  }\n}\n```\n\n### 1. Look up employee details by employee ID\n\nThis can simply be done by querying the employee model with an employee ID, no `@primaryKey` or `@index` need to be explicitly specified to make this work.\n\n```graphql\nquery getEmployee($id: ID!) {\n  getEmployee(id: $id) {\n    id\n    name\n    phoneNumber\n    startDate\n    jobTitle\n  }\n}\n```\n\n### 2. Query employee details by employee name\n\nThe `@index` `byName` on the `Employee` type makes this access-pattern feasible because under the hood an index is created and a query is used to match against the name field. We can use this query:\n\n```graphql\nquery employeeByName($name: String!) {\n  employeeByName(name: $name) {\n    items {\n      id\n      name\n      phoneNumber\n      startDate\n      jobTitle\n    }\n  }\n}\n```\n\n### 3. Find an Employee’s phone number\n\nEither one of the previous queries would work to find an employee’s phone number as long as one has their ID or name.\n\n### 4. Find a customer’s phone number\n\nA similar query to those given above but on the Customer model would give you a customer’s phone number.\n\n```graphql\nquery getCustomer($customerID: ID!) {\n  getCustomer(id: $customerID) {\n    phoneNumber\n  }\n}\n```\n\n### 5. Get orders for a given customer within a given date range\n\nThere is a one-to-many relation that lets all the orders of a customer be queried.\n\nThis relationship is created by having the `@index` name `byCustomerByDate` on the Order model that is queried by the `@hasMany` relationship on the orders field of the Customer model.\n\nA sort key with the date is used. What this means is that the GraphQL resolver can use predicates like `Between` to efficiently search the date range rather than scanning all records in the database and then filtering them out.\n\nThe query one would need to get the orders to a customer within a date range would be:\n\n```graphql\nquery getCustomerWithOrdersByDate($customerID: ID!) {\n  getCustomer(id: $customerID) {\n    ordersByDate(date: {\n      between: [ \"2018-01-22\", \"2020-10-11\" ]\n    }) {\n      items {\n        id\n        amount\n        productID\n      }\n    }\n  }\n}\n```\n\n### 6. Show all open orders within a given date range across all customers\n\nThe `@index` `byCustomerByStatusByDate` enables you to run a query that would work for this access pattern.\n\nIn this example, a composite sort key (combination of two or more keys) with the `status` and `date` is used. What this means is that the unique identifier of a record in the database is created by concatenating these two fields (status and date) together, and then the GraphQL resolver can use predicates like `Between` or `Contains` to efficiently search the unique identifier for matches rather than scanning all records in the database and then filtering them out.\n\n```graphql\nquery getCustomerWithOrdersByStatusDate($customerID: ID!) {\n  getCustomer(id: $customerID) {\n    ordersByStatusDate (statusDate: {\n      between: [\n        { status: \"pending\" date:  \"2018-01-22\" },\n        { status: \"pending\", date: \"2020-10-11\"}\n      ]}) {\n        items {\n            id\n            amount\n            date\n        }\n    }\n  }\n}\n```\n\n### 7. See all employees hired recently\n\nHaving `@index(name: \"newHire\", fields: [\"newHire\", \"id\"])` on the `Employee` model allows one to query by whether an employee has been hired recently.\n\n```graphql\nquery employeesNewHire {\n  employeesNewHire(newHire: \"true\") {\n    items {\n      id\n      name\n      phoneNumber\n      startDate\n      jobTitle\n    }\n  }\n}\n```\n\nWe can also query and have the results returned by start date by using the `employeesNewHireByStartDate` query:\n\n```graphql\nquery employeesNewHireByDate {\n  employeesNewHireByStartDate(newHire: \"true\") {\n    items {\n      id\n      name\n      phoneNumber\n      startDate\n      jobTitle\n    }\n  }\n}\n```\n\n### 8. Find all employees working in a given warehouse\n\nThis needs a one to many relationship from warehouses to employees. As can be seen from the `@hasMany` relationship in the `Warehouse` model, this relationship uses the `byWarehouse` index on the `Employee` model. The relevant query would look like this:\n\n```graphql\nquery getWarehouse($warehouseID: ID!) {\n  getWarehouse(id: $warehouseID) {\n    id\n    employees{\n      items {\n        id\n        name\n        startDate\n        phoneNumber\n        jobTitle\n      }\n    }\n  }\n}\n```\n\n### 9. Get all items on order for a given product\n\nThis access-pattern would use a one-to-many relation from products to orders. With this query we can get all orders of a given product:\n\n```graphql\nquery getProductOrders($productID: ID!) {\n  getProduct(id: $productID) {\n    id\n    orders {\n      items {\n        id\n        status\n        amount\n        date\n      }\n    }\n  }\n}\n```\n\n### 10. Get current inventories for a product at all warehouses\n\nThe query needed to get the inventories of a product in all warehouses would be:\n\n```graphql\nquery getProductInventoryInfo($productID: ID!) {\n  getProduct(id: $productID) {\n    id\n    inventories {\n      items {\n        warehouseID\n        inventoryAmount\n      }\n    }\n  }\n}\n```\n\n### 11. Get customers by account representative\n\nThis uses a has-many relationship between account representatives and customers:\n\nThe query needed would look like this:\n\n```graphql\nquery getCustomersForAccountRepresentative($representativeId: ID!) {\n  getAccountRepresentative(id: $representativeId) {\n    customers {\n      items {\n        id\n        name\n        phoneNumber\n      }\n    }\n  }\n}\n```\n\n### 12. Get orders by account representative and date\n\nAs can be seen in the AccountRepresentative model this relationship uses the `byRepresentativebyDate` field on the `Order` model to create the connection needed. The query needed would look like this:\n\n```graphql\nquery getOrdersForAccountRepresentative($representativeId: ID!) {\n  getAccountRepresentative(id: $representativeId) {\n    id\n    orders(date: {\n      between: [\n         \"2010-01-22\", \"2020-10-11\"\n      ]\n    }) {\n        items {\n          id\n          status\n          amount\n          date\n        }\n    }\n  }\n}\n```\n\n### 13. Get all items on order for a given product\n\nThis is the same as number 9.\n\n### 14. Get all employees with a given job title\n\nUsing the `byTitle` `@index` makes this access pattern quite easy.\n\n```graphql\nquery employeesByJobTitle {\n  employeesByJobTitle(jobTitle: \"Manager\") {\n    items {\n      id\n      name\n      phoneNumber\n      jobTitle\n    }\n  }\n}\n```\n\n### 15. Get inventory by product by warehouse\n\nHere having the inventories be held in a separate model is particularly useful since this model can have its own partition key and sort key such that the inventories themselves can be queried as is needed for this access-pattern.\n\nA query on this model would look like this:\n\n```graphql\nquery inventoryByProductAndWarehouse($productID: ID!, $warehouseID: ID!) {\n  getInventory(productID: $productID, warehouseID: $warehouseID) {\n    productID\n    warehouseID\n    inventoryAmount\n  }\n}\n\n```\n\nWe can also get all inventory from an individual warehouse by using the `itemsByWarehouseID` query created by the `byWarehouseID` key:\n\n```graphql\nquery byWarehouseId($warehouseID: ID!) {\n  itemsByWarehouseID(warehouseID: $warehouseID) {\n    items {\n      inventoryAmount\n      productID\n    }\n  }\n}\n```\n\n### 16. Get total product inventory\n\nHow this would be done depends on the use case. If one just wants a list of all inventories in all warehouses, one could just run a list inventories on the Inventory model:\n\n```graphql\nquery listInventorys {\n  listInventorys {\n    items {\n      productID\n      warehouseID\n      inventoryAmount\n    }\n  }\n}\n```\n\n### 17. Get sales representatives ranked by order total and sales period\n\nThe sales period is either a date range or maybe even a month or week. Therefore we can set the sales period as a string and query using the combination of `salesPeriod` and `orderTotal`. We can also set the `sortDirection` in order to get the return values from largest to smallest:\n\n```graphql\nquery repsByPeriodAndTotal {\n  repsByPeriodAndTotal(\n    sortDirection: DESC,\n    salesPeriod: \"January 2019\",\n    orderTotal: {\n      ge: 1000\n    }) {\n    items {\n      id\n      orderTotal\n    }\n  }\n}\n```\n\n## Advanced\n\n### Batch Put Custom Resolver\n\nSometimes you need to create objects in bulk, rather than creating individual objects sequentially and waiting for all the requests to complete.\n\n1. Define your schema with a custom mutation. The custom mutation should not be deployed to AppSync beforehand if following these steps, the CLI will attach its own resolver preventing you from attaching a custom resource this way.\n```graphql\ntype Todo @model {\n  id: ID!\n  name: String!\n  description: String\n}\n\ntype Mutation {\n  batchCreateTodo(todos: [BatchCreateTodo]): [Todo]\n}\n\ninput BatchCreateTodo {\n  id: ID\n  name: String!\n  description: String\n}\n```\n\n2. [Create a custom resource for your resolver](/cli/graphql/custom-business-logic/#vtl-resolver) and use the following code snippets as a guide to get started\n\n2. Follow the steps for creating a custom resolver:\n```bash\namplify add custom\n```\n```console\n? How do you want to define this custom resource?\n❯ AWS CDK\n? Provide a name for your custom resource\n❯ MyCustomResolvers\n```\n\nNext, install the AppSync dependencies for your custom resource:\n```bash\ncd amplify/backend/custom/MyCustomResolvers\nnpm i @aws-cdk/aws-appsync@~1.124.0\n```\n\nUse the following template as a starting point for your custom CDK stack, the resolvers must be templated with environment references\n\n```ts\nimport * as cdk from '@aws-cdk/core';\nimport * as AmplifyHelpers from '@aws-amplify/cli-extensibility-helper';\nimport * as appsync from '@aws-cdk/aws-appsync';\nimport { AmplifyDependentResourcesAttributes } from '../../types/amplify-dependent-resources-ref';\n\nexport class cdkStack extends cdk.Stack {\n  constructor(scope: cdk.Construct, id: string, props?: cdk.StackProps, amplifyResourceProps?: AmplifyHelpers.AmplifyResourceProps) {\n    super(scope, id, props);\n    /* Do not remove - Amplify CLI automatically injects the current deployment environment in this input parameter */\n    new cdk.CfnParameter(this, 'env', {\n      type: 'String',\n      description: 'Current Amplify CLI env name',\n    });\n    \n    // Access other Amplify Resources \n    const retVal:AmplifyDependentResourcesAttributes = AmplifyHelpers.addResourceDependency(this, \n      amplifyResourceProps.category, \n      amplifyResourceProps.resourceName, \n      [{\n        category: \"api\",\n        resourceName: \"<YOUR-API-NAME>\"\n      }]\n    );\n\n    const requestVTL = `\n      ## [Start] Initialization default values. **\n      $util.qr($ctx.stash.put(\"defaultValues\", $util.defaultIfNull($ctx.stash.defaultValues, {})))\n      #set( $createdAt = $util.time.nowISO8601() )\n      #set($todosArray = [])\n      #foreach($item in \\${ctx.args.todos})\n        $util.qr($item.put(\"id\", $util.defaultIfNullOrBlank($item.id, $util.autoId())))\n        $util.qr($item.put(\"createdAt\", $util.defaultIfNull($item.createdAt, $createdAt)))\n        $util.qr($item.put(\"updatedAt\", $util.defaultIfNull($item.updatedAt, $createdAt)))\n        $util.qr($item.put(\"__typename\", \"Todo\"))\n        $util.qr($todosArray.add($util.dynamodb.toMapValues($item)))\n      #end\n      ## [End] Initialization default values. **\n      $util.toJson( {\n        \"version\": \"2018-05-29\",\n        \"operation\": \"BatchPutItem\",\n        \"tables\": {\n          \"<TYPE-NAME-HERE>-${apiIdRef}-${envRef}\": $todosArray\n        }\n      } )\n    `\n    const responseVTL = `\n      ## [Start] ResponseTemplate. **\n      #if( $ctx.error )\n        $util.error($ctx.error.message, $ctx.error.type)\n      #else\n        $util.toJson($ctx.result.data.<TYPE-NAME-HERE>-${apiIdRef}-${envRef})\n      #end\n      ## [End] ResponseTemplate. **\n    `;\n\n\n    const resolver = new appsync.CfnResolver(this, \"custom-resolver\", {\n      // apiId: retVal.api.new.GraphQLAPIIdOutput,\n      // https://github.com/aws-amplify/amplify-cli/issues/9391#event-5843293887\n      // If you use Amplify you can access the parameter via Ref since it's a CDK parameter passed from the root stack.\n      // Previously the ApiId is the variable Name which is wrong , it should be variable value as below\n      apiId: cdk.Fn.ref(retVal.api.replaceWithAPIName.GraphQLAPIIdOutput),\n      fieldName: \"querySomething\", \n      typeName: \"Query\", // Query | Mutation | Subscription\n      requestMappingTemplate: requestVTL,\n      responseMappingTemplate: responseVTL,\n      dataSourceName: \"TodoTable\" // DataSource name\n    })\n  }\n}\n```\n\nBy using CloudFormation parameters, you contextualize your custom resolvers to the environment you're working with.\n\n3. Run `amplify push` and deploy your API\n\nThe full documentation for custom resolvers [is available here](https://docs.amplify.aws/cli/graphql/custom-business-logic/#vtl-resolver)\n",
    "meta": {
      "title": "Examples and solutions",
      "description": "Add authorization rules to your GraphQL schema to control access to your data.",
      "subcategory": "API (GraphQL)",
      "category": "Amplify CLI"
    },
    "filename": "/cli/graphql/examples-and-solutions"
  },
  {
    "searchableText": [
      {
        "heading": "Deploying multiple index changes at once",
        "depth": 2,
        "text": "You can make @index updates on one \"amplify push\". Under the hood, Amplify CLI needs to locally sequence multiple individual deployments to your DynamoDB table because each Global Secondary Index (GSI), managed by @index, change requires time to create the new index."
      },
      {
        "heading": "Deploying multiple index changes at once",
        "depth": 2,
        "text": "If your deployment fails locally when updating multiple GSIs, you'll have the ability to run:"
      },
      {
        "heading": "Deploying multiple index changes at once",
        "depth": 2,
        "text": "amplify push --iterative-rollback to rollback the last-known-good state"
      },
      {
        "heading": "Deploying multiple index changes at once",
        "depth": 2,
        "text": "amplify push --force to rollback the last-known-good state and try redeploying your changes again using."
      },
      {
        "heading": "Deploying multiple index changes at once",
        "depth": 2,
        "text": "If you're running into the error above during amplify push, it is likely that you don't have this feature enabled. To enable multiple GSI updates, set the \"enableIterativeGsiUpdates\" feature flag to true in your amplify/cli.json file."
      },
      {
        "heading": "Backfill OpenSearch index from DynamoDB table",
        "depth": 2,
        "text": "When you add @searchable to a @model type with existing data, then you need to backfill the OpenSearch index. Download the following Python script to help you backfill your OpenSearch index:"
      },
      {
        "heading": "Backfill OpenSearch index from DynamoDB table",
        "depth": 2,
        "text": "DynamoDB to OpenSearch backfill script"
      },
      {
        "heading": "Backfill OpenSearch index from DynamoDB table",
        "depth": 2,
        "text": "The script creates an event stream of your DynamoDB records and sends them to your OpenSearch Index. Execute the script with the following parameters to initiate the backfill:"
      },
      {
        "heading": "Backfill OpenSearch index from DynamoDB table",
        "depth": 2,
        "text": "|Parameter|Description|Required|\n|---------|-----------|--------|\n|--rn   | DynamoDB table region. See AWS Regions for available options |Yes|\n|--tn   | DynamoDB table name. Format: {@model type name}-{AppSync API ID}-{Amplify environment}|Yes|\n|--lf   | ARN of the \"DynamoDB to OpenSearch streaming\" Lambda function. Format: arn:aws:lambda:{region}:{AWS Account ID}:function:amplify-{Amplify app name}-{Amplify environment}-{Random string}-OpenSearchStreamingLambd-{Random string}|Yes|\n|--esarn| ARN of the DynamoDB table stream. Format: arn:aws:dynamodb:{region}:{AWS Account ID}:table/{@model type name}-{AppSync API ID}-{Amplify environment}/stream/{Table creation date}|Yes|\n|--ak   | AWS Access Key ID. This is used to authenticate with your AWS account in case no local AWS profile is set up. | No|\n|--sk   | AWS Secret Access Key. This is used to authenticate with your AWS account in case no local AWS profile is set up. | No|\n|--st   | AWS Session Token. This is used to authenticate with your AWS account in case no local AWS profile is set up. | No|"
      },
      {
        "heading": "Backfill OpenSearch index from DynamoDB table",
        "depth": 2,
        "text": "In the example below, the Post table data in us-west-2 gets backfilled in the OpenSearch index."
      },
      {
        "heading": "Index with multiple sort key fields",
        "depth": 2,
        "text": "When you add an @index directive with 2 or more sort key fields, you will need to backfill the new composite sort key for existing data. With @index(sortKeyFields: [\"status\", \"date\"]), you will need to backfill the status#date field with composite key values made up of each object's status and date fields joined by a #. You do not need to backfill data for @index directives with zero to one sort key field(s)."
      }
    ],
    "source": "export const meta = {\n  title: `Troubleshooting`,\n  description: `Add authorization rules to your GraphQL schema to control access to your data.`,\n};\n\n## Deploying multiple index changes at once\n\nYou can make `@index` updates on one \"amplify push\". Under the hood, Amplify CLI needs to locally sequence multiple individual deployments to your DynamoDB table because each Global Secondary Index (GSI), managed by `@index`, change requires time to create the new index.\n\nIf your deployment fails locally when updating multiple GSIs, you'll have the ability to run:\n\n- `amplify push --iterative-rollback` to rollback the last-known-good state\n- `amplify push --force` to rollback the last-known-good state and try redeploying your changes again using.\n\n```console\nAttempting to mutate more than 1 global secondary index at the same time.\n```\n\nIf you're running into the error above during `amplify push`, it is likely that you don't have this feature enabled. To enable multiple GSI updates, set the \"enableIterativeGsiUpdates\" feature flag to true in your `amplify/cli.json` file.\n\n## Backfill OpenSearch index from DynamoDB table\n\nWhen you add `@searchable` to a `@model` type with existing data, then you need to backfill the OpenSearch index. Download the following Python script to help you backfill your OpenSearch index:\n\n[DynamoDB to OpenSearch backfill script](https://raw.githubusercontent.com/aws-amplify/amplify-category-api/main/packages/graphql-elasticsearch-transformer/scripts/ddb_to_es.py)\n\nThe script creates an event stream of your DynamoDB records and sends them to your OpenSearch Index. Execute the script with the following parameters to initiate the backfill:\n\n|Parameter|Description|Required|\n|---------|-----------|--------|\n|`--rn`   | DynamoDB table region. See [AWS Regions](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.RegionsAndAvailabilityZones.html) for available options |Yes|\n|`--tn`   | DynamoDB table name. Format: `{@model type name}-{AppSync API ID}-{Amplify environment}`|Yes|\n|`--lf`   | ARN of the \"DynamoDB to OpenSearch streaming\" Lambda function. Format: `arn:aws:lambda:{region}:{AWS Account ID}:function:amplify-{Amplify app name}-{Amplify environment}-{Random string}-OpenSearchStreamingLambd-{Random string}`|Yes|\n|`--esarn`| ARN of the DynamoDB table stream. Format: `arn:aws:dynamodb:{region}:{AWS Account ID}:table/{@model type name}-{AppSync API ID}-{Amplify environment}/stream/{Table creation date}`|Yes|\n|`--ak`   | AWS Access Key ID. This is used to authenticate with your AWS account in case no local AWS profile is set up. | No|\n|`--sk`   | AWS Secret Access Key. This is used to authenticate with your AWS account in case no local AWS profile is set up. | No|\n|`--st`   | AWS Session Token. This is used to authenticate with your AWS account in case no local AWS profile is set up. | No|\n\nIn the example below, the `Post` table data in `us-west-2` gets backfilled in the OpenSearch index.\n\n```bash\npython3 ddb_to_es.py \\\n  --rn 'us-west-2' \\ # Use the region in which your table and OpenSearch domain reside\n  --tn 'Post-XXXX-dev' \\ # Table name\n  --lf 'arn:aws:lambda:us-west-2:<...>:function:amplify-<...>-OpenSearchStreamingLambd-<...>' \\ # Lambda function ARN, find the DynamoDB to OpenSearch streaming functions, copy entire ARN\n  --esarn 'arn:aws:dynamodb:us-west-2:<...>:table/Post-<...>/stream/2019-20-03T00:00:00.350' # Event source ARN, copy the full DynamoDB table ARN\n```\n\n## Index with multiple sort key fields\n\nWhen you add an `@index` directive with 2 or more sort key fields, you will need to backfill the new composite sort key for existing data. With `@index(sortKeyFields: [\"status\", \"date\"])`, you will need to backfill the `status#date` field with composite key values made up of each object's `status` and `date` fields joined by a `#`. You do not need to backfill data for `@index` directives with zero to one sort key field(s).",
    "meta": {
      "title": "Troubleshooting",
      "description": "Add authorization rules to your GraphQL schema to control access to your data.",
      "subcategory": "API (GraphQL)",
      "category": "Amplify CLI"
    },
    "filename": "/cli/graphql/troubleshooting"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Run the command above to override Amplify-generated GraphQL API resources including AWS AppSync API, Amazon DynamoDB table, Amazon OpenSearch domain, and more."
      },
      {
        "heading": null,
        "depth": null,
        "text": "If you need to customize a specific Amplify-generated VTL resolver, review Override Amplify-generated resolvers first."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The command creates a new overrides.ts file under amplify/backend/api/<resource-name>/ which provides you the Amplify-generated resources as CDK constructs."
      },
      {
        "heading": "Customize Amplify-generated AppSync GraphQL API resources",
        "depth": 2,
        "text": "Apply all the overrides in the override(...) function. For example to enable X-Ray tracing for the AppSync GraphQL API:"
      },
      {
        "heading": "Customize Amplify-generated AppSync GraphQL API resources",
        "depth": 2,
        "text": "You can override the following GraphQL API resources that Amplify generates:"
      },
      {
        "heading": "Customize Amplify-generated AppSync GraphQL API resources",
        "depth": 2,
        "text": "|Amplify-generated resource|Description|\n|-|-|\n|GraphQLAPI|AWS AppSync GraphQL API resource|\n|GraphQLAPIDefaultApiKey|API Key resource for the AppSync GraphQL API|\n|GraphQLAPITransformerSchema|The GraphQL schema that's being deployed. (The output of the GraphQL Transformer)|\n|GraphQLAPINONEDS|A \"none\" data source that is used for requests that don't exit the AppSync API|\n|AmplifyDataStore|The delta sync table used for Amplify DataStore's conflict resolution|\n|AmplifyDataStoreIAMRole|IAM role used to access the delta sync table for DataStore|\n|DynamoDBAccess|IAM policy to access the DynamoDB resources from AppSync|"
      },
      {
        "heading": "Customize Amplify-generated resources for @model directive",
        "depth": 2,
        "text": "Apply all the overrides in the override(...) function. Pass in the @model type name into resources.models[...] to modify the resources generated for that particular @model type. For example, to enable time-to-live on the Todo @model type's DynamoDB table:"
      },
      {
        "heading": "Customize Amplify-generated resources for @model directive",
        "depth": 2,
        "text": "You can override the following @model directive resources that Amplify generates:"
      },
      {
        "heading": "Customize Amplify-generated resources for @model directive",
        "depth": 2,
        "text": "|Amplify-generated resource|Description|\n|-|-|\nmodelStack|The nested stack containing all resources for the @model type|\nmodelDDBTable|The DynamoDB table containing the data for this @model type|\nmodelIamRole|IAM role to access the DynamoDB table for this @model type|\nmodelIamRoleDefaultPolicy|IAM policy to access the delta sync table for this @model type in case DataStore is enabled|\ndynamoDBAccess|Default policy associated with the IAM role to access the DynamoDB table for this @model type|\nmodelDatasource|The AppSync DataSource to representing the DynamoDB table|\ninvokeLambdaFunction|IAM policy for Lambda-based conflict resolution function|"
      },
      {
        "heading": "Customize Amplify-generated resources for @model directive",
        "depth": 2,
        "text": "For example, we can override a model generated DynamoDB table configuration."
      },
      {
        "heading": "Customize Amplify-generated resources for @searchable (OpenSearch) directive",
        "depth": 2,
        "text": "Apply all the overrides in the override(...) function. For example, to modify the OpenSearch instance count:"
      },
      {
        "heading": "Customize Amplify-generated resources for @searchable (OpenSearch) directive",
        "depth": 2,
        "text": "You can override the following @searchable directive resources that Amplify generates:"
      },
      {
        "heading": "Customize Amplify-generated resources for @searchable (OpenSearch) directive",
        "depth": 2,
        "text": "|Amplify-generated resource|Description|\n|-|-|\nOpenSearchDataSource|The AppSync data source representing the OpenSearch integration|\nOpenSearchAccessIAMRole|IAM role to access OpenSearch domain|\nOpenSearchAccessIAMRoleDefaultPolicy|IAM policy to access OpenSearch domain|\nOpenSearchDomain|OpenSearch domain containing the @searchable data|\nOpenSearchStreamingLambdaIAMRole|IAM role to stream DynamoDB data to OpenSearch domain|\nOpenSearchStreamingLambdaIAMRoleDefaultPolicy|IAM policy to stream DynamoDB data to OpenSearch domain|\nCloudwatchLogsAccess|IAM policy for granting CloudWatch logs access|\nOpenSearchStreamingLambdaFunction|Lambda function to stream DynamoDB data to OpenSearch domain|\nOpenSearchModelLambdaMapping|Event source mapping for DynamoDB table stream to Lambda function|"
      },
      {
        "heading": "Customize Amplify-generated resources for @predictions directive",
        "depth": 2,
        "text": "Apply all the overrides in the override(...) function. For example, to add a Path to IAM role that facilitates text translation:"
      },
      {
        "heading": "Customize Amplify-generated resources for @predictions directive",
        "depth": 2,
        "text": "You can override the following @predictions directive resources that Amplify generates:"
      },
      {
        "heading": "Customize Amplify-generated resources for @predictions directive",
        "depth": 2,
        "text": "|Amplify-generated resource|Description|\n|-|-|\n|RekognitionDataSource|AppSync HTTP data source to connect to Amazon Rekognition service|\n|RekognitionDataSourceServiceRole|AppSync service role to connect to Amazon Rekognition|\n|TranslateDataSource|AppSync HTTP data source to connect to Amazon Translate service|\n|translateTextAccess|IAM policy to connect to Amazon Translate|\n|LambdaDataSource|AppSync Lambda data source to connect to Amazon Polly|\n|LambdaDataSourceServiceRole|AppSync service role to connect to Lambda function calling Amazon Polly|\n|LambdaDataSourceServiceRoleDefaultPolicy|IAM policy for AppSync to connect to Lambda function calling Amazon Polly|\n|TranslateDataSourceServiceRole|AppSync service role to connect to Amazon Translate|\n|predictionsLambdaIAMRole|IAM role for Lambda function calling Amazon Polly|\n|predictionsLambdaFunction|Lambda function calling Amazon Polly|\n|PredictionsLambdaAccess|IAM policy for Lambda function to access Amazon Polly|\n|predictionsIAMRole|IAM role to access s3 bucket used by @predictions|\n|PredictionsStorageAccess|IAM policy to access S3 bucket used by @predictions|\n|identifyTextAccess|IAM policy to enable Identify Text|\n|identifyLabelsAccess|IAM policy to enable Identify Text|"
      },
      {
        "heading": "Place AppSync Resolvers in Custom-named Stacks",
        "depth": 2,
        "text": "If you have a particularly large GraphQL schema, you may run into issues with too many resources defined in a stack. The most common case where this happens is in the ConnectionStack which contains the resolvers for all of the relational directives in the schema."
      },
      {
        "heading": "Place AppSync Resolvers in Custom-named Stacks",
        "depth": 2,
        "text": "Creating a stack mapping does not create an additional root stack for the Amplify environment. All mapped stacks will still be placed under the existing Amplify environment root stack.\nTo map a resolver to a different stack, update <project root>/amplify/api/<api name>/transform.conf.json with a \"StackMapping\" block. The StackMapping defines a map from resolver logical ID to stack name."
      },
      {
        "heading": "Place AppSync Resolvers in Custom-named Stacks",
        "depth": 2,
        "text": "The easiest way to determine a resolver logical ID is to run amplify api gql-compile and note the resolver logical ID in the list of Resources in the generated CloudFormation stack.\nResolvers for model operations will be of the form <Get | List | Create | Update | Delete><model name>Resolver. Resolvers for relational directives are of the form <model name><field name>Resolver."
      },
      {
        "heading": "Example",
        "depth": 3,
        "text": "Given the following schema:"
      },
      {
        "heading": "Example",
        "depth": 3,
        "text": "To map the CreatePostResolver and the relational resolvers to a stack named 'MyCustomStack', add the following in transform.conf.json:"
      }
    ],
    "source": "export const meta = {\n  title: `Override Amplify-generated AppSync resources`,\n  description: `The \"amplify override api\" command generates a developer-configurable \"overrides\" TypeScript file which provides Amplify-generated AppSync resources as CDK constructs. For example, developers can set api settings that are not directly available in the Amplify CLI workflow, such as X-Ray tracing.`,\n};\n\n```bash\namplify override api\n```\n\nRun the command above to override Amplify-generated GraphQL API resources including AWS AppSync API, Amazon DynamoDB table, Amazon OpenSearch domain, and more.\n\n<Callout>\n\nIf you need to customize a specific Amplify-generated VTL resolver, review [Override Amplify-generated resolvers](/cli/graphql/custom-business-logic/#override-amplify-generated-resolvers) first.\n</Callout>\n\nThe command creates a new `overrides.ts` file under `amplify/backend/api/<resource-name>/` which provides you the Amplify-generated resources as [CDK constructs](https://docs.aws.amazon.com/cdk/latest/guide/home.html).\n\n## Customize Amplify-generated AppSync GraphQL API resources\n\nApply all the overrides in the `override(...)` function. For example to enable X-Ray tracing for the AppSync GraphQL API:\n\n```ts\nimport { AmplifyApiGraphQlResourceStackTemplate } from '@aws-amplify/cli-extensibility-helper';\n\nexport function override(resources: AmplifyApiGraphQlResourceStackTemplate) {\n  resources.api.GraphQLAPI.xrayEnabled = true\n}\n```\n\nYou can override the following GraphQL API resources that Amplify generates:\n\n|Amplify-generated resource|Description|\n|-|-|\n|[GraphQLAPI](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-appsync-graphqlapi.html)|AWS AppSync GraphQL API resource|\n|[GraphQLAPIDefaultApiKey](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-appsync-apikey.html)|API Key resource for the AppSync GraphQL API|\n|[GraphQLAPITransformerSchema](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-appsync-graphqlschema.html)|The GraphQL schema that's being deployed. (The output of the GraphQL Transformer)|\n|[GraphQLAPINONEDS](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-appsync-datasource.html)|A \"none\" data source that is used for requests that don't exit the AppSync API|\n|[AmplifyDataStore](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-dynamodb-table.html)|The delta sync table used for Amplify DataStore's conflict resolution|\n|[AmplifyDataStoreIAMRole](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-role.html)|IAM role used to access the delta sync table for DataStore|\n|[DynamoDBAccess](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html)|IAM policy to access the DynamoDB resources from AppSync|\n\n## Customize Amplify-generated resources for @model directive\n\nApply all the overrides in the `override(...)` function. Pass in the @model type name into `resources.models[...]` to modify the resources generated for that particular @model type. For example, to enable time-to-live on the Todo `@model` type's DynamoDB table:\n\n```ts\nimport { AmplifyApiGraphQlResourceStackTemplate } from '@aws-amplify/cli-extensibility-helper';\n\nexport function override(resources: AmplifyApiGraphQlResourceStackTemplate) {\n  resources.models[\"Todo\"].modelDDBTable.timeToLiveSpecification = {\n    attributeName: \"ttl\",\n    enabled: true\n  }\n}\n```\n\nYou can override the following @model directive resources that Amplify generates:\n\n|Amplify-generated resource|Description|\n|-|-|\n[modelStack](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-stack.html)|The nested stack containing all resources for the @model type|\n[modelDDBTable](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-dynamodb-table.html)|The DynamoDB table containing the data for this @model type|\n[modelIamRole](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-role.html)|IAM role to access the DynamoDB table for this @model type|\n[modelIamRoleDefaultPolicy](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html)|IAM policy to access the delta sync table for this @model type in case DataStore is enabled|\n[dynamoDBAccess](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html)|Default policy associated with the IAM role to access the DynamoDB table for this @model type|\n[modelDatasource](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-appsync-datasource.html)|The AppSync DataSource to representing the DynamoDB table|\n[invokeLambdaFunction](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html)|IAM policy for Lambda-based conflict resolution function|\n\nFor example, we can override a model generated DynamoDB table configuration. \n\n```ts\nimport { AmplifyApiGraphQlResourceStackTemplate } from '@aws-amplify/cli-extensibility-helper';\n\nexport function override(resources: AmplifyApiGraphQlResourceStackTemplate) {\n  resources.models[\"Todo\"].modelDatasource.dynamoDbConfig['deltaSyncConfig']['baseTableTtl'] = '3600'\n}\n```\n\n## Customize Amplify-generated resources for @searchable (OpenSearch) directive\n\nApply all the overrides in the `override(...)` function. For example, to modify the OpenSearch instance count:\n\n```ts\nimport { AmplifyApiGraphQlResourceStackTemplate } from '@aws-amplify/cli-extensibility-helper';\n\nexport function override(resources: AmplifyApiGraphQlResourceStackTemplate) {\n  resources.opensearch.OpenSearchDomain.elasticsearchClusterConfig = {\n    ...resources.opensearch.OpenSearchDomain.elasticsearchClusterConfig,\n    instanceCount: 6\n  }\n}\n```\n\nYou can override the following @searchable directive resources that Amplify generates:\n\n|Amplify-generated resource|Description|\n|-|-|\n[OpenSearchDataSource](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-appsync-datasource.html)|The AppSync data source representing the OpenSearch integration|\n[OpenSearchAccessIAMRole](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-role.html)|IAM role to access OpenSearch domain|\n[OpenSearchAccessIAMRoleDefaultPolicy](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html)|IAM policy to access OpenSearch domain|\n[OpenSearchDomain](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-elasticsearch-domain.html)|OpenSearch domain containing the @searchable data|\n[OpenSearchStreamingLambdaIAMRole](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-role.html)|IAM role to stream DynamoDB data to OpenSearch domain|\n[OpenSearchStreamingLambdaIAMRoleDefaultPolicy](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html)|IAM policy to stream DynamoDB data to OpenSearch domain|\n[CloudwatchLogsAccess](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html)|IAM policy for granting CloudWatch logs access|\n[OpenSearchStreamingLambdaFunction](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-lambda-function.html)|Lambda function to stream DynamoDB data to OpenSearch domain|\n[OpenSearchModelLambdaMapping](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-lambda-eventsourcemapping.html)|Event source mapping for DynamoDB table stream to Lambda function|\n\n## Customize Amplify-generated resources for @predictions directive\n\nApply all the overrides in the `override(...)` function. For example, to add a Path to IAM role that facilitates text translation:\n\n```ts\nimport { AmplifyApiGraphQlResourceStackTemplate } from '@aws-amplify/cli-extensibility-helper';\n\nexport function override(resources: AmplifyApiGraphQlResourceStackTemplate) {\n  resources.predictions.TranslateDataSourceServiceRole.path = \"/my/organization/\"\n}\n```\n\nYou can override the following @predictions directive resources that Amplify generates:\n\n|Amplify-generated resource|Description|\n|-|-|\n|[RekognitionDataSource](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-appsync-datasource.html)|AppSync HTTP data source to connect to Amazon Rekognition service|\n|[RekognitionDataSourceServiceRole](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-role.html)|AppSync service role to connect to Amazon Rekognition|\n|[TranslateDataSource](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-appsync-datasource.html)|AppSync HTTP data source to connect to Amazon Translate service|\n|[translateTextAccess](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html)|IAM policy to connect to Amazon Translate|\n|[LambdaDataSource](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-appsync-datasource.html)|AppSync Lambda data source to connect to Amazon Polly|\n|[LambdaDataSourceServiceRole](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-role.html)|AppSync service role to connect to Lambda function calling Amazon Polly|\n|[LambdaDataSourceServiceRoleDefaultPolicy](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html)|IAM policy for AppSync to connect to Lambda function calling Amazon Polly|\n|[TranslateDataSourceServiceRole](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-role.html)|AppSync service role to connect to Amazon Translate|\n|[predictionsLambdaIAMRole](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-role.html)|IAM role for Lambda function calling Amazon Polly|\n|[predictionsLambdaFunction](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-lambda-function.html)|Lambda function calling Amazon Polly|\n|[PredictionsLambdaAccess](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html)|IAM policy for Lambda function to access Amazon Polly|\n|[predictionsIAMRole](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-role.html)|IAM role to access s3 bucket used by @predictions|\n|[PredictionsStorageAccess](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html)|IAM policy to access S3 bucket used by @predictions|\n|[identifyTextAccess](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html)|IAM policy to enable Identify Text|\n|[identifyLabelsAccess](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html)|IAM policy to enable Identify Text|\n\n## Place AppSync Resolvers in Custom-named Stacks\n\nIf you have a particularly large GraphQL schema, you may run into issues with too many resources defined in a stack. The most common case where this happens is in the ConnectionStack which contains the resolvers for all of the relational directives in the schema.\n\nCreating a stack mapping does not create an additional root stack for the Amplify environment. All mapped stacks will still be placed under the existing Amplify environment root stack.\nTo map a resolver to a different stack, update `<project root>/amplify/api/<api name>/transform.conf.json` with a \"StackMapping\" block. The StackMapping defines a map from resolver logical ID to stack name.\n\n```json\n{\n  \"Version\": 5,\n  \"ElasticsearchWarning\": true,\n  \"StackMapping\": {\n    \"<Resolver logical ID>\": \"Custom stack name\",\n  }\n}\n```\n\nThe easiest way to determine a resolver logical ID is to run `amplify api gql-compile` and note the resolver logical ID in the list of Resources in the generated CloudFormation stack.\nResolvers for model operations will be of the form `<Get | List | Create | Update | Delete><model name>Resolver`. Resolvers for relational directives are of the form `<model name><field name>Resolver`.\n\n### Example\n\nGiven the following schema:\n\n```graphql\ntype Blog @model {\n  id: ID!\n  name: String!\n  posts: [Post] @hasMany\n}\n\ntype Post @model {\n  id: ID!\n  title: String!\n  content: String\n  blog: Blog @belongsTo\n}\n```\n\nTo map the CreatePostResolver and the relational resolvers to a stack named 'MyCustomStack', add the following in `transform.conf.json`:\n\n```json\n\"StackMapping\": {\n  \"CreatePostResolver\": \"MyCustomStack\",\n  \"BlogpostsResolver\": \"MyCustomStack\",\n  \"PostblogResolver\": \"MyCustomStack\",\n}\n```",
    "meta": {
      "title": "Override Amplify-generated AppSync resources",
      "description": "The \"amplify override api\" command generates a developer-configurable \"overrides\" TypeScript file which provides Amplify-generated AppSync resources as CDK constructs. For example, developers can set api settings that are not directly available in the Amplify CLI workflow, such as X-Ray tracing.",
      "subcategory": "API (GraphQL)",
      "category": "Amplify CLI"
    },
    "filename": "/cli/graphql/override"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "\"Codegen\" generates native code for Swift (iOS), Java (Android), and JavaScript that represent your GraphQL API's data models. It can also generate GraphQL statements (queries, mutations, and subscriptions) so that you don't have to hand code them."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The design of codegen functionality provides mechanisms to run at different points in your app development lifecycle, including when you create or update an API as well as independently when you want to just update the data fetching requirements of your app but leave your API alone. It additionally allows you to work in a team where the schema is updated or managed by another person. Finally, you can also include the codegen in your build process so that it runs automatically (such as from in Xcode)."
      },
      {
        "heading": "Create API then automatically generate code",
        "depth": 2,
        "text": "You’ll see questions as before, but now it will also automatically ask you if you want to generate GraphQL statements and do codegen. It will also respect the ./app/src/main directory for Android projects. After the AppSync deployment finishes the Swift file will be automatically generated (Android you’ll need to kick off a Gradle Build step) and you can begin using in your app immediately."
      },
      {
        "heading": "Create API then automatically generate code",
        "depth": 2,
        "text": "When you deploy your GraphQL API to the cloud, you are prompted to configure codegen. When a project is configured to generate code with codegen, it stores all the configuration .graphqlconfig.yml file in the root folder of your project. To make changes to the configuration, use amplify configure codegen."
      },
      {
        "heading": "Modify GraphQL schema, push, then automatically generate code",
        "depth": 2,
        "text": "During development, you might wish to update your GraphQL schema and generated code as part of an iterative dev/test cycle. Modify & save your schema in amplify/backend/api/<apiname>/schema.graphql then run:"
      },
      {
        "heading": "Modify GraphQL schema, push, then automatically generate code",
        "depth": 2,
        "text": "Each time you will be prompted to update the code in your API and also ask you if you want to run codegen again as well, including regeneration of the GraphQL statements from the new schema."
      },
      {
        "heading": "No API changes, just update GraphQL statements & generate code",
        "depth": 2,
        "text": "One of the benefits of GraphQL is the client can define it's data fetching requirements independently of the API. Amplify codegen supports this by allowing you to modify the selection set (e.g. add/remove fields inside the curly braces) for the GraphQL statements and running type generation again. This gives you fine-grained control over the network requests that your application is making. Modify your GraphQL statements (default in the ./graphql folder unless you changed it) then save the files and run:"
      },
      {
        "heading": "No API changes, just update GraphQL statements & generate code",
        "depth": 2,
        "text": "A new updated Swift file will be created (or run Gradle Build on Android for the same). You can then use the updates in your application code."
      },
      {
        "heading": "Shared schema, modified elsewhere (e.g. console or team workflows)",
        "depth": 2,
        "text": "Suppose you are working in a team and the schema is updated either from the AWS AppSync console or on another system. Your types are now out of date because your GraphQL statement was generated off an outdated schema. The easiest way to resolve this is to regenerate your GraphQL statements, update them if necessary, and then generate your types again. Modify the schema in the console or on a separate system, then run:"
      },
      {
        "heading": "Shared schema, modified elsewhere (e.g. console or team workflows)",
        "depth": 2,
        "text": "You should have newly generated GraphQL statements and Swift code that matches the schema updates. If you ran the second command your types will be updated as well. Alternatively, if you run amplify codegen alone it will perform both of these actions."
      },
      {
        "heading": "Introspection Schema outside of an initialized project",
        "depth": 2,
        "text": "If you would like to generate statements and types without initializing an amplify project, you can do so by providing your introspection schema named schema.json in your project directory and adding codegen from the same directory. To download your introspection schema from an AppSync api, in the AppSync console go to the schema editor and under \"Export schema\" choose schema.json."
      },
      {
        "heading": "Introspection Schema outside of an initialized project",
        "depth": 2,
        "text": "Once codegen has been added you can update your introspection schema, then generate statements and types again without re-entering your project information."
      },
      {
        "heading": "Introspection Schema outside of an initialized project",
        "depth": 2,
        "text": "You can update your project and codegen configuration if required."
      },
      {
        "heading": "Introspection Schema outside of an initialized project",
        "depth": 2,
        "text": "When generating types, codegen uses GraphQL statements as input. It will generate only the types that are being used in the GraphQL statements."
      },
      {
        "heading": "amplify add codegen",
        "depth": 3,
        "text": "The amplify add codegen allows you to add AppSync API created using the AWS console. If you have your API is in a different region then that of your current region, the command asks you to choose the region. If you are adding codegen outside of an initialized amplify project, provide your introspection schema named schema.json in the same directory that you make the add codegen call from.\nNote: If you use the --apiId flag to add an externally created AppSync API, such as one created in the AWS console, you will not be able to manage this API from the Amplify CLI with commands such as amplify api update when performing schema updates. You cannot add an external AppSync API when outside of an initialized project."
      },
      {
        "heading": "amplify configure codegen",
        "depth": 3,
        "text": "The amplify configure codegen command allows you to update the codegen configuration after it is added to your project. When outside of an initialized project, you can use this to update your project configuration as well as the codegen configuration."
      },
      {
        "heading": "amplify codegen statements",
        "depth": 3,
        "text": "The amplify codegen statements command  generates GraphQL statements(queries, mutation and subscription) based on your GraphQL schema. This command downloads introspection schema every time it is run, but it can be forced to use previously downloaded introspection schema by passing --nodownload flag."
      },
      {
        "heading": "amplify codegen types",
        "depth": 3,
        "text": "The amplify codegen types [--nodownload] command generates GraphQL types for Flow and typescript and Swift class in an iOS project. This command downloads introspection schema every time it is run, but it can be forced to use previously downloaded introspection schema by passing --nodownload flag."
      },
      {
        "heading": "amplify codegen",
        "depth": 3,
        "text": "The amplify codegen [--nodownload] generates GraphQL statements and types. This command downloads introspection schema every time it is run but it can be forced to use previously downloaded introspection schema by passing --nodownload flag. If you are running codegen outside of an initialized amplify project, the introspection schema named schema.json must be in the same directory that you run amplify codegen from. This command will not download the introspection schema when outside of an amplify project - it will only use the introspection schema provided."
      },
      {
        "heading": "Statement depth",
        "depth": 2,
        "text": "In the below schema there are connections between Comment -> Post -> Blog -> Post -> Comments. When generating statements codegen has a default limit of 2 for depth traversal. But if you need to go deeper than 2 levels you can change the maxDepth parameter either when setting up your codegen or by passing  --maxDepth parameter to codegen"
      }
    ],
    "source": "export const meta = {\n  title: `JavaScript, Java, Swift code generation`,\n  description: `Amplify's codegen capabilities generates native code for iOS and Android, as well as the generation of types for Flow and TypeScript. It can also generate GraphQL statements(queries, mutations, and subscriptions).`,\n};\n\n<MigrationAlert url={\"/cli-legacy/graphql-transformer/codegen\"}/>\n\n\"Codegen\" generates native code for Swift (iOS), Java (Android), and JavaScript that represent your GraphQL API's data models. It can also generate GraphQL statements (queries, mutations, and subscriptions) so that you don't have to hand code them.\n\nThe design of codegen functionality provides mechanisms to run at different points in your app development lifecycle, including when you create or update an API as well as independently when you want to just update the data fetching requirements of your app but leave your API alone. It additionally allows you to work in a team where the schema is updated or managed by another person. Finally, you can also include the codegen in your build process so that it runs automatically (such as from in Xcode).\n\n## Create API then automatically generate code\n\n```bash\namplify init\namplify add api (select GraphQL)\namplify push\n```\n\nYou’ll see questions as before, but now it will also automatically ask you if you want to generate GraphQL statements and do codegen. It will also respect the `./app/src/main` directory for Android projects. After the AppSync deployment finishes the Swift file will be automatically generated (Android you’ll need to kick off a [Gradle Build step](#androiduse)) and you can begin using in your app immediately.\n\nWhen you deploy your GraphQL API to the cloud, you are prompted to configure codegen. When a project is configured to generate code with codegen, it stores all the configuration `.graphqlconfig.yml` file in the root folder of your project. To make changes to the configuration, use `amplify configure codegen`.\n\n## Modify GraphQL schema, push, then automatically generate code\n\nDuring development, you might wish to update your GraphQL schema and generated code as part of an iterative dev/test cycle. Modify & save your schema in `amplify/backend/api/<apiname>/schema.graphql` then run:\n\n```bash\namplify push\n```\n\nEach time you will be prompted to update the code in your API and also ask you if you want to run codegen again as well, including regeneration of the GraphQL statements from the new schema.\n\n## No API changes, just update GraphQL statements & generate code\n\nOne of the benefits of GraphQL is the client can define it's data fetching requirements independently of the API. Amplify codegen supports this by allowing you to modify the selection set (e.g. add/remove fields inside the curly braces) for the GraphQL statements and running type generation again. This gives you fine-grained control over the network requests that your application is making. Modify your GraphQL statements (default in the `./graphql` folder unless you changed it) then save the files and run:\n\n```bash\namplify codegen types\n```\n\nA new updated Swift file will be created (or run Gradle Build on Android for the same). You can then use the updates in your application code.\n\n## Shared schema, modified elsewhere (e.g. console or team workflows)\n\nSuppose you are working in a team and the schema is updated either from the AWS AppSync console or on another system. Your types are now out of date because your GraphQL statement was generated off an outdated schema. The easiest way to resolve this is to regenerate your GraphQL statements, update them if necessary, and then generate your types again. Modify the schema in the console or on a separate system, then run:\n\n```bash\namplify codegen statements\namplify codegen types\n```\n\nYou should have newly generated GraphQL statements and Swift code that matches the schema updates. If you ran the second command your types will be updated as well. Alternatively, if you run `amplify codegen` alone it will perform both of these actions.\n\n## Introspection Schema outside of an initialized project\n\nIf you would like to generate statements and types without initializing an amplify project, you can do so by providing your introspection schema named `schema.json` in your project directory and adding codegen from the same directory. To download your introspection schema from an AppSync api, in the AppSync console go to the schema editor and under \"Export schema\" choose `schema.json`.\n\n```bash\namplify add codegen\n```\n\nOnce codegen has been added you can update your introspection schema, then generate statements and types again without re-entering your project information.\n\n```bash\namplify codegen\n```\n\nYou can update your project and codegen configuration if required.\n\n```bash\namplify configure codegen\namplify codegen\n```\n\nWhen generating types, codegen uses GraphQL statements as input. It will generate only the types that are being used in the GraphQL statements.\n\n## Codegen commands\n\n### amplify add codegen\n\n```bash\namplify add codegen\n```\n\nThe `amplify add codegen` allows you to add AppSync API created using the AWS console. If you have your API is in a different region then that of your current region, the command asks you to choose the region. If you are adding codegen outside of an initialized amplify project, provide your introspection schema named `schema.json` in the same directory that you make the add codegen call from.\n__Note__: If you use the --apiId flag to add an externally created AppSync API, such as one created in the AWS console, you will not be able to manage this API from the Amplify CLI with commands such as amplify api update when performing schema updates. You cannot add an external AppSync API when outside of an initialized project.\n\n### amplify configure codegen\n\n```bash\namplify configure codegen\n```\n\nThe `amplify configure codegen` command allows you to update the codegen configuration after it is added to your project. When outside of an initialized project, you can use this to update your project configuration as well as the codegen configuration.\n\n### amplify codegen statements\n\n```bash\namplify codegen statements [--nodownload] [--maxDepth <int>]\n```\n\nThe `amplify codegen statements` command  generates GraphQL statements(queries, mutation and subscription) based on your GraphQL schema. This command downloads introspection schema every time it is run, but it can be forced to use previously downloaded introspection schema by passing `--nodownload` flag.\n\n### amplify codegen types\n\n```bash\namplify codegen types\n```\n\nThe `amplify codegen types [--nodownload]` command generates GraphQL `types` for Flow and typescript and Swift class in an iOS project. This command downloads introspection schema every time it is run, but it can be forced to use previously downloaded introspection schema by passing `--nodownload` flag.\n\n### amplify codegen\n\n```bash\namplify codegen [--maxDepth <int>]\n```\n\nThe `amplify codegen [--nodownload]` generates GraphQL `statements` and `types`. This command downloads introspection schema every time it is run but it can be forced to use previously downloaded introspection schema by passing `--nodownload` flag. If you are running codegen outside of an initialized amplify project, the introspection schema named `schema.json` must be in the same directory that you run amplify codegen from. This command will not download the introspection schema when outside of an amplify project - it will only use the introspection schema provided.\n\n## Statement depth\n\nIn the below schema there are connections between `Comment` -> `Post` -> `Blog` -> `Post` -> `Comments`. When generating statements codegen has a default limit of 2 for depth traversal. But if you need to go deeper than 2 levels you can change the `maxDepth` parameter either when setting up your codegen or by passing  `--maxDepth` parameter to `codegen`\n\n```graphql\ntype Blog @model {\n  id: ID!\n  name: String!\n  posts: [Post] @hasMany\n}\ntype Post @model {\n  id: ID!\n  title: String!\n  blog: Blog @belongsTo\n  comments: [Comment] @hasMany\n}\ntype Comment @model {\n  id: ID!\n  content: String\n  post: Post @belongsTo\n}\n```\n\n```graphql\nquery GetComment($id: ID!) {\n  getComment(id: $id) { # depth level 1\n    id\n    content\n    post { # depth level 2\n      id\n      title\n      blog { # depth level 3\n        id\n        name\n        posts { # depth level 4\n          items { # depth level 5\n            id\n            title\n          }\n          nextToken\n        }\n      }\n      comments { # depth level 3\n        items { # depth level 4\n          id\n          content\n          post { # depth level 5\n            id\n            title\n          }\n        }\n        nextToken\n      }\n    }\n  }\n}\n```\n",
    "meta": {
      "title": "JavaScript, Java, Swift code generation",
      "description": "Amplify's codegen capabilities generates native code for iOS and Android, as well as the generation of types for Flow and TypeScript. It can also generate GraphQL statements(queries, mutations, and subscriptions).",
      "subcategory": "API (GraphQL)",
      "category": "Amplify CLI"
    },
    "filename": "/cli/graphql/client-code-generation"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "GraphQL schemas change over the lifecycle of a project. Sometimes these changes include breaking API changes. One such change is renaming a model in the schema, which Amplify offers a way to do while retaining the underlying records for that model."
      },
      {
        "heading": "Renaming models while retaining data",
        "depth": 2,
        "text": "Amplify supports renaming models in a GraphQL schema by using the @mapsTo directive.\nNormally when renaming a model, Amplify will remove the underlying table for the model and create a new table with the new name. Once a table contains production data that cannot be deleted, @mapsTo can be used to specify the original name. Amplify will use the original name to ensure the underlying DynamoDB tables and other resources point to the existing data.\nOther GraphQL API references to the model will use the new name."
      },
      {
        "heading": "Renaming models while retaining data",
        "depth": 2,
        "text": "For example, a schema such as:"
      },
      {
        "heading": "Renaming models while retaining data",
        "depth": 2,
        "text": "becomes:"
      },
      {
        "heading": "Renaming models while retaining data",
        "depth": 2,
        "text": "Amplify will update all of the GraphQL operations and types to use the name Task, but the Task model will point to the table that Todo was originally using."
      },
      {
        "heading": "Renaming models while retaining data",
        "depth": 2,
        "text": "@mapsTo cannot be used to point a model to an arbitrarily named table. It can only be used to point a renamed model to it's original name."
      },
      {
        "heading": "Renaming models while retaining data",
        "depth": 2,
        "text": "@mapsTo can only be used on @model GraphQL types that are backed by a DynamoDB table."
      },
      {
        "heading": "Renaming models while retaining data",
        "depth": 2,
        "text": "When renaming a model that has relationships with other models, Amplify will automatically map auto-generated foreign key fields to their original name. For example, given:"
      },
      {
        "heading": "Renaming models while retaining data",
        "depth": 2,
        "text": "Amplify will automatically add a field named postCommentsId to the Comment model that contains the foreign key of the Post. If the Post type is renamed to Article:"
      },
      {
        "heading": "Renaming models while retaining data",
        "depth": 2,
        "text": "The underlying table still contains records with postCommentsId as the foreign key field in the Comment table. In the new schema the foreign key field is now articleCommentsId.\nAmplify is aware of this and will automatically map incoming requests with articleCommentsId to postCommentsId and do the reverse mapping for results."
      },
      {
        "heading": "Constraint on relationship field names with @mapsTo",
        "depth": 3,
        "text": "In the above example if you renamed Comment to Reaction:"
      },
      {
        "heading": "Constraint on relationship field names with @mapsTo",
        "depth": 3,
        "text": "The @hasMany field comments cannot be renamed to reactions. This is because the foreign key field in Reaction uses the parent field name as part of the name. Amplify cannot determine the original name if this is changed."
      },
      {
        "heading": "Constraint on relationship field names with @mapsTo",
        "depth": 3,
        "text": "If a model is renamed multiple times, the value specified in @mapsTo must be the original name, not the previous name."
      },
      {
        "heading": "Constraints to prevent naming conflicts",
        "depth": 3,
        "text": "A model in the schema cannot have the same name as the name another type maps to. For example, the following schema is invalid:"
      },
      {
        "heading": "Constraints to prevent naming conflicts",
        "depth": 3,
        "text": "This schema would create a conflict on the Post table."
      },
      {
        "heading": "Constraints to prevent naming conflicts",
        "depth": 3,
        "text": "Furthermore, even if the Post model is mapped to a different name, it is still not allowed. While this scenario technically does not pose a conflict, it is disallowed to prevent confusion."
      },
      {
        "heading": "Constraints to prevent naming conflicts",
        "depth": 3,
        "text": "If you are accessing the table of a renamed model directly (ie. without going through AppSync), your access patterns will need to be aware that foreign key fields of records in the database are not renamed. See \"How it works\" below."
      },
      {
        "heading": "How it works",
        "depth": 2,
        "text": "@mapsTo does not modify any existing tables or records. Instead, it points AppSync resolvers for the new name to the existing DynamoDB table for the original name."
      },
      {
        "heading": "How it works",
        "depth": 2,
        "text": "To handle renamed autogenerated foreign key fields when using relational directives, Amplify adds additional AppSync pipeline resolvers before and after fetching data from the database.\nThe resolvers before the fetch map any occurrence of the renamed foreign keys in the request to the original name. Then the resolvers after the fetch map any occurrence of the original name to the current name before returning the result."
      }
    ],
    "source": "export const meta = {\n  title: `Evolving GraphQL schemas`,\n  description: `Evolve your GraphQL schema over time using the @mapsTo directive to retain tables while renaming models`,\n};\n\nGraphQL schemas change over the lifecycle of a project. Sometimes these changes include breaking API changes. One such change is renaming a model in the schema, which Amplify offers a way to do while retaining the underlying records for that model.\n\n## Renaming models while retaining data\n\nAmplify supports renaming models in a GraphQL schema by using the `@mapsTo` directive. \nNormally when renaming a model, Amplify will remove the underlying table for the model and create a new table with the new name. Once a table contains production data that cannot be deleted, `@mapsTo` can be used to specify the original name. Amplify will use the original name to ensure the underlying DynamoDB tables and other resources point to the existing data.\nOther GraphQL API references to the model will use the new name.\n\nFor example, a schema such as:\n```graphql\ntype Todo @model {\n  id: ID!\n  title: String!\n}\n```\nbecomes:\n```graphql\ntype Task @model @mapsTo(name: \"Todo\") {\n  id: ID!\n  title: String!\n}\n```\nAmplify will update all of the GraphQL operations and types to use the name Task, but the Task model will point to the table that Todo was originally using.\n\n<Callout>\n\n- `@mapsTo` cannot be used to point a model to an arbitrarily named table. It can only be used to point a renamed model to it's original name.\n- `@mapsTo` can only be used on @model GraphQL types that are backed by a DynamoDB table.\n\n</Callout>\n\nWhen renaming a model that has relationships with other models, Amplify will automatically map auto-generated foreign key fields to their original name. For example, given:\n\n```graphql\ntype Post @model {\n  id: ID!\n  title: String!\n  comments: [Comment] @hasMany\n}\n\ntype Comment @model {\n  id: ID!\n  message: String!\n  # postCommentsId: String is an autogenerated field containing the foreign key\n}\n```\nAmplify will automatically add a field named `postCommentsId` to the Comment model that contains the foreign key of the Post. If the Post type is renamed to Article:\n\n```graphql\ntype Article @model @mapsTo(name: \"Post\") {\n  id: ID!\n  title: String!\n  comments: [Comment] @hasMany\n}\n\ntype Comment @model {\n  id: ID!\n  message: String!\n  # articleCommentsId: String is the new autogenerated field containing the foreign key\n}\n```\nThe underlying table still contains records with `postCommentsId` as the foreign key field in the Comment table. In the new schema the foreign key field is now `articleCommentsId`.\nAmplify is aware of this and will automatically map incoming requests with `articleCommentsId` to `postCommentsId` and do the reverse mapping for results.\n\n## Limitations \n\n### Constraint on relationship field names with @mapsTo\n\nIn the above example if you renamed Comment to Reaction:\n```graphql\ntype Post @model {\n  id: ID!\n  title: String!\n  comments: [Reaction] @hasMany # this field cannot be renamed and still access existing relationship data\n}\n\ntype Reaction @model @mapsTo(name: \"Comment\") {\n  id: ID!\n  message: String!\n  # autogenerated field postCommentsId: String contains the foreign key\n}\n```\nThe `@hasMany` field `comments` cannot be renamed to `reactions`. This is because the foreign key field in Reaction uses the parent field name as part of the name. Amplify cannot determine the original name if this is changed.\n\nIf a model is renamed multiple times, the value specified in `@mapsTo` must be the _original_ name, not the previous name.\n\n### Constraints to prevent naming conflicts\n\nA model in the schema cannot have the same name as the name another type maps to. For example, the following schema is invalid:\n```graphql\ntype Article @model @mapsTo(name: \"Post\") {\n  id: ID!\n}\n\ntype Post @model {\n  id: ID!\n}\n```\nThis schema would create a conflict on the Post table.\n\nFurthermore, even if the Post model is mapped to a different name, it is still not allowed. While this scenario technically does not pose a conflict, it is disallowed to prevent confusion.\n\nIf you are accessing the table of a renamed model directly (ie. without going through AppSync), your access patterns will need to be aware that foreign key fields of records in the database are not renamed. See \"How it works\" below.\n\n## How it works\n`@mapsTo` does not modify any existing tables or records. Instead, it points AppSync resolvers for the new name to the existing DynamoDB table for the original name.\n\nTo handle renamed autogenerated foreign key fields when using relational directives, Amplify adds additional AppSync pipeline resolvers before and after fetching data from the database.\nThe resolvers before the fetch map any occurrence of the renamed foreign keys in the request to the original name. Then the resolvers after the fetch map any occurrence of the original name to the current name before returning the result.",
    "meta": {
      "title": "Evolving GraphQL schemas",
      "description": "Evolve your GraphQL schema over time using the @mapsTo directive to retain tables while renaming models",
      "subcategory": "API (GraphQL)",
      "category": "Amplify CLI"
    },
    "filename": "/cli/graphql/schema-evolution"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Amplify allows you to identify text on an image, identify labels on an image, translate text, and synthesize speech from text with the @predictions directive."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Note: The @predictions directive requires a S3 storage bucket configured via amplify add storage."
      },
      {
        "heading": "Identify text on an image",
        "depth": 2,
        "text": "To configure text recognition on an image use the identifyText action in the @predictions directive."
      },
      {
        "heading": "Identify text on an image",
        "depth": 2,
        "text": "In your GraphQL query, can pass in a S3 key for the image. At the moment, this directive works only with objects located within the public/ folder of your S3 bucket. The public/ prefix is automatically added to the key input. For instance, in the example below, public/myimage.jpg will be used as the input."
      },
      {
        "heading": "Identify labels on an image",
        "depth": 2,
        "text": "To configure label recognition on an image use the identifyLabels action in the @predictions directive."
      },
      {
        "heading": "Identify labels on an image",
        "depth": 2,
        "text": "In your GraphQL query, you can pass in a S3 key for the image. At the moment, this directive works only with objects located within public/ folder in your S3 bucket. The public/ prefix is automatically added to the key input. For instance, in the example below, public/myimage.jpg will be used as the input."
      },
      {
        "heading": "Identify labels on an image",
        "depth": 2,
        "text": "The query below will return a list of identified labels. Review Detecting Labels in the Amazon Rekognition documentation for the full list of supported labels."
      },
      {
        "heading": "Translate text",
        "depth": 2,
        "text": "To configure text translation use the identifyLabels action in the @predictions directive."
      },
      {
        "heading": "Translate text",
        "depth": 2,
        "text": "The query below will return the translated string. Populate the sourceLanguage and targetLanguage parameters with one of the Supported Language Codes. Pass in the text to translate via the text parameter."
      },
      {
        "heading": "Synthesize speech from text",
        "depth": 2,
        "text": "To configure Text-to-Speech synthesis use the convertTextToSpeech action in the @predictions directive."
      },
      {
        "heading": "Synthesize speech from text",
        "depth": 2,
        "text": "The query below will return a presigned URL with the synthesized speech. Populate the voiceID parameter with one of the Supported Voice IDs. Pass in the text to synthesize via the text parameter."
      },
      {
        "heading": "Combining Predictions actions",
        "depth": 2,
        "text": "You can also combine multiple Predictions actions together into a sequence. The following action sequences are supported:"
      },
      {
        "heading": "Combining Predictions actions",
        "depth": 2,
        "text": "identifyText -> translateText -> convertTextToSpeech"
      },
      {
        "heading": "Combining Predictions actions",
        "depth": 2,
        "text": "identifyLabels -> translateText -> convertTextToSpeech"
      },
      {
        "heading": "Combining Predictions actions",
        "depth": 2,
        "text": "translateText -> convertTextToSpeech"
      },
      {
        "heading": "Combining Predictions actions",
        "depth": 2,
        "text": "In the example below, speakTranslatedImageText identifies text from an image, then translates it into another language, and finally converts the translated text to speech."
      },
      {
        "heading": "Combining Predictions actions",
        "depth": 2,
        "text": "An example of that query will look like:"
      },
      {
        "heading": "Combining Predictions actions",
        "depth": 2,
        "text": "A code example of this using the JS Library is shown below:"
      },
      {
        "heading": "How it works",
        "depth": 2,
        "text": "Definition of the @predictions directive:"
      },
      {
        "heading": "How it works",
        "depth": 2,
        "text": "@predictions creates resources to communicate with Amazon Rekognition, Translate, and Polly.\nFor each action the following is created:"
      },
      {
        "heading": "How it works",
        "depth": 2,
        "text": "IAM Policy for each service (e.g. Amazon Rekognition detectText Policy)"
      },
      {
        "heading": "How it works",
        "depth": 2,
        "text": "An AppSync VTL function"
      },
      {
        "heading": "How it works",
        "depth": 2,
        "text": "An AppSync DataSource"
      },
      {
        "heading": "How it works",
        "depth": 2,
        "text": "Finally, a pipeline resolver is created for the query or field. The pipeline resolver is composed of AppSync functions which are defined by the action list provided in the directive."
      }
    ],
    "source": "export const meta = {\n  title: `Connect to machine learning services`,\n  description: `Add AI/ML capabilities such as text recognition, image labeling, text-to-speech, and translation to your GraphQL API.`,\n};\n\n<MigrationAlert url={\"/cli-legacy/graphql-transformer/predictions\"}/>\n\nAmplify allows you to identify text on an image, identify labels on an image, translate text, and synthesize speech from text with the `@predictions` directive.\n\n> Note: The `@predictions` directive requires a S3 storage bucket configured via `amplify add storage`. \n\n## Identify text on an image\n\nTo configure text recognition on an image use the `identifyText` action in the `@predictions` directive.\n\n```graphql\ntype Query {\n  recognizeTextFromImage: String @predictions(actions: [identifyText])\n}\n```\n\nIn your GraphQL query, can pass in a S3 `key` for the image. At the moment, this directive works only with objects located within the `public/` folder of your S3 bucket. The `public/` prefix is automatically added to the `key` input. For instance, in the example below, `public/myimage.jpg` will be used as the input. \n\n```graphql\nquery RecognizeTextFromImage($input: RecognizeTextFromImageInput!) {\n  recognizeTextFromImage(input: {\n    identifyText: {\n      key: \"myimage.jpg\"\n    }\n  })\n}\n```\n\n## Identify labels on an image\n\nTo configure label recognition on an image use the `identifyLabels` action in the `@predictions` directive.\n\n```graphql\ntype Query {\n  recognizeLabelsFromImage: [String] @predictions(actions: [identifyLabels])\n}\n```\n\nIn your GraphQL query, you can pass in a S3 `key` for the image. At the moment, this directive works only with objects located within `public/` folder in your S3 bucket. The `public/` prefix is automatically added to the `key` input. For instance, in the example below, `public/myimage.jpg` will be used as the input. \n\nThe query below will return a list of identified labels. Review [Detecting Labels](https://docs.aws.amazon.com/rekognition/latest/dg/labels.html) in the Amazon Rekognition documentation for the full list of supported labels.\n\n```graphql\nquery RecognizeLabelsFromImage($input: RecognizeLabelsFromImageInput!) {\n  recognizeLabelsFromImage(input: {\n    identifyLabels: {\n      key: \"myimage.jpg\"\n    }\n  })\n}\n```\n\n## Translate text\n\nTo configure text translation use the `identifyLabels` action in the `@predictions` directive. \n\n```graphql\ntype Query {\n  translate: String @predictions(actions: [translateText])\n}\n```\n\nThe query below will return the translated string. Populate the `sourceLanguage` and `targetLanguage` parameters with one of the [Supported Language Codes](https://docs.aws.amazon.com/translate/latest/dg/what-is.html#what-is-languages). Pass in the text to translate via the `text` parameter.\n\n```graphql\nquery TranslateText($input: TranslateTextInput!) {\n  translate(input: {\n    translateText: {\n      sourceLanguage: \"en\"\n      targetLanguage: \"de\"\n      text: \"Translate me\"\n    }\n  })\n}\n```\n\n## Synthesize speech from text\n\nTo configure Text-to-Speech synthesis use the `convertTextToSpeech` action in the `@predictions` directive. \n\n```graphql\ntype Query {\n  textToSpeech: String @predictions(actions: [convertTextToSpeech])\n}\n```\n\nThe query below will return a presigned URL with the synthesized speech. Populate the `voiceID` parameter with one of the [Supported Voice IDs](https://docs.aws.amazon.com/polly/latest/dg/voicelist.htm). Pass in the text to synthesize via the `text` parameter.\n\n```graphql\nquery ConvertTextToSpeech($input: ConvertTextToSpeechInput!) {\n  textToSpeech(input: {\n    convertTextToSpeech: {\n      voiceID: \"Nicole\"\n      text: \"Hello from AWS Amplify!\"\n    }\n  })\n}\n```\n\n## Combining Predictions actions\n\nYou can also combine multiple Predictions actions together into a sequence. The following action sequences are supported:\n- `identifyText -> translateText -> convertTextToSpeech`\n- `identifyLabels -> translateText -> convertTextToSpeech`\n- `translateText -> convertTextToSpeech`\n\nIn the example below, `speakTranslatedImageText` identifies text from an image, then translates it into another language, and finally converts the translated text to speech.\n\n```graphql\ntype Query {\n  speakTranslatedImageText: String @predictions(actions: [\n    identifyText\n    translateText\n    convertTextToSpeech\n  ])\n}\n```\n\nAn example of that query will look like:\n\n```graphql\nquery SpeakTranslatedImageText($input: SpeakTranslatedImageTextInput!) {\n  speakTranslatedImageText(input: {\n    identifyText: {\n      key: \"myimage.jpg\"\n    }\n    translateText: {\n      sourceLanguage: \"en\"\n      targetLanguage: \"es\"\n    }\n    convertTextToSpeech: {\n      voiceID: \"Conchita\"\n    }\n  })\n}\n```\n\nA code example of this using the JS Library is shown below:\n\n```js\nimport React, { useState } from 'react';\nimport { Amplify, Storage, API, graphqlOperation } from 'aws-amplify';\nimport awsconfig from './aws-exports';\nimport { speakTranslatedImageText } from './graphql/queries';\n\n/* Configure Exports */\nAmplify.configure(awsconfig);\n\nfunction SpeakTranslatedImage() {\n  const [src, setSrc] = useState(\"\");\n  const [img, setImg] = useState(\"\");\n\n  function putS3Image(event) {\n    const file = event.target.files[0];\n    Storage.put(file.name, file)\n    .then(async (result) => {\n      setSrc(await speakTranslatedImageTextOP(result.key))\n      setImg(await Storage.get(result.key));\n    })\n    .catch(err => console.log(err));\n  }\n\n  return (\n    <div className=\"Text\">\n      <div>\n        <h3>Upload Image</h3>\n        <input\n          type = \"file\" accept='image/jpeg'\n          onChange = {(event) => {\n            putS3Image(event)\n          }}\n          />\n        <br />\n        { img && <img src = {img}></img>}\n        { src &&\n          <div> \n            <audio id=\"audioPlayback\" controls>\n              <source id=\"audioSource\" type=\"audio/mp3\" src = {src}/>\n            </audio>\n          </div>\n        }\n      </div>\n    </div>\n  );\n}\n\nasync function speakTranslatedImageTextOP(key) {\n  const inputObj = {\n    translateText: {\n      sourceLanguage: \"en\",\n      targetLanguage: \"es\"\n    },\n    identifyText: { key },\n    convertTextToSpeech: { voiceID: \"Conchita\" }\n  };\n  const response = await API.graphql(\n    graphqlOperation(speakTranslatedImageText, { input: inputObj }));\n  return response.data.speakTranslatedImageText;\n}\nfunction App() {\n  return (\n    <div className=\"App\">\n      <h1>Speak Translated Image</h1>\n      <SpeakTranslatedImage />\n    </div>\n  );\n}\nexport default App;\n```\n\n## How it works\n\nDefinition of the `@predictions` directive:\n\n```graphql\ndirective @predictions(actions: [PredictionsActions!]!) on FIELD_DEFINITION\nenum PredictionsActions {\n  identifyText # uses Amazon Rekognition to detect text\n  identifyLabels # uses Amazon Rekognition to detect labels\n  convertTextToSpeech # uses Amazon Polly in a lambda to output a presigned url to synthesized speech\n  translateText # uses Amazon Translate to translate text from source to target language\n}\n```\n\n`@predictions` creates resources to communicate with Amazon Rekognition, Translate, and Polly.\nFor each action the following is created:\n\n- IAM Policy for each service (e.g. Amazon Rekognition `detectText` Policy)\n- An AppSync VTL function\n- An AppSync DataSource\n\nFinally, a pipeline resolver is created for the query or field. The pipeline resolver is composed of AppSync functions which are defined by the action list provided in the directive.",
    "meta": {
      "title": "Connect to machine learning services",
      "description": "Add AI/ML capabilities such as text recognition, image labeling, text-to-speech, and translation to your GraphQL API.",
      "subcategory": "API (GraphQL)",
      "category": "Amplify CLI"
    },
    "filename": "/cli/graphql/connect-to-machine-learning-services"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Add the @searchable directive to an @model type to enable OpenSearch-based data search and result aggregations. This gives you the ability to:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "search for data using advanced filters, such as substring matching, wildcards, regex, and/or/not conditions"
      },
      {
        "heading": null,
        "depth": null,
        "text": "get aggregation values, such as sum, average, min, max, terms"
      },
      {
        "heading": null,
        "depth": null,
        "text": "retrieve total search result count"
      },
      {
        "heading": null,
        "depth": null,
        "text": "sort the search results across one or multiple fields"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Once the @searchable directive is added, all new records added to the model are streamed to OpenSearch. To backfill existing data, see Backfill OpenSearch index from DynamoDB table."
      },
      {
        "heading": "Search and filter data",
        "depth": 2,
        "text": "Every model with a @searchable directive attached generates a new \"search\" GraphQL query to search and filter for records. The example above provides you the ability to search for \"Student\" records using a \"searchStudents\" query."
      },
      {
        "heading": "Search and filter data",
        "depth": 2,
        "text": "The filter parameter allows you to filter for records based on their field values."
      },
      {
        "heading": "Search and filter data",
        "depth": 2,
        "text": "In the example above, the search result consists of students with the name \"Rene Brandel\""
      },
      {
        "heading": "Supported search operations",
        "depth": 3,
        "text": "|Field type|Supported search operations|\n|-|-|\n|String|ne, eq, match, matchPhrase, matchPhrasePrefix, multiMatch, exists, wildcard, regexp|\n|Int|ne, gt, lt, gte, lte, eq, range|\n|Float|ne, gt, lt, gte, lte, eq, range|\n|Boolean|eq, ne|\n|Enum|ne, eq, match, matchPhrase, matchPhrasePrefix, multiMatch, exists, wildcard, regexp|"
      },
      {
        "heading": "Nested search conditions (and, or, not)",
        "depth": 3,
        "text": "Use the filter parameter to pass a nested and/or/not condition."
      },
      {
        "heading": "Nested search conditions (and, or, not)",
        "depth": 3,
        "text": "By default, every operation in the filter properties is anded. Use the or or not properties in the search query's filter parameter to override this behavior."
      },
      {
        "heading": "Nested search conditions (and, or, not)",
        "depth": 3,
        "text": "The query above returns a \"Student\" if:"
      },
      {
        "heading": "Nested search conditions (and, or, not)",
        "depth": 3,
        "text": "their name ends with \"Brandel\""
      },
      {
        "heading": "Nested search conditions (and, or, not)",
        "depth": 3,
        "text": "and"
      },
      {
        "heading": "Nested search conditions (and, or, not)",
        "depth": 3,
        "text": "their date of birth is earlier than 2000-01-01"
      },
      {
        "heading": "Nested search conditions (and, or, not)",
        "depth": 3,
        "text": "or"
      },
      {
        "heading": "Nested search conditions (and, or, not)",
        "depth": 3,
        "text": "their email exists."
      },
      {
        "heading": "Sort search results",
        "depth": 2,
        "text": "Use the sort parameter to sort your search results by a field in ascending or descending order. The field argument accepts any field available on the model. The direction accepts either asc or desc."
      },
      {
        "heading": "Sort search results",
        "depth": 2,
        "text": "In the example above, the search result is sorted based on their name in a descending order."
      },
      {
        "heading": "Sort search result over multiple fields",
        "depth": 3,
        "text": "To sort over multiple fields, provide array of sort conditions. When sorting over multiple fields, the sort conditions are applied in the sort array's order."
      },
      {
        "heading": "Sort search result over multiple fields",
        "depth": 3,
        "text": "In the example above, the search result is first sorted by name in a descending order and then by dateOfBirth in an ascending order."
      },
      {
        "heading": "Paginate over search results",
        "depth": 2,
        "text": "By default, the search result page size is 100. To customize the page size modify the limit parameter. Query for the nextToken and use it in your subsequent pagination requests:"
      },
      {
        "heading": "Total count of search results",
        "depth": 2,
        "text": "Add the total field in your query response to get the total count of search result hits."
      },
      {
        "heading": "Total count of search results",
        "depth": 2,
        "text": "In the example above, the response's total field contains the total search result count for \"Students\" whose name ends with \"Brandel\".\nNote: total is calculated based on all records, irrespective of pagination configurations."
      },
      {
        "heading": "Aggregate values for search result (minimum, maximum, average, sum, terms)",
        "depth": 2,
        "text": "Use the aggregates parameter to get aggregate values such as \"minimum\", \"maximum\", \"average\", and \"sum\" returned in the aggregateItems field.\nNote: aggregates are calculated based on all records, irrespective of pagination configurations."
      },
      {
        "heading": "Aggregate values for search result (minimum, maximum, average, sum, terms)",
        "depth": 2,
        "text": "Provide the min value as the aggregate type and specify the aggregateItems in the response field."
      },
      {
        "heading": "Aggregate values for search result (minimum, maximum, average, sum, terms)",
        "depth": 2,
        "text": "In the example above, the response includes the minimum value of \"examsCompleted\" for all Students whose name starts with \"Rene\"."
      },
      {
        "heading": "Aggregate values for search result (minimum, maximum, average, sum, terms)",
        "depth": 2,
        "text": "Provide the max value as the aggregate type and specify the aggregateItems in the response field."
      },
      {
        "heading": "Aggregate values for search result (minimum, maximum, average, sum, terms)",
        "depth": 2,
        "text": "In the example above, the response includes the maximum value of \"examsCompleted\" for all Students whose name starts with \"Rene\"."
      },
      {
        "heading": "Aggregate values for search result (minimum, maximum, average, sum, terms)",
        "depth": 2,
        "text": "Provide the avg value as the aggregate type and specify the aggregateItems in the response field."
      },
      {
        "heading": "Aggregate values for search result (minimum, maximum, average, sum, terms)",
        "depth": 2,
        "text": "In the example above, the response includes the average value of \"examsCompleted\" for all Students whose name starts with \"Rene\"."
      },
      {
        "heading": "Aggregate values for search result (minimum, maximum, average, sum, terms)",
        "depth": 2,
        "text": "Provide the sum value as the aggregate type and specify the aggregateItems in the response field."
      },
      {
        "heading": "Aggregate values for search result (minimum, maximum, average, sum, terms)",
        "depth": 2,
        "text": "In the example above, the response includes the sum of all \"examsCompleted\" values for all Students whose name starts with \"Rene\"."
      },
      {
        "heading": "Aggregate values for search result (minimum, maximum, average, sum, terms)",
        "depth": 2,
        "text": "Provide the terms value as the aggregate type and specify the aggregateItems in the response field."
      },
      {
        "heading": "Aggregate values for search result (minimum, maximum, average, sum, terms)",
        "depth": 2,
        "text": "In the example above, the response includes the terms for the description and their count:"
      },
      {
        "heading": "Set up OpenSearch for production environments",
        "depth": 2,
        "text": "By default, Amplify CLI will configure a t2.small instance type. This is great for getting started and prototyping but not recommended to be used in the production environment per the OpenSearch best practices."
      },
      {
        "heading": "Set up OpenSearch for production environments",
        "depth": 2,
        "text": "To configure the OpenSearch instance type per environment:"
      },
      {
        "heading": "Set up OpenSearch for production environments",
        "depth": 2,
        "text": "Run amplify env add to create a new environment (e.g. \"prod\")"
      },
      {
        "heading": "Set up OpenSearch for production environments",
        "depth": 2,
        "text": "Edit the amplify/team-provider-info.json file and set OpenSearchInstanceType to the instance type that works for your application"
      },
      {
        "heading": "Set up OpenSearch for production environments",
        "depth": 2,
        "text": "Deploy your changes with amplify push"
      },
      {
        "heading": "Set up OpenSearch for production environments",
        "depth": 2,
        "text": "Learn more about Amazon OpenSearch Service instance types here."
      },
      {
        "heading": "How it works",
        "depth": 2,
        "text": "The @searchable directive streams the data of an @model type to Amazon OpenSearch Service and configures search resolvers to query against OpenSearch."
      },
      {
        "heading": "How it works",
        "depth": 2,
        "text": "Type definition of the @searchable directive:"
      }
    ],
    "source": "export const meta = {\n  title: `Search and result aggregations`,\n  description: `Add authorization rules to your GraphQL schema to control access to your data.`,\n};\n\n<MigrationAlert url={\"/cli-legacy/graphql-transformer/searchable\"}/>\n\nAdd the `@searchable` directive to an `@model` type to enable OpenSearch-based data search and result aggregations. This gives you the ability to:\n- search for data using advanced filters, such as substring matching, wildcards, regex, `and`/`or`/`not` conditions\n- get aggregation values, such as sum, average, min, max, terms\n- retrieve total search result count\n- sort the search results across one or multiple fields\n\n```graphql\ntype Student @model @searchable {\n  name: String\n  dateOfBirth: AWSDate\n  email: AWSEmail\n  examsCompleted: Int\n}\n```\n\n> Once the `@searchable` directive is added, all new records added to the model are streamed to OpenSearch. To backfill existing data, see [Backfill OpenSearch index from DynamoDB table](/cli/graphql/troubleshooting#backfill-opensearch-index-from-dynamodb-table).\n\n## Search and filter data\n\nEvery model with a `@searchable` directive attached generates a new \"search\" GraphQL query to search and filter for records. The example above provides you the ability to search for \"Student\" records using a \"searchStudents\" query.  \n\nThe `filter` parameter allows you to filter for records based on their field values. \n\n```graphql\nquery SearchStudentsByEmail {\n  searchStudents(filter: { name: { eq: \"Rene Brandel\" }}) {\n    items {\n      id\n      name\n      email\n    }\n  }\n}\n```\n\nIn the example above, the search result consists of students with the name \"Rene Brandel\"\n\n### Supported search operations\n\n|Field type|Supported search operations|\n|-|-|\n|String|ne, eq, match, matchPhrase, matchPhrasePrefix, multiMatch, exists, wildcard, regexp|\n|Int|ne, gt, lt, gte, lte, eq, range|\n|Float|ne, gt, lt, gte, lte, eq, range|\n|Boolean|eq, ne|\n|Enum|ne, eq, match, matchPhrase, matchPhrasePrefix, multiMatch, exists, wildcard, regexp|\n\n### Nested search conditions (and, or, not)\nUse the filter parameter to pass a nested `and`/`or`/`not` condition. \n\n```graphql\nquery MyQuery {\n  searchStudents(filter: {\n    name: {wildcard: \"*Brandel\"}\n    or: [\n      { dateOfBirth: { lt: \"2000-01-01\" } },\n      { email: { exists: true } }\n    ]\n  }) {\n    items {\n      id\n      name\n      email\n      dateOfBirth\n    }\n  }\n}\n```\n\nBy default, every operation in the filter properties is `and`ed. Use the `or` or `not` properties in the search query's `filter` parameter to override this behavior. \n\nThe query above returns a \"Student\" if:\n- their name ends with \"Brandel\"\n- `and`\n  - their date of birth is earlier than 2000-01-01\n  - `or`\n  - their email exists. \n\n## Sort search results\n\nUse the `sort` parameter to sort your search results by a field in ascending or descending order. The `field` argument accepts any field available on the model. The `direction` accepts either `asc` or `desc`. \n\n```graphql\nquery SearchAndSort {\n  searchStudents(\n    filter: { name: { wildcard: \"*Brandel\" } },\n    sort: { direction: desc, field: name }\n  ) {\n    items {\n      name\n      id\n    }\n  }\n}\n```\n\nIn the example above, the search result is sorted based on their `name` in a `desc`ending order.\n\n### Sort search result over multiple fields\n\nTo sort over multiple fields, provide array of sort conditions. When sorting over multiple fields, the sort conditions are applied in the `sort` array's order.\n\n```graphql\nquery SearchAndSort {\n  searchStudents(\n    filter: {name: {wildcard: \"*Brandel\"}},\n    sort: [\n      {field: name, direction: desc}, # Sort condition #1\n      {field: dateOfBirth, direction: asc} # Sort condition #2\n    ]  \n  ) {\n    items {\n      id\n      name\n      dateOfBirth\n    }\n  }\n}\n```\n\nIn the example above, the search result is first sorted by `name` in a `desc`ending order and then by `dateOfBirth` in an `asc`ending order.\n\n## Paginate over search results\n\nBy default, the search result page size is 100. To customize the page size modify the `limit` parameter. Query for the `nextToken` and use it in your subsequent pagination requests:\n\n```\nquery MyQuery {\n  searchTodos(nextToken: \"<YOUR_NEXT_TOKEN>\") { # Pass in your nextToken in query\n    items {\n      description\n      id\n      name\n      createdAt\n    }\n    nextToken # Next token to paginate on\n  }\n}\n```\n\n## Total count of search results\n\nAdd the `total` field in your query response to get the total count of search result hits.\n\n```graphql\nquery MyQuery {\n  searchStudents(filter: {name: {wildcard: \"*Brandel\"}}) {\n    items {\n      id\n    }\n    total # Specify to get total counts\n  }\n}\n```\n\nIn the example above, the response's `total` field contains the total search result count for \"Students\" whose name ends with \"Brandel\".\nNote: `total` is calculated based on all records, irrespective of pagination configurations.\n\n## Aggregate values for search result (minimum, maximum, average, sum, terms)\n\nUse the `aggregates` parameter to get aggregate values such as \"minimum\", \"maximum\", \"average\", and \"sum\" returned in the `aggregateItems` field.\nNote: `aggregates` are calculated based on all records, irrespective of pagination configurations.\n\n<BlockSwitcher>\n<Block name=\"Minimum (min)\">\n\nProvide the `min` value as the `aggregate` `type` and specify the `aggregateItems` in the response field.\n\n```graphql\nquery MyQuery {\n  searchStudents(\n    aggregates: {\n      type: min, # Specifies that you want the \"min\" value\n      field: examsCompleted, # Specifies the field for the aggregate value\n      name: \"minimumExams\" # provides a name to reference in the response field \n    } filter: { name: {wildcard: \"Rene*\"}}) {\n    aggregateItems {\n      name\n      result {\n        ... on SearchableAggregateScalarResult {\n          value\n        }\n      }\n    }\n  }\n}\n```\n\nIn the example above, the response includes the minimum value of \"examsCompleted\" for all Students whose name starts with \"Rene\".\n\n```graphql\n{\n  \"data\": {\n    \"searchStudents\": {\n      \"aggregateItems\": [{\n        \"name\": \"minimumExams\",\n        \"result\": {\n          \"value\": 7\n        }\n      }]\n    }\n  }\n}\n```\n</Block>\n\n<Block name=\"Maximum (max)\">\n\nProvide the `max` value as the `aggregate` `type` and specify the `aggregateItems` in the response field.\n\n```graphql\nquery MyQuery {\n  searchStudents(\n    aggregates: {\n      type: max, # Specifies that you want the \"max\" value\n      field: examsCompleted, # Specifies the field for the aggregate value\n      name: \"maximumExams\" # provides a name to reference in the response field \n    } filter: { name: {wildcard: \"Rene*\"}}) {\n    aggregateItems {\n      name\n      result {\n        ... on SearchableAggregateScalarResult {\n          value\n        }\n      }\n    }\n  }\n}\n```\n\nIn the example above, the response includes the maximum value of \"examsCompleted\" for all Students whose name starts with \"Rene\".\n\n```graphql\n{\n  \"data\": {\n    \"searchStudents\": {\n      \"aggregateItems\": [{\n        \"name\": \"maximumExams\",\n        \"result\": {\n          \"value\": 28\n        }\n      }]\n    }\n  }\n}\n```\n</Block>\n\n<Block name=\"Average (avg)\">\n\nProvide the `avg` value as the `aggregate` `type` and specify the `aggregateItems` in the response field.\n\n```graphql\nquery MyQuery {\n  searchStudents(\n    aggregates: {\n      type: avg, # Specifies that you want the \"avg\" value\n      field: examsCompleted, # Specifies the field for the aggregate value\n      name: \"averageExams\" # provides a name to reference in the response field \n    } filter: { name: {wildcard: \"Rene*\"}}) {\n    aggregateItems {\n      name\n      result {\n        ... on SearchableAggregateScalarResult {\n          value\n        }\n      }\n    }\n  }\n}\n```\n\nIn the example above, the response includes the average value of \"examsCompleted\" for all Students whose name starts with \"Rene\".\n```graphql\n{\n  \"data\": {\n    \"searchStudents\": {\n      \"aggregateItems\": [{\n        \"name\": \"averageExams\",\n        \"result\": {\n          \"value\": 17.3\n        }\n      }]\n    }\n  }\n}\n```\n\n</Block>\n\n<Block name=\"Sum (sum)\">\n\nProvide the `sum` value as the `aggregate` `type` and specify the `aggregateItems` in the response field.\n\n```graphql\nquery MyQuery {\n  searchStudents(\n    aggregates: {\n      type: sum, # Specifies that you want the \"sum\" value\n      field: examsCompleted, # Specifies the field for the aggregate value\n      name: \"examsSum\" # provides a name to reference in the response field \n    } filter: { name: {wildcard: \"Rene*\"}}) {\n    aggregateItems {\n      name\n      result {\n        ... on SearchableAggregateScalarResult {\n          value\n        }\n      }\n    }\n  }\n}\n```\n\nIn the example above, the response includes the sum of all \"examsCompleted\" values for all Students whose name starts with \"Rene\".\n\n```graphql\n{\n  \"data\": {\n    \"searchStudents\": {\n      \"aggregateItems\": [{\n        \"name\": \"examsSum\",\n        \"result\": {\n          \"value\": 392\n        }\n      }]\n    }\n  }\n}\n```\n\n</Block>\n<Block name=\"Terms\">\n\nProvide the `terms` value as the `aggregate` `type` and specify the `aggregateItems` in the response field.\n\n```graphql\nquery MyQuery {\n  searchTodos(aggregates: {\n    field: description,\n    type: terms,\n    name: \"descriptionTerms\"\n  }) {\n    aggregateItems {\n      result {\n        ... on SearchableAggregateBucketResult {\n          __typename\n          buckets {\n            doc_count\n            key\n          }\n        }\n      }\n      name\n    }\n  }\n}\n\n```\n\nIn the example above, the response includes the terms for the description and their count:\n\n```graphql\n{\n  \"data\": {\n    \"searchTodos\": {\n      \"aggregateItems\": [\n        {\n          \"result\": {\n            \"__typename\": \"SearchableAggregateBucketResult\",\n            \"buckets\": [{\n                \"doc_count\": 2,\n                \"key\": \"Shopping list\"\n              }, {\n                \"doc_count\": 1,\n                \"key\": \"Me next todo\"\n              }]\n          },\n          \"name\": \"descriptionTerms\"\n        }\n      ]\n    }\n  }\n}\n```\n\n</Block>\n</BlockSwitcher>\n\n## Set up OpenSearch for production environments\nBy default, Amplify CLI will configure a t2.small instance type. This is great for getting started and prototyping but not recommended to be used in the production environment per the [OpenSearch best practices](https://docs.aws.amazon.com/opensearch-service/latest/developerguide/bp.html). \n\nTo configure the OpenSearch instance type per environment:\n1. Run `amplify env add` to create a new environment (e.g. \"prod\")\n2. Edit the `amplify/team-provider-info.json` file and set `OpenSearchInstanceType` to the instance type that works for your application\n```json\n{\n  \"dev\": {\n    \"categories\": {\n      \"api\": {\n        \"<your-api-name>\" : {\n          \"OpenSearchInstanceType\": \"t2.small.elasticsearch\"\n        }\n      }\n    }\n  },\n  \"prod\": {\n    \"categories\": {\n      \"api\": {\n        \"<your-api-name>\" : {\n          \"OpenSearchInstanceType\": \"t2.medium.elasticsearch\"\n        }\n      }\n    }\n  }\n}\n```\n3. Deploy your changes with `amplify push`\n\nLearn more about Amazon OpenSearch Service instance types [here](https://docs.aws.amazon.com/opensearch-service/latest/developerguide/supported-instance-types.html).\n\n## How it works\nThe `@searchable` directive streams the data of an @model type to Amazon OpenSearch Service and configures search resolvers to query against OpenSearch.\n\nType definition of the `@searchable` directive:\n```graphql\n# Streams data from DynamoDB to OpenSearch and exposes search capabilities.\ndirective @searchable(queries: SearchableQueryMap) on OBJECT\ninput SearchableQueryMap { search: String }\n```\n",
    "meta": {
      "title": "Search and result aggregations",
      "description": "Add authorization rules to your GraphQL schema to control access to your data.",
      "subcategory": "API (GraphQL)",
      "category": "Amplify CLI"
    },
    "filename": "/cli/graphql/search-and-result-aggregations"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Define your custom business logic in a Lambda function resolver, HTTP resolver, or VTL resolver and expose them in a GraphQL query or mutation. Extend or override Amplify-generated GraphQL resolvers to optimize for your specific use cases."
      },
      {
        "heading": "Create a custom query or mutation",
        "depth": 2,
        "text": "While @model automatically generates dedicated \"create\", \"read\", \"update\", \"delete\", and \"subscription\" queries or mutations for you, there are some cases where you want to define a stand-alone query or mutation."
      },
      {
        "heading": "Create a custom query or mutation",
        "depth": 2,
        "text": "Define your custom query or mutation"
      },
      {
        "heading": "Create a custom query or mutation",
        "depth": 2,
        "text": "Use one of these resolver choices to handle the query or mutation request:"
      },
      {
        "heading": "Create a custom query or mutation",
        "depth": 2,
        "text": "Lambda function resolver: use a custom Lambda function to handle query or mutation"
      },
      {
        "heading": "Create a custom query or mutation",
        "depth": 2,
        "text": "HTTP resolver: call an HTTP endpoint upon a query or mutation"
      },
      {
        "heading": "Create a custom query or mutation",
        "depth": 2,
        "text": "VTL resolver (most advanced): use VTL mapping templates to customize the query and mutation logic"
      },
      {
        "heading": "Create a custom query or mutation",
        "depth": 2,
        "text": "Secure your custom query or mutation with field-level authorization rules"
      },
      {
        "heading": "Create a custom query or mutation",
        "depth": 2,
        "text": "Note: Dynamic authorization rules are not supported on a custom query or mutation."
      },
      {
        "heading": "Lambda function resolver",
        "depth": 2,
        "text": "The @function directive allows you to quickly & easily configure a AWS Lambda resolvers with your GraphQL API. You can use any AWS Lambda functions that was created with the Amplify CLI, AWS Lambda console, or any other tool."
      },
      {
        "heading": "Lambda function resolver",
        "depth": 2,
        "text": "For example, use amplify add function to add a Lambda function called \"echofunction\" with the following handler:"
      },
      {
        "heading": "Lambda function resolver",
        "depth": 2,
        "text": "To connect an AWS Lambda resolver to the GraphQL API, add the @function directive to a field in your schema."
      },
      {
        "heading": "Lambda function resolver",
        "depth": 2,
        "text": "The Amplify CLI provides support for maintaining multiple environments. When you deploy a function via amplify add function, it will automatically add the environment suffix to your Lambda function name. For example, if you create a function named echofunction using amplify add function in the dev environment, the deployed function will be named echofunction-dev. The @function directive allows you to use ${env} to reference the current Amplify CLI environment."
      },
      {
        "heading": "Lambda function resolver",
        "depth": 2,
        "text": "If you deployed your Lambda function without Amplify CLI then you must provide the full Lambda function name in the name parameter. If you deployed the same function with the name echofunction then you would have:"
      },
      {
        "heading": "Structure of the function event",
        "depth": 3,
        "text": "When writing Lambda functions that are connected via the @function directive, you can expect the following structure for the AWS Lambda event object."
      },
      {
        "heading": "Structure of the function event",
        "depth": 3,
        "text": "| Key  | Description  |\n|---|---|\n| typeName  | The name of the parent object type of the field being resolver.  |\n| fieldName  | The name of the field being resolved.  |\n| arguments  | A map containing the arguments passed to the field being resolved.  |\n| identity  | A map containing identity information for the request. Contains a nested key 'claims' that will contains the JWT claims if they exist. |\n| source  | When resolving a nested field in a query, the source contains parent value at runtime. For example when resolving Post.comments, the source will be the Post object.  |\n| request   | The AppSync request object. Contains header information.  |\n| prev | When using pipeline resolvers, this contains the object returned by the previous function. You can return the previous value for auditing use cases. |"
      },
      {
        "heading": "Structure of the function event",
        "depth": 3,
        "text": "Your function should follow the Lambda handler guidelines for your specific language. See the developer guides from the\nAWS Lambda documentation for your chosen language. If you choose to use structured types, your type should serialize\nthe AWS Lambda event object outlined above. For example, if using Golang, you should define a struct with the above fields."
      },
      {
        "heading": "Calling functions in different regions",
        "depth": 3,
        "text": "By default, you expect the function to be in the same region as the Amplify project. If you need to call a function in a different or a specific region, you can provide the region argument."
      },
      {
        "heading": "Calling functions in different regions",
        "depth": 3,
        "text": "Calling functions in different AWS accounts is not supported via the @function directive but is supported by AWS AppSync."
      },
      {
        "heading": "Chaining functions",
        "depth": 3,
        "text": "You can chain together multiple @function resolvers such that they are invoked in series when your field's resolver is invoked. To create a pipeline resolver that calls to multiple AWS Lambda functions in series, use multiple @function directives on the field.\nSimilarly, @function can be combined with field-level @auth. When combining these field directives, the ordering in the schema matches the ordering in the pipeline resolver. You can choose to have functions before and/or after field level authorization is applied."
      },
      {
        "heading": "Chaining functions",
        "depth": 3,
        "text": "Note: Be careful when using @auth directives on a field in a root type. @auth directives on field definitions use the source object to perform authorization logic and the source will be an empty object for fields on root types. Static group authorization should perform as expected."
      },
      {
        "heading": "Chaining functions",
        "depth": 3,
        "text": "In the example above when you run a mutation that calls the Mutation.doSomeWork field, the worker-function will be invoked first then the audit-function will be invoked with an event that contains the results of the worker-function under the event.prev.result key. The audit-function would need to return event.prev.result if you want the result of worker-function to be returned for the field."
      },
      {
        "heading": "How it works",
        "depth": 3,
        "text": "Definition of @function directive:"
      },
      {
        "heading": "How it works",
        "depth": 3,
        "text": "Under the hood, Amplify creates an AppSync::FunctionConfiguration for each unique instance of @function in a document and a pipeline resolver containing a pointer to a function for each @function on a given field."
      },
      {
        "heading": "How it works",
        "depth": 3,
        "text": "The @function directive generates these resources as necessary:"
      },
      {
        "heading": "How it works",
        "depth": 3,
        "text": "An AWS IAM role that has permission to invoke the function as well as a trust policy with AWS AppSync."
      },
      {
        "heading": "How it works",
        "depth": 3,
        "text": "An AWS AppSync data source that registers the new role and existing function with your AppSync API."
      },
      {
        "heading": "How it works",
        "depth": 3,
        "text": "An AWS AppSync pipeline function that prepares the lambda event and invokes the new data source."
      },
      {
        "heading": "How it works",
        "depth": 3,
        "text": "An AWS AppSync resolver that attaches to the GraphQL field and invokes the new pipeline functions."
      },
      {
        "heading": "HTTP resolver",
        "depth": 2,
        "text": "The @http directive allows you to quickly configure HTTP resolvers within your GraphQL API."
      },
      {
        "heading": "HTTP resolver",
        "depth": 2,
        "text": "To connect to an endpoint, add the @http directive to a field in your GraphQL schema. The directive allows you to define URL path parameters, and specify a query string and/or specify a request body. For example, given the definition of a Post type:"
      },
      {
        "heading": "HTTP resolver",
        "depth": 2,
        "text": "Amplify generates the definition below that sends a request to the url when the listPosts query is used."
      },
      {
        "heading": "Request headers",
        "depth": 3,
        "text": "The @http directive generates resolvers that can handle XML and JSON responses. If an HTTP method is not defined, GET is used. You can specify a list of static headers to be passed with the HTTP requests to your backend in your directive definition."
      },
      {
        "heading": "Path parameters",
        "depth": 3,
        "text": "You can create dynamic paths by specifying parameters in the directive URL by using the special :<parameter> notation. Your set of parameters can then be specified in the params input object of the query. Note that path parameters are not added to the request body or query string. You can define multiple parameters."
      },
      {
        "heading": "Path parameters",
        "depth": 3,
        "text": "In the example above, the :id parameter will generate the appropriate query input as shown below:"
      },
      {
        "heading": "Path parameters",
        "depth": 3,
        "text": "You can fetch a specific post by enclosing the id in the params input object."
      },
      {
        "heading": "Path parameters",
        "depth": 3,
        "text": "This executes the following request:"
      },
      {
        "heading": "Query String",
        "depth": 3,
        "text": "You can send a query string with your request by specifying variables for your query. The query string is supported with all request methods."
      },
      {
        "heading": "Query String",
        "depth": 3,
        "text": "Given the definition"
      },
      {
        "heading": "Query String",
        "depth": 3,
        "text": "Amplify generates"
      },
      {
        "heading": "Query String",
        "depth": 3,
        "text": "You can query for posts using the query input object"
      },
      {
        "heading": "Query String",
        "depth": 3,
        "text": "which sends the following request:"
      },
      {
        "heading": "Request Body",
        "depth": 3,
        "text": "The @http directive also allows you to specify the body of a request, which is used for POST, PUT, and PATCH requests. To create a new post, you can define the following."
      },
      {
        "heading": "Request Body",
        "depth": 3,
        "text": "Amplify generates the addPost query field with the query and body input objects since this type of request also supports a query string. The generated resolver verifies that non-null arguments (e.g.: the title and description) are passed in at least one of the input objects; if not, an error is returned."
      },
      {
        "heading": "Request Body",
        "depth": 3,
        "text": "You can add a post by using the body input object:"
      },
      {
        "heading": "Request Body",
        "depth": 3,
        "text": "which will send"
      },
      {
        "heading": "Reference Amplify environment name",
        "depth": 3,
        "text": "The @http directive allows you to use ${env} to reference the current Amplify CLI environment."
      },
      {
        "heading": "Reference Amplify environment name",
        "depth": 3,
        "text": "which, in the DEV environment, will send"
      },
      {
        "heading": "Reference Amplify environment name",
        "depth": 3,
        "text": "Combining the different components"
      },
      {
        "heading": "Reference Amplify environment name",
        "depth": 3,
        "text": "You can use a combination of parameters, query, body, headers, and environments in your @http directive definition."
      },
      {
        "heading": "Reference Amplify environment name",
        "depth": 3,
        "text": "Given the definition"
      },
      {
        "heading": "Reference Amplify environment name",
        "depth": 3,
        "text": "you can update a post with"
      },
      {
        "heading": "Reference Amplify environment name",
        "depth": 3,
        "text": "which, in the DEV environment, will send"
      },
      {
        "heading": "Reference existing field data",
        "depth": 3,
        "text": "In some cases, you may want to send a request based on existing field data. Take a scenario where you have a post and want to fetch comments associated with the post in a single query. Let's use the previous definition of Post and Comment."
      },
      {
        "heading": "Reference existing field data",
        "depth": 3,
        "text": "A post can be fetched at /posts/:id and a post's comments at /posts/:id/comments. You can fetch the comments based on the post id with the following updated definition. $ctx.source is a map that contains the resolution of the parent field (Post) and gives access to id."
      },
      {
        "heading": "Reference existing field data",
        "depth": 3,
        "text": "You can retrieve the comments of a specific post with the following query and selection set."
      },
      {
        "heading": "Reference existing field data",
        "depth": 3,
        "text": "Assuming that getPost retrieves a post with the id POST_ID, the comments field is resolved by sending this request to the endpoint"
      },
      {
        "heading": "Reference existing field data",
        "depth": 3,
        "text": "Note that there is no check to ensure that the reference variable (here the post ID) exists. When using this technique, it is recommended to make sure the referenced field is non-null."
      },
      {
        "heading": "How it works",
        "depth": 3,
        "text": "Definition of @http directive:"
      },
      {
        "heading": "How it works",
        "depth": 3,
        "text": "The @http transformer will create one HTTP datasource for each identified base URL. For example, if multiple HTTP resolvers are created that interact with the \"https://www.example.com\" endpoint, only a single datasource is created. Each directive generates one resolver. Depending on the definition, the appropriate body, params, and query input types are created. Note that @http transformer does not support calling other AWS services where Signature Version 4 signing process is required."
      },
      {
        "heading": "VTL resolver",
        "depth": 2,
        "text": "You can use AWS Cloud Development Kit (CDK) to define custom VTL resolvers for your GraphQL API."
      },
      {
        "heading": "VTL resolver",
        "depth": 2,
        "text": "Next, install the AppSync dependencies for your custom resource:"
      },
      {
        "heading": "VTL resolver",
        "depth": 2,
        "text": "Note: Installations using the '~' character do not modify the package.json. To use '~' for default npm configurations, make sure your package.json reflects the right dependency to avoid compatibility errors in CDK."
      },
      {
        "heading": "VTL resolver",
        "depth": 2,
        "text": "Finally, add your custom resolvers into the cdk-stack.ts file. You can either add the VTL inline into your cdk-stack.ts file or define them externally in another file. Review the Resolver Mapping Template Programming Guide to learn more about the VTL template."
      },
      {
        "heading": "VTL resolver",
        "depth": 2,
        "text": "Note: Users moving from ElasticSearch to OpenSearch will need to change the datasource name from ElasticSearchDomain to OpenSearchDataSource if the upgrade process changes the source name. For new @searchable models the datasource name will default to OpenSearchDataSource."
      },
      {
        "heading": "VTL resolver",
        "depth": 2,
        "text": "You can alternatively define the VTL templates in another file such as Query.querySomething.req.vtl or Query.querySomething.res.vtl in amplify/backend/custom/MyCustomResolvers/. Then use the following code snippets to retrieve them:"
      },
      {
        "heading": "VTL resolver",
        "depth": 2,
        "text": "Note: the .. is added to the path because the path is always relative to the build folder of the custom resource."
      },
      {
        "heading": "Override Amplify-generated resolvers",
        "depth": 2,
        "text": "Amplify generates AWS AppSync pipeline resolver for your queries and mutations. The resolvers are listed the following API resource's folder amplify/backend/api/<resource_name>/build/resolvers/."
      },
      {
        "heading": "Override Amplify-generated resolvers",
        "depth": 2,
        "text": "To override an Amplify-generated resolver:"
      },
      {
        "heading": "Override Amplify-generated resolvers",
        "depth": 2,
        "text": "Find the resolver file name you want to override under build/resolvers"
      },
      {
        "heading": "Override Amplify-generated resolvers",
        "depth": 2,
        "text": "Place a .vtl with the same file name the resource's resolvers/ (not under build/)"
      },
      {
        "heading": "Override Amplify-generated resolvers",
        "depth": 2,
        "text": "Upon the next amplify api gql-compile or amplify push the Amplify-generated resolver file will be replaced with your overwritten resolver file"
      },
      {
        "heading": "Override Amplify-generated resolvers",
        "depth": 2,
        "text": "The example above shows how the Query.searchTodos.req.vtl is overwritten with a custom resolver. Review the Resolver Mapping Template Programming Guide to learn more about the VTL template."
      },
      {
        "heading": "Extend Amplify-generated resolvers",
        "depth": 2,
        "text": "Amplify generates AWS AppSync pipeline resolvers for your queries and mutations. You can \"slot\" in your custom business logic between Amplify-generated resolvers. You can find Amplify-generated resolvers under your API resources' build/resolvers/ folder. The resolver functions file name determines its placement within the slot sequence."
      },
      {
        "heading": "Extend Amplify-generated resolvers",
        "depth": 2,
        "text": "To extend an Amplify-generated resolver:"
      },
      {
        "heading": "Extend Amplify-generated resolvers",
        "depth": 2,
        "text": "Find the resolver slot you want to add your custom business logic to"
      },
      {
        "heading": "Extend Amplify-generated resolvers",
        "depth": 2,
        "text": "Place a .vtl file with the correct the file naming convention into resolvers/ (not under build/)"
      },
      {
        "heading": "Extend Amplify-generated resolvers",
        "depth": 2,
        "text": "Upon the next amplify api gql-compile or amplify push the Amplify-generated resolver file will be replaced within the desired slot within the resolver sequence."
      },
      {
        "heading": "Extend Amplify-generated resolvers",
        "depth": 2,
        "text": "For example, the a resolver function file named Mutation.createTodo.postAuth.2.req.vtl will be slotted in right after the Mutation.createTodo.postAuth.1.req.vtl resolver. Review the Resolver Mapping Template Programming Guide to learn more about the VTL template."
      },
      {
        "heading": "Query",
        "depth": 4,
        "text": "| Sequence | Slot name    | Description                                                                                |\n| -------- | ------------ | ------------------------------------------------------------------------------------------ |\n| 1        | init         | Initial resolvers that are run. Usually used for initializing default values.              |\n| 2        | preAuth      | Resolvers that are intended to run before authorization rule checks are applied.           |\n| 3        | auth         | Resolvers that implement authorization rule checks.                                        |\n| 4        | postAuth     | Resolvers that are run after authorization rule checks.                                    |\n| 5        | preDataLoad  | Resolvers to configure values to make a request to the data source.                        |\n| 6        | postDataLoad | Resolvers for post-processing after request to data source.                                |\n| 7        | finish       | Final set of resolvers before response is returned to client. Typically used for clean-up. |"
      },
      {
        "heading": "Mutation",
        "depth": 4,
        "text": "| Sequence | Slot name  | Description                                                                                |\n| -------- | ---------- | ------------------------------------------------------------------------------------------ |\n| 1        | init       | Initial resolvers that are run. Usually used for initializing default values.              |\n| 2        | preAuth    | Resolvers that are intended to run before authorization rule checks are applied.           |\n| 3        | auth       | Resolvers that implement authorization rule checks.                                        |\n| 4        | postAuth   | Resolvers that are run after authorization rule checks.                                    |\n| 5        | preUpdate  | Resolvers to configure values to make a request to the data source.                        |\n| 6        | postUpdate | Resolvers for post-processing after request to data source.                                |\n| 7        | finish     | Final set of resolvers before response is returned to client. Typically used for clean-up. |"
      },
      {
        "heading": "Subscription",
        "depth": 4,
        "text": "| Sequence | Slot name    | Description                                                                      |\n| -------- | ------------ | -------------------------------------------------------------------------------- |\n| 1        | init         | Initial resolvers that are run. Usually used for initializing default values.    |\n| 2        | preAuth      | Resolvers that are intended to run before authorization rule checks are applied. |\n| 3        | auth         | Resolvers that implement authorization rule checks.                              |\n| 4        | postAuth     | Resolvers that are run after authorization rule checks.                          |\n| 5        | preSubscribe | Resolver slot that executes after auth but before the subscription returns       |"
      }
    ],
    "source": "export const meta = {\n  title: `Custom business logic (Lambda function, HTTP, and VTL resolvers)`,\n  description: `Add authorization rules to your GraphQL schema to control access to your data.`,\n};\n\n<MigrationAlert url={\"/cli-legacy/graphql-transformer/function\"}/>\n\nDefine your custom business logic in a Lambda function resolver, HTTP resolver, or VTL resolver and expose them in a GraphQL query or mutation. Extend or override Amplify-generated GraphQL resolvers to optimize for your specific use cases.  \n\n## Create a custom query or mutation\n\nWhile `@model` automatically generates dedicated \"create\", \"read\", \"update\", \"delete\", and \"subscription\" queries or mutations for you, there are some cases where you want to define a stand-alone query or mutation.\n\n1. Define your custom query or mutation\n\n```graphql\ntype Mutation {\n  myCustomMutation(args: String): String # your custom mutations here\n}\n\ntype Query {\n  myCustomQuery(args: String): String # your custom queries here\n}\n```\n\n2. Use one of these resolver choices to handle the query or mutation request:\n    - [Lambda function resolver](#lambda-function-resolver): use a custom Lambda function to handle query or mutation\n    - [HTTP resolver](#http-resolver): call an HTTP endpoint upon a query or mutation\n    - [VTL resolver](#vtl-resolver) (most advanced): use VTL mapping templates to customize the query and mutation logic\n\n3. Secure your custom query or mutation with [field-level authorization rules](/cli/graphql/authorization-rules/)\n    - Note: Dynamic authorization rules are not supported on a custom query or mutation.\n\n## Lambda function resolver\nThe `@function` directive allows you to quickly & easily configure a AWS Lambda resolvers with your GraphQL API. You can use any AWS Lambda functions that was created with the Amplify CLI, AWS Lambda console, or any other tool.\n\n<BlockSwitcher>\n\n<Block name=\"Function deployed using Amplify CLI\">\n\nFor example, use `amplify add function` to add a Lambda function called \"echofunction\" with the following handler:\n\n```js\nexports.handler =  async function(event, context){\n  return event.arguments.msg;\n};\n```\n\nTo connect an AWS Lambda resolver to the GraphQL API, add the `@function` directive to a field in your schema.\n\n```graphql\ntype Query {\n  echo(msg: String): String @function(name: \"echofunction-${env}\")\n}\n```\n\nThe Amplify CLI provides support for maintaining multiple environments. When you deploy a function via `amplify add function`, it will automatically add the environment suffix to your Lambda function name. For example, if you create a function named `echofunction` using `amplify add function` in the `dev` environment, the deployed function will be named `echofunction-dev`. The `@function` directive allows you to use `${env}` to reference the current Amplify CLI environment.\n\n</Block>\n\n<Block name=\"Function deployed without Amplify CLI\">\n\nIf you deployed your Lambda function without Amplify CLI then you must provide the full Lambda function name in the `name` parameter. If you deployed the same function with the name echofunction then you would have:\n\n```graphql\ntype Query {\n  echo(msg: String): String @function(name: \"echofunction\")\n}\n```\n\n\n</Block>\n\n</BlockSwitcher>\n\n### Structure of the function event\n\nWhen writing Lambda functions that are connected via the `@function` directive, you can expect the following structure for the AWS Lambda `event` object.\n\n| Key  | Description  |\n|---|---|\n| typeName  | The name of the parent object type of the field being resolver.  |\n| fieldName  | The name of the field being resolved.  |\n| arguments  | A map containing the arguments passed to the field being resolved.  |\n| identity  | A map containing identity information for the request. Contains a nested key 'claims' that will contains the JWT claims if they exist. |\n| source  | When resolving a nested field in a query, the source contains parent value at runtime. For example when resolving `Post.comments`, the source will be the Post object.  |\n| request   | The AppSync request object. Contains header information.  |\n| prev | When using pipeline resolvers, this contains the object returned by the previous function. You can return the previous value for auditing use cases. |\n\nYour function should follow the Lambda handler guidelines for your specific language. See the developer guides from the\n[AWS Lambda](https://docs.aws.amazon.com/lambda/latest/dg/welcome.html) documentation for your chosen language. If you choose to use structured types, your type should serialize\nthe AWS Lambda event object outlined above. For example, if using Golang, you should define a struct with the above fields.\n\n### Calling functions in different regions\n\nBy default, you expect the function to be in the same region as the Amplify project. If you need to call a function in a different or a specific region, you can provide the **region** argument.\n\n```graphql\ntype Query {\n  echo(msg: String): String @function(name: \"echofunction\", region: \"us-east-1\")\n}\n```\n\nCalling functions in different AWS accounts is not supported via the `@function` directive but is supported by AWS AppSync.\n\n### Chaining functions\n\nYou can chain together multiple `@function` resolvers such that they are invoked in series when your field's resolver is invoked. To create a pipeline resolver that calls to multiple AWS Lambda functions in series, use multiple `@function` directives on the field.\nSimilarly, `@function` can be combined with field-level `@auth`. When combining these field directives, the ordering in the schema matches the ordering in the pipeline resolver. You can choose to have functions before and/or after field level authorization is applied.\n\n> **Note:** Be careful when using @auth directives on a field in a root type. @auth directives on field definitions use the source object to perform authorization logic and the source will be an empty object for fields on root types. Static group authorization should perform as expected.\n\n```graphql\ntype Mutation {\n  doSomeWork(msg: String): String @function(name: \"worker-function\") @function(name: \"audit-function\")\n}\n```\n\nIn the example above when you run a mutation that calls the `Mutation.doSomeWork` field, the **worker-function** will be invoked first then the **audit-function** will be invoked with an event that contains the results of the **worker-function** under the **event.prev.result** key. The **audit-function** would need to return **event.prev.result** if you want the result of **worker-function** to be returned for the field.\n\n### How it works\n\nDefinition of `@function` directive:\n\n```graphql\ndirective @function(name: String!, region: String) on FIELD_DEFINITION\n```\n\nUnder the hood, Amplify creates an `AppSync::FunctionConfiguration` for each unique instance of `@function` in a document and a pipeline resolver containing a pointer to a function for each `@function` on a given field.\n\n\nThe `@function` directive generates these resources as necessary:\n1. An AWS IAM role that has permission to invoke the function as well as a trust policy with AWS AppSync.\n2. An AWS AppSync data source that registers the new role and existing function with your AppSync API.\n3. An AWS AppSync pipeline function that prepares the lambda event and invokes the new data source.\n4. An AWS AppSync resolver that attaches to the GraphQL field and invokes the new pipeline functions.\n\n## HTTP resolver\nThe `@http` directive allows you to quickly configure HTTP resolvers within your GraphQL API.\n\nTo connect to an endpoint, add the @http directive to a field in your GraphQL schema. The directive allows you to define URL path parameters, and specify a query string and/or specify a request body. For example, given the definition of a Post type:\n\n```graphql\ntype Post {\n  id: ID!\n  title: String\n  description: String\n  views: Int\n}\n\ntype Query {\n  listPosts: [Post] @http(url: \"https://www.example.com/posts\")\n}\n```\n\nAmplify generates the definition below that sends a request to the url when the listPosts query is used.\n\n```graphql\ntype Query {\n  listPosts: [Post]\n}\n```\n\n### Request headers\nThe `@http` directive generates resolvers that can handle XML and JSON responses. If an HTTP method is not defined, `GET` is used. You can specify a list of static headers to be passed with the HTTP requests to your backend in your directive definition.\n\n```graphql\ntype Query {\n  listPosts: [Post]\n    @http(\n      url: \"https://www.example.com/posts\"\n      headers: [{ key: \"X-Header\", value: \"X-Header-Value\" }]\n    )\n}\n```\n\n### Path parameters\n\nYou can create dynamic paths by specifying parameters in the directive URL by using the special `:<parameter>` notation. Your set of parameters can then be specified in the params input object of the query. Note that path parameters are not added to the request body or query string. You can define multiple parameters.\n\n```graphql\ntype Query {\n  getPost: Post @http(url: \"https://www.example.com/posts/:id\")\n}\n```\n\nIn the example above, the `:id` parameter will generate the appropriate query input as shown below:\n\n```graphql\ntype Query {\n  getPost(params: QueryGetPostParamsInput!): Post\n}\n\ninput QueryGetPostParamsInput {\n  id: String!\n}\n```\n\nYou can fetch a specific post by enclosing the id in the params input object.\n\n```graphql\nquery post {\n  getPost(params: {id: \"POST_ID\"}) {\n    id\n    title\n  }\n}\n```\n\nThis executes the following request:\n```console\nGET /posts/POST_ID\nHost: www.example.com\n```\n\n### Query String\n\nYou can send a query string with your request by specifying variables for your query. The query string is supported with all request methods.\n\nGiven the definition\n\n```graphql\ntype Query {\n  listPosts(sort: String!, from: String!, limit: Int!): Post\n    @http(url: \"https://www.example.com/posts\")\n}\n```\n\nAmplify generates\n\n```graphql\ntype Query {\n  listPosts(query: QueryListPostsQueryInput!): [Post]\n}\n\ninput QueryListPostsQueryInput {\n  sort: String!\n  from: String!\n  limit: Int!\n}\n```\n\nYou can query for posts using the `query` input object\n\n```graphql\nquery posts{\n  listPosts(query: {sort: \"DESC\", from: \"last-week\", limit: 5}) {\n    id\n    title\n    description\n  }\n}\n```\n\nwhich sends the following request:\n\n```text\nGET /posts?sort=DESC&from=last-week&limit=5\nHost: www.example.com\n```\n\n### Request Body\n\nThe `@http` directive also allows you to specify the body of a request, which is used for `POST`, `PUT`, and `PATCH` requests. To create a new post, you can define the following.\n\n```graphql\ntype Mutation {\n  addPost(title: String!, description: String!, views: Int): Post\n    @http(method: POST, url: \"https://www.example.com/post\")\n}\n```\n\nAmplify generates the `addPost` query field with the `query` and `body` input objects since this type of request also supports a query string. The generated resolver verifies that non-null arguments (e.g.: the `title` and `description`) are passed in at least one of the input objects; if not, an error is returned.\n\n```graphql\ntype Mutation {\n  addPost(query: QueryAddPostQueryInput, body: QueryAddPostBodyInput): Post\n}\n\ninput QueryAddPostQueryInput {\n  title: String\n  description: String\n  views: Int\n}\n\ninput QueryAddPostBodyInput {\n  title: String\n  description: String\n  views: Int\n}\n```\n\nYou can add a post by using the `body` input object:\n\n```graphql\nmutation add {\n  addPost(body: {title: \"new post\", description: \"fresh content\"}) {\n    id\n  }\n}\n```\n\nwhich will send\n\n```text\nPOST /post\nHost: www.example.com\n{\n  title: \"new post\"\n  description: \"fresh content\"\n}\n```\n\n### Reference Amplify environment name\n\nThe `@http` directive allows you to use `${env}` to reference the current Amplify CLI environment.\n\n```graphql\ntype Query {\n  listPosts: Post @http(\n    url: \"https://www.example.com/${env}/posts\"\n  )\n}\n```\n\nwhich, in the `DEV` environment, will send\n\n```text\nGET /DEV/posts\nHost: www.example.com\n```\n\n**Combining the different components**\n\nYou can use a combination of parameters, query, body, headers, and environments in your `@http` directive definition.\n\nGiven the definition\n\n```graphql\ntype Post {\n  id: ID!\n  title: String\n  description: String\n  views: Int\n  comments: [Comment]\n}\n\ntype Comment {\n  id: ID!\n  content: String\n}\n\ntype Mutation {\n  updatePost(\n    title: String!\n    description: String!\n    views: Int\n    withComments: Boolean\n  ): Post\n    @http(\n      method: PUT\n      url: \"https://www.example.com/${env}/posts/:id\"\n      headers: [{ key: \"X-Header\", value: \"X-Header-Value\" }]\n    )\n}\n```\n\nyou can update a post with\n\n```graphql\nmutation update {\n  updatePost(\n    body: {title: \"new title\", description: \"updated description\", views: 100}\n    params: {id: \"EXISTING_ID\"}\n    query: {withComments: true}) {\n    id\n    title\n    description\n    comments {\n      id\n      content\n    }\n  }\n}\n```\n\nwhich, in the `DEV` environment, will send\n\n```text\nPUT /DEV/posts/EXISTING_ID?withComments=true\nHost: www.example.com\nX-Header: X-Header-Value\n{\n  title: \"new title\"\n  description: \"updated description\"\n  views: 100\n}\n```\n\n### Reference existing field data\n\nIn some cases, you may want to send a request based on existing field data. Take a scenario where you have a post and want to fetch comments associated with the post in a single query. Let's use the previous definition of `Post` and `Comment`.\n\n```graphql\ntype Post {\n  id: ID!\n  title: String\n  description: String\n  views: Int\n  comments: [Comment]\n}\n\ntype Comment {\n  id: ID!\n  content: String\n}\n```\n\nA post can be fetched at `/posts/:id` and a post's comments at `/posts/:id/comments`. You can fetch the comments based on the post id with the following updated definition. `$ctx.source` is a map that contains the resolution of the parent field (`Post`) and gives access to `id`.\n\n```graphql\ntype Post {\n  id: ID!\n  title: String\n  description: String\n  views: Int\n  comments: [Comment]\n    @http(url: \"https://www.example.com/posts/${ctx.source.id}/comments\")\n}\n\ntype Comment {\n  id: ID!\n  content: String\n}\n\ntype Query {\n  getPost: Post @http(url: \"https://www.example.com/posts/:id\")\n}\n```\n\nYou can retrieve the comments of a specific post with the following query and selection set.\n\n```graphql\nquery post {\n  getPost(params: {id: \"POST_ID\"}) {\n    id\n    title\n    description\n    comments {\n      id\n      content\n    }\n  }\n}\n```\n\nAssuming that `getPost` retrieves a post with the id `POST_ID`, the comments field is resolved by sending this request to the endpoint\n\n```text\nGET /posts/POST_ID/comments\nHost: www.example.com\n```\n\nNote that there is no check to ensure that the reference variable (here the post ID) exists. When using this technique, it is recommended to make sure the referenced field is non-null.\n\n### How it works\nDefinition of `@http` directive:\n\n```graphql\ndirective @http(method: HttpMethod, url: String!, headers: [HttpHeader]) on FIELD_DEFINITION\nenum HttpMethod { PUT POST GET DELETE PATCH }\ninput HttpHeader {\n  key: String\n  value: String\n}\n```\n\nThe `@http` transformer will create one HTTP datasource for each identified base URL. For example, if multiple HTTP resolvers are created that interact with the \"https://www.example.com\" endpoint, only a single datasource is created. Each directive generates one resolver. Depending on the definition, the appropriate `body`, `params`, and `query` input types are created. Note that `@http` transformer does not support calling other AWS services where Signature Version 4 signing process is required.\n\n\n## VTL resolver\n\nYou can use AWS Cloud Development Kit (CDK) to define custom VTL resolvers for your GraphQL API.\n```bash\namplify add custom\n```\n```console\n? How do you want to define this custom resource?\n❯ AWS CDK\n? Provide a name for your custom resource\n❯ MyCustomResolvers\n```\n\nNext, install the AppSync dependencies for your custom resource:\n```bash\ncd amplify/backend/custom/MyCustomResolvers\nnpm i @aws-cdk/aws-appsync@~1.124.0\n```\n> **Note:** Installations using the '\\~' character do not modify the package.json. To use '\\~' for default npm configurations, make sure your package.json reflects the right dependency to avoid compatibility errors in CDK.\n\n\nFinally, add your custom resolvers into the `cdk-stack.ts` file. You can either add the VTL inline into your `cdk-stack.ts` file or define them externally in another file. Review the [Resolver Mapping Template Programming Guide](https://docs.aws.amazon.com/appsync/latest/devguide/resolver-mapping-template-reference-programming-guide.html) to learn more about the VTL template.\n\n```ts\nimport * as cdk from '@aws-cdk/core';\nimport * as AmplifyHelpers from '@aws-amplify/cli-extensibility-helper';\nimport * as appsync from '@aws-cdk/aws-appsync';\nimport { AmplifyDependentResourcesAttributes } from '../../types/amplify-dependent-resources-ref';\n\nconst requestVTL =`\n<YOUR CUSTOM VTL REQUEST MAPPING TEMPLATE HERE>\n`\nconst responseVTL =`\n<YOUR CUSTOM VTL RESPONSE MAPPING TEMPLATE HERE>\n`\n\nexport class cdkStack extends cdk.Stack {\n  constructor(scope: cdk.Construct, id: string, props?: cdk.StackProps, amplifyResourceProps?: AmplifyHelpers.AmplifyResourceProps) {\n    super(scope, id, props);\n    /* Do not remove - Amplify CLI automatically injects the current deployment environment in this input parameter */\n    new cdk.CfnParameter(this, 'env', {\n      type: 'String',\n      description: 'Current Amplify CLI env name',\n    });\n    \n    // Access other Amplify Resources \n    const retVal:AmplifyDependentResourcesAttributes = AmplifyHelpers.addResourceDependency(this, \n      amplifyResourceProps.category, \n      amplifyResourceProps.resourceName, \n      [{\n        category: \"api\",\n        resourceName: \"<YOUR-API-NAME>\"\n      }]\n    );\n\n    const resolver = new appsync.CfnResolver(this, \"custom-resolver\", {\n      // apiId: retVal.api.new.GraphQLAPIIdOutput,\n      // https://github.com/aws-amplify/amplify-cli/issues/9391#event-5843293887\n      // If you use Amplify you can access the parameter via Ref since it's a CDK parameter passed from the root stack.\n      // Previously the ApiId is the variable Name which is wrong , it should be variable value as below\n      apiId: cdk.Fn.ref(retVal.api.replaceWithAPIName.GraphQLAPIIdOutput),\n      fieldName: \"querySomething\", \n      typeName: \"Query\", // Query | Mutation | Subscription\n      requestMappingTemplate: requestVTL,\n      responseMappingTemplate: responseVTL,\n      dataSourceName: \"TodoTable\" // DataSource name\n    })\n  }\n}\n```\n> **Note:** Users moving from ElasticSearch to OpenSearch will need to change the datasource name from `ElasticSearchDomain` to `OpenSearchDataSource` if the upgrade process changes the source name. For new @searchable models the datasource name will default to `OpenSearchDataSource`.\n\nYou can alternatively define the VTL templates in another file such as `Query.querySomething.req.vtl` or `Query.querySomething.res.vtl` in `amplify/backend/custom/MyCustomResolvers/`. Then use the following code snippets to retrieve them:\n\n```ts\nrequestMappingTemplate: appsync.MappingTemplate.fromFile(path.join(__dirname, \"..\", \"Query.testColin.req.vtl\")).renderTemplate(),\nresponseMappingTemplate: appsync.MappingTemplate.fromFile(path.join(__dirname, \"..\", \"Query.testColin.res.vtl\")).renderTemplate(),\n```\n\n> **Note:** the `..` is added to the path because the path is always relative to the `build` folder of the custom resource.\n\n## Override Amplify-generated resolvers\n\nAmplify generates [AWS AppSync pipeline resolver](https://docs.aws.amazon.com/appsync/latest/devguide/pipeline-resolvers.html) for your queries and mutations. The resolvers are listed the following API resource's folder `amplify/backend/api/<resource_name>/build/resolvers/`. \n\nTo override an Amplify-generated resolver:\n1. Find the resolver file name you want to override under `build/resolvers`\n2. Place a `.vtl` with the same file name the resource's `resolvers/` (not under `build/`)\n3. Upon the next `amplify api gql-compile` or `amplify push` the Amplify-generated resolver file will be replaced with your overwritten resolver file\n\n```console\namplify/backend/api/<resource_name>\n├── build\n│   ├── ...\n│   ├── resolvers\n│   │   ├── ...\n│   │   ├── Query.searchTodos.req.vtl # Find resolver file name\n│   │   └── ...\n|   ...\n├── resolvers\n│   └── Query.searchTodos.req.vtl # Place resolver overrides with the same file name here\n```\n\nThe example above shows how the `Query.searchTodos.req.vtl` is overwritten with a custom resolver. Review the [Resolver Mapping Template Programming Guide](https://docs.aws.amazon.com/appsync/latest/devguide/resolver-mapping-template-reference-programming-guide.html) to learn more about the VTL template.\n\n## Extend Amplify-generated resolvers\n\nAmplify generates [AWS AppSync pipeline resolvers](https://docs.aws.amazon.com/appsync/latest/devguide/pipeline-resolvers.html) for your queries and mutations. You can \"slot\" in your custom business logic between Amplify-generated resolvers. You can find Amplify-generated resolvers under your API resources' `build/resolvers/` folder. The resolver functions file name determines its placement within the slot sequence.\n\n```console\nFile name convention: \n  [Query|Mutation|Subscription].[field name].[slot name].[slot placement].[req|res].vtl\nExample:\n  Mutation.createTodo.postAuth.1.req.vtl\n```\n\nTo extend an Amplify-generated resolver:\n1. Find the [resolver slot](#supported-resolver-slots) you want to add your custom business logic to\n2. Place a `.vtl` file with the correct the file naming convention into `resolvers/` (not under `build/`)\n3. Upon the next `amplify api gql-compile` or `amplify push` the Amplify-generated resolver file will be replaced within the desired slot within the resolver sequence.\n\n```console\namplify/backend/api/<resource_name>\n├── build\n│   ├── ...\n│   ├── resolvers\n│   │   ├── ...\n│   │   ├── Mutation.createTodo.postAuth.1.req.vtl # Amplify-generated resolvers\n│   │   └── ...\n|   ...\n├── resolvers\n│   └── Query.createTodo.postAuth.2.req.vtl # Custom resolver slotted in after postAuth.1 resolver\n```\n\nFor example, the a resolver function file named `Mutation.createTodo.postAuth.2.req.vtl` will be slotted in right after the `Mutation.createTodo.postAuth.1.req.vtl` resolver. Review the [Resolver Mapping Template Programming Guide](https://docs.aws.amazon.com/appsync/latest/devguide/resolver-mapping-template-reference-programming-guide.html) to learn more about the VTL template.\n\n### Supported resolver slots\n\n#### Query\n\n| Sequence | Slot name    | Description                                                                                |\n| -------- | ------------ | ------------------------------------------------------------------------------------------ |\n| 1        | init         | Initial resolvers that are run. Usually used for initializing default values.              |\n| 2        | preAuth      | Resolvers that are intended to run before authorization rule checks are applied.           |\n| 3        | auth         | Resolvers that implement authorization rule checks.                                        |\n| 4        | postAuth     | Resolvers that are run after authorization rule checks.                                    |\n| 5        | preDataLoad  | Resolvers to configure values to make a request to the data source.                        |\n| 6        | postDataLoad | Resolvers for post-processing after request to data source.                                |\n| 7        | finish       | Final set of resolvers before response is returned to client. Typically used for clean-up. |\n\n#### Mutation\n\n| Sequence | Slot name  | Description                                                                                |\n| -------- | ---------- | ------------------------------------------------------------------------------------------ |\n| 1        | init       | Initial resolvers that are run. Usually used for initializing default values.              |\n| 2        | preAuth    | Resolvers that are intended to run before authorization rule checks are applied.           |\n| 3        | auth       | Resolvers that implement authorization rule checks.                                        |\n| 4        | postAuth   | Resolvers that are run after authorization rule checks.                                    |\n| 5        | preUpdate  | Resolvers to configure values to make a request to the data source.                        |\n| 6        | postUpdate | Resolvers for post-processing after request to data source.                                |\n| 7        | finish     | Final set of resolvers before response is returned to client. Typically used for clean-up. |\n\n#### Subscription\n\n| Sequence | Slot name    | Description                                                                      |\n| -------- | ------------ | -------------------------------------------------------------------------------- |\n| 1        | init         | Initial resolvers that are run. Usually used for initializing default values.    |\n| 2        | preAuth      | Resolvers that are intended to run before authorization rule checks are applied. |\n| 3        | auth         | Resolvers that implement authorization rule checks.                              |\n| 4        | postAuth     | Resolvers that are run after authorization rule checks.                          |\n| 5        | preSubscribe | Resolver slot that executes after auth but before the subscription returns       |\n\n",
    "meta": {
      "title": "Custom business logic (Lambda function, HTTP, VTL resolvers)",
      "description": "Add authorization rules to your GraphQL schema to control access to your data.",
      "subcategory": "API (GraphQL)",
      "category": "Amplify CLI"
    },
    "filename": "/cli/graphql/custom-business-logic"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Use the @auth directive to configure authorization rules for public, sign-in user, per user, and per user group data access. Authorization rules operate on the deny-by-default principle. Meaning that if an authorization rule is not specifically configured, it is denied."
      },
      {
        "heading": null,
        "depth": null,
        "text": "In the example above, each signed-in user, or also known as \"owner\", of a Todo can create, read, update, and delete their own Todos."
      },
      {
        "heading": null,
        "depth": null,
        "text": "Amplify also allows you to restrict the allowed operations, combine multiple authorization rules, and apply fine-grained field-level authorization."
      },
      {
        "heading": null,
        "depth": null,
        "text": "In the example above, everyone (public) can read every Todo but owner (authenticated users) can create, read, update, and delete their own Todos."
      },
      {
        "heading": "Global authorization rule (only for getting started)",
        "depth": 3,
        "text": "To help you get started, there's a global authorization rule defined when you create a new GraphQL schema. For production environments, remove the global authorization rule and apply rules on each model instead."
      },
      {
        "heading": "Global authorization rule (only for getting started)",
        "depth": 3,
        "text": "The global authorization rule (in this case { allow: public } - allows anyone to create, read, update, and delete) is applied to every data model in the GraphQL schema."
      },
      {
        "heading": "Global authorization rule (only for getting started)",
        "depth": 3,
        "text": "Currently, only { allow: public } is supported as a global authorization rule."
      },
      {
        "heading": "Authorization strategies",
        "depth": 2,
        "text": "Use the guide below to select the correct authorization strategy for your use case:"
      },
      {
        "heading": "Authorization strategies",
        "depth": 2,
        "text": "| Recommended use case | Strategy | Provider |\n|---|---|---|\n| Public data access where users or devices are anonymous. Anyone with the AppSync API key is granted access. | public | apiKey |\n| Recommended for production environment's public data access. Public data access where unauthenticated users or devices are granted permissions using AWS IAM controls. | public | iam |\n| Per user data access. Access is restricted to the \"owner\" of a record. Leverages amplify add auth Cognito user pool by default. | owner | userPools / oidc |\n| Any signed-in data access. Unlike owner-based access, any signed-in user has access. | private | userPools / oidc / iam |\n| Per user group data access. A specific or dynamically configured group of users have access | group | userPools / oidc |\n| Define your own custom authorization rule within a Lambda function | custom | function |"
      },
      {
        "heading": "Public data access",
        "depth": 3,
        "text": "To grant everyone access, use the public authorization strategy. Behind the scenes, the API will be protected with an API Key."
      },
      {
        "heading": "Public data access",
        "depth": 3,
        "text": "You can also override the authorization provider. In the example below, iam is specified as the provider which allows you to use an \"Unauthenticated Role\" from the Cognito identity pool for public access instead of an API Key. When you run amplify add auth, the  Amplify CLI generates scoped down IAM policies for the \"Unauthenticated role\" in Cognito identity pool automatically."
      },
      {
        "heading": "Per-user / owner-based data access",
        "depth": 3,
        "text": "To restrict a record's access to a specific user, use the owner authorization strategy. When owner authorization is configured, only the record's owner is allowed the specified operations."
      },
      {
        "heading": "Per-user / owner-based data access",
        "depth": 3,
        "text": "Behind the scenes, Amplify will automatically add a owner: String field to each record which contains the record owner's identity information upon record creation."
      },
      {
        "heading": "Per-user / owner-based data access",
        "depth": 3,
        "text": "By default, the Cognito user pool's user information is populated into the owner field. The value saved includes sub and username in the format <sub>::<username>. The API will authorize against the full value of <sub>::<username> or sub / username separately and return username. You can alternatively configure OpenID Connect as an authorization provider."
      },
      {
        "heading": "Per-user / owner-based data access",
        "depth": 3,
        "text": "You can override the owner field to your own preferred field, by specifying a custom ownerField in the authorization rule."
      },
      {
        "heading": "Per-user / owner-based data access",
        "depth": 3,
        "text": "By default, owners can reassign the owner of their existing record to another user."
      },
      {
        "heading": "Per-user / owner-based data access",
        "depth": 3,
        "text": "To prevent an owner from reassigning their record to another user, protect the owner field (by default owner: String) with a field-level authorization rule. For example, in a social media app, you would want to prevent Alice from being able to reassign Alice's Post to Bob."
      },
      {
        "heading": "Per-user / owner-based data access",
        "depth": 3,
        "text": "By default, only one user can be an owner of a record. If you want to grant a set of users access to a record, you can override the ownerField to a list of owners. Use this if you want a dynamic set of users to have access to a record."
      },
      {
        "heading": "Per-user / owner-based data access",
        "depth": 3,
        "text": "In the example above, upon record creation, the authors list is populated with the creator of the record. The creator can then update the authors field with additional users. Any user listed in the authors field can access the record."
      },
      {
        "heading": "Per-user / owner-based data access",
        "depth": 3,
        "text": "Known limitation: Real-time subscriptions are not supported when owner authorization is configured with a list of owners."
      },
      {
        "heading": "Signed-in user data access",
        "depth": 3,
        "text": "To restrict a record's access to every signed-in user, use the private authorization strategy."
      },
      {
        "heading": "Signed-in user data access",
        "depth": 3,
        "text": "If you want to restrict a record's access to a specific user, see Per-user / owner-based data access. private authorization applies the authorization rule to every signed-in user access."
      },
      {
        "heading": "Signed-in user data access",
        "depth": 3,
        "text": "In the example above, anyone with a valid JWT token from Cognito user pool are allowed to access all Todos."
      },
      {
        "heading": "Signed-in user data access",
        "depth": 3,
        "text": "You can also override the authorization provider. In the example below, iam is specified as the provider which allows you to use an \"Authenticated Role\" from the Cognito identity pool for public access instead of an API Key. When you run amplify add auth, the  Amplify CLI generates scoped down IAM policies for the \"Authenticated role\" in Cognito identity pool automatically."
      },
      {
        "heading": "Signed-in user data access",
        "depth": 3,
        "text": "In addition, you can also use OpenID Connect with private authorization. See OpenID Connect as an authorization provider."
      },
      {
        "heading": "Signed-in user data access",
        "depth": 3,
        "text": "Note: If you have a connected child model that allows private level access, any user authorized to fetch it from the parent model will be able to read the connected child model.\nFor example,"
      },
      {
        "heading": "Signed-in user data access",
        "depth": 3,
        "text": "In the above relationship, the owner of a Todo record can query all the tasks connected to it, since the Task model allows private read access."
      },
      {
        "heading": "User group-based data access",
        "depth": 3,
        "text": "To restrict access based on user groups, use the group authorization strategy."
      },
      {
        "heading": "User group-based data access",
        "depth": 3,
        "text": "Static group authorization: When you want to restrict access to a specific set of user groups, provide the group names in the groups parameter."
      },
      {
        "heading": "User group-based data access",
        "depth": 3,
        "text": "In the example above, only users that are part of the \"Admin\" user group are granted access to the Salary model."
      },
      {
        "heading": "User group-based data access",
        "depth": 3,
        "text": "Dynamic group authorization: When you want to restrict access to a set of user groups."
      },
      {
        "heading": "User group-based data access",
        "depth": 3,
        "text": "With dynamic group authorization, each record contains an attribute specifying what Cognito groups should be able to access it. Use the groupsField argument to specify which attribute in the underlying data store holds this group information. To specify that a single group should have access, use a field of type String. To specify that multiple groups should have access, use a field of type [String]."
      },
      {
        "heading": "User group-based data access",
        "depth": 3,
        "text": "By default, group authorization leverages Amazon Cognito user pool groups but you can also use OpenID Connect with group authorization. See OpenID Connect as an authorization provider."
      },
      {
        "heading": "User group-based data access",
        "depth": 3,
        "text": "Known limitation: Real-time subscriptions are not supported for dynamic group authorization."
      },
      {
        "heading": "Custom authorization rule",
        "depth": 3,
        "text": "You can define your own custom authorization rule with a Lambda function."
      },
      {
        "heading": "Custom authorization rule",
        "depth": 3,
        "text": "The Lambda function of choice will receive an authorization token from the client and execute the desired authorization logic. The AppSync GraphQL API will receive a payload from Lambda after invocation to allow or deny the API call accordingly."
      },
      {
        "heading": "Custom authorization rule",
        "depth": 3,
        "text": "Configure the GraphQL API with the Lambda authorization mode:"
      },
      {
        "heading": "Custom authorization rule",
        "depth": 3,
        "text": "You can use the default Amplify provided template as a starting point for your custom authorization rule. The authorization Lambda function receives:"
      },
      {
        "heading": "Custom authorization rule",
        "depth": 3,
        "text": "Your Lambda authorization function needs to return the following JSON:"
      },
      {
        "heading": "Custom authorization rule",
        "depth": 3,
        "text": "Review the Amplify Library documentation to set the custom authorization token for GraphQL API and DataStore."
      },
      {
        "heading": "Configure multiple authorization rules",
        "depth": 2,
        "text": "When combining multiple authorization rules, they are \"logically OR\"-ed."
      },
      {
        "heading": "Configure multiple authorization rules",
        "depth": 2,
        "text": "In the example above:"
      },
      {
        "heading": "Configure multiple authorization rules",
        "depth": 2,
        "text": "any user (signed in or not, verified by IAM) is allowed to read all posts"
      },
      {
        "heading": "Configure multiple authorization rules",
        "depth": 2,
        "text": "owners are allowed to create, read, update, and delete their own posts."
      },
      {
        "heading": "Field-level authorization rules",
        "depth": 2,
        "text": "When an authorization rule is added to a field, it'll strictly define the authorization rules applied on the field. Field-level authorization rules do not inherit model-level authorization rules. Meaning, only the specified field-level authorization rule is applied."
      },
      {
        "heading": "Field-level authorization rules",
        "depth": 2,
        "text": "In the example above:"
      },
      {
        "heading": "Field-level authorization rules",
        "depth": 2,
        "text": "Owners are allowed to create, read, update, and delete Employee records they own"
      },
      {
        "heading": "Field-level authorization rules",
        "depth": 2,
        "text": "Any signed in user has read access"
      },
      {
        "heading": "Field-level authorization rules",
        "depth": 2,
        "text": "Any signed in user can read data with the exception of the ssn field. This field only has owner auth applied, the field-level auth rule means that model-level auth rules are not applied"
      },
      {
        "heading": "Field-level authorization rules",
        "depth": 2,
        "text": "To prevent sensitive data from being sent over subscriptions, the GraphQL Transformer needs to alter the response of mutations for those fields by setting them to null. Therefore, to facilitate field-level authorization with subscriptions, you need to either apply field-level authorization rules to all required fields, make the other fields nullable, or disable subscriptions by setting it to public or off."
      },
      {
        "heading": "Field-level authorization rules",
        "depth": 2,
        "text": "In the example above:"
      },
      {
        "heading": "Field-level authorization rules",
        "depth": 2,
        "text": "any signed in user is allowed to read the list of employees' name and email fields"
      },
      {
        "heading": "Field-level authorization rules",
        "depth": 2,
        "text": "only the employee/owner themselves have CRUD access to their ssn field"
      },
      {
        "heading": "Review and print access control matrix",
        "depth": 3,
        "text": "Verify your API's access control matrix, by running the following command:"
      },
      {
        "heading": "Use IAM authorization within the AppSync console",
        "depth": 3,
        "text": "IAM-based @auth rules are scoped down to only work with Amplify-generated IAM roles. To access the GraphQL API with IAM authorization within your AppSync console, you need to explicitly allow list the IAM user's name by adding them to amplify/backend/api/<your-api-name>/custom-roles.json. (Create the custom-roles.json file if it doesn't exist). Append the adminRoleNames array with the IAM role or user names:"
      },
      {
        "heading": "Use IAM authorization within the AppSync console",
        "depth": 3,
        "text": "These \"Admin Roles\" have special access privileges that are scoped based on their IAM policy instead of any particular @auth rule."
      },
      {
        "heading": "Using OIDC authorization provider",
        "depth": 3,
        "text": "private, owner, and group authorization can be configured with an OpenID Connect (OIDC) authorization mode. Add provider: oidc to the authorization rule. Upon the next amplify push, Amplify CLI prompts you for the OpenID Connect provider domain, Client ID, Issued at TTL, and Auth Time TTL."
      },
      {
        "heading": "Using OIDC authorization provider",
        "depth": 3,
        "text": "The example above highlights the supported authorization strategies with oidc authorization provider. For owner and group authorization, you also need to specify a custom identity and group claim."
      },
      {
        "heading": "Configure custom identity and group claims",
        "depth": 3,
        "text": "@auth supports using custom claims if you do not wish to use the default Amazon Cognito-provided \"cognito:groups\" or the double-colon-delimited claims, \"sub::username\", from your JWT token. This can be helpful if you are using tokens from a 3rd party OIDC system or if you wish to populate a claim with a list of groups from an external system, such as when using a Pre Token Generation Lambda Trigger which reads from a database. To use custom claims specify identityClaim or groupClaim as appropriate like in the example below:"
      },
      {
        "heading": "Configure custom identity and group claims",
        "depth": 3,
        "text": "In this example the record owner will check against a user_id claim. Similarly, if the user_groups claim contains a \"Moderator\" string then access will be granted."
      },
      {
        "heading": "Grant Lambda function access to GraphQL API",
        "depth": 3,
        "text": "If you grant a Lambda function in your Amplify project access to the GraphQL API via amplify update function, then the Lambda function's IAM execution role is allow-listed to honor the permissions granted on the Query, Mutation, and Subscription types."
      },
      {
        "heading": "Grant Lambda function access to GraphQL API",
        "depth": 3,
        "text": "Therefore, these functions have special access privileges that are scoped based on their IAM policy instead of any particular @auth rule."
      },
      {
        "heading": "Grant Lambda function access to GraphQL API",
        "depth": 3,
        "text": "To grant an external Lambda function or an IAM role access to this GraphQL API, you need to explicitly allow list the IAM role's name by adding them to amplify/backend/api/<your-api-name>/custom-roles.json. (Create the custom-roles.json file if it doesn't exist). Append the adminRoleNames array with the IAM role names:"
      },
      {
        "heading": "Grant Lambda function access to GraphQL API",
        "depth": 3,
        "text": "These \"Admin Roles\" have special access privileges that are scoped based on their IAM policy instead of any particular @auth rule."
      },
      {
        "heading": "How it works",
        "depth": 3,
        "text": "Definition of the @auth directive:"
      },
      {
        "heading": "How it works",
        "depth": 3,
        "text": "Authorization rules consists of:"
      },
      {
        "heading": "How it works",
        "depth": 3,
        "text": "authorization strategy (allow): who the authorization rule applies to"
      },
      {
        "heading": "How it works",
        "depth": 3,
        "text": "authorization provider (provider): which mechanism is used to apply the authorization rule (API Key, IAM, Amazon Cognito user pool, OIDC)"
      },
      {
        "heading": "How it works",
        "depth": 3,
        "text": "authorized operations (operations): which operations are allowed for the given strategy and provider. If not specified, create, read, update, and delete operations are allowed."
      },
      {
        "heading": "How it works",
        "depth": 3,
        "text": "read operation: read operation can be replaced with get, list, sync, listen, and search for a more granular query access"
      },
      {
        "heading": "How it works",
        "depth": 3,
        "text": "API Keys are best used for public APIs (or parts of your schema which you wish to be public) or prototyping, and you must specify the expiration time before deploying. IAM authorization uses Signature Version 4 to make request with policies attached to Roles. OIDC tokens provided by Amazon Cognito user pool or 3rd party OpenID Connect providers can also be used for authorization, and enabling this provides a simple access control requiring users to authenticate to be granted top level access to API actions."
      }
    ],
    "source": "export const meta = {\n  title: `Authorization rules`,\n  description: `Add authorization rules to your GraphQL schema to control access to your data.`,\n};\n\n<MigrationAlert url={\"/cli-legacy/graphql-transformer/auth\"}/>\n\nUse the `@auth` directive to configure authorization rules for public, sign-in user, per user, and per user group data access. **Authorization rules operate on the deny-by-default principle**. Meaning that if an authorization rule is not specifically configured, it is denied.\n\n```graphql\ntype Todo @model @auth(rules: [{ allow: owner }]) {\n  content: String\n}\n```\n\nIn the example above, each signed-in user, or also known as \"owner\", of a Todo can create, read, update, and delete their own Todos.\n\nAmplify also allows you to restrict the allowed operations, combine multiple authorization rules, and apply fine-grained field-level authorization.\n\n``` graphql\ntype Todo @model @auth(rules: [\n  { allow: public, operations: [read]},\n  { allow: owner }\n]) {\n  content: String\n}\n```\n\nIn the example above, everyone (`public`) can read every Todo but owner (authenticated users) can create, read, update, and delete their own Todos.\n\n### Global authorization rule (only for getting started)\n\nTo help you get started, there's a global authorization rule defined when you create a new GraphQL schema. For production environments, remove the global authorization rule and apply rules on each model instead.\n\n```graphql\ninput AMPLIFY { globalAuthRule: AuthRule = { allow: public } }\n```\n\nThe global authorization rule (in this case `{ allow: public }` - allows anyone to create, read, update, and delete) is applied to every data model in the GraphQL schema.\n\n<Callout warning>\n\nCurrently, only `{ allow: public }` is supported as a global authorization rule.\n\n</Callout>\n\n## Authorization strategies\n\nUse the guide below to select the correct authorization strategy for your use case:\n\n| **Recommended use case** | **Strategy** | **Provider** |\n|---|---|---|\n| Public data access where users or devices are anonymous. Anyone with the AppSync API key is granted access. | [`public`]() | `apiKey` |\n| Recommended for production environment's public data access. Public data access where unauthenticated users or devices are granted permissions using AWS IAM controls. | [`public`]() | `iam` |\n| Per user data access. Access is restricted to the \"owner\" of a record. Leverages `amplify add auth` Cognito user pool by default. | [`owner`]() | `userPools` / `oidc` |\n| Any signed-in data access. Unlike owner-based access, **any** signed-in user has access. | [`private`]() | `userPools` / `oidc` / `iam` |\n| Per user group data access. A specific or dynamically configured group of users have access | [`group`]() | `userPools` / `oidc` |\n| Define your own custom authorization rule within a Lambda function | [`custom`]() | `function` |\n\n### Public data access\n\nTo grant everyone access, use the `public` authorization strategy. Behind the scenes, the API will be protected with an API Key.\n\n```graphql\ntype Todo @model @auth(rules: [{ allow: public }]) {\n  content: String\n}\n```\n\nYou can also override the authorization provider. In the example below, `iam` is specified as the provider which allows you to use an \"Unauthenticated Role\" from the Cognito identity pool for public access instead of an API Key. When you run `amplify add auth`, the  Amplify CLI generates scoped down IAM policies for the \"Unauthenticated role\" in Cognito identity pool automatically.\n\n```graphql\n# public authorization with provider override\ntype Post @model @auth(rules: [{ allow: public, provider: iam }]) {\n  id: ID!\n  title: String!\n}\n```\n\n### Per-user / owner-based data access\nTo restrict a record's access to a specific user, use the `owner` authorization strategy. When `owner` authorization is configured, only the record's `owner` is allowed the specified operations.\n\n```graphql\n# The \"owner\" of a Todo is allowed to create, read, update, and delete their own todos\ntype Todo @model @auth(rules: [{ allow: owner }]) {\n  content: String\n}\n\n# The \"owner\" of a Todo record is only allowed to create, read, and update it.\n# The \"owner\" of a Todo record is denied to delete it.\ntype Todo @model @auth(rules: [{ allow: owner, operations: [create, read, update] }]) {\n  content: String\n}\n```\n\nBehind the scenes, Amplify will automatically add a `owner: String` field to each record which contains the record owner's identity information upon record creation.\n\nBy default, the Cognito user pool's user information is populated into the `owner` field. The value saved includes `sub` and `username` in the format `<sub>::<username>`. The API will authorize against the full value of `<sub>::<username>` or `sub` / `username` separately and return `username`. You can alternatively configure [OpenID Connect as an authorization provider](#using-oidc-authorization-provider).\n\nYou can override the `owner` field to your own preferred field, by specifying a custom `ownerField` in the authorization rule.\n\n```graphql\ntype Todo @model @auth(rules: [{ allow: owner, ownerField: \"author\" }]) {\n  content: String                             #^^^^^^^^^^^^^^^^^^^^\n  author: String # record owner information now stored in \"author\" field\n}\n```\n\n<Callout warning>\n\n  **By default, owners can reassign the owner of their existing record to another user.**\n\n  To prevent an owner from reassigning their record to another user, protect the owner field (by default `owner: String`) with a [field-level authorization rule](#field-level-authorization-rules). For example, in a social media app, you would want to prevent Alice from being able to reassign Alice's Post to Bob.\n\n  ```graphql\n  type Todo @model @auth(rules: [{ allow: owner }]) {\n    id: ID!\n    description: String\n    owner: String @auth(rules: [{ allow: owner, operations: [read, delete] }])\n  }\n  ```\n</Callout>\n\nBy default, only one user can be an owner of a record. If you want to grant a set of users access to a record, you can override the `ownerField` to a list of owners. Use this if you want a dynamic set of users to have access to a record.\n\n```graphql\ntype Todo @model @auth(rules: [{ allow: owner, ownerField: \"authors\" }]) {\n  content: String\n  authors: [String]\n}\n```\n\nIn the example above, upon record creation, the `authors` list is populated with the creator of the record. The creator can then update the `authors` field with additional users. Any user listed in the `authors` field can access the record.\n\n**Known limitation**: Real-time subscriptions are not supported when `owner` authorization is configured with a list of owners.\n\n### Signed-in user data access\nTo restrict a record's access to every signed-in user, use the `private` authorization strategy.\n\n> If you want to restrict a record's access to a specific user, see [Per-user / owner-based data access](#per-user--owner-based-data-access). `private` authorization applies the authorization rule to **every** signed-in user access.\n\n```graphql\ntype Todo @model @auth(rules: [{ allow: private }]) {\n  content: String\n}\n```\n\nIn the example above, anyone with a valid JWT token from Cognito user pool are allowed to access all Todos.\n\nYou can also override the authorization provider. In the example below, `iam` is specified as the provider which allows you to use an \"Authenticated Role\" from the Cognito identity pool for public access instead of an API Key. When you run `amplify add auth`, the  Amplify CLI generates scoped down IAM policies for the \"Authenticated role\" in Cognito identity pool automatically.\n\n```graphql\ntype Todo @model @auth(rules: [{ allow: private, provider: iam }]) {\n  content: String\n}\n```\n\nIn addition, you can also use OpenID Connect with `private` authorization. See [OpenID Connect as an authorization provider](#using-oidc-authorization-provider).\n\n**Note:** If you have a connected child model that allows `private` level access, any user authorized to fetch it from the parent model will be able to read the connected child model.\nFor example,\n```graphql\ntype Todo @model @auth(rules: [{ allow: owner }]) {\n  id: ID!\n  name: String!\n  task: [Task] @hasMany\n}\n\ntype Task @model @auth(rules: [{ allow: owner }, { allow: private, operations: [read] }]) {\n  id: ID!\n  description: String!\n}\n```\nIn the above relationship, the owner of a `Todo` record can query all the tasks connected to it, since the `Task` model allows `private` read access.\n\n### User group-based data access\nTo restrict access based on user groups, use the `group` authorization strategy.\n\n**Static group authorization**: When you want to restrict access to a specific set of user groups, provide the group names in the `groups` parameter.\n\n```graphql\ntype Salary @model @auth(rules: [{ allow: groups, groups: [\"Admin\"] }]) {\n  id: ID!\n  wage: Int\n  currency: String\n}\n```\n\nIn the example above, only users that are part of the \"Admin\" user group are granted access to the Salary model.\n\n**Dynamic group authorization**: When you want to restrict access to a set of user groups.\n\n```graphql\n# Dynamic group authorization with multiple groups\ntype Post @model @auth(rules: [{ allow: groups, groupsField: \"groups\" }]) {\n  id: ID!\n  title: String\n  groups: [String]\n}\n\n# Dynamic group authorization with a single group\ntype Post @model @auth(rules: [{ allow: groups, groupsField: \"group\" }]) {\n  id: ID!\n  title: String\n  group: String\n}\n```\n\nWith dynamic group authorization, each record contains an attribute specifying what Cognito groups should be able to access it. Use the `groupsField` argument to specify which attribute in the underlying data store holds this group information. To specify that a single group should have access, use a field of type `String`. To specify that multiple groups should have access, use a field of type `[String]`.\n\nBy default, `group` authorization leverages Amazon Cognito user pool groups but you can also use OpenID Connect with `group` authorization. See [OpenID Connect as an authorization provider](#using-oidc-authorization-provider).\n\n**Known limitation**: Real-time subscriptions are not supported for dynamic group authorization.\n\n### Custom authorization rule\n\nYou can define your own custom authorization rule with a Lambda function.\n\n```graphql\ntype Salary @model @auth(rules: [{ allow: custom }]) {\n  id: ID!\n  wage: Int\n  currency: String\n}\n```\n\nThe Lambda function of choice will receive an authorization token from the client and execute the desired authorization logic. The AppSync GraphQL API will receive a payload from Lambda after invocation to allow or deny the API call accordingly.\n\nConfigure the GraphQL API with the Lambda authorization mode:\n\n```bash\namplify update api\n```\n```\n? Select a setting to edit:\n> Authorization modes\n\n> Lambda\n\n? Choose a Lambda source:\n> Create a new Lambda function\n```\n\nYou can use the default Amplify provided template as a starting point for your custom authorization rule. The authorization Lambda function receives:\n\n```json\n{\n    \"authorizationToken\": \"ExampleAuthToken123123123\", # Authorization token specified by client\n    \"requestContext\": {\n        \"apiId\": \"aaaaaa123123123example123\", # AppSync API ID\n        \"accountId\": \"111122223333\", # AWS Account ID\n        \"requestId\": \"f4081827-1111-4444-5555-5cf4695f339f\",\n        \"queryString\": \"mutation CreateEvent {...}\\n\\nquery MyQuery {...}\\n\", # GraphQL query\n        \"operationName\": \"MyQuery\", # GraphQL operation name\n        \"variables\": {} # any additional variables supplied to the operation\n    }\n}\n```\n\nYour Lambda authorization function needs to return the following JSON:\n\n```json\n{\n  // required\n  \"isAuthorized\": true, // if \"false\" then an UnauthorizedException is raised, access is denied\n  \"resolverContext\": { \"banana\": \"very yellow\" }, // JSON object visible as $ctx.identity.resolverContext in VTL resolver templates\n\n  // optional\n  \"deniedFields\": [\"TypeName.FieldName\"], // Forces the fields to \"null\" when returned to the client\n  \"ttlOverride\": 10 // The number of seconds that the response should be cached for. Overrides default specified in \"amplify update api\"\n}\n```\n\nReview the Amplify Library documentation to set the custom authorization token for [GraphQL API](/lib/graphqlapi/authz#aws-lambda) and [DataStore](/lib/datastore/setup-auth-rules#configure-custom-authorization-logic-with-aws-lambda).\n\n## Configure multiple authorization rules\nWhen combining multiple authorization rules, they are \"logically OR\"-ed.\n\n```graphql\ntype Post @model @auth(rules: [\n  { allow: public, operations: [read], provider: iam },\n  { allow: owner }]) {\n  title: String\n  content: String\n}\n```\n\nIn the example above:\n- any user (signed in or not, verified by IAM) is allowed to read all posts\n- owners are allowed to create, read, update, and delete their own posts.\n\n## Field-level authorization rules\n\nWhen an authorization rule is added to a field, it'll strictly define the authorization rules applied on the field. Field-level authorization rules **do not** inherit model-level authorization rules. Meaning, only the specified field-level authorization rule is applied.\n\n```graphql\ntype Employee @model @auth(rules: [\n  { allow: private, operations: [read] },\n  { allow: owner }\n]) {\n  name: String\n  email: String\n  ssn: String @auth(rules: [{ allow: owner }])\n}\n```\n\nIn the example above:\n- Owners are allowed to create, read, update, and delete Employee records they own\n- Any signed in user has read access\n- Any signed in user can read data with the exception of the `ssn` field. This field only has owner auth applied, the field-level auth rule means that model-level auth rules are not applied\n\n<Callout warning>\n\nTo prevent sensitive data from being sent over subscriptions, the GraphQL Transformer needs to alter the response of mutations for those fields by setting them to null. Therefore, to facilitate field-level authorization with subscriptions, you need to either apply field-level authorization rules to all **required** fields, make the other fields nullable, or disable subscriptions by setting it to public or off. \n  \n</Callout>\n\nIn the example above:\n- **any signed in user** is allowed to read the list of employees' `name` and `email` fields\n- **only the employee/owner themselves** have CRUD access to their `ssn` field\n\n## Advanced\n\n### Review and print access control matrix\n\nVerify your API's access control matrix, by running the following command:\n```bash\namplify status api -acm Blog\n```\n```console\niam:public\n  ┌─────────┬────────┬──────┬────────┬────────┐\n  │ (index) │ create │ read │ update │ delete │\n  ├─────────┼────────┼──────┼────────┼────────┤\n  │  title  │ false  │ true │ false  │ false  │\n  │ content │ false  │ true │ false  │ false  │\n  └─────────┴────────┴──────┴────────┴────────┘\nuserPools:owner:owner\n  ┌─────────┬────────┬──────┬────────┬────────┐\n  │ (index) │ create │ read │ update │ delete │\n  ├─────────┼────────┼──────┼────────┼────────┤\n  │  title  │  true  │ true │  true  │  true  │\n  │ content │  true  │ true │  true  │  true  │\n  └─────────┴────────┴──────┴────────┴────────┘\n```\n\n### Use IAM authorization within the AppSync console\nIAM-based `@auth` rules are scoped down to only work with Amplify-generated IAM roles. To access the GraphQL API with IAM authorization within your AppSync console, you need to explicitly allow list the IAM user's name by adding them to `amplify/backend/api/<your-api-name>/custom-roles.json`. (Create the `custom-roles.json` file if it doesn't exist). Append the `adminRoleNames` array with the IAM role or user names:\n\n```json\n{\n  \"adminRoleNames\": [\"<YOUR_IAM_USER_OR_ROLE_NAME>\"]\n}\n```\n\nThese \"Admin Roles\" have special access privileges that are scoped based on their IAM policy instead of any particular `@auth` rule.\n\n### Using OIDC authorization provider\n`private`, `owner`, and `group` authorization can be configured with an OpenID Connect (OIDC) authorization mode. Add `provider: oidc` to the authorization rule. Upon the next `amplify push`, Amplify CLI prompts you for the *OpenID Connect provider domain*, *Client ID*, *Issued at TTL*, and *Auth Time TTL*.\n\n```graphql\ntype Todo\n  @model\n  @auth(rules: [\n    { allow: owner, provider: oidc, identityClaim: \"user_id\" },\n    { allow: private, provider: oidc },\n    { allow: group, provider: oidc, groupClaim: \"user_groups\" },\n  ]) {\n  content: String\n}\n```\n\nThe example above highlights the supported authorization strategies with `oidc` authorization provider. For `owner` and `group` authorization, you also need to [specify a custom identity and group claim](#configure-custom-identity-and-group-claims).\n\n### Configure custom identity and group claims\n\n`@auth` supports using custom claims if you do not wish to use the default Amazon Cognito-provided \"cognito:groups\" or the double-colon-delimited claims, \"sub::username\", from your JWT token. This can be helpful if you are using tokens from a 3rd party OIDC system or if you wish to populate a claim with a list of groups from an external system, such as when using a [Pre Token Generation Lambda Trigger](https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-lambda-pre-token-generation.html) which reads from a database. To use custom claims specify `identityClaim` or `groupClaim` as appropriate like in the example below:\n\n```graphql\ntype Post @model\n  @auth(rules: [\n    { allow: owner, identityClaim: \"user_id\" },\n    { allow: groups, groups: [\"Moderator\"], groupClaim: \"user_groups\" }\n  ]) {\n  id: ID!\n  owner: String\n  postname: String\n  content: String\n}\n```\n\nIn this example the record owner will check against a `user_id` claim. Similarly, if the `user_groups` claim contains a \"Moderator\" string then access will be granted.\n\n### Grant Lambda function access to GraphQL API\n<BlockSwitcher>\n\n<Block name=\"Function deployed using Amplify CLI\">\n\nIf you grant a Lambda function in your Amplify project access to the GraphQL API via `amplify update function`, then the Lambda function's IAM execution role is allow-listed to honor the permissions granted on the `Query`, `Mutation`, and `Subscription` types.\n\nTherefore, these functions have special access privileges that are scoped based on their IAM policy instead of any particular `@auth` rule.\n</Block>\n\n<Block name=\"Function deployed without Amplify CLI\">\n\nTo grant an external Lambda function or an IAM role access to this GraphQL API, you need to explicitly allow list the IAM role's name by adding them to `amplify/backend/api/<your-api-name>/custom-roles.json`. (Create the `custom-roles.json` file if it doesn't exist). Append the `adminRoleNames` array with the IAM role names:\n\n```json\n{\n  \"adminRoleNames\": [\"<YOUR_IAM_ROLE_NAME>\"]\n}\n```\n\nThese \"Admin Roles\" have special access privileges that are scoped based on their IAM policy instead of any particular `@auth` rule.\n\n</Block>\n\n</BlockSwitcher>\n\n### How it works\n\nDefinition of the `@auth` directive:\n```graphql\n# When applied to a type, augments the application with\n# owner and group-based authorization rules.\ndirective @auth(rules: [AuthRule!]!) on OBJECT | FIELD_DEFINITION\ninput AuthRule {\n  allow: AuthStrategy!\n  provider: AuthProvider\n  ownerField: String # defaults to \"owner\" when using owner auth\n  identityClaim: String # defaults to \"sub::username\" when using owner auth\n  groupClaim: String # defaults to \"cognito:groups\" when using Group auth\n  groups: [String]  # Required when using Static Group auth\n  groupsField: String # defaults to \"groups\" when using Dynamic Group auth\n  operations: [ModelOperation] # Required for finer control\n}\n\nenum AuthStrategy { owner groups private public custom }\nenum AuthProvider { apiKey iam oidc userPools function }\nenum ModelOperation {\n  create\n  update\n  delete\n  read # Short-hand to allow \"get\", \"list\", \"sync\", \"listen\", and \"search\"\n  \n  get # Retrieves an individual item\n  list # Retrieves a list of items\n  sync # Enables ability to sync offline/online changes (including via DataStore)\n  listen # Subscribes to real-time changes\n  search # Enables ability to search using @searchable directive\n}\n```\n\nAuthorization rules consists of:\n- **authorization strategy** (`allow`): who the authorization rule applies to\n- **authorization provider** (`provider`): which mechanism is used to apply the authorization rule (API Key, IAM, Amazon Cognito user pool, OIDC)\n- **authorized operations** (`operations`): which operations are allowed for the given strategy and provider. If not specified, `create`, `read`, `update`, and `delete` operations are allowed.\n  - **`read` operation**: `read` operation can be replaced with `get`, `list`, `sync`, `listen`, and `search` for a more granular query access\n\n**API Keys** are best used for public APIs (or parts of your schema which you wish to be public) or prototyping, and you must specify the expiration time before deploying. **IAM** authorization uses [Signature Version 4](https://docs.aws.amazon.com/general/latest/gr/signature-version-4.html) to make request with policies attached to Roles. OIDC tokens provided by **Amazon Cognito user pool** or **3rd party OpenID Connect** providers can also be used for authorization, and enabling this provides a simple access control requiring users to authenticate to be granted top level access to API actions.\n",
    "meta": {
      "title": "Authorization rules",
      "description": "Add authorization rules to your GraphQL schema to control access to your data.",
      "subcategory": "API (GraphQL)",
      "category": "Amplify CLI"
    },
    "filename": "/cli/graphql/authorization-rules"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Amplify automatically creates Amazon DynamoDB database tables for GraphQL types annotated with the @model directive in your GraphQL schema. You can create relations between the data models via the @hasOne, @hasMany, @belongsTo, and @manyToMany directives."
      },
      {
        "heading": "Setup database tables",
        "depth": 2,
        "text": "The following GraphQL schema automatically creates a database table for \"Todo\". @model will also automatically add an id field as a primary key to the database table. See Configure a primary key to learn how to customize the primary key."
      },
      {
        "heading": "Setup database tables",
        "depth": 2,
        "text": "The Amplify CLI generates the Todo database table upon amplify push and generates a GraphQL API to perform create, read, update, delete, and list operations for the Todo model."
      },
      {
        "heading": "Setup database tables",
        "depth": 2,
        "text": "In addition, @model also adds the helper fields createdAt and updatedAt to your type. The values for those fields are read-only by clients unless explicitly overwritten. See Customize creation and update timestamps to learn more."
      },
      {
        "heading": "Setup database tables",
        "depth": 2,
        "text": "Try listing all the todos by executing the following query:"
      },
      {
        "heading": "Configure a primary key",
        "depth": 3,
        "text": "Every GraphQL type with the @model directive will automatically have an id field set as the primary key. You can override this behavior by marking another required field with the @primaryKey directive."
      },
      {
        "heading": "Configure a primary key",
        "depth": 3,
        "text": "In the example below, todoId is the database's primary key and an id field will no longer be created automatically anymore by the @model directive."
      },
      {
        "heading": "Configure a primary key",
        "depth": 3,
        "text": "Without any further configuration, you'll only be able to query for a Todo via an exact equality match of its primary key field. In the example above, this is the todoId field."
      },
      {
        "heading": "Configure a primary key",
        "depth": 3,
        "text": "Note: After a primary key is configured and deployed, you can't change it without deleting and recreating your database table."
      },
      {
        "heading": "Configure a primary key",
        "depth": 3,
        "text": "You can also specify \"sort keys\" to use a combination of different fields as a primary key. This also allows you to apply more advanced sorting and filtering conditions on the specified \"sort key fields\"."
      },
      {
        "heading": "Configure a primary key",
        "depth": 3,
        "text": "The schema above will allow you to pass different conditions to query the correct inventory item:"
      },
      {
        "heading": "Configure a secondary index",
        "depth": 3,
        "text": "Amplify uses Amazon DynamoDB tables as the underlying data source for @model types. For key-value databases, it is critical to model your access patterns with \"secondary indexes\". Use the @index directive to configure a secondary index."
      },
      {
        "heading": "Configure a secondary index",
        "depth": 3,
        "text": "Amazon DynamoDB is a key-value and document database that delivers single-digit millisecond performance at any scale but making it work for your access patterns requires a bit of forethought. DynamoDB query operations may use at most two attributes to efficiently query data. The first query argument passed to a query (the hash key) must use strict equality and the second attribute (the sort key) may use gt, ge, lt, le, eq, beginsWith, and between. DynamoDB can effectively implement a wide variety of access patterns that are powerful enough for the majority of applications."
      },
      {
        "heading": "Configure a secondary index",
        "depth": 3,
        "text": "A secondary index consists of a \"hash key\" and, optionally, a \"sort key\". Use the \"hash key\" to perform strict equality and the \"sort key\" for greater than (gt), greater than or equal to (ge), less than (lt), less than or equal to (le), equals (eq), begins with, and between operations."
      },
      {
        "heading": "Configure a secondary index",
        "depth": 3,
        "text": "The example client query below allows you to query for \"Customer\" based on their accountRepresentativeID:"
      },
      {
        "heading": "Configure a secondary index",
        "depth": 3,
        "text": "To optionally configure sort keys, provide the additional fields in the sortKeyFields parameter:"
      },
      {
        "heading": "Configure a secondary index",
        "depth": 3,
        "text": "The example client query below allows you to query for \"Customer\" based on their name and filter based on phoneNumber:"
      },
      {
        "heading": "Setup relationships between models",
        "depth": 2,
        "text": "Create \"has one\", \"has many\", \"belongs to\", and \"many to many\" relationships between @model types."
      },
      {
        "heading": "Setup relationships between models",
        "depth": 2,
        "text": "|Relationship|Description|\n|------------|--------|\n|@hasOne|Create a one-directional one-to-one relationship between two models. For example, a Project \"has one\" Team. This allows you to query the team from the project record.\n|@hasMany|Create a one-directional one-to-many relationship between two models. For example, a Post has many comments. This allows you to query all the comments from the post record.\n|@belongsTo|Use a \"belongs to\" relationship to make a \"has one\" or \"has many\" relationship bi-directional. For example, a Project has one Team and a Team belongs to a Project. This allows you to query the team from the project record and vice versa.\n|@manyToMany|Configures a \"join table\" between two models to facilitate a many-to-many relationship. For example, a Blog has many Tags and a Tag has many Blogs."
      },
      {
        "heading": "Has One relationship",
        "depth": 3,
        "text": "Create a one-directional one-to-one relationship between two models using the @hasOne directive."
      },
      {
        "heading": "Has One relationship",
        "depth": 3,
        "text": "In the example below, a Project has a Team."
      },
      {
        "heading": "Has One relationship",
        "depth": 3,
        "text": "This generates queries and mutations that allow you to retrieve the related record from the source record:"
      },
      {
        "heading": "Has One relationship",
        "depth": 3,
        "text": "To customize the field to be used for storing the relationship information, set the fields array argument and matching it to a field on the type:"
      },
      {
        "heading": "Has One relationship",
        "depth": 3,
        "text": "In this case, the Project type has a teamID field added as an identifier for the team. @hasOne can then get the connected Team object by querying the Team table with this teamID:"
      },
      {
        "heading": "Has One relationship",
        "depth": 3,
        "text": "A @hasOne relationship always uses a reference to the primary key of the related model, by default id unless overridden with the @primaryKey directive."
      },
      {
        "heading": "Has Many relationship",
        "depth": 3,
        "text": "Create a one-directional one-to-many relationship between two models using the @hasMany directive."
      },
      {
        "heading": "Has Many relationship",
        "depth": 3,
        "text": "This generates queries and mutations that allow you to retrieve the related Comment records from the source Post record:"
      },
      {
        "heading": "Has Many relationship",
        "depth": 3,
        "text": "Under the hood, @hasMany configures a default secondary index on the related table to enable you to query the related model from the source model."
      },
      {
        "heading": "Has Many relationship",
        "depth": 3,
        "text": "To customize the specific secondary index used for the \"has many\" relationship, create an @index directive on the field in the related table where you want to assign the secondary index."
      },
      {
        "heading": "Has Many relationship",
        "depth": 3,
        "text": "Next, provide the secondary index with a name attribute and a value. Optionally, you can configure a “sort key” on the secondary index by providing a sortKeyFields attribute and a designated field as its value."
      },
      {
        "heading": "Has Many relationship",
        "depth": 3,
        "text": "On the @hasMany configuration, pass in the name value from your secondary index as the value for the indexName parameter. Then, pass in the respective fields that match the connected index."
      },
      {
        "heading": "Has Many relationship",
        "depth": 3,
        "text": "In this case, the Comment type has a postID field added to store the reference of Post record. The id field referenced by @hasMany is the id on the Post type. @hasMany can then get the connected Comment object by querying the Comment table's secondary index \"byPost\" with this postID:"
      },
      {
        "heading": "Belongs To relationship",
        "depth": 3,
        "text": "Bi-directional \"has one\" relationships currently cannot be represented on iOS due to Swift language limitations."
      },
      {
        "heading": "Belongs To relationship",
        "depth": 3,
        "text": "Make a \"has one\" or \"has many\" relationship bi-directional with the @belongsTo directive."
      },
      {
        "heading": "Belongs To relationship",
        "depth": 3,
        "text": "This generates queries and mutations that allow you to retrieve the related Comment records from the source Post record and vice versa:"
      },
      {
        "heading": "Belongs To relationship",
        "depth": 3,
        "text": "This generates queries and mutations that allow you to retrieve the related Comment records from the source Post record and vice versa:"
      },
      {
        "heading": "Belongs To relationship",
        "depth": 3,
        "text": "@belongsTo can be used without the fields argument. In those cases, a field is automatically generated to reference the parent’s primary key."
      },
      {
        "heading": "Belongs To relationship",
        "depth": 3,
        "text": "Alternatively, you set up a custom field to store the reference of the parent object. An example bidirectional “has many” relationship is shown below."
      },
      {
        "heading": "Belongs To relationship",
        "depth": 3,
        "text": "Note: The @belongsTo directive requires that a @hasOne or @hasMany relationship already exists from parent to the related model."
      },
      {
        "heading": "Many-to-many relationship",
        "depth": 3,
        "text": "Create a many-to-many relationship between two models with the @manyToMany directive. Provide a common relationName on both models to join them into a many-to-many relationship."
      },
      {
        "heading": "Many-to-many relationship",
        "depth": 3,
        "text": "Under the hood, the @manyToMany directive will create a \"join table\" named after the relationName to facilitate the many-to-many relationship. This generates queries and mutations that allow you to retrieve the related Comment records from the source Post record and vice versa:"
      },
      {
        "heading": "Assign default values for fields",
        "depth": 2,
        "text": "You can use the @default directive to specify a default value for optional scalar type fields such as Int, String, and more."
      },
      {
        "heading": "Assign default values for fields",
        "depth": 2,
        "text": "If you create a new Todo and don't supply a content input, Amplify will ensure that My new Todo is auto populated as a value.\nWhen @default is applied, non-null assertions using ! are disregarded. For example, String! is treated the same as String."
      },
      {
        "heading": "Rename generated queries, mutations, and subscriptions",
        "depth": 3,
        "text": "You can override the names of any @model-generated GraphQL queries, mutations, and subscriptions by supplying the desired name."
      },
      {
        "heading": "Rename generated queries, mutations, and subscriptions",
        "depth": 3,
        "text": "In the example above, we will be able to run a queryForTodo query to get a single Todo element."
      },
      {
        "heading": "Disable generated queries, mutations, and subscriptions",
        "depth": 3,
        "text": "We can disable specific operations by assigning their value to null."
      },
      {
        "heading": "Disable generated queries, mutations, and subscriptions",
        "depth": 3,
        "text": "The example above disables the getTodo query, all mutations, and all subscriptions while allowing the generation of other queries such as listTodo."
      },
      {
        "heading": "Creating a custom query",
        "depth": 3,
        "text": "We can disable the get query and create a custom query that enables us to retrieve a single Todo model."
      },
      {
        "heading": "Creating a custom query",
        "depth": 3,
        "text": "The example above creates a custom query that utilizes the @function directive to call a Lambda function for this query."
      },
      {
        "heading": "Creating a custom query",
        "depth": 3,
        "text": "For the type definitions of queries, mutations, and subscriptions, see Type Definitions of the @model Directive."
      },
      {
        "heading": "Customize creation and update timestamps",
        "depth": 3,
        "text": "The @model directive automatically adds createdAt and updatedAt timestamps to each entity. The timestamp field names can be changed by passing timestamps attribute to the directive."
      },
      {
        "heading": "Customize creation and update timestamps",
        "depth": 3,
        "text": "For example, the schema above will allow you to query for the following contents:"
      },
      {
        "heading": "Modify subscriptions (real-time updates) access level",
        "depth": 3,
        "text": "By default, real-time updates are on for all @model types, which means customers receive real-time updates and authorization rules are applied during initial connection time. You can also turn off subscriptions for that model or make the real-time updates public, receivable by all subscribers."
      },
      {
        "heading": "Create multiple relationships between two models",
        "depth": 3,
        "text": "You need to explicitly specify the connection field names if relational directives are used to create two connections of the same type between the two models."
      },
      {
        "heading": "How it works",
        "depth": 2,
        "text": "The @model directive will generate:"
      },
      {
        "heading": "How it works",
        "depth": 2,
        "text": "An Amazon DynamoDB table with PAY_PER_REQUEST billing mode enabled by default."
      },
      {
        "heading": "How it works",
        "depth": 2,
        "text": "An AWS AppSync DataSource configured to access the table above."
      },
      {
        "heading": "How it works",
        "depth": 2,
        "text": "An AWS IAM role attached to the DataSource that allows AWS AppSync to call the above table on your behalf."
      },
      {
        "heading": "How it works",
        "depth": 2,
        "text": "Up to 8 resolvers (create, update, delete, get, list, onCreate, onUpdate, onDelete) but this is configurable via the queries, mutations, and subscriptions arguments on the @model directive."
      },
      {
        "heading": "How it works",
        "depth": 2,
        "text": "Input objects for create, update, and delete mutations."
      },
      {
        "heading": "How it works",
        "depth": 2,
        "text": "Filter input objects that allow you to filter objects in list queries and relationship fields."
      },
      {
        "heading": "How it works",
        "depth": 2,
        "text": "For list queries the default number of objects returned is 100. You can override this behavior by setting the limit argument."
      }
    ],
    "source": "export const meta = {\n  title: `Data modeling`,\n  description: `Add authorization rules to your GraphQL schema to control access to your data.`,\n};\n\n<MigrationAlert url={\"/cli-legacy/graphql-transformer/key\"}/>\n\nAmplify automatically creates Amazon DynamoDB database tables for GraphQL types annotated with the `@model` directive in your GraphQL schema. You can create relations between the data models via the `@hasOne`, `@hasMany`, `@belongsTo`, and `@manyToMany` directives.\n\n## Setup database tables\n\nThe following GraphQL schema automatically creates a database table for \"Todo\". `@model` will also automatically add an `id` field as a primary key to the database table. *See [Configure a primary key](#configure-a-primary-key) to learn how to customize the primary key.*\n\n```graphql\ntype Todo @model {\n  content: String\n}\n```\n\nThe Amplify CLI generates the Todo database table upon `amplify push` and generates a GraphQL API to perform create, read, update, delete, and list operations for the Todo model.\n\nIn addition, `@model` also adds the helper fields `createdAt` and `updatedAt` to your type. The values for those fields are read-only by clients unless explicitly overwritten. See [Customize creation and update timestamps](#customize-creation-and-update-timestamps) to learn more.\n\nTry listing all the todos by executing the following query:\n```graphql\nquery QueryAllTodos {\n  listTodos() {\n    todos {\n      items {\n        id\n        content\n        createdAt\n        updatedAt\n      }\n    }\n  }\n}\n```\n\n### Configure a primary key\n\nEvery GraphQL type with the `@model` directive will automatically have an `id` field set as the primary key. You can override this behavior by marking another required field with the `@primaryKey` directive. \n\nIn the example below, `todoId` is the database's primary key and an `id` field will no longer be created automatically anymore by the `@model` directive.\n```graphql\ntype Todo @model {\n  todoId: ID! @primaryKey\n  content: String\n}\n```\n\nWithout any further configuration, you'll only be able to query for a Todo via an exact equality match of its primary key field. In the example above, this is the `todoId` field.\n\n> Note: After a primary key is configured and deployed, you can't change it without deleting and recreating your database table.\n\nYou can also specify \"sort keys\" to use a combination of different fields as a primary key. This also allows you to apply more advanced sorting and filtering conditions on the specified \"sort key fields\".\n\n```graphql\ntype Inventory @model {\n  productID: ID! @primaryKey(sortKeyFields: [\"warehouseID\"])\n  warehouseID: ID!\n  InventoryAmount: Int!\n}\n```\n\nThe schema above will allow you to pass different conditions to query the correct inventory item:\n```graphql\nquery QueryInventoryByProductAndWarehouse($productID: ID!, $warehouseID: ID!) {\n  getInventory(productID: $productID, warehouseID: $warehouseID) {\n    productID\n    warehouseID\n    inventoryAmount\n  }\n}\n```\n\n### Configure a secondary index\n\nAmplify uses Amazon DynamoDB tables as the underlying data source for @model types. For key-value databases, it is critical to model your access patterns with \"secondary indexes\". Use the `@index` directive to configure a secondary index. \n\n> **Amazon DynamoDB** is a key-value and document database that delivers single-digit millisecond performance at any scale but making it work for your access patterns requires a bit of forethought. DynamoDB query operations may use at most two attributes to efficiently query data. The first query argument passed to a query (the hash key) must use strict equality and the second attribute (the sort key) may use gt, ge, lt, le, eq, beginsWith, and between. DynamoDB can effectively implement a wide variety of access patterns that are powerful enough for the majority of applications.\n\nA secondary index consists of a \"hash key\" and, optionally, a \"sort key\". Use the \"hash key\" to perform strict equality and the \"sort key\" for greater than (gt), greater than or equal to (ge), less than (lt), less than or equal to (le), equals (eq), begins with, and between operations. \n\n```graphql\ntype Customer @model {\n  id: ID!\n  name: String!\n  phoneNumber: String\n  accountRepresentativeID: ID! @index(name: \"byRepresentative\", queryField: \"customerByRepresentative\")\n}\n```\n\nThe example client query below allows you to query for \"Customer\" based on their `accountRepresentativeID`:\n\n```graphql\nquery QueryCustomersForAccountRepresentative($representativeId: ID!) {\n  customerByRepresentative(accountRepresentativeID: $representativeId) {\n    customers {\n      items {\n        id\n        name\n        phoneNumber\n      }\n    }\n  }\n}\n```\n\nTo optionally configure sort keys, provide the additional fields in the `sortKeyFields` parameter:\n\n```graphql\ntype Customer @model @auth(rules: [{ allow: public }]) {\n  id: ID!\n  name: String! @index(name: \"byNameAndPhoneNumber\", sortKeyFields: [\"phoneNumber\"], queryField: \"customerByNameAndPhone\")\n  phoneNumber: String\n  accountRepresentativeID: ID! @index(name: \"byRepresentative\", queryField: \"customerByRepresentative\")\n}\n```\n\nThe example client query below allows you to query for \"Customer\" based on their `name` and filter based on `phoneNumber`:\n\n```graphql\nquery MyQuery {\n  customerByNameAndPhone(phoneNumber: {beginsWith: \"+1\"}, name: \"Rene\") {\n    items {\n      id\n      name\n      phoneNumber\n    }\n  }\n}\n```\n\n## Setup relationships between models\n\nCreate \"has one\", \"has many\", \"belongs to\", and \"many to many\" relationships between `@model` types.\n\n|Relationship|Description|\n|------------|--------|\n|`@hasOne`|Create a one-directional one-to-one relationship between two models. For example, a Project \"has one\" Team. This allows you to query the team from the project record.\n|`@hasMany`|Create a one-directional one-to-many relationship between two models. For example, a Post has many comments. This allows you to query all the comments from the post record.\n|`@belongsTo`|Use a \"belongs to\" relationship to make a \"has one\" or \"has many\" relationship bi-directional. For example, a Project has one Team and a Team belongs to a Project. This allows you to query the team from the project record and vice versa.\n|`@manyToMany`|Configures a \"join table\" between two models to facilitate a many-to-many relationship. For example, a Blog has many Tags and a Tag has many Blogs.  \n\n### Has One relationship\n\nimport gqlv2callout from \"/src/fragments/cli/gqlv2callout.mdx\";\n\n<Fragments fragments={{all: gqlv2callout}} />\n\nCreate a one-directional one-to-one relationship between two models using the `@hasOne` directive.\n\nIn the example below, a Project has a Team.\n```graphql\ntype Project @model {\n  id: ID!\n  name: String\n  team: Team @hasOne\n}\n\ntype Team @model {\n  id: ID!\n  name: String!\n}\n```\n\nThis generates queries and mutations that allow you to retrieve the related record from the source record:\n\n```graphql\nmutation CreateProject {\n  createProject(input: {projectTeamId: \"team-id\", name: \"Some Name\"}) {\n    team {\n      name\n      id\n    }\n    name\n    id\n  }\n}\n```\n\nTo customize the field to be used for storing the relationship information, set the `fields` array argument and matching it to a field on the type:\n\n```graphql\ntype Project @model {\n  id: ID!\n  name: String\n  teamID: ID\n  team: Team @hasOne(fields: [\"teamID\"])\n}\n\ntype Team @model {\n  id: ID!\n  name: String!\n}\n```\n\nIn this case, the Project type has a `teamID` field added as an identifier for the team. @hasOne can then get the connected Team object by querying the Team table with this `teamID`:\n\n```graphql\nmutation CreateProject {\n  createProject(input: { name: \"New Project\", teamID: \"a-team-id\"}) {\n    id\n    name\n    team {\n      id\n      name\n    }\n  }\n}\n```\n\nA `@hasOne` relationship always uses a reference to the primary key of the related model, by default `id` unless overridden with the [`@primaryKey` directive](#configure-a-primary-key).\n\n### Has Many relationship\n\n<Fragments fragments={{all: gqlv2callout}} />\n\nCreate a one-directional one-to-many relationship between two models using the `@hasMany` directive.\n\n```graphql\ntype Post @model {\n  id: ID!\n  title: String!\n  comments: [Comment] @hasMany\n}\n\ntype Comment @model {\n  id: ID!\n  content: String!\n}\n```\n\nThis generates queries and mutations that allow you to retrieve the related Comment records from the source Post record:\n\n```graphql\nmutation CreatePost {\n  createPost(input: {title: \"Hello World!!\"}) {\n    title\n    id\n    comments {\n      items {\n        id\n        content\n      }\n    }\n  }\n}\n```\n\nUnder the hood, `@hasMany` configures a default secondary index on the related table to enable you to query the related model from the source model.\n\nTo customize the specific secondary index used for the \"has many\" relationship, create an `@index` directive on the field in the related table where you want to assign the secondary index. \n\nNext, provide the secondary index with a `name` attribute and a value. Optionally, you can configure a “sort key” on the secondary index by providing a `sortKeyFields` attribute and a designated field as its value.\n\nOn the `@hasMany` configuration, pass in the name value from your secondary index as the value for the `indexName` parameter. Then, pass in the respective `fields` that match the connected index.\n\n\n```graphql\ntype Post @model {\n  id: ID!\n  title: String!\n  comments: [Comment] @hasMany(indexName: \"byPost\", fields: [\"id\"])\n}\n\ntype Comment @model {\n  id: ID!\n  postID: ID! @index(name: \"byPost\", sortKeyFields: [\"content\"])\n  content: String!\n}\n```\n\nIn this case, the Comment type has a `postID` field added to store the reference of Post record. The `id` field referenced by `@hasMany` is the `id` on the `Post` type. `@hasMany` can then get the connected Comment object by querying the Comment table's secondary index \"byPost\" with this `postID`:\n\n```graphql\nmutation CreatePost {\n  createPost(input: {title: \"Hello world!\"}) {\n    comments {\n      items {\n        postID\n        content\n        id\n      }\n    }\n    title\n    id\n  }\n}\n```\n\n### Belongs To relationship\n\n<Callout>\n\nBi-directional \"has one\" relationships currently cannot be represented on iOS due to Swift language limitations.\n</Callout>\n\nMake a \"has one\" or \"has many\" relationship bi-directional with the `@belongsTo` directive.\n\n<BlockSwitcher>\n\n<Block name='Bi-directional \"has one\" relationship'>\n\n```graphql\ntype Project @model {\n  id: ID!\n  name: String\n  team: Team @hasOne\n}\n\ntype Team @model {\n  id: ID!\n  name: String!\n  project: Project @belongsTo\n}\n```\n\nThis generates queries and mutations that allow you to retrieve the related Comment records from the source Post record and vice versa:\n\n```graphql\nmutation CreateProject {\n  createProject(input: { name: \"New Project\", teamID: \"a-team-id\"}) {\n    id\n    name\n    team { # query team from project\n      id\n      name\n      project { # bi-directional query: team to project\n        id\n        name\n      }\n    }\n  }\n}\n```\n</Block>\n\n<Block name='Bi-directional \"has many\" relationship'>\n\n```graphql\ntype Post @model {\n  id: ID!\n  title: String!\n  comments: [Comment] @hasMany\n}\n\ntype Comment @model {\n  id: ID!\n  content: String!\n  post: Post @belongsTo\n}\n```\n\nThis generates queries and mutations that allow you to retrieve the related Comment records from the source Post record and vice versa:\n\n```graphql\nmutation CreatePost {\n  createPost(input: {title: \"Hello World!!\"}) {\n    title\n    id\n    comments { # query comments from the post\n      items {\n        id\n        content\n        post { # bi-directional query: comment to post\n          id\n          title\n        }\n      }\n    }\n  }\n}\n```\n</Block>\n\n</BlockSwitcher>\n\n`@belongsTo` can be used without the `fields` argument. In those cases, a field is automatically generated to reference the parent’s primary key.\n\nAlternatively, you set up a custom field to store the reference of the parent object. An example bidirectional “has many” relationship is shown below.\n\n```graphql\ntype Post @model {\n  id: ID!\n  title: String!\n  comments: [Comment] @hasMany(indexName: \"byPost\", fields: [\"id\"])\n}\n\ntype Comment @model {\n  id: ID!\n  postID: ID! @index(name: \"byPost\", sortKeyFields: [\"content\"])\n  content: String!\n  post: Post @belongsTo(fields: [\"postID\"])\n}\n```\n\n> Note: The `@belongsTo` directive requires that a `@hasOne` or `@hasMany` relationship already exists from parent to the related model. \n\n### Many-to-many relationship\nCreate a many-to-many relationship between two models with the `@manyToMany` directive. Provide a common `relationName` on both models to join them into a many-to-many relationship. \n\n```graphql\ntype Post @model {\n  id: ID!\n  title: String!\n  content: String\n  tags: [Tag] @manyToMany(relationName: \"PostTags\")\n}\n\ntype Tag @model {\n  id: ID!\n  label: String!\n  posts: [Post] @manyToMany(relationName: \"PostTags\")\n}\n```\n\nUnder the hood, the `@manyToMany` directive will create a \"join table\" named after the `relationName` to facilitate the many-to-many relationship. This generates queries and mutations that allow you to retrieve the related Comment records from the source Post record and vice versa:\n\n```graphql\nmutation CreatePost {\n  createPost(input: {title: \"Hello World!!\"}) {\n    id\n    title\n    content\n    tags { # queries the \"join table\" PostTags\n      items {\n        tag { # related Tag records from Post\n          id\n          label\n          posts { # queries the \"join table\" PostTags\n            items {\n              post { # related Post records from Tag\n                id\n                title\n                content\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n## Assign default values for fields\n\nYou can use the `@default` directive to specify a default value for optional [scalar type fields](https://docs.aws.amazon.com/appsync/latest/devguide/scalars.html) such as `Int`, `String`, and more. \n\n```graphql\ntype Todo @model {\n  content: String @default(value: \"My new Todo\")\n}\n```\n\nIf you create a new Todo and don't supply a `content` input, Amplify will ensure that `My new Todo` is auto populated as a value. \nWhen `@default` is applied, non-null assertions using `!` are disregarded. For example, `String!` is treated the same as `String`.\n\n## Advanced\n\n### Rename generated queries, mutations, and subscriptions\n\nYou can override the names of any `@model`-generated GraphQL queries, mutations, and subscriptions by supplying the desired name.\n\n```graphql\ntype Todo @model(queries: { get: \"queryFor\" }) {\n  name: String!\n  description: String\n}\n```\n\nIn the example above, we will be able to run a `queryForTodo` query to get a single Todo element.  \n\n### Disable generated queries, mutations, and subscriptions\n\nWe can disable specific operations by assigning their value to `null`.\n\n```graphql\ntype Todo @model(queries: { get: null }, mutations: null, subscriptions: null) {\n  name: String!\n  description: String\n}\n```\n\nThe example above disables the `getTodo` query, all mutations, and all subscriptions while allowing the generation of other queries such as `listTodo`.\n\n### Creating a custom query\n\nWe can disable the `get` query and create a custom query that enables us to retrieve a single Todo model.\n\n```graphql\ntype Query {\n   getMyTodo(id: ID!): Todo @function(name: \"getmytodofunction-${env}\")\n}\n```\n\nThe example above creates a custom query that utilizes the `@function` directive to call a Lambda function for this query.\n\nFor the type definitions of queries, mutations, and subscriptions, see [Type Definitions of the `@model` Directive](#type-definition-of-the-`@model`-directive).\n\n### Customize creation and update timestamps\nThe `@model` directive automatically adds `createdAt` and `updatedAt` timestamps to each entity. The timestamp field names can be changed by passing timestamps attribute to the directive.\n\n```graphql\ntype Todo @model(timestamps: { createdAt: \"createdOn\", updatedAt: \"updatedOn\" }) {\n  name: String!\n  description: String\n}\n```\n\nFor example, the schema above will allow you to query for the following contents:\n\n```graphql\ntype Todo {\n  id: ID!\n  name: String!\n  description: String\n  createdOn: AWSDateTime!\n  updatedOn: AWSDateTime!\n}\n```\n\n### Modify subscriptions (real-time updates) access level\n\nBy default, real-time updates are on for all `@model` types, which means customers receive real-time updates and authorization rules are applied during initial connection time. You can also turn off subscriptions for that model or make the real-time updates public, receivable by all subscribers.\n\n```graphql\ntype Todo @model(subscriptions: { level: off }) { # or level: public\n  name: String!\n  description: String\n}\n```\n\n### Create multiple relationships between two models\n\nYou need to explicitly specify the connection field names if relational directives are used to create two connections of the same type between the two models.\n\n```graphql\ntype Individual @model {\n  id: ID!\n  homeAddress: Address @hasOne\n  shippingAddress: Address @hasOne\n}\n\ntype Address @model {\n  id: ID!\n  homeIndividualID: ID\n  shippingIndividualID: ID\n  homeIndividual: Individual @belongsTo(fields: [\"homeIndividualID\"])\n  shipIndividual: Individual @belongsTo(fields: [\"shippingIndividualID\"])\n}\n```\n\n## How it works\nThe `@model` directive will generate:\n- An Amazon DynamoDB table with PAY_PER_REQUEST billing mode enabled by default.\n- An AWS AppSync DataSource configured to access the table above.\n- An AWS IAM role attached to the DataSource that allows AWS AppSync to call the above table on your behalf.\n- Up to 8 resolvers (create, update, delete, get, list, onCreate, onUpdate, onDelete) but this is configurable via the queries, mutations, and subscriptions arguments on the @model directive.\n- Input objects for create, update, and delete mutations.\n- Filter input objects that allow you to filter objects in list queries and relationship fields.\n- For list queries the default number of objects returned is 100. You can override this behavior by setting the limit argument.\n\n### Type definition of the `@model` directive\n\n```graphql\ndirective @model(\n  queries: ModelQueryMap\n  mutations: ModelMutationMap\n  subscriptions: ModelSubscriptionMap\n  timestamps: TimestampConfiguration\n) on OBJECT\n\ninput ModelMutationMap {\n  create: String\n  update: String\n  delete: String\n}\n\ninput ModelQueryMap {\n  get: String\n  list: String\n}\n\ninput ModelSubscriptionMap {\n  onCreate: [String]\n  onUpdate: [String]\n  onDelete: [String]\n  level: ModelSubscriptionLevel\n}\n\nenum ModelSubscriptionLevel {\n  off\n  public\n  on\n}\n\ninput TimestampConfiguration {\n  createdAt: String\n  updatedAt: String\n}\n```",
    "meta": {
      "title": "Data modeling",
      "description": "Add authorization rules to your GraphQL schema to control access to your data.",
      "subcategory": "API (GraphQL)",
      "category": "Amplify CLI"
    },
    "filename": "/cli/graphql/data-modeling"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Amplify CLI's GraphQL API category makes it easy for you to create a new GraphQL API backed by a database. Just define a GraphQL schema and Amplify CLI will automatically transform the schema into a fully functioning GraphQL API powered by AWS AppSync, Amazon DynamoDB, and more."
      },
      {
        "heading": "Creating your first table",
        "depth": 2,
        "text": "First, set up your GraphQL API by running:"
      },
      {
        "heading": "Creating your first table",
        "depth": 2,
        "text": "Accept the default values and your code editor should show a GraphQL schema for a Todo app."
      },
      {
        "heading": "Creating your first table",
        "depth": 2,
        "text": "Every GraphQL type with the @model directive is automatically backed by a new DynamoDB database table."
      },
      {
        "heading": "Creating your first table",
        "depth": 2,
        "text": "input AMPLIFY { globalAuthRule: AuthRule = { allow: public } } allows you to get started quickly without worrying about authorization rules. Review the Authorization rules section to setup the appropriate access control for your GraphQL API."
      },
      {
        "heading": "Creating your first table",
        "depth": 2,
        "text": "Now let's deploy your changes to the cloud:"
      },
      {
        "heading": "Creating your first table",
        "depth": 2,
        "text": "That's it! Your API and database tables are set up."
      },
      {
        "heading": "Setup your app code",
        "depth": 2,
        "text": "Use Amplify libraries to connect your app with your GraphQL endpoint."
      },
      {
        "heading": "Setup your app code",
        "depth": 2,
        "text": "Add the Amplify library to your app with yarn or npm:"
      },
      {
        "heading": "Setup your app code",
        "depth": 2,
        "text": "In your app's entry point i.e. App.js, import and load the configuration file:"
      },
      {
        "heading": "Add your first record",
        "depth": 2,
        "text": "Next, let's try to query from the GraphQL API. Follow along the steps below to make a query from a React app:"
      },
      {
        "heading": "Add your first record",
        "depth": 2,
        "text": "Then, create your first todo item with the a GraphQL API call:"
      },
      {
        "heading": "Query records from the table",
        "depth": 2,
        "text": "Use the GraphQL query statement to list all todos in your app:"
      },
      {
        "heading": "Query records from the table",
        "depth": 2,
        "text": "You should see the record created above: My first todo!."
      },
      {
        "heading": "Update the record",
        "depth": 2,
        "text": "To update the record use the GraphQL update mutation:"
      },
      {
        "heading": "Update the record",
        "depth": 2,
        "text": "The result should contain the updated value: My first updated todo!."
      },
      {
        "heading": "Delete a record",
        "depth": 2,
        "text": "Let's clean up our database! Delete the todo by using the delete mutation:"
      },
      {
        "heading": "Delete a record",
        "depth": 2,
        "text": "The result output should indicate to you that the record was successfully deleted!"
      },
      {
        "heading": "Update schema",
        "depth": 2,
        "text": "If you want to update your API, open your project's amplify/backend/api/<api-name>/schema.graphql file (NOT the one in the amplify/backend/api/<api-name>/build folder) and edit it in your favorite code editor. You can compile the amplify/backend/api/<api-name>/schema.graphql file by running:"
      },
      {
        "heading": "Update schema",
        "depth": 2,
        "text": "and view the compiled schema output in backend/api/~apiname~/build/schema.graphql."
      },
      {
        "heading": "Update schema",
        "depth": 2,
        "text": "You can then push updated changes with:"
      },
      {
        "heading": "Update schema",
        "depth": 2,
        "text": "The following schema updates require replacement of the underlying DynamoDB table:"
      },
      {
        "heading": "Update schema",
        "depth": 2,
        "text": "Removing or renaming a model"
      },
      {
        "heading": "Update schema",
        "depth": 2,
        "text": "Modifying the primary key of a model"
      },
      {
        "heading": "Update schema",
        "depth": 2,
        "text": "Modifying a Local Secondary Index of a model (only applies to projects with secondaryKeyAsGSI turned off)"
      },
      {
        "heading": "Update schema",
        "depth": 2,
        "text": "When trying to push a schema change with one or more of these updates you will see an error message explaining that you will lose ALL DATA in any table that requires replacement. To confirm you want to continue with the deployment, run:"
      },
      {
        "heading": "Update schema",
        "depth": 2,
        "text": "In general, this command should only be used during development."
      },
      {
        "heading": "Update schema",
        "depth": 2,
        "text": "If you are making a breaking change to a production API but you want to retain the data in the affected table(s), you can create a backup before running amplify push --allow-destructive-graphql-schema-updates"
      },
      {
        "heading": "Rebuild GraphQL API",
        "depth": 2,
        "text": "Rebuild should NEVER be used in a production environment!"
      },
      {
        "heading": "Rebuild GraphQL API",
        "depth": 2,
        "text": "When in development, sometimes test data gets in a bad state or you want to make many changes to your schema all at once. In these cases, you may wish to \"rebuild\" all of the tables backing your schema. To do this, run:"
      },
      {
        "heading": "Rebuild GraphQL API",
        "depth": 2,
        "text": "This will recreate ALL of the tables backing models in your schema. ALL DATA in ALL TABLES will be deleted."
      },
      {
        "heading": "Next steps",
        "depth": 2,
        "text": "Success! You've learned how to create a GraphQL API backed by a database table and also how to run queries and mutations from your app."
      },
      {
        "heading": "Next steps",
        "depth": 2,
        "text": "There's so much more to discover with Amplify's GraphQL API capabilities. Learn more about:"
      },
      {
        "heading": "Next steps",
        "depth": 2,
        "text": "How to model your database table and their access patterns"
      },
      {
        "heading": "Next steps",
        "depth": 2,
        "text": "Secure your API with fine-grained authorization rules"
      },
      {
        "heading": "Next steps",
        "depth": 2,
        "text": "Create relationships between different database model"
      },
      {
        "heading": "Next steps",
        "depth": 2,
        "text": "Add custom business logic to the GraphQL API"
      },
      {
        "heading": "Next steps",
        "depth": 2,
        "text": "Run search and result aggregation queries"
      },
      {
        "heading": "Next steps",
        "depth": 2,
        "text": "Connect to machine learning services"
      },
      {
        "heading": "Next steps",
        "depth": 2,
        "text": "Examples and solutions"
      }
    ],
    "source": "export const meta = {\n  title: `Overview`,\n  description: `Add authorization rules to your GraphQL schema to control access to your data.`,\n};\n\n<MigrationAlert url={\"/cli-legacy/graphql-transformer/overview\"}/>\n\nAmplify CLI's GraphQL API category makes it easy for you to create a new GraphQL API backed by a database. Just define a GraphQL schema and Amplify CLI will automatically transform the schema into a fully functioning GraphQL API powered by AWS AppSync, Amazon DynamoDB, and more. \n\n## Creating your first table\n\nFirst, set up your GraphQL API by running:\n```bash\namplify add api\n```\n```console\n? Select from one of the below mentioned services:\n> GraphQL\n? Here is the GraphQL API that we will create. Select a setting to edit or continue\n> Continue\n? Choose a schema template:\n> Single object with fields (e.g., “Todo” with ID, name, description)\n...\nEdit your schema at <...>/schema.graphql or place .graphql files in a directory at <...>/schema\n✔ Do you want to edit the schema now? (Y/n)\n> yes\nEdit the file in your editor: <...>/schema.graphql\n✅ Successfully added resource new locally\n```\n\nAccept the default values and your code editor should show a GraphQL schema for a Todo app.\n\n```graphql\n# This \"input\" configures a global authorization rule to enable public access to\n# all models in this schema. Learn more about authorization rules here: https://docs.amplify.aws/cli/graphql/auth\ninput AMPLIFY { globalAuthRule: AuthRule = { allow: public } } # FOR TESTING ONLY!\n\ntype Todo @model {\n  id: ID!\n  name: String!\n  description: String\n}\n```\n\nEvery GraphQL `type` with the `@model` directive is automatically backed by a new DynamoDB database table.\n\n<Callout warning>\n\n`input AMPLIFY { globalAuthRule: AuthRule = { allow: public } }` allows you to get started quickly without worrying about authorization rules. Review the [Authorization rules](/cli/graphql/authorization-rules) section to setup the appropriate access control for your GraphQL API.\n</Callout>\n\nNow let's deploy your changes to the cloud:\n\n```bash\namplify push\n```\n\nThat's it! Your API and database tables are set up. \n\n## Setup your app code\n\nUse Amplify libraries to connect your app with your GraphQL endpoint. \n\nAdd the Amplify library to your app with `yarn` or `npm`:\n\n```bash\nnpm install aws-amplify\n```\nIn your app's entry point i.e. App.js, import and load the configuration file:\n\n```js\nimport { Amplify, API, graphqlOperation } from 'aws-amplify';\nimport awsconfig from './aws-exports';\nAmplify.configure(awsconfig);\n```\n\n## Add your first record\n\nNext, let's try to query from the GraphQL API. Follow along the steps below to make a query from a React app:\n\n```js\nimport { API } from 'aws-amplify'\nimport { createTodo, updateTodo, deleteTodo } from './graphql/mutations'\nimport { listTodos } from './graphql/queries'\n```\n\nThen, create your first todo item with the a GraphQL API call:\n\n```js\nconst result = await API.graphql(graphqlOperation(createTodo, {\n  input: {\n    name: 'My first todo!'\n  }\n}))\n```\n\n## Query records from the table\n\nUse the GraphQL query statement to list all todos in your app:\n\n```js\nconst result = await API.graphql(graphqlOperation(listTodos))\nconsole.log(result)\n```\n\nYou should see the record created above: `My first todo!`.\n\n## Update the record\n\nTo update the record use the GraphQL update mutation:\n\n```js\nconst result = await API.graphql(graphqlOperation(updateTodo, {\n  input: {\n    id: \"<...>\",\n    name: \"My first updated todo!\"\n  }\n}))\nconsole.log(result)\n```\n\nThe result should contain the updated value: `My first updated todo!`.\n\n## Delete a record\n\nLet's clean up our database! Delete the todo by using the delete mutation:\n\n```js\nconst result = await API.graphql(graphqlOperation(deleteTodo, {\n  input: {\n    id: \"<...>\",\n  }\n}))\nconsole.log(result)\n```\nThe result output should indicate to you that the record was successfully deleted!\n\n## Update schema\n\nIf you want to update your API, open your project's `amplify/backend/api/<api-name>/schema.graphql` file (NOT the one in the `amplify/backend/api/<api-name>/build` folder) and edit it in your favorite code editor. You can compile the `amplify/backend/api/<api-name>/schema.graphql` file by running:\n\n```bash\namplify api gql-compile\n```\n\nand view the compiled schema output in `backend/api/~apiname~/build/schema.graphql`.\n\nYou can then push updated changes with:\n\n```bash\namplify push\n```\n\nThe following schema updates require replacement of the underlying DynamoDB table:\n1. Removing or renaming a model\n2. Modifying the [primary key](/cli/graphql/data-modeling/#configure-a-primary-key) of a model\n3. Modifying a Local Secondary Index of a model (only applies to projects with [secondaryKeyAsGSI](/cli/reference/feature-flags/#secondaryKeyAsGSI) turned off)\n\nWhen trying to push a schema change with one or more of these updates you will see an error message explaining that you will lose ALL DATA in any table that requires replacement. To confirm you want to continue with the deployment, run:\n```bash\namplify push --allow-destructive-graphql-schema-updates\n```\n<Callout>\nIn general, this command should only be used during development.\n\nIf you are making a breaking change to a production API but you want to retain the data in the affected table(s), you can [create a backup](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/CreateBackupAWS.html) before running `amplify push --allow-destructive-graphql-schema-updates`\n</Callout>\n\n## Rebuild GraphQL API\n\n<Callout>\nRebuild should NEVER be used in a production environment!\n</Callout>\n\nWhen in development, sometimes test data gets in a bad state or you want to make many changes to your schema all at once. In these cases, you may wish to \"rebuild\" all of the tables backing your schema. To do this, run:\n```bash\namplify rebuild api\n```\nThis will recreate ALL of the tables backing models in your schema. ALL DATA in ALL TABLES will be deleted.\n\n\n\n## Next steps\n\nSuccess! You've learned how to create a GraphQL API backed by a database table and also how to run queries and mutations from your app. \n\nThere's so much more to discover with Amplify's GraphQL API capabilities. Learn more about: \n- [How to model your database table and their access patterns](/cli/graphql/data-modeling)\n- [Secure your API with fine-grained authorization rules](/cli/graphql/authorization-rules)\n- [Create relationships between different database model](/cli/graphql/data-modeling/#setup-relationships-between-models)\n- [Add custom business logic to the GraphQL API](/cli/graphql/custom-business-logic)\n- [Run search and result aggregation queries](/cli/graphql/search-and-result-aggregations/)\n- [Connect to machine learning services](/cli/graphql/connect-to-machine-learning-services/)\n- [Examples and solutions](/cli/graphql/examples-and-solutions/)\n",
    "meta": {
      "title": "Overview",
      "description": "Add authorization rules to your GraphQL schema to control access to your data.",
      "subcategory": "API (GraphQL)",
      "category": "Amplify CLI"
    },
    "filename": "/cli/graphql/overview"
  },
  {
    "searchableText": [
      {
        "heading": "Initialize new project",
        "depth": 2,
        "text": "To initialize a new Amplify project, run the following command from the root directory of your frontend app."
      },
      {
        "heading": "Initialize new project",
        "depth": 2,
        "text": "The init command goes through the following steps:"
      },
      {
        "heading": "Initialize new project",
        "depth": 2,
        "text": "Analyzes the project and confirms the frontend settings"
      },
      {
        "heading": "Initialize new project",
        "depth": 2,
        "text": "Carries out the initialization logic of the selected frontend"
      },
      {
        "heading": "Initialize new project",
        "depth": 2,
        "text": "If there are multiple provider plugins, prompts to select the plugins that will provide accesses to cloud resources"
      },
      {
        "heading": "Initialize new project",
        "depth": 2,
        "text": "Carries out, in sequence, the initialization logic of the selected plugin(s)"
      },
      {
        "heading": "Initialize new project",
        "depth": 2,
        "text": "Insert amplify folder structure into the project's root directory, with the initial project configuration"
      },
      {
        "heading": "Initialize new project",
        "depth": 2,
        "text": "Generate the project metadata files, with the outputs of the above-selected plugin(s)"
      },
      {
        "heading": "Initialize new project",
        "depth": 2,
        "text": "Creates a cloud project in the AWS Amplify Console to view and manage resources for all backend environments."
      },
      {
        "heading": "Clone sample Amplify project",
        "depth": 2,
        "text": "To clone a sample amplify fullstack project, execute the following command inside an empty directory:"
      },
      {
        "heading": "Clone sample Amplify project",
        "depth": 2,
        "text": "amplify init --app <github-url>"
      },
      {
        "heading": "Clone sample Amplify project",
        "depth": 2,
        "text": "where <github-url> is a valid sample Amplify project repository. Click here for more details."
      },
      {
        "heading": "amplify init",
        "depth": 3,
        "text": "The init command can determine defaults for the project based on the contents of the directory. To accept the defaults offered, answer yes to:"
      },
      {
        "heading": "amplify init",
        "depth": 3,
        "text": "Initialize the project with the above configuration?"
      },
      {
        "heading": "amplify init",
        "depth": 3,
        "text": "During the init process, the root stack is created with three resources:"
      },
      {
        "heading": "amplify init",
        "depth": 3,
        "text": "IAM role for unauthenticated users"
      },
      {
        "heading": "amplify init",
        "depth": 3,
        "text": "IAM role for authenticated users"
      },
      {
        "heading": "amplify init",
        "depth": 3,
        "text": "S3 bucket, the deployment bucket, to support this provider's workflow"
      },
      {
        "heading": "amplify init",
        "depth": 3,
        "text": "The provider logs the information of the root stack and the resources into the project metadata file (amplify/backend/amplify-meta.json)."
      },
      {
        "heading": "amplify <category> add",
        "depth": 3,
        "text": "Once init is complete, run the command amplify <category> add to add resources of a category to the cloud. This will place a CloudFormation template for the resources of this category in the category's subdirectory amplify/backend/<category> and insert its reference into the above-mentioned root stack as the nested child stack. When working in teams, it is good practice to run an amplify pull before modifying the backend categories."
      },
      {
        "heading": "amplify push",
        "depth": 3,
        "text": "Once you have made your category updates, run the command amplify push to update the cloud resources. The CLI will first upload the latest versions of the category nested stack templates to the S3 deployment bucket, and then call the AWS CloudFormation API to create / update resources in the cloud. Based upon the resources added/updated, the aws-exports.js file (for JS projects) and the awsconfiguration.json file (for native projects) gets created/updated. The root stack's template can be found in amplify/backend/awscloudformation."
      },
      {
        "heading": "amplify pull",
        "depth": 3,
        "text": "The amplify pull command operates similar to a git pull, fetching upstream backend environment definition changes from the cloud* and update the local environment to match that definition. The command is particularly helpful in team scenarios when multiple team members are editing the same backend, pulling a backend into a new project, or when connecting to multiple frontend projects that share the same Amplify backend environment."
      },
      {
        "heading": "amplify pull",
        "depth": 3,
        "text": "* The CLI will use the S3 deployment bucket to retrieve your project information including the CloudFormation templates from the last successful amplify push."
      },
      {
        "heading": "amplify pull",
        "depth": 3,
        "text": "To generate client configuration files (aws-exports.js, amplifyconfiguration.json, or amplifyconfiguration.dart) for an existing project that is listed in the Amplify Hosting console, or to checkout a backend environment that has not been pulled locally:"
      },
      {
        "heading": "amplify pull",
        "depth": 3,
        "text": "Log in to the AWS console"
      },
      {
        "heading": "amplify pull",
        "depth": 3,
        "text": "Choose AWS Amplify"
      },
      {
        "heading": "amplify pull",
        "depth": 3,
        "text": "Click your app"
      },
      {
        "heading": "amplify pull",
        "depth": 3,
        "text": "Go to Backend environments"
      },
      {
        "heading": "amplify pull",
        "depth": 3,
        "text": "Find the backend environment you wish to pull"
      },
      {
        "heading": "amplify pull",
        "depth": 3,
        "text": "Click Edit backend"
      },
      {
        "heading": "amplify pull",
        "depth": 3,
        "text": "Run the command that is listed (amplify pull --appId YOUR_APP_ID --envName YOUR_ENV_NAME)"
      },
      {
        "heading": "amplify console",
        "depth": 3,
        "text": "The amplify console command launches the browser directing you to your cloud project in the AWS Amplify Console. The Amplify Console provides a central location for development teams to view and manage their backend environments, status of the backend deployment, deep-links to the backend resources by Amplify category, and instructions on how to pull, clone, update, or delete environments."
      },
      {
        "heading": "amplify configure project",
        "depth": 3,
        "text": "The amplify configure project command is an advanced command and not commonly used for initial getting started projects. The command should be used to modify the project configuration present in the .config/ directory and re-configuring AWS credentials (based on profile on your local machine) set up during the amplify init step. The .config/ directory is generated in the amplify/ directory, if not already present, and the local-aws-info.json, local-env-info.json and project-info.json files are configured to reflect the selections made as a part of the amplify configure project command."
      },
      {
        "heading": "amplify configure project",
        "depth": 3,
        "text": "amplify configure project is also used to enable Serverless Container options in your project with Amazon Elastic Container Service. When enabled, you will be able to build APIs with both AWS Lambda and AWS Fargate using a Dockerfile or a Docker Compose file. See Serverless Containers for more information."
      },
      {
        "heading": "amplify logout --appId <Amplify App Id>",
        "depth": 3,
        "text": "When Amplify CLI is authenticated with Amplify Studio, JSON Web Tokens (JWTs) are stored on the developer's machine. This command will remove the JWTs associated with a particular Amplify app. The CLI will also prompt if you want to logout from all sessions. 'Yes' will remove the JWTs and ensure they are invalidated globally. 'No' will still remove the locally-stored JWTs but the tokens will remain valid until they expire."
      },
      {
        "heading": "Upgrade Amplify CLI",
        "depth": 2,
        "text": "The Amplify CLI team continuously pushes new features, enhancements and security improvements and it is recommended to update the Amplify CLI version which you or your team is using to the latest version. You can keep track of the latest releases of the Amplify CLI on npm - https://www.npmjs.com/package/@aws-amplify/cli"
      },
      {
        "heading": "Verify Amplify CLI upgrade",
        "depth": 3,
        "text": "Verify the successful installation of the latest CLI version by entering the following command in the CLI:"
      },
      {
        "heading": "Verify Amplify CLI upgrade",
        "depth": 3,
        "text": "Confirm the installed version of the Amplify CLI. You can find the latest version of the CLI here - https://www.npmjs.com/package/@aws-amplify/cli."
      },
      {
        "heading": "(Optional) Update projects using latest Amplify CLI",
        "depth": 3,
        "text": "Navigate to your Amplify project folder using the following command cd <Project-Filepath>. To verify if it is a valid Amplify project folder, enter the following command in the CLI:"
      },
      {
        "heading": "(Optional) Update projects using latest Amplify CLI",
        "depth": 3,
        "text": "If it is a valid Amplify project folder, Amplify will display a list of the resources in the project folder that you have deployed to the AWS cloud."
      },
      {
        "heading": "(Optional) Update projects using latest Amplify CLI",
        "depth": 3,
        "text": "Update your backend resources with updated security configurations or improvements by entering the following command in the CLI:"
      },
      {
        "heading": "(Optional) Update projects using latest Amplify CLI",
        "depth": 3,
        "text": "Hit Enter or type Y when prompted for confirmations. Look for the following result to validate the configuration updates have been applied."
      },
      {
        "heading": "(Optional) Update projects using latest Amplify CLI",
        "depth": 3,
        "text": "If you have multiple AWS Amplify project folders, repeat steps above for each project folder."
      },
      {
        "heading": "(Optional) Update projects using latest Amplify CLI",
        "depth": 3,
        "text": "If you are receiving errors on push regarding unknown GraphQL directives and have not yet migrated your GraphQL resource to use GraphQL Transformer v2, please review the migration documentation page for an in-depth guide to migrating the resource."
      },
      {
        "heading": "Uninstall Amplify CLI",
        "depth": 2,
        "text": "Use the following commands to completely remove Amplify CLI from your system. Removing the Amplify CLI will NOT delete any of your Amplify projects.\nTo delete a project, run amplify delete within the project directory."
      },
      {
        "heading": "List of commands",
        "depth": 2,
        "text": "amplify <category> <subcommand>"
      },
      {
        "heading": "List of commands",
        "depth": 2,
        "text": "amplify push"
      },
      {
        "heading": "List of commands",
        "depth": 2,
        "text": "amplify pull"
      },
      {
        "heading": "List of commands",
        "depth": 2,
        "text": "amplify env <subcommand>"
      },
      {
        "heading": "List of commands",
        "depth": 2,
        "text": "amplify configure"
      },
      {
        "heading": "List of commands",
        "depth": 2,
        "text": "amplify console"
      },
      {
        "heading": "List of commands",
        "depth": 2,
        "text": "amplify delete"
      },
      {
        "heading": "List of commands",
        "depth": 2,
        "text": "amplify help"
      },
      {
        "heading": "List of commands",
        "depth": 2,
        "text": "amplify init"
      },
      {
        "heading": "List of commands",
        "depth": 2,
        "text": "amplify publish"
      },
      {
        "heading": "List of commands",
        "depth": 2,
        "text": "amplify run"
      },
      {
        "heading": "List of commands",
        "depth": 2,
        "text": "amplify status"
      },
      {
        "heading": "List of commands",
        "depth": 2,
        "text": "amplify logout"
      },
      {
        "heading": "Category commands",
        "depth": 3,
        "text": "amplify <category> add"
      },
      {
        "heading": "Category commands",
        "depth": 3,
        "text": "amplify <category> update"
      },
      {
        "heading": "Category commands",
        "depth": 3,
        "text": "amplify <category> remove"
      },
      {
        "heading": "Category commands",
        "depth": 3,
        "text": "amplify <category> push"
      }
    ],
    "source": "export const meta = {\n  title: `Typical workflows`,\n  description: `How to initialize a new Amplify project and other typical Amplify CLI workflows & commands.`,\n};\n\n## Initialize new project\n\nTo initialize a new Amplify project, run the following command from the root directory of your frontend app.\n\n```bash\namplify init\n```\n\nThe `init` command goes through the following steps:\n\n- Analyzes the project and confirms the frontend settings\n- Carries out the initialization logic of the selected frontend\n- If there are multiple provider plugins, prompts to select the plugins that will provide accesses to cloud resources\n- Carries out, in sequence, the initialization logic of the selected plugin(s)\n- Insert amplify folder structure into the project's root directory, with the initial project configuration\n- Generate the project metadata files, with the outputs of the above-selected plugin(s)\n- Creates a cloud project in the [AWS Amplify Console](https://console.aws.amazon.com/amplify) to view and manage resources for all backend environments.\n\n## Clone sample Amplify project\n\nTo clone a sample amplify fullstack project, execute the following command inside an empty directory:\n\n`amplify init --app <github-url>`\n\nwhere `<github-url>` is a valid sample Amplify project repository. Click [here](/cli/usage/headless#--app) for more details.\n\n## Common CLI commands\n\n### amplify init\n\nThe `init` command can determine defaults for the project based on the contents of the directory. To accept the defaults offered, answer yes to:\n\n`Initialize the project with the above configuration?`\n\nDuring the init process, the root stack is created with three resources:\n\n- IAM role for unauthenticated users\n- IAM role for authenticated users\n- S3 bucket, the deployment bucket, to support this provider's workflow\n\nThe provider logs the information of the root stack and the resources into the project metadata file (amplify/backend/amplify-meta.json).\n\n### amplify &lt;category&gt; add\n\nOnce init is complete, run the command `amplify <category> add` to add resources of a category to the cloud. This will place a CloudFormation template for the resources of this category in the category's subdirectory `amplify/backend/<category>` and insert its reference into the above-mentioned root stack as the nested child stack. When working in teams, it is good practice to run an `amplify pull` before modifying the backend categories.\n\n### amplify push\n\nOnce you have made your category updates, run the command `amplify push` to update the cloud resources. The CLI will first upload the latest versions of the category nested stack templates to the S3 deployment bucket, and then call the AWS CloudFormation API to create / update resources in the cloud. Based upon the resources added/updated, the `aws-exports.js` file (for JS projects) and the `awsconfiguration.json` file (for native projects) gets created/updated. The root stack's template can be found in `amplify/backend/awscloudformation`.\n\n### amplify pull\n\nThe `amplify pull` command operates similar to a _git pull_, fetching upstream backend environment definition changes from the cloud* and update the local environment to match that definition. The command is particularly helpful in team scenarios when multiple team members are editing the same backend, pulling a backend into a new project, or when connecting to [multiple frontend projects](/cli/teams/multi-frontend) that share the same Amplify backend environment.\n> \\* The CLI will use the S3 deployment bucket to retrieve your project information including the CloudFormation templates from the last successful `amplify push`.\n\n<Callout> \n\nTo generate client configuration files (aws-exports.js, amplifyconfiguration.json, or amplifyconfiguration.dart) for an existing project that is listed in the Amplify Hosting console, or to checkout a backend environment that has not been pulled locally:\n\n1. Log in to the AWS console\n2. Choose `AWS Amplify`\n3. Click your app\n4. Go to `Backend environments`\n5. Find the backend environment you wish to pull\n6. Click `Edit backend`\n7. Run the command that is listed (`amplify pull --appId YOUR_APP_ID --envName YOUR_ENV_NAME`)\n\n</Callout>\n\n### amplify console\n\nThe `amplify console` command launches the browser directing you to your cloud project in the AWS Amplify Console. The Amplify Console provides a central location for development teams to view and manage their backend environments, status of the backend deployment, deep-links to the backend resources by Amplify category, and instructions on how to pull, clone, update, or delete environments.\n\n### amplify configure project\n\nThe `amplify configure project` command is an advanced command and not commonly used for initial getting started projects. The command should be used to modify the project configuration present in the `.config/` directory and re-configuring AWS credentials (based on profile on your local machine) set up during the `amplify init` step. The `.config/` directory is generated in the `amplify/` directory, if not already present, and the `local-aws-info.json`, `local-env-info.json` and `project-info.json` files are configured to reflect the selections made as a part of the `amplify configure project` command.\n\n`amplify configure project` is also used to enable **Serverless Container** options in your project with Amazon Elastic Container Service. When enabled, you will be able to build APIs with both AWS Lambda and AWS Fargate using a [Dockerfile](https://docs.docker.com/engine/reference/builder/) or a [Docker Compose file](https://docs.docker.com/compose/compose-file/). See [Serverless Containers](/cli/usage/containers) for more information.\n\n### amplify logout --appId &lt;Amplify App Id&gt;\n\nWhen Amplify CLI is authenticated with Amplify Studio, JSON Web Tokens (JWTs) are stored on the developer's machine. This command will remove the JWTs associated with a particular Amplify app. The CLI will also prompt if you want to logout from all sessions. 'Yes' will remove the JWTs and ensure they are invalidated globally. 'No' will still remove the locally-stored JWTs but the tokens will remain valid until they expire.\n\n## Upgrade Amplify CLI\n\nThe Amplify CLI team continuously pushes new features, enhancements and security improvements and it is recommended to update the Amplify CLI version which you or your team is using to the latest version. You can keep track of the latest releases of the Amplify CLI on npm - [https://www.npmjs.com/package/@aws-amplify/cli](https://www.npmjs.com/package/@aws-amplify/cli)\n\n<BlockSwitcher>\n<Block name=\"NPM\">\n\n```bash\nnpm install -g @aws-amplify/cli\n```\n\n</Block>\n<Block name=\"cURL (Mac and Linux)\">\n\n```bash\namplify upgrade\n```\n</Block>\n<Block name=\"cURL (Windows)\">\n\n```bash\namplify upgrade\n```\n</Block>\n</BlockSwitcher>\n\n### Verify Amplify CLI upgrade\n\nVerify the successful installation of the latest CLI version by entering the following command in the CLI:\n\n```bash\namplify -v\n```\n\nConfirm the installed version of the Amplify CLI. You can find the latest version of the CLI here - [https://www.npmjs.com/package/@aws-amplify/cli](https://www.npmjs.com/package/@aws-amplify/cli).\n\n### (Optional) Update projects using latest Amplify CLI\nNavigate to your Amplify project folder using the following command `cd <Project-Filepath>`. To verify if it is a valid Amplify project folder, enter the following command in the CLI:\n\n```bash\namplify status\n```\n\nIf it is a valid Amplify project folder, Amplify will display a list of the resources in the project folder that you have deployed to the AWS cloud.\n\nUpdate your backend resources with updated security configurations or improvements by entering the following command in the CLI:\n\n```bash\namplify push --force\n```\n\nHit Enter or type Y when prompted for confirmations. Look for the following result to validate the configuration updates have been applied.\n\n```console\n✔ All resources are updated in the cloud \n```\n\nIf you have multiple AWS Amplify project folders, repeat steps above for each project folder.\n\n<Callout warning>\n\nIf you are receiving errors on push regarding unknown GraphQL directives and have not yet migrated your GraphQL resource to use GraphQL Transformer v2, please review the [migration documentation page](/cli/migration/transformer-migration/) for an in-depth guide to migrating the resource.\n  \n</Callout>\n\n## Uninstall Amplify CLI\n\nUse the following commands to completely remove Amplify CLI from your system. Removing the Amplify CLI will NOT delete any of your Amplify projects.\nTo delete a project, run `amplify delete` within the project directory.\n\n<BlockSwitcher>\n<Block name=\"NPM\">\n\n```bash\nnpm uninstall -g @aws-amplify/cli\n```\n\n</Block>\n<Block name=\"cURL (Mac and Linux)\">\n\n```bash\namplify uninstall\n```\n</Block>\n<Block name=\"cURL (Windows)\">\n\n```bash\namplify uninstall\n```\n</Block>\n</BlockSwitcher>\n\n\n## List of commands\n\n- `amplify <category> <subcommand>`\n- `amplify push`\n- `amplify pull`\n- `amplify env <subcommand>`\n- `amplify configure`\n- `amplify console`\n- `amplify delete`\n- `amplify help`\n- `amplify init`\n- `amplify publish`\n- `amplify run`\n- `amplify status`\n- `amplify logout`\n\n### Category commands\n\n- `amplify <category> add`\n- `amplify <category> update`\n- `amplify <category> remove`\n- `amplify <category> push`\n",
    "meta": {
      "title": "Typical workflows",
      "description": "How to initialize a new Amplify project and other typical Amplify CLI workflows & commands.",
      "subcategory": "Get started",
      "category": "Amplify CLI"
    },
    "filename": "/cli/start/workflows"
  },
  {
    "searchableText": [
      {
        "heading": "Install the Amplify CLI",
        "depth": 2,
        "text": "The Amplify Command Line Interface (CLI) is a unified toolchain to create AWS cloud services for your app. Let's go ahead and install the Amplify CLI."
      },
      {
        "heading": "Pre-requisites for installation",
        "depth": 3,
        "text": "Install Node.js® and NPM if they are not already on your machine."
      },
      {
        "heading": "Pre-requisites for installation",
        "depth": 3,
        "text": "Verify that you are running at least Node.js version 12.x and npm version 6.x or greater by running node -v and npm -v in a terminal/console window"
      },
      {
        "heading": "Pre-requisites for installation",
        "depth": 3,
        "text": "Create AWS Account. If you don't already have an AWS account, you'll need to create one in order to follow the steps outlined in this tutorial."
      },
      {
        "heading": "Configure the Amplify CLI",
        "depth": 2,
        "text": "To set up the Amplify CLI on your local machine, you have to configure it to connect to your AWS account."
      },
      {
        "heading": "Option 1: Watch the video guide",
        "depth": 3,
        "text": "Watch the video below to learn how to install and configure the Amplify CLI or skip to the next section to follow the step-by-step instructions."
      },
      {
        "heading": "Option 2: Follow the instructions",
        "depth": 3,
        "text": "Configure Amplify by running the following command:"
      },
      {
        "heading": "Option 2: Follow the instructions",
        "depth": 3,
        "text": "amplify configure will ask you to sign into the AWS Console."
      },
      {
        "heading": "Option 2: Follow the instructions",
        "depth": 3,
        "text": "Once you're signed in, Amplify CLI will ask you to create an IAM user."
      },
      {
        "heading": "Option 2: Follow the instructions",
        "depth": 3,
        "text": "Amazon IAM (Identity and Access Management) enables you to manage users and user permissions in AWS. You can learn more about Amazon IAM here."
      },
      {
        "heading": "Option 2: Follow the instructions",
        "depth": 3,
        "text": "Create a user with AdministratorAccess-Amplify to your account to provision AWS resources for you like AppSync, Cognito etc."
      },
      {
        "heading": "Option 2: Follow the instructions",
        "depth": 3,
        "text": ""
      },
      {
        "heading": "Option 2: Follow the instructions",
        "depth": 3,
        "text": "Once the user is created, Amplify CLI will ask you to provide the accessKeyId and the secretAccessKey to connect Amplify CLI with your newly created IAM user."
      },
      {
        "heading": "Option 2: Follow the instructions",
        "depth": 3,
        "text": "It is recommended to create a new IAM user for every device that installs the Amplify CLI, rather than attempt to use an existing IAM user used on another device. Having a distinct user for each machine provides the best level of visibility and control without breaking the deployment of your app, allowing for the quick deactivation of an individual machine if needed."
      },
      {
        "heading": "Work within your frontend project",
        "depth": 3,
        "text": "After you install the CLI, navigate to a JavaScript, iOS, or Android project root, initialize AWS Amplify in the new directory by running amplify init. After a few configuration questions, you can use amplify help at any time to see the overall command structure. When you’re ready to add a feature, run amplify add <category>."
      }
    ],
    "source": "export const meta = {\n  title: `Installation`,\n  description: `How to install & configure Amplify CLI`,\n};\n\n  \n\n## Install the Amplify CLI\n\nThe Amplify Command Line Interface (CLI) is a unified toolchain to create AWS cloud services for your app. Let's go ahead and install the Amplify CLI.\n\nimport all0 from \"/src/fragments/cli-install-block.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\n### Pre-requisites for installation\n\n- [Install Node.js®](https://nodejs.org/en/download/) and [NPM](https://www.npmjs.com/get-npm) if they are not already on your machine.\n- Verify that you are running at least Node.js version 12.x and npm version 6.x or greater by running `node -v` and `npm -v` in a terminal/console window\n- [Create AWS Account](https://portal.aws.amazon.com/billing/signup?redirect_url=https%3A%2F%2Faws.amazon.com%2Fregistration-confirmation#/start). If you don't already have an AWS account, you'll need to create one in order to follow the steps outlined in this tutorial.\n\n## Configure the Amplify CLI\n\nTo set up the Amplify CLI on your local machine, you have to configure it to connect to your AWS account.\n\n### Option 1: Watch the video guide\n\nWatch the video below to learn how to install and configure the Amplify CLI or skip to the next section to follow the step-by-step instructions.\n\n<iframe src=\"https://www.youtube-nocookie.com/embed/fWbM5DLh25U\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n### Option 2: Follow the instructions\n\nConfigure Amplify by running the following command:\n\n```bash\namplify configure\n```\n\n`amplify configure` will ask you to sign into the AWS Console.\n\nOnce you're signed in, Amplify CLI will ask you to create an IAM user.\n> Amazon IAM (Identity and Access Management) enables you to manage users and user permissions in AWS. You can learn more about Amazon IAM [here](https://aws.amazon.com/iam/).\n\n```console\nSpecify the AWS Region\n? region:  # Your preferred region\nSpecify the username of the new IAM user:\n? user name:  # User name for Amplify IAM user\nComplete the user creation using the AWS console\n```\n\nCreate a user with `AdministratorAccess-Amplify` to your account to provision AWS resources for you like AppSync, Cognito etc.\n\n![image](/images/user-creation.gif)\n\nOnce the user is created, Amplify CLI will ask you to provide the `accessKeyId` and the `secretAccessKey` to connect Amplify CLI with your newly created IAM user.\n\n```console\nEnter the access key of the newly created user:\n? accessKeyId:  # YOUR_ACCESS_KEY_ID\n? secretAccessKey:  # YOUR_SECRET_ACCESS_KEY\nThis would update/create the AWS Profile in your local machine\n? Profile Name:  # (default)\n\nSuccessfully set up the new user.\n```\n\n<Callout>\n\nIt is recommended to create a new IAM user for every device that installs the Amplify CLI, rather than attempt to use an existing IAM user used on another device. Having a distinct user for each machine provides the best level of visibility and control without breaking the deployment of your app, allowing for the quick deactivation of an individual machine if needed.\n\n</Callout>\n\n### Work within your frontend project\n\nAfter you install the CLI, navigate to a JavaScript, iOS, or Android project root, initialize AWS Amplify in the new directory by running `amplify init`. After a few configuration questions, you can use amplify help at any time to see the overall command structure. When you’re ready to add a feature, run `amplify add <category>`.",
    "meta": {
      "title": "Installation",
      "description": "How to install & configure Amplify CLI",
      "subcategory": "Get started",
      "category": "Amplify CLI"
    },
    "filename": "/cli/start/install"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "Customizing text and adding language translations can be done via the I18n module:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "A complete list of all translatable strings can be found in Translations.ts."
      }
    ],
    "source": "export const meta = {\n  title: `Translations`,\n  description: `Internationalization and Custom Text`,\n};\n\nCustomizing text and adding language translations can be done via the `I18n` module:\n\n```js\nimport { I18n } from \"aws-amplify\";\nimport { Translations } from \"@aws-amplify/ui-components\";\n\nI18n.putVocabulariesForLanguage(\"en-US\", {\n  [Translations.SIGN_IN_HEADER_TEXT]: \"Custom Sign In Header Text\",\n  [Translations.SIGN_IN_ACTION]: \"Custom Click Here to Sign In\"\n});\n```\n\nA complete list of all translatable strings can be found in [`Translations.ts`](https://github.com/aws-amplify/amplify-js/blob/main/packages/amplify-ui-components/src/common/Translations.ts).\n",
    "meta": {
      "title": "Translations - React Native",
      "description": "Internationalization and Custom Text - React Native",
      "subcategory": "Customization",
      "category": "Amplify UI Components"
    },
    "filename": "/ui/customization/translations/q/framework/react-native"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "You can control top level components directly using CSS. For instance, to control the layout of the amplify-authenticator, we can specify the properties directly inside of its selector."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The top level control is available for the following components. Note: The components needs to be rolled out in the client in order to enable this CSS update."
      },
      {
        "heading": null,
        "depth": null,
        "text": "amplify-sign-in"
      },
      {
        "heading": null,
        "depth": null,
        "text": "amplify-confirm-sign-in"
      },
      {
        "heading": null,
        "depth": null,
        "text": "amplify-sign-up"
      },
      {
        "heading": null,
        "depth": null,
        "text": "amplify-confirm-sign-up"
      },
      {
        "heading": null,
        "depth": null,
        "text": "amplify-forgot-password"
      },
      {
        "heading": null,
        "depth": null,
        "text": "amplify-require-new-password"
      },
      {
        "heading": null,
        "depth": null,
        "text": "amplify-verify-contact"
      },
      {
        "heading": null,
        "depth": null,
        "text": "amplify-totp-setup"
      }
    ],
    "source": "export const meta = {\n  title: `Customizing CSS`,\n  description: `Managing the layout and styling of Components`,\n};\n\nYou can control top level components directly using CSS. For instance, to control the layout of the `amplify-authenticator`, we can specify the properties directly inside of its selector.\n\n```css\namplify-authenticator {\n  background: tomato;\n  padding: 5px;\n}\n```\n\nThe top level control is available for the following components. _**Note:**_ The components needs to be rolled out in the client in order to enable this CSS update.\n\n- `amplify-sign-in`\n- `amplify-confirm-sign-in`\n- `amplify-sign-up`\n- `amplify-confirm-sign-up`\n- `amplify-forgot-password`\n- `amplify-require-new-password`\n- `amplify-verify-contact`\n- `amplify-totp-setup`\n",
    "meta": {
      "title": "Customizing CSS - React Native",
      "description": "Managing the layout and styling of Components - React Native",
      "subcategory": "Customization",
      "category": "Amplify UI Components"
    },
    "filename": "/ui/customization/customizing-css/q/framework/react-native"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Theming`,\n  description: `Theming UI Components`,\n  filterKey: `framework`,\n};\n\nimport react0 from \"/src/fragments/ui/customization/web/theming.mdx\";\n\n<Fragments fragments={{react: react0}} />\n\nimport angular1 from \"/src/fragments/ui/customization/web/theming.mdx\";\n\n<Fragments fragments={{angular: angular1}} />\n\nimport vue2 from \"/src/fragments/ui/customization/web/theming.mdx\";\n\n<Fragments fragments={{vue: vue2}} />\n\nimport ionic3 from \"/src/fragments/ui/customization/web/theming.mdx\";\n\n<Fragments fragments={{ionic: ionic3}} />\n\nimport react_native4 from \"/src/fragments/ui/customization/react-native/theming.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native4}} />",
    "meta": {
      "title": "Theming - React Native",
      "description": "Theming UI Components - React Native",
      "filterKey": "framework",
      "subcategory": "Customization",
      "category": "Amplify UI Components"
    },
    "filename": "/ui/customization/theming/q/framework/react-native"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Customization`,\n  description: `Customizing Storage UI Components`,\n  filterKey: `framework`,\n};\n\nimport react_native0 from \"/src/fragments/ui/storage/react-native/customization.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native0}} />\n",
    "meta": {
      "title": "Customization - React Native",
      "description": "Customizing Storage UI Components - React Native",
      "filterKey": "framework",
      "subcategory": "Storage",
      "category": "Amplify UI Components"
    },
    "filename": "/ui/storage/customization/q/framework/react-native"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Tracking Events`,\n  description: `Tracking Events for UI Components`,\n  filterKey: `framework`,\n};\n\nimport react0 from \"/src/fragments/ui/storage/web/tracking-events.mdx\";\n\n<Fragments fragments={{react: react0}} />\n\nimport angular1 from \"/src/fragments/ui/storage/web/tracking-events.mdx\";\n\n<Fragments fragments={{angular: angular1}} />\n\nimport vue2 from \"/src/fragments/ui/storage/web/tracking-events.mdx\";\n\n<Fragments fragments={{vue: vue2}} />\n\nimport ionic3 from \"/src/fragments/ui/storage/web/tracking-events.mdx\";\n\n<Fragments fragments={{ionic: ionic3}} />\n\nimport react_native4 from \"/src/fragments/ui/storage/react-native/tracking-events.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native4}} />\n",
    "meta": {
      "title": "Tracking Events - React Native",
      "description": "Tracking Events for UI Components - React Native",
      "filterKey": "framework",
      "subcategory": "Storage",
      "category": "Amplify UI Components"
    },
    "filename": "/ui/storage/tracking-events/q/framework/react-native"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `S3 Image`,\n  description: `Amplify S3 Image Component is used to upload and render an image from S3 bucket using an image key`,\n  filterKey: `framework`,\n};\n\nimport react0 from \"/src/fragments/ui/storage/web/s3-image.mdx\";\n\n<Fragments fragments={{react: react0}} />\n\nimport angular1 from \"/src/fragments/ui/storage/web/s3-image.mdx\";\n\n<Fragments fragments={{angular: angular1}} />\n\nimport vue2 from \"/src/fragments/ui/storage/web/s3-image.mdx\";\n\n<Fragments fragments={{vue: vue2}} />\n\nimport ionic3 from \"/src/fragments/ui/storage/web/s3-image.mdx\";\n\n<Fragments fragments={{ionic: ionic3}} />\n\nimport react_native4 from \"/src/fragments/ui/storage/react-native/s3-image.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native4}} />",
    "meta": {
      "title": "S3 Image - React Native",
      "description": "Amplify S3 Image Component is used to upload and render an image from S3 bucket using an image key - React Native",
      "filterKey": "framework",
      "subcategory": "Storage",
      "category": "Amplify UI Components"
    },
    "filename": "/ui/storage/s3-image/q/framework/react-native"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `S3 Album`,\n  description: `Amplify S3 Album Component is used to list images from S3 bucket into a responsive image grid. Also allows file input from local machine`,\n  filterKey: `framework`,\n};\n\nimport react0 from \"/src/fragments/ui/storage/web/s3-album.mdx\";\n\n<Fragments fragments={{react: react0}} />\n\nimport angular1 from \"/src/fragments/ui/storage/web/s3-album.mdx\";\n\n<Fragments fragments={{angular: angular1}} />\n\nimport vue2 from \"/src/fragments/ui/storage/web/s3-album.mdx\";\n\n<Fragments fragments={{vue: vue2}} />\n\nimport ionic3 from \"/src/fragments/ui/storage/web/s3-album.mdx\";\n\n<Fragments fragments={{ionic: ionic3}} />\n\nimport react_native4 from \"/src/fragments/ui/storage/react-native/s3-album.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native4}} />\n",
    "meta": {
      "title": "S3 Album - React Native",
      "description": "Amplify S3 Album Component is used to list images from S3 bucket into a responsive image grid. Also allows file input from local machine - React Native",
      "filterKey": "framework",
      "subcategory": "Storage",
      "category": "Amplify UI Components"
    },
    "filename": "/ui/storage/s3-album/q/framework/react-native"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Chatbot`,\n  description: `Chatbot UI Component`,\n  filterKey: `framework`,\n};\n\nimport react0 from \"/src/fragments/ui/interactions/web/chatbot.mdx\";\n\n<Fragments fragments={{react: react0}} />\n\nimport angular1 from \"/src/fragments/ui/interactions/web/chatbot.mdx\";\n\n<Fragments fragments={{angular: angular1}} />\n\nimport ionic2 from \"/src/fragments/ui/interactions/web/chatbot.mdx\";\n\n<Fragments fragments={{ionic: ionic2}} />\n\nimport vue3 from \"/src/fragments/ui/interactions/web/chatbot.mdx\";\n\n<Fragments fragments={{vue: vue3}} />\n\nimport react_native4 from \"/src/fragments/ui/interactions/react-native/chatbot.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native4}} />\n",
    "meta": {
      "title": "Chatbot - React Native",
      "description": "Chatbot UI Component - React Native",
      "filterKey": "framework",
      "subcategory": "Interactions",
      "category": "Amplify UI Components"
    },
    "filename": "/ui/interactions/chatbot/q/framework/react-native"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "A simple way to add authentication flows into your app is to use the Authenticator component. The Authenticator component encapsulates an authentication workflow in the framework of your choice and is backed by the cloud resources set up in your Auth cloud resources."
      }
    ],
    "source": "export const meta = {\n  title: `Authenticator`,\n  description: `Authenticator UI component`,\n  filterKey: `framework`,\n};\n\nimport developerpreviewjs from '/src/fragments/ui/auth/developer-preview-callout-js.mdx';\n\n<Fragments fragments={{ react: developerpreviewjs }} />\n<Fragments fragments={{ angular: developerpreviewjs }} />\n<Fragments fragments={{ vue: developerpreviewjs }} />\n<Fragments fragments={{ ionic: developerpreviewjs }} />\n<Fragments fragments={{ 'react-native': developerpreviewjs }} />\n\nA simple way to add authentication flows into your app is to use the Authenticator component. The Authenticator component encapsulates an authentication workflow in the framework of your choice and is backed by the cloud resources set up in your Auth cloud resources.\n\nimport react0 from \"/src/fragments/ui/auth/web/authenticator.mdx\";\n\n<Fragments fragments={{react: react0}} />\n\nimport angular1 from \"/src/fragments/ui/auth/web/authenticator.mdx\";\n\n<Fragments fragments={{angular: angular1}} />\n\nimport vue2 from \"/src/fragments/ui/auth/web/authenticator.mdx\";\n\n<Fragments fragments={{vue: vue2}} />\n\nimport ionic3 from \"/src/fragments/ui/auth/web/authenticator.mdx\";\n\n<Fragments fragments={{ionic: ionic3}} />\n\nimport react_native4 from \"/src/fragments/ui/auth/react-native/authenticator.mdx\";\n\n<Fragments fragments={{\"react-native\": react_native4}} />\n\nimport flutter5 from \"/src/fragments/ui/auth/flutter/authenticator.mdx\";\n\n<Fragments fragments={{flutter: flutter5}} />\n",
    "meta": {
      "title": "Authenticator - Flutter",
      "description": "Authenticator UI component - Flutter",
      "filterKey": "framework",
      "subcategory": "Authentication",
      "category": "Amplify UI Components"
    },
    "filename": "/ui/auth/authenticator/q/framework/flutter"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "A simple way to add authentication flows into your app is to use the Authenticator component. The Authenticator component encapsulates an authentication workflow in the framework of your choice and is backed by the cloud resources set up in your Auth cloud resources."
      }
    ],
    "source": "export const meta = {\n  title: `Authenticator`,\n  description: `Authenticator UI component`,\n  filterKey: `framework`,\n};\n\nimport developerpreviewjs from '/src/fragments/ui/auth/developer-preview-callout-js.mdx';\n\n<Fragments fragments={{ react: developerpreviewjs }} />\n<Fragments fragments={{ angular: developerpreviewjs }} />\n<Fragments fragments={{ vue: developerpreviewjs }} />\n<Fragments fragments={{ ionic: developerpreviewjs }} />\n<Fragments fragments={{ 'react-native': developerpreviewjs }} />\n\nA simple way to add authentication flows into your app is to use the Authenticator component. The Authenticator component encapsulates an authentication workflow in the framework of your choice and is backed by the cloud resources set up in your Auth cloud resources.\n\nimport react0 from \"/src/fragments/ui/auth/web/authenticator.mdx\";\n\n<Fragments fragments={{react: react0}} />\n\nimport angular1 from \"/src/fragments/ui/auth/web/authenticator.mdx\";\n\n<Fragments fragments={{angular: angular1}} />\n\nimport vue2 from \"/src/fragments/ui/auth/web/authenticator.mdx\";\n\n<Fragments fragments={{vue: vue2}} />\n\nimport ionic3 from \"/src/fragments/ui/auth/web/authenticator.mdx\";\n\n<Fragments fragments={{ionic: ionic3}} />\n\nimport react_native4 from \"/src/fragments/ui/auth/react-native/authenticator.mdx\";\n\n<Fragments fragments={{\"react-native\": react_native4}} />\n\nimport flutter5 from \"/src/fragments/ui/auth/flutter/authenticator.mdx\";\n\n<Fragments fragments={{flutter: flutter5}} />\n",
    "meta": {
      "title": "Authenticator - React Native",
      "description": "Authenticator UI component - React Native",
      "filterKey": "framework",
      "subcategory": "Authentication",
      "category": "Amplify UI Components"
    },
    "filename": "/ui/auth/authenticator/q/framework/react-native"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Connect`,\n  description: `Connect UI Component`,\n  filterKey: `framework`,\n};\n\nimport react_native0 from \"/src/fragments/ui/api/react-native/connect.mdx\";\n\n  <Fragments fragments={{\"react-native\": react_native0}} />",
    "meta": {
      "title": "Connect - React Native",
      "description": "Connect UI Component - React Native",
      "filterKey": "framework",
      "subcategory": "API",
      "category": "Amplify UI Components"
    },
    "filename": "/ui/api/connect/q/framework/react-native"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Uninstalling the app`,\n  description: `Learn about the data that gets stored persistently on a device.`,\n};\n\nimport ios0 from \"/src/fragments/sdk/info/native_common/app-uninstall/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n",
    "meta": {
      "title": "Uninstalling the app - Android",
      "description": "Learn about the data that gets stored persistently on a device. - Android",
      "subcategory": "Info",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/info/app-uninstall/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `SDK Setup Options`,\n  description: `The AWS SDK contains high level client interfaces for quickly adding common features and functionality to your app. You can also manually add the generated AWS service interfaces for direct interaction if you have custom or advanced requirements.`,\n};\n\nimport ios0 from \"/src/fragments/sdk/configuration/ios/setup-options.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/sdk/configuration/android/setup-options.mdx\";\n\n<Fragments fragments={{android: android1}} />\n",
    "meta": {
      "title": "SDK Setup Options - iOS",
      "description": "The AWS SDK contains high level client interfaces for quickly adding common features and functionality to your app. You can also manually add the generated AWS service interfaces for direct interaction if you have custom or advanced requirements. - iOS",
      "subcategory": "Configuration",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/configuration/setup-options/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `SDK Setup Options`,\n  description: `The AWS SDK contains high level client interfaces for quickly adding common features and functionality to your app. You can also manually add the generated AWS service interfaces for direct interaction if you have custom or advanced requirements.`,\n};\n\nimport ios0 from \"/src/fragments/sdk/configuration/ios/setup-options.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/sdk/configuration/android/setup-options.mdx\";\n\n<Fragments fragments={{android: android1}} />\n",
    "meta": {
      "title": "SDK Setup Options - Android",
      "description": "The AWS SDK contains high level client interfaces for quickly adding common features and functionality to your app. You can also manually add the generated AWS service interfaces for direct interaction if you have custom or advanced requirements. - Android",
      "subcategory": "Configuration",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/configuration/setup-options/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Configure Access `,\n  description: `description`,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/storage/ios/configure-access.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n",
    "meta": {
      "title": "Configure Access - iOS",
      "description": "description - iOS",
      "subcategory": "Storage",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/storage/configure-access/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Configure Access `,\n  description: `description`,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/storage/ios/configure-access.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n",
    "meta": {
      "title": "Configure Access - Android",
      "description": "description - Android",
      "subcategory": "Storage",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/storage/configure-access/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Using GraphQL API`,\n  description: `Learn how to upload and download Amazon S3 Objects using AWS AppSync, a GraphQL based solution to build data-driven apps with real-time and offline capabilities.`,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/storage/ios/graphql-api.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/storage/android/graphql-api.mdx\";\n\n<Fragments fragments={{android: android2}} /> ",
    "meta": {
      "title": "Using GraphQL API - iOS",
      "description": "Learn how to upload and download Amazon S3 Objects using AWS AppSync, a GraphQL based solution to build data-driven apps with real-time and offline capabilities. - iOS",
      "subcategory": "Storage",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/storage/graphql-api/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Using GraphQL API`,\n  description: `Learn how to upload and download Amazon S3 Objects using AWS AppSync, a GraphQL based solution to build data-driven apps with real-time and offline capabilities.`,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/storage/ios/graphql-api.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/storage/android/graphql-api.mdx\";\n\n<Fragments fragments={{android: android2}} /> ",
    "meta": {
      "title": "Using GraphQL API - Android",
      "description": "Learn how to upload and download Amazon S3 Objects using AWS AppSync, a GraphQL based solution to build data-driven apps with real-time and offline capabilities. - Android",
      "subcategory": "Storage",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/storage/graphql-api/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Using TransferUtility`,\n  description: `To make it easy to upload and download objects from Amazon S3, AWS Mobile SDK provides a TransferUtility component with built-in support for background transfers, progress tracking, and MultiPart uploads. `,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/storage/ios/transfer-utility.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/storage/android/transfer-utility.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Using TransferUtility - iOS",
      "description": "To make it easy to upload and download objects from Amazon S3, AWS Mobile SDK provides a TransferUtility component with built-in support for background transfers, progress tracking, and MultiPart uploads.  - iOS",
      "subcategory": "Storage",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/storage/transfer-utility/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Using TransferUtility`,\n  description: `To make it easy to upload and download objects from Amazon S3, AWS Mobile SDK provides a TransferUtility component with built-in support for background transfers, progress tracking, and MultiPart uploads. `,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/storage/ios/transfer-utility.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/storage/android/transfer-utility.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Using TransferUtility - Android",
      "description": "To make it easy to upload and download objects from Amazon S3, AWS Mobile SDK provides a TransferUtility component with built-in support for background transfers, progress tracking, and MultiPart uploads.  - Android",
      "subcategory": "Storage",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/storage/transfer-utility/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `Learn how to configure the data access level on your stored objects using AWS Mobile SDK.`,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/storage/ios/getting-started.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/storage/android/getting-started.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Getting started - iOS",
      "description": "Learn how to configure the data access level on your stored objects using AWS Mobile SDK. - iOS",
      "subcategory": "Storage",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/storage/getting-started/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `Learn how to configure the data access level on your stored objects using AWS Mobile SDK.`,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/storage/ios/getting-started.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/storage/android/getting-started.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Getting started - Android",
      "description": "Learn how to configure the data access level on your stored objects using AWS Mobile SDK. - Android",
      "subcategory": "Storage",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/storage/getting-started/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Working with the API`,\n  description: `Learn how to establish a connection, subscribe to a topic, publish to a topic, unsubscribe from a topic and close a connection with PubSub on AWS Mobile SDK.`,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/pubsub/ios/working-api.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/pubsub/android/working-api.mdx\";\n\n<Fragments fragments={{android: android2}} />",
    "meta": {
      "title": "Working with the API - iOS",
      "description": "Learn how to establish a connection, subscribe to a topic, publish to a topic, unsubscribe from a topic and close a connection with PubSub on AWS Mobile SDK. - iOS",
      "subcategory": "PubSub",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/pubsub/working-api/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Working with the API`,\n  description: `Learn how to establish a connection, subscribe to a topic, publish to a topic, unsubscribe from a topic and close a connection with PubSub on AWS Mobile SDK.`,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/pubsub/ios/working-api.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/pubsub/android/working-api.mdx\";\n\n<Fragments fragments={{android: android2}} />",
    "meta": {
      "title": "Working with the API - Android",
      "description": "Learn how to establish a connection, subscribe to a topic, publish to a topic, unsubscribe from a topic and close a connection with PubSub on AWS Mobile SDK. - Android",
      "subcategory": "PubSub",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/pubsub/working-api/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `Learn how to integrate connectivity with cloud-based message-oriented middleware using PubSub and AWS Mobile SDK. You can use PubSub to pass messages between your app instances and your app’s backend creating real-time interactive experiences.`,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/pubsub/ios/getting-started.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/pubsub/android/getting-started.mdx\";\n\n<Fragments fragments={{android: android2}} />",
    "meta": {
      "title": "Getting started - iOS",
      "description": "Learn how to integrate connectivity with cloud-based message-oriented middleware using PubSub and AWS Mobile SDK. You can use PubSub to pass messages between your app instances and your app’s backend creating real-time interactive experiences. - iOS",
      "subcategory": "PubSub",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/pubsub/getting-started/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `Learn how to integrate connectivity with cloud-based message-oriented middleware using PubSub and AWS Mobile SDK. You can use PubSub to pass messages between your app instances and your app’s backend creating real-time interactive experiences.`,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/pubsub/ios/getting-started.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/pubsub/android/getting-started.mdx\";\n\n<Fragments fragments={{android: android2}} />",
    "meta": {
      "title": "Getting started - Android",
      "description": "Learn how to integrate connectivity with cloud-based message-oriented middleware using PubSub and AWS Mobile SDK. You can use PubSub to pass messages between your app instances and your app’s backend creating real-time interactive experiences. - Android",
      "subcategory": "PubSub",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/pubsub/getting-started/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Setting up push notification services`,\n  description: `Learn how to setup the various push notification services for your mobile app.`,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/push-notifications/ios/setup-apns.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/push-notifications/android/setup-fcm.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport android3 from \"/src/fragments/sdk/push-notifications/android/handle-fcm.mdx\";\n\n<Fragments fragments={{android: android3}} />\n\nimport android4 from \"/src/fragments/sdk/push-notifications/android/handle-adm.mdx\";\n\n<Fragments fragments={{android: android4}} />\n\nimport android5 from \"/src/fragments/sdk/push-notifications/android/handle-baidu.mdx\";\n\n<Fragments fragments={{android: android5}} />\n",
    "meta": {
      "title": "Setting up push notification services - iOS",
      "description": "Learn how to setup the various push notification services for your mobile app. - iOS",
      "subcategory": "Push notifications",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/push-notifications/setup-push-service/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Setting up push notification services`,\n  description: `Learn how to setup the various push notification services for your mobile app.`,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/push-notifications/ios/setup-apns.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/push-notifications/android/setup-fcm.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport android3 from \"/src/fragments/sdk/push-notifications/android/handle-fcm.mdx\";\n\n<Fragments fragments={{android: android3}} />\n\nimport android4 from \"/src/fragments/sdk/push-notifications/android/handle-adm.mdx\";\n\n<Fragments fragments={{android: android4}} />\n\nimport android5 from \"/src/fragments/sdk/push-notifications/android/handle-baidu.mdx\";\n\n<Fragments fragments={{android: android5}} />\n",
    "meta": {
      "title": "Setting up push notification services - Android",
      "description": "Learn how to setup the various push notification services for your mobile app. - Android",
      "subcategory": "Push notifications",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/push-notifications/setup-push-service/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Messaging campaigns`,\n  description: `Use AWS Mobile SDK and the Amazon Pinpoint console to target your app users with push messaging. You can send individual messages or configure campaigns that target a group of users that match a profile that you define.`,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/push-notifications/ios/messaging-campaign.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/push-notifications/android/messaging-campaign.mdx\";\n\n<Fragments fragments={{android: android2}} />",
    "meta": {
      "title": "Messaging campaigns - iOS",
      "description": "Use AWS Mobile SDK and the Amazon Pinpoint console to target your app users with push messaging. You can send individual messages or configure campaigns that target a group of users that match a profile that you define. - iOS",
      "subcategory": "Push notifications",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/push-notifications/messaging-campaign/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Messaging campaigns`,\n  description: `Use AWS Mobile SDK and the Amazon Pinpoint console to target your app users with push messaging. You can send individual messages or configure campaigns that target a group of users that match a profile that you define.`,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/push-notifications/ios/messaging-campaign.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/push-notifications/android/messaging-campaign.mdx\";\n\n<Fragments fragments={{android: android2}} />",
    "meta": {
      "title": "Messaging campaigns - Android",
      "description": "Use AWS Mobile SDK and the Amazon Pinpoint console to target your app users with push messaging. You can send individual messages or configure campaigns that target a group of users that match a profile that you define. - Android",
      "subcategory": "Push notifications",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/push-notifications/messaging-campaign/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `Enable your users to receive mobile push messages sent from the Apple (APNs) and Google (FCM/GCM) platforms. The Amplify CLI deploys your push notification backend using Amazon Pinpoint. You can also create Amazon Pinpoint campaigns that tie user behavior to push or other forms of messaging.`,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/push-notifications/ios/getting-started.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/push-notifications/android/getting-started.mdx\";\n\n<Fragments fragments={{android: android2}} />",
    "meta": {
      "title": "Getting started - iOS",
      "description": "Enable your users to receive mobile push messages sent from the Apple (APNs) and Google (FCM/GCM) platforms. The Amplify CLI deploys your push notification backend using Amazon Pinpoint. You can also create Amazon Pinpoint campaigns that tie user behavior to push or other forms of messaging. - iOS",
      "subcategory": "Push notifications",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/push-notifications/getting-started/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `Enable your users to receive mobile push messages sent from the Apple (APNs) and Google (FCM/GCM) platforms. The Amplify CLI deploys your push notification backend using Amazon Pinpoint. You can also create Amazon Pinpoint campaigns that tie user behavior to push or other forms of messaging.`,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/push-notifications/ios/getting-started.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/push-notifications/android/getting-started.mdx\";\n\n<Fragments fragments={{android: android2}} />",
    "meta": {
      "title": "Getting started - Android",
      "description": "Enable your users to receive mobile push messages sent from the Apple (APNs) and Google (FCM/GCM) platforms. The Amplify CLI deploys your push notification backend using Amazon Pinpoint. You can also create Amazon Pinpoint campaigns that tie user behavior to push or other forms of messaging. - Android",
      "subcategory": "Push notifications",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/push-notifications/getting-started/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Device features`,\n  description: `You can use the device related features of Amazon Cognito UserPools by enabling the Devices features.`,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/auth/ios/device-features.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/auth/android/device-features.mdx\";\n\n<Fragments fragments={{android: android2}} />",
    "meta": {
      "title": "Device features - iOS",
      "description": "You can use the device related features of Amazon Cognito UserPools by enabling the Devices features. - iOS",
      "subcategory": "Authentication",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/auth/device-features/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Device features`,\n  description: `You can use the device related features of Amazon Cognito UserPools by enabling the Devices features.`,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/auth/ios/device-features.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/auth/android/device-features.mdx\";\n\n<Fragments fragments={{android: android2}} />",
    "meta": {
      "title": "Device features - Android",
      "description": "You can use the device related features of Amazon Cognito UserPools by enabling the Devices features. - Android",
      "subcategory": "Authentication",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/auth/device-features/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Custom auth flow`,\n  description: `Learn how to customize the authentication flow with Amazon Cognito User Pools to enable custom challenge types, in addition to a password in order to verify the identity of users. `,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/auth/ios/custom-auth-flow.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/auth/android/custom-auth-flow.mdx\";\n\n<Fragments fragments={{android: android2}} />",
    "meta": {
      "title": "Custom auth flow - iOS",
      "description": "Learn how to customize the authentication flow with Amazon Cognito User Pools to enable custom challenge types, in addition to a password in order to verify the identity of users.  - iOS",
      "subcategory": "Authentication",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/auth/custom-auth-flow/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Custom auth flow`,\n  description: `Learn how to customize the authentication flow with Amazon Cognito User Pools to enable custom challenge types, in addition to a password in order to verify the identity of users. `,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/auth/ios/custom-auth-flow.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/auth/android/custom-auth-flow.mdx\";\n\n<Fragments fragments={{android: android2}} />",
    "meta": {
      "title": "Custom auth flow - Android",
      "description": "Learn how to customize the authentication flow with Amazon Cognito User Pools to enable custom challenge types, in addition to a password in order to verify the identity of users.  - Android",
      "subcategory": "Authentication",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/auth/custom-auth-flow/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Hosted UI`,\n  description: `Amazon Cognito provides a customizable user experience via the Hosted UI. The Hosted UI is an OAuth 2.0 flow that allows you to launch a login screen without embedding an SDK for Cognito or a social provider into your application. `,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/auth/ios/hosted-ui.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/auth/android/hosted-ui.mdx\";\n\n<Fragments fragments={{android: android2}} />",
    "meta": {
      "title": "Hosted UI - iOS",
      "description": "Amazon Cognito provides a customizable user experience via the Hosted UI. The Hosted UI is an OAuth 2.0 flow that allows you to launch a login screen without embedding an SDK for Cognito or a social provider into your application.  - iOS",
      "subcategory": "Authentication",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/auth/hosted-ui/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Hosted UI`,\n  description: `Amazon Cognito provides a customizable user experience via the Hosted UI. The Hosted UI is an OAuth 2.0 flow that allows you to launch a login screen without embedding an SDK for Cognito or a social provider into your application. `,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/auth/ios/hosted-ui.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/auth/android/hosted-ui.mdx\";\n\n<Fragments fragments={{android: android2}} />",
    "meta": {
      "title": "Hosted UI - Android",
      "description": "Amazon Cognito provides a customizable user experience via the Hosted UI. The Hosted UI is an OAuth 2.0 flow that allows you to launch a login screen without embedding an SDK for Cognito or a social provider into your application.  - Android",
      "subcategory": "Authentication",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/auth/hosted-ui/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Federated identities`,\n  description: `Federated Sign In can be used to obtain federated “Identity ID” using external providers. Learn how to setup external sign-in providers like SAML provider, Facebook, Google, Sign in with Apple. `,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/auth/ios/federated-identities.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/auth/android/federated-identities.mdx\";\n\n<Fragments fragments={{android: android2}} />",
    "meta": {
      "title": "Federated identities - iOS",
      "description": "Federated Sign In can be used to obtain federated “Identity ID” using external providers. Learn how to setup external sign-in providers like SAML provider, Facebook, Google, Sign in with Apple.  - iOS",
      "subcategory": "Authentication",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/auth/federated-identities/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Federated identities`,\n  description: `Federated Sign In can be used to obtain federated “Identity ID” using external providers. Learn how to setup external sign-in providers like SAML provider, Facebook, Google, Sign in with Apple. `,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/auth/ios/federated-identities.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/auth/android/federated-identities.mdx\";\n\n<Fragments fragments={{android: android2}} />",
    "meta": {
      "title": "Federated identities - Android",
      "description": "Federated Sign In can be used to obtain federated “Identity ID” using external providers. Learn how to setup external sign-in providers like SAML provider, Facebook, Google, Sign in with Apple.  - Android",
      "subcategory": "Authentication",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/auth/federated-identities/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Working with the API`,\n  description: `Learn more about how to use the Amplify Framework's auth APIs  `,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/auth/ios/working-with-api.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/auth/android/working-with-api.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Working with the API - iOS",
      "description": "Learn more about how to use the Amplify Framework's auth APIs   - iOS",
      "subcategory": "Authentication",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/auth/working-with-api/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Working with the API`,\n  description: `Learn more about how to use the Amplify Framework's auth APIs  `,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/auth/ios/working-with-api.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/auth/android/working-with-api.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Working with the API - Android",
      "description": "Learn more about how to use the Amplify Framework's auth APIs   - Android",
      "subcategory": "Authentication",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/auth/working-with-api/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Drop-in auth`,\n  description: `Learn how to use and customize AWSMobileClient's simple “drop-in” auth UI for your application. `,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/auth/ios/drop-in-auth.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/auth/android/drop-in-auth.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Drop-in auth - iOS",
      "description": "Learn how to use and customize AWSMobileClient's simple “drop-in” auth UI for your application.  - iOS",
      "subcategory": "Authentication",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/auth/drop-in-auth/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Drop-in auth`,\n  description: `Learn how to use and customize AWSMobileClient's simple “drop-in” auth UI for your application. `,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/auth/ios/drop-in-auth.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/auth/android/drop-in-auth.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Drop-in auth - Android",
      "description": "Learn how to use and customize AWSMobileClient's simple “drop-in” auth UI for your application.  - Android",
      "subcategory": "Authentication",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/auth/drop-in-auth/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Guest access`,\n  description: `Learn how to enable “Guest” or “Unauthenticated” UX in your application. This is provided out of the box with AWSMobileClient through the initialization routine you have added.`,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/auth/ios/guest-access.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/auth/android/guest-access.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Guest access - iOS",
      "description": "Learn how to enable “Guest” or “Unauthenticated” UX in your application. This is provided out of the box with AWSMobileClient through the initialization routine you have added. - iOS",
      "subcategory": "Authentication",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/auth/guest-access/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Guest access`,\n  description: `Learn how to enable “Guest” or “Unauthenticated” UX in your application. This is provided out of the box with AWSMobileClient through the initialization routine you have added.`,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/auth/ios/guest-access.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/auth/android/guest-access.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Guest access - Android",
      "description": "Learn how to enable “Guest” or “Unauthenticated” UX in your application. This is provided out of the box with AWSMobileClient through the initialization routine you have added. - Android",
      "subcategory": "Authentication",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/auth/guest-access/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Overview`,\n  description: `The AWSMobileClient provides client APIs and building blocks for developers who want to create user authentication experiences. Learn more about how it works. `,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/auth/ios/how-it-works.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/auth/android/how-it-works.mdx\";\n\n<Fragments fragments={{android: android2}} />",
    "meta": {
      "title": "Overview - iOS",
      "description": "The AWSMobileClient provides client APIs and building blocks for developers who want to create user authentication experiences. Learn more about how it works.  - iOS",
      "subcategory": "Authentication",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/auth/how-it-works/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Overview`,\n  description: `The AWSMobileClient provides client APIs and building blocks for developers who want to create user authentication experiences. Learn more about how it works. `,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/auth/ios/how-it-works.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/auth/android/how-it-works.mdx\";\n\n<Fragments fragments={{android: android2}} />",
    "meta": {
      "title": "Overview - Android",
      "description": "The AWSMobileClient provides client APIs and building blocks for developers who want to create user authentication experiences. Learn more about how it works.  - Android",
      "subcategory": "Authentication",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/auth/how-it-works/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `Learn how to integrate auth capabilities into your mobile app with AWS Mobile SDK.`,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/auth/ios/getting-started.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/auth/android/getting-started.mdx\";\n\n<Fragments fragments={{android: android2}} />",
    "meta": {
      "title": "Getting started - iOS",
      "description": "Learn how to integrate auth capabilities into your mobile app with AWS Mobile SDK. - iOS",
      "subcategory": "Authentication",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/auth/getting-started/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `Learn how to integrate auth capabilities into your mobile app with AWS Mobile SDK.`,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/auth/ios/getting-started.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/auth/android/getting-started.mdx\";\n\n<Fragments fragments={{android: android2}} />",
    "meta": {
      "title": "Getting started - Android",
      "description": "Learn how to integrate auth capabilities into your mobile app with AWS Mobile SDK. - Android",
      "subcategory": "Authentication",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/auth/getting-started/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Using Amazon Kinesis`,\n  description: `Learn how to interface with Amazon Kinesis Data Streams and Amazon Kinesis Data Firehose to stream analytics data for real-time processing using Amplify.`,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/analytics/ios/kinesis.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/analytics/android/kinesis.mdx\";\n\n<Fragments fragments={{android: android2}} />",
    "meta": {
      "title": "Using Amazon Kinesis - iOS",
      "description": "Learn how to interface with Amazon Kinesis Data Streams and Amazon Kinesis Data Firehose to stream analytics data for real-time processing using Amplify. - iOS",
      "subcategory": "Analytics",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/analytics/kinesis/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Using Amazon Kinesis`,\n  description: `Learn how to interface with Amazon Kinesis Data Streams and Amazon Kinesis Data Firehose to stream analytics data for real-time processing using Amplify.`,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/analytics/ios/kinesis.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/analytics/android/kinesis.mdx\";\n\n<Fragments fragments={{android: android2}} />",
    "meta": {
      "title": "Using Amazon Kinesis - Android",
      "description": "Learn how to interface with Amazon Kinesis Data Streams and Amazon Kinesis Data Firehose to stream analytics data for real-time processing using Amplify. - Android",
      "subcategory": "Analytics",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/analytics/kinesis/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Endpoints`,\n  description: `When a user starts a session (for example, by launching your mobile app), your mobile or web application can automatically register (or update) an endpoint with Amazon Pinpoint. The endpoint represents the device that the user starts the session with.`,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/analytics/ios/endpoints.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/analytics/android/endpoints.mdx\";\n\n<Fragments fragments={{android: android2}} />",
    "meta": {
      "title": "Endpoints - iOS",
      "description": "When a user starts a session (for example, by launching your mobile app), your mobile or web application can automatically register (or update) an endpoint with Amazon Pinpoint. The endpoint represents the device that the user starts the session with. - iOS",
      "subcategory": "Analytics",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/analytics/endpoints/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Endpoints`,\n  description: `When a user starts a session (for example, by launching your mobile app), your mobile or web application can automatically register (or update) an endpoint with Amazon Pinpoint. The endpoint represents the device that the user starts the session with.`,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/analytics/ios/endpoints.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/analytics/android/endpoints.mdx\";\n\n<Fragments fragments={{android: android2}} />",
    "meta": {
      "title": "Endpoints - Android",
      "description": "When a user starts a session (for example, by launching your mobile app), your mobile or web application can automatically register (or update) an endpoint with Amazon Pinpoint. The endpoint represents the device that the user starts the session with. - Android",
      "subcategory": "Analytics",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/analytics/endpoints/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Events`,\n  description: `You can use the AWS Android SDK for Pinpoint to report usage data, or events, to Amazon Pinpoint. You can report events to capture information such as session times, users’ purchasing behavior, sign-in attempts, or any custom event type that you need.`,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/analytics/ios/events.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/analytics/android/events.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Events - iOS",
      "description": "You can use the AWS Android SDK for Pinpoint to report usage data, or events, to Amazon Pinpoint. You can report events to capture information such as session times, users’ purchasing behavior, sign-in attempts, or any custom event type that you need. - iOS",
      "subcategory": "Analytics",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/analytics/events/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Events`,\n  description: `You can use the AWS Android SDK for Pinpoint to report usage data, or events, to Amazon Pinpoint. You can report events to capture information such as session times, users’ purchasing behavior, sign-in attempts, or any custom event type that you need.`,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/analytics/ios/events.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/analytics/android/events.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Events - Android",
      "description": "You can use the AWS Android SDK for Pinpoint to report usage data, or events, to Amazon Pinpoint. You can report events to capture information such as session times, users’ purchasing behavior, sign-in attempts, or any custom event type that you need. - Android",
      "subcategory": "Analytics",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/analytics/events/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting Started`,\n  description: `Learn more about how to add analytics capabilities in your cloud-based application using AWS Amplify.`,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/analytics/ios/getting-started.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/analytics/android/getting-started.mdx\";\n\n<Fragments fragments={{android: android2}} />",
    "meta": {
      "title": "Getting Started - iOS",
      "description": "Learn more about how to add analytics capabilities in your cloud-based application using AWS Amplify. - iOS",
      "subcategory": "Analytics",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/analytics/getting-started/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting Started`,\n  description: `Learn more about how to add analytics capabilities in your cloud-based application using AWS Amplify.`,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/analytics/ios/getting-started.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/analytics/android/getting-started.mdx\";\n\n<Fragments fragments={{android: android2}} />",
    "meta": {
      "title": "Getting Started - Android",
      "description": "Learn more about how to add analytics capabilities in your cloud-based application using AWS Amplify. - Android",
      "subcategory": "Analytics",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/analytics/getting-started/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `REST API`,\n  description: `The API category will perform SDK code generation which, when used with the AWSMobileClient can be used for creating signed requests for Amazon API Gateway when the service Authorization is set to AWS_IAM or when using a Cognito User Pools Authorizer.`,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/api/ios/rest.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/api/android/rest.mdx\";\n\n<Fragments fragments={{android: android2}} />",
    "meta": {
      "title": "REST API - iOS",
      "description": "The API category will perform SDK code generation which, when used with the AWSMobileClient can be used for creating signed requests for Amazon API Gateway when the service Authorization is set to AWS_IAM or when using a Cognito User Pools Authorizer. - iOS",
      "subcategory": "API",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/api/rest/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `REST API`,\n  description: `The API category will perform SDK code generation which, when used with the AWSMobileClient can be used for creating signed requests for Amazon API Gateway when the service Authorization is set to AWS_IAM or when using a Cognito User Pools Authorizer.`,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/api/ios/rest.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/api/android/rest.mdx\";\n\n<Fragments fragments={{android: android2}} />",
    "meta": {
      "title": "REST API - Android",
      "description": "The API category will perform SDK code generation which, when used with the AWSMobileClient can be used for creating signed requests for Amazon API Gateway when the service Authorization is set to AWS_IAM or when using a Cognito User Pools Authorizer. - Android",
      "subcategory": "API",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/api/rest/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `GraphQL - Realtime and Offline`,\n  description: `AWS AppSync helps you build data-driven apps with real-time and offline capabilities. The AppSync Android SDK enables you to integrate your app with the AWS AppSync service and is based off of the Apollo project found here.  `,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/api/ios/graphql.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/api/android/graphql.mdx\";\n\n<Fragments fragments={{android: android2}} />",
    "meta": {
      "title": "GraphQL - Realtime and Offline - iOS",
      "description": "AWS AppSync helps you build data-driven apps with real-time and offline capabilities. The AppSync Android SDK enables you to integrate your app with the AWS AppSync service and is based off of the Apollo project found here.   - iOS",
      "subcategory": "API",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/api/graphql/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `GraphQL - Realtime and Offline`,\n  description: `AWS AppSync helps you build data-driven apps with real-time and offline capabilities. The AppSync Android SDK enables you to integrate your app with the AWS AppSync service and is based off of the Apollo project found here.  `,\n};\n\nimport all0 from \"/src/fragments/sdk/library-callout.mdx\";\n\n<Fragments fragments={{all: all0}} />\n\nimport ios1 from \"/src/fragments/sdk/api/ios/graphql.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/sdk/api/android/graphql.mdx\";\n\n<Fragments fragments={{android: android2}} />",
    "meta": {
      "title": "GraphQL - Realtime and Offline - Android",
      "description": "AWS AppSync helps you build data-driven apps with real-time and offline capabilities. The AppSync Android SDK enables you to integrate your app with the AWS AppSync service and is based off of the Apollo project found here.   - Android",
      "subcategory": "API",
      "category": "AWS Mobile SDK"
    },
    "filename": "/sdk/api/graphql/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Typescript Strict Mode `,\n  description: `Typescript Strict Mode `,\n};\n\nimport js0 from \"/src/fragments/lib/troubleshooting/js/strict-mode.mdx\";\n\n<Fragments fragments={{js: js0}} />",
    "meta": {
      "title": "TypeScript strict mode - JavaScript",
      "description": "Typescript Strict Mode  - JavaScript",
      "subcategory": "Troubleshooting",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/troubleshooting/strict-mode/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Upgrading Amplify packages  `,\n  description: `Upgrading Amplify packages `,\n};\n\nimport js0 from \"/src/fragments/lib/troubleshooting/js/upgrading.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport flutter1 from \"/src/fragments/lib/troubleshooting/flutter/upgrading.mdx\";\n\n<Fragments fragments={{flutter: flutter1}} />",
    "meta": {
      "title": "Upgrading Amplify packages - JavaScript",
      "description": "Upgrading Amplify packages  - JavaScript",
      "subcategory": "Troubleshooting",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/troubleshooting/upgrading/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Upgrading Amplify packages  `,\n  description: `Upgrading Amplify packages `,\n};\n\nimport js0 from \"/src/fragments/lib/troubleshooting/js/upgrading.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport flutter1 from \"/src/fragments/lib/troubleshooting/flutter/upgrading.mdx\";\n\n<Fragments fragments={{flutter: flutter1}} />",
    "meta": {
      "title": "Upgrading Amplify packages - Flutter",
      "description": "Upgrading Amplify packages  - Flutter",
      "subcategory": "Troubleshooting",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/troubleshooting/upgrading/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting Started with Server-Side Rendering (SSR)`,\n  description: `Getting Started with Server-Side Rendering (SSR)`,\n};\n\nimport js0 from \"/src/fragments/lib/ssr/js/getting-started.mdx\";\n\n<Fragments fragments={{js: js0}} />",
    "meta": {
      "title": "Getting Started with Server-Side Rendering (SSR) - JavaScript",
      "description": "Getting Started with Server-Side Rendering (SSR) - JavaScript",
      "subcategory": "Server-Side Rendering",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/ssr/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Uninstalling the app`,\n  description: `Learn about the data that gets stored persistently on a device.`,\n};\n\nimport ios0 from \"/src/fragments/lib/info/native_common/app-uninstall/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n",
    "meta": {
      "title": "Uninstalling the app - iOS",
      "description": "Learn about the data that gets stored persistently on a device. - iOS",
      "subcategory": "Info",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/info/app-uninstall/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Data Information`,\n  description: `Information regarding the data collected by the library`,\n};\n\nimport ios0 from \"/src/fragments/lib/info/native_common/data-information/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport ios1 from \"/src/fragments/lib/info/native_common/app-uninstall/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n",
    "meta": {
      "title": "Data Information - iOS",
      "description": "Information regarding the data collected by the library - iOS",
      "subcategory": "Info",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/info/overview/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Developer Menu`,\n  description: `Amplify developer menu helps you quickly file GitHub issues with critical information (environment and device information) automatically added to the issue description. Learn how to setup, activate, and use the developer menu.`,\n};\n\nimport ios0 from \"/src/fragments/lib/debugging/native_common/dev-menu/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/debugging/native_common/dev-menu/common.mdx\";\n\n<Fragments fragments={{android: android1}} />",
    "meta": {
      "title": "Developer Menu - iOS",
      "description": "Amplify developer menu helps you quickly file GitHub issues with critical information (environment and device information) automatically added to the issue description. Learn how to setup, activate, and use the developer menu. - iOS",
      "subcategory": "Debugging",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/debugging/dev-menu/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Developer Menu`,\n  description: `Amplify developer menu helps you quickly file GitHub issues with critical information (environment and device information) automatically added to the issue description. Learn how to setup, activate, and use the developer menu.`,\n};\n\nimport ios0 from \"/src/fragments/lib/debugging/native_common/dev-menu/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/debugging/native_common/dev-menu/common.mdx\";\n\n<Fragments fragments={{android: android1}} />",
    "meta": {
      "title": "Developer Menu - Android",
      "description": "Amplify developer menu helps you quickly file GitHub issues with critical information (environment and device information) automatically added to the issue description. Learn how to setup, activate, and use the developer menu. - Android",
      "subcategory": "Debugging",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/debugging/dev-menu/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Configuring Amplify Categories`,\n  description: `Configuring the client `,\n};\n\nimport js0 from \"/src/fragments/lib/client-configuration/js/js-configuration.mdx\";\n\n<Fragments fragments={{js: js0}} />",
    "meta": {
      "title": "Configuring Amplify Categories - JavaScript",
      "description": "Configuring the client  - JavaScript",
      "subcategory": "Client configuration",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/client-configuration/configuring-amplify-categories/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Logger`,\n  description: `AWS Amplify writes console logs through Logger. You can use Logger in your apps for the same purpose.`,\n};\n\nimport js0 from \"/src/fragments/lib/utilities/logger.mdx\";\n\n<Fragments fragments={{js: js0}} />",
    "meta": {
      "title": "Logger - JavaScript",
      "description": "AWS Amplify writes console logs through Logger. You can use Logger in your apps for the same purpose. - JavaScript",
      "subcategory": "Utilities",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/utilities/logger/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Internationalization`,\n  description: `The AWS Amplify I18n module is a lightweight internationalization solution.`,\n};\n\nimport js0 from \"/src/fragments/lib/utilities/i18n.mdx\";\n\n<Fragments fragments={{js: js0}} />",
    "meta": {
      "title": "Internationalization - JavaScript",
      "description": "The AWS Amplify I18n module is a lightweight internationalization solution. - JavaScript",
      "subcategory": "Utilities",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/utilities/i18n/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Hub`,\n  description: `Amplify has a local eventing system called Hub. It is a lightweight implementation of Publisher-Subscriber pattern, and is used to share data between modules and components in your app. `,\n};\n\nimport js0 from \"/src/fragments/lib/utilities/js/hub.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport android1 from \"/src/fragments/lib/utilities/native_common/hub/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport ios2 from \"/src/fragments/lib/utilities/native_common/hub/common.mdx\";\n\n<Fragments fragments={{ios: ios2}} />\n",
    "meta": {
      "title": "Hub - JavaScript",
      "description": "Amplify has a local eventing system called Hub. It is a lightweight implementation of Publisher-Subscriber pattern, and is used to share data between modules and components in your app.  - JavaScript",
      "subcategory": "Utilities",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/utilities/hub/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Hub`,\n  description: `Amplify has a local eventing system called Hub. It is a lightweight implementation of Publisher-Subscriber pattern, and is used to share data between modules and components in your app. `,\n};\n\nimport js0 from \"/src/fragments/lib/utilities/js/hub.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport android1 from \"/src/fragments/lib/utilities/native_common/hub/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport ios2 from \"/src/fragments/lib/utilities/native_common/hub/common.mdx\";\n\n<Fragments fragments={{ios: ios2}} />\n",
    "meta": {
      "title": "Hub - iOS",
      "description": "Amplify has a local eventing system called Hub. It is a lightweight implementation of Publisher-Subscriber pattern, and is used to share data between modules and components in your app.  - iOS",
      "subcategory": "Utilities",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/utilities/hub/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Hub`,\n  description: `Amplify has a local eventing system called Hub. It is a lightweight implementation of Publisher-Subscriber pattern, and is used to share data between modules and components in your app. `,\n};\n\nimport js0 from \"/src/fragments/lib/utilities/js/hub.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport android1 from \"/src/fragments/lib/utilities/native_common/hub/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport ios2 from \"/src/fragments/lib/utilities/native_common/hub/common.mdx\";\n\n<Fragments fragments={{ios: ios2}} />\n",
    "meta": {
      "title": "Hub - Android",
      "description": "Amplify has a local eventing system called Hub. It is a lightweight implementation of Publisher-Subscriber pattern, and is used to share data between modules and components in your app.  - Android",
      "subcategory": "Utilities",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/utilities/hub/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Cache`,\n  description: `The Amplify Cache module provides a generic LRU cache for JavaScript developers to store data with priority and expiration settings.`,\n};\n\nimport js0 from \"/src/fragments/lib/utilities/cache.mdx\";\n\n<Fragments fragments={{js: js0}} />",
    "meta": {
      "title": "Cache - JavaScript",
      "description": "The Amplify Cache module provides a generic LRU cache for JavaScript developers to store data with priority and expiration settings. - JavaScript",
      "subcategory": "Utilities",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/utilities/cache/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Service Worker`,\n  description: `AWS Amplify ServiceWorker class enables registering a service worker in the browser and communicating with it via postMessage events, so that you can create rich offline experiences with Push APIs and analytics.`,\n};\n\nimport js0 from \"/src/fragments/lib/utilities/serviceworker.mdx\";\n\n<Fragments fragments={{js: js0}} />",
    "meta": {
      "title": "Service Worker - JavaScript",
      "description": "AWS Amplify ServiceWorker class enables registering a service worker in the browser and communicating with it via postMessage events, so that you can create rich offline experiences with Push APIs and analytics. - JavaScript",
      "subcategory": "Utilities",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/utilities/serviceworker/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Scene API`,\n  description: `Learn more about the Scene API in the XR category of Amplify`,\n};\n\nimport js0 from \"/src/fragments/lib/xr/sceneapi.mdx\";\n\n<Fragments fragments={{js: js0}} />",
    "meta": {
      "title": "Scene API - JavaScript",
      "description": "Learn more about the Scene API in the XR category of Amplify - JavaScript",
      "subcategory": "XR",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/xr/sceneapi/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `Get started with XR category in Amplify`,\n};\n\nimport js0 from \"/src/fragments/lib/xr/getting-started.mdx\";\n\n<Fragments fragments={{js: js0}} />",
    "meta": {
      "title": "Getting started - JavaScript",
      "description": "Get started with XR category in Amplify - JavaScript",
      "subcategory": "XR",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/xr/getting-started/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Use existing AWS resources`,\n  description: `Configure the Amplify Libraries to use an existing Amazon S3 bucket by referencing it in your configuration.`,\n};\n\nimport android0 from \"/src/fragments/lib/storage/existing-resources.mdx\";\n\n<Fragments fragments={{android: android0}} />\n\nimport ios1 from \"/src/fragments/lib/storage/existing-resources.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport flutter2 from \"/src/fragments/lib/storage/existing-resources.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />",
    "meta": {
      "title": "Use existing AWS resources - Flutter",
      "description": "Configure the Amplify Libraries to use an existing Amazon S3 bucket by referencing it in your configuration. - Flutter",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/existing-resources/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Use existing AWS resources`,\n  description: `Configure the Amplify Libraries to use an existing Amazon S3 bucket by referencing it in your configuration.`,\n};\n\nimport android0 from \"/src/fragments/lib/storage/existing-resources.mdx\";\n\n<Fragments fragments={{android: android0}} />\n\nimport ios1 from \"/src/fragments/lib/storage/existing-resources.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport flutter2 from \"/src/fragments/lib/storage/existing-resources.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />",
    "meta": {
      "title": "Use existing AWS resources - iOS",
      "description": "Configure the Amplify Libraries to use an existing Amazon S3 bucket by referencing it in your configuration. - iOS",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/existing-resources/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Use existing AWS resources`,\n  description: `Configure the Amplify Libraries to use an existing Amazon S3 bucket by referencing it in your configuration.`,\n};\n\nimport android0 from \"/src/fragments/lib/storage/existing-resources.mdx\";\n\n<Fragments fragments={{android: android0}} />\n\nimport ios1 from \"/src/fragments/lib/storage/existing-resources.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport flutter2 from \"/src/fragments/lib/storage/existing-resources.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />",
    "meta": {
      "title": "Use existing AWS resources - Android",
      "description": "Configure the Amplify Libraries to use an existing Amazon S3 bucket by referencing it in your configuration. - Android",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/existing-resources/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Escape hatch`,\n  description: `For specialized use cases where Amplify does not provide the functionality, you can use the escape hatch to access an AWSS3 low-level client instance. The returned AWSS3 instance is already configured with your access credentials.`,\n};\n\nimport ios0 from \"/src/fragments/lib/storage/ios/escapehatch.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/storage/android/escapehatch.mdx\";\n\n<Fragments fragments={{android: android1}} />\n",
    "meta": {
      "title": "Escape hatch - iOS",
      "description": "For specialized use cases where Amplify does not provide the functionality, you can use the escape hatch to access an AWSS3 low-level client instance. The returned AWSS3 instance is already configured with your access credentials. - iOS",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/escapehatch/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Escape hatch`,\n  description: `For specialized use cases where Amplify does not provide the functionality, you can use the escape hatch to access an AWSS3 low-level client instance. The returned AWSS3 instance is already configured with your access credentials.`,\n};\n\nimport ios0 from \"/src/fragments/lib/storage/ios/escapehatch.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/storage/android/escapehatch.mdx\";\n\n<Fragments fragments={{android: android1}} />\n",
    "meta": {
      "title": "Escape hatch - Android",
      "description": "For specialized use cases where Amplify does not provide the functionality, you can use the escape hatch to access an AWSS3 low-level client instance. The returned AWSS3 instance is already configured with your access credentials. - Android",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/escapehatch/q/platform/android"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "If you are looking to enable triggers for the Storage Category with Amazon S3 & Amazon DynamoDB as Providers, the CLI supports associating Lambda triggers with S3 and DynamoDB events. For example, this can be useful for a use case where you want to invoke a Lambda function after a create or update operation on a DynamoDB table managed by the Amplify CLI."
      },
      {
        "heading": null,
        "depth": null,
        "text": "For more information on this topic, please read on File Storage Lambda Triggers through our Amplify CLI documentation."
      }
    ],
    "source": "export const meta = {\n  title: `Lambda triggers`,\n  description: `Learn more about how to enable triggers for the Storage Category with Amazon S3 & Amazon DynamoDB as Providers. The CLI supports associating Lambda triggers with S3 and DynamoDB events. `,\n};\n\nIf you are looking to enable triggers for the Storage Category with Amazon S3 & Amazon DynamoDB as Providers, the CLI supports associating Lambda triggers with S3 and DynamoDB events. For example, this can be useful for a use case where you want to invoke a Lambda function after a create or update operation on a DynamoDB table managed by the Amplify CLI. \n\nFor more information on this topic, please read on [File Storage Lambda Triggers](/cli/usage/lambda-triggers#s3-lambda-triggers) through our Amplify CLI documentation.",
    "meta": {
      "title": "Lambda triggers - JavaScript",
      "description": "Learn more about how to enable triggers for the Storage Category with Amazon S3 & Amazon DynamoDB as Providers. The CLI supports associating Lambda triggers with S3 and DynamoDB events.  - JavaScript",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/triggers/q/platform/js"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "If you are looking to enable triggers for the Storage Category with Amazon S3 & Amazon DynamoDB as Providers, the CLI supports associating Lambda triggers with S3 and DynamoDB events. For example, this can be useful for a use case where you want to invoke a Lambda function after a create or update operation on a DynamoDB table managed by the Amplify CLI."
      },
      {
        "heading": null,
        "depth": null,
        "text": "For more information on this topic, please read on File Storage Lambda Triggers through our Amplify CLI documentation."
      }
    ],
    "source": "export const meta = {\n  title: `Lambda triggers`,\n  description: `Learn more about how to enable triggers for the Storage Category with Amazon S3 & Amazon DynamoDB as Providers. The CLI supports associating Lambda triggers with S3 and DynamoDB events. `,\n};\n\nIf you are looking to enable triggers for the Storage Category with Amazon S3 & Amazon DynamoDB as Providers, the CLI supports associating Lambda triggers with S3 and DynamoDB events. For example, this can be useful for a use case where you want to invoke a Lambda function after a create or update operation on a DynamoDB table managed by the Amplify CLI. \n\nFor more information on this topic, please read on [File Storage Lambda Triggers](/cli/usage/lambda-triggers#s3-lambda-triggers) through our Amplify CLI documentation.",
    "meta": {
      "title": "Lambda triggers - Flutter",
      "description": "Learn more about how to enable triggers for the Storage Category with Amazon S3 & Amazon DynamoDB as Providers. The CLI supports associating Lambda triggers with S3 and DynamoDB events.  - Flutter",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/triggers/q/platform/flutter"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "If you are looking to enable triggers for the Storage Category with Amazon S3 & Amazon DynamoDB as Providers, the CLI supports associating Lambda triggers with S3 and DynamoDB events. For example, this can be useful for a use case where you want to invoke a Lambda function after a create or update operation on a DynamoDB table managed by the Amplify CLI."
      },
      {
        "heading": null,
        "depth": null,
        "text": "For more information on this topic, please read on File Storage Lambda Triggers through our Amplify CLI documentation."
      }
    ],
    "source": "export const meta = {\n  title: `Lambda triggers`,\n  description: `Learn more about how to enable triggers for the Storage Category with Amazon S3 & Amazon DynamoDB as Providers. The CLI supports associating Lambda triggers with S3 and DynamoDB events. `,\n};\n\nIf you are looking to enable triggers for the Storage Category with Amazon S3 & Amazon DynamoDB as Providers, the CLI supports associating Lambda triggers with S3 and DynamoDB events. For example, this can be useful for a use case where you want to invoke a Lambda function after a create or update operation on a DynamoDB table managed by the Amplify CLI. \n\nFor more information on this topic, please read on [File Storage Lambda Triggers](/cli/usage/lambda-triggers#s3-lambda-triggers) through our Amplify CLI documentation.",
    "meta": {
      "title": "Lambda triggers - iOS",
      "description": "Learn more about how to enable triggers for the Storage Category with Amazon S3 & Amazon DynamoDB as Providers. The CLI supports associating Lambda triggers with S3 and DynamoDB events.  - iOS",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/triggers/q/platform/ios"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "If you are looking to enable triggers for the Storage Category with Amazon S3 & Amazon DynamoDB as Providers, the CLI supports associating Lambda triggers with S3 and DynamoDB events. For example, this can be useful for a use case where you want to invoke a Lambda function after a create or update operation on a DynamoDB table managed by the Amplify CLI."
      },
      {
        "heading": null,
        "depth": null,
        "text": "For more information on this topic, please read on File Storage Lambda Triggers through our Amplify CLI documentation."
      }
    ],
    "source": "export const meta = {\n  title: `Lambda triggers`,\n  description: `Learn more about how to enable triggers for the Storage Category with Amazon S3 & Amazon DynamoDB as Providers. The CLI supports associating Lambda triggers with S3 and DynamoDB events. `,\n};\n\nIf you are looking to enable triggers for the Storage Category with Amazon S3 & Amazon DynamoDB as Providers, the CLI supports associating Lambda triggers with S3 and DynamoDB events. For example, this can be useful for a use case where you want to invoke a Lambda function after a create or update operation on a DynamoDB table managed by the Amplify CLI. \n\nFor more information on this topic, please read on [File Storage Lambda Triggers](/cli/usage/lambda-triggers#s3-lambda-triggers) through our Amplify CLI documentation.",
    "meta": {
      "title": "Lambda triggers - Android",
      "description": "Learn more about how to enable triggers for the Storage Category with Amazon S3 & Amazon DynamoDB as Providers. The CLI supports associating Lambda triggers with S3 and DynamoDB events.  - Android",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/triggers/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Automatically track events`,\n  description: `You can enable automatic tracking of Storage Events such as uploads and downloads. Enabling this will automatically send Storage Events to Amazon Pinpoint and you will be able to see them within the AWS Pinpoint Console under Custom Events. `,\n};\n\nimport js0 from \"/src/fragments/lib/storage/js/autotrack.mdx\";\n\n<Fragments fragments={{js: js0}} />",
    "meta": {
      "title": "Automatically track events - JavaScript",
      "description": "You can enable automatic tracking of Storage Events such as uploads and downloads. Enabling this will automatically send Storage Events to Amazon Pinpoint and you will be able to see them within the AWS Pinpoint Console under Custom Events.  - JavaScript",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/autotrack/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `File access levels`,\n  description: `Learn about configuring different access levels in Amplify Storage. Objects can be public, protected, or private.`,\n};\n\nimport js0 from \"/src/fragments/lib/storage/js/configureaccess.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/storage/native_common/configureaccess/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/storage/native_common/configureaccess/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/storage/native_common/configureaccess/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "File access levels - JavaScript",
      "description": "Learn about configuring different access levels in Amplify Storage. Objects can be public, protected, or private. - JavaScript",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/configureaccess/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `File access levels`,\n  description: `Learn about configuring different access levels in Amplify Storage. Objects can be public, protected, or private.`,\n};\n\nimport js0 from \"/src/fragments/lib/storage/js/configureaccess.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/storage/native_common/configureaccess/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/storage/native_common/configureaccess/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/storage/native_common/configureaccess/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "File access levels - Flutter",
      "description": "Learn about configuring different access levels in Amplify Storage. Objects can be public, protected, or private. - Flutter",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/configureaccess/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `File access levels`,\n  description: `Learn about configuring different access levels in Amplify Storage. Objects can be public, protected, or private.`,\n};\n\nimport js0 from \"/src/fragments/lib/storage/js/configureaccess.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/storage/native_common/configureaccess/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/storage/native_common/configureaccess/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/storage/native_common/configureaccess/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "File access levels - iOS",
      "description": "Learn about configuring different access levels in Amplify Storage. Objects can be public, protected, or private. - iOS",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/configureaccess/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `File access levels`,\n  description: `Learn about configuring different access levels in Amplify Storage. Objects can be public, protected, or private.`,\n};\n\nimport js0 from \"/src/fragments/lib/storage/js/configureaccess.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/storage/native_common/configureaccess/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/storage/native_common/configureaccess/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/storage/native_common/configureaccess/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "File access levels - Android",
      "description": "Learn about configuring different access levels in Amplify Storage. Objects can be public, protected, or private. - Android",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/configureaccess/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Cancel requests`,\n  description: `Cancel an in-flight get or put requests from Storage`,\n};\n\nimport js0 from \"/src/fragments/lib/storage/js/cancel-requests.mdx\";\n\n<Fragments fragments={{js: js0}} />\n",
    "meta": {
      "title": "Cancel requests - JavaScript",
      "description": "Cancel an in-flight get or put requests from Storage - JavaScript",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/cancel-requests/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Remove files`,\n  description: `Learn more about how to remove files using Amplify Framework's storage category`,\n};\n\nimport js0 from \"/src/fragments/lib/storage/js/remove.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/storage/ios/remove.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/storage/android/remove.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/storage/flutter/remove.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Remove files - JavaScript",
      "description": "Learn more about how to remove files using Amplify Framework's storage category - JavaScript",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/remove/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Remove files`,\n  description: `Learn more about how to remove files using Amplify Framework's storage category`,\n};\n\nimport js0 from \"/src/fragments/lib/storage/js/remove.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/storage/ios/remove.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/storage/android/remove.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/storage/flutter/remove.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Remove files - Flutter",
      "description": "Learn more about how to remove files using Amplify Framework's storage category - Flutter",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/remove/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Remove files`,\n  description: `Learn more about how to remove files using Amplify Framework's storage category`,\n};\n\nimport js0 from \"/src/fragments/lib/storage/js/remove.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/storage/ios/remove.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/storage/android/remove.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/storage/flutter/remove.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Remove files - iOS",
      "description": "Learn more about how to remove files using Amplify Framework's storage category - iOS",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/remove/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Remove files`,\n  description: `Learn more about how to remove files using Amplify Framework's storage category`,\n};\n\nimport js0 from \"/src/fragments/lib/storage/js/remove.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/storage/ios/remove.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/storage/android/remove.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/storage/flutter/remove.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Remove files - Android",
      "description": "Learn more about how to remove files using Amplify Framework's storage category - Android",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/remove/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Copy files`,\n  description: `Learn more about how to copy files using Amplify Framework's storage category.`,\n};\n\nimport js0 from \"/src/fragments/lib/storage/js/copy.mdx\";\n\n<Fragments fragments={{js: js0}} />\n",
    "meta": {
      "title": "Copy files - JavaScript",
      "description": "Learn more about how to copy files using Amplify Framework's storage category. - JavaScript",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/copy/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `List files`,\n  description: `Learn more about how to list all of the uploaded objects using Amplify Framework's storage category.`,\n};\n\nimport js0 from \"/src/fragments/lib/storage/js/list.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/storage/ios/list.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/storage/android/list.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/storage/flutter/list.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "List files - JavaScript",
      "description": "Learn more about how to list all of the uploaded objects using Amplify Framework's storage category. - JavaScript",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/list/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `List files`,\n  description: `Learn more about how to list all of the uploaded objects using Amplify Framework's storage category.`,\n};\n\nimport js0 from \"/src/fragments/lib/storage/js/list.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/storage/ios/list.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/storage/android/list.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/storage/flutter/list.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "List files - Flutter",
      "description": "Learn more about how to list all of the uploaded objects using Amplify Framework's storage category. - Flutter",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/list/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `List files`,\n  description: `Learn more about how to list all of the uploaded objects using Amplify Framework's storage category.`,\n};\n\nimport js0 from \"/src/fragments/lib/storage/js/list.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/storage/ios/list.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/storage/android/list.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/storage/flutter/list.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "List files - iOS",
      "description": "Learn more about how to list all of the uploaded objects using Amplify Framework's storage category. - iOS",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/list/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `List files`,\n  description: `Learn more about how to list all of the uploaded objects using Amplify Framework's storage category.`,\n};\n\nimport js0 from \"/src/fragments/lib/storage/js/list.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/storage/ios/list.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/storage/android/list.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/storage/flutter/list.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "List files - Android",
      "description": "Learn more about how to list all of the uploaded objects using Amplify Framework's storage category. - Android",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/list/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Download files`,\n  description: `Learn more about how to download / retrieve files using the Storage category of Amplify Framework`,\n};\n\nimport js0 from \"/src/fragments/lib/storage/js/download.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/storage/ios/download.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/storage/android/download.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/storage/flutter/download.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Download files - JavaScript",
      "description": "Learn more about how to download / retrieve files using the Storage category of Amplify Framework - JavaScript",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/download/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Download files`,\n  description: `Learn more about how to download / retrieve files using the Storage category of Amplify Framework`,\n};\n\nimport js0 from \"/src/fragments/lib/storage/js/download.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/storage/ios/download.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/storage/android/download.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/storage/flutter/download.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Download files - Flutter",
      "description": "Learn more about how to download / retrieve files using the Storage category of Amplify Framework - Flutter",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/download/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Download files`,\n  description: `Learn more about how to download / retrieve files using the Storage category of Amplify Framework`,\n};\n\nimport js0 from \"/src/fragments/lib/storage/js/download.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/storage/ios/download.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/storage/android/download.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/storage/flutter/download.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Download files - iOS",
      "description": "Learn more about how to download / retrieve files using the Storage category of Amplify Framework - iOS",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/download/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Download files`,\n  description: `Learn more about how to download / retrieve files using the Storage category of Amplify Framework`,\n};\n\nimport js0 from \"/src/fragments/lib/storage/js/download.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/storage/ios/download.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/storage/android/download.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/storage/flutter/download.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Download files - Android",
      "description": "Learn more about how to download / retrieve files using the Storage category of Amplify Framework - Android",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/download/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Upload files`,\n  description: `Learn more about how to upload files using Amplify Framework's storage category`,\n};\n\nimport js0 from \"/src/fragments/lib/storage/js/upload.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/storage/ios/upload.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/storage/android/upload.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/storage/flutter/upload.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Upload files - JavaScript",
      "description": "Learn more about how to upload files using Amplify Framework's storage category - JavaScript",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/upload/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Upload files`,\n  description: `Learn more about how to upload files using Amplify Framework's storage category`,\n};\n\nimport js0 from \"/src/fragments/lib/storage/js/upload.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/storage/ios/upload.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/storage/android/upload.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/storage/flutter/upload.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Upload files - Flutter",
      "description": "Learn more about how to upload files using Amplify Framework's storage category - Flutter",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/upload/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Upload files`,\n  description: `Learn more about how to upload files using Amplify Framework's storage category`,\n};\n\nimport js0 from \"/src/fragments/lib/storage/js/upload.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/storage/ios/upload.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/storage/android/upload.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/storage/flutter/upload.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Upload files - iOS",
      "description": "Learn more about how to upload files using Amplify Framework's storage category - iOS",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/upload/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Upload files`,\n  description: `Learn more about how to upload files using Amplify Framework's storage category`,\n};\n\nimport js0 from \"/src/fragments/lib/storage/js/upload.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/storage/ios/upload.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/storage/android/upload.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/storage/flutter/upload.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Upload files - Android",
      "description": "Learn more about how to upload files using Amplify Framework's storage category - Android",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/upload/q/platform/android"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "AWS Amplify storage module provides a simple mechanism for managing user content for your app in public, protected or private storage buckets. The storage category comes with built-in support for Amazon S3 (Simple Storage Service)."
      },
      {
        "heading": null,
        "depth": null,
        "text": ""
      },
      {
        "heading": "S3 Core Concepts",
        "depth": 2,
        "text": "Amazon S3 stores data as objects within container buckets. An object consists of a file and optionally any metadata that describes that file. To store an object in Amazon S3, you upload the file you want to store to a bucket. When you upload a file, you can set permissions on the object and any metadata."
      },
      {
        "heading": "S3 Core Concepts",
        "depth": 2,
        "text": "Buckets are the containers for objects. You can have one or more buckets. For each bucket, you can control access to it (who can create, delete, and list objects in the bucket), view access logs for it and its objects, and choose the geographical region where Amazon S3 will store the bucket and its contents."
      },
      {
        "heading": "Accessing AWS services",
        "depth": 2,
        "text": "With storage, it's important to understand user-level access to storage assets. While Amplify helps with abstraction with provisioning your S3 buckets, it is important to understand the right level of control for your customers."
      },
      {
        "heading": "Accessing AWS services",
        "depth": 2,
        "text": "When you run amplify add storage, the CLI will configure appropriate IAM policies on the bucket using a Cognito Identity Pool Role. You will have the option of adding CRUD (Create, Update, Read and Delete) based permissions as well, so that Authenticated and Guest users will be granted limited permissions within these levels."
      }
    ],
    "source": "export const meta = {\n  title: `Concepts`,\n  description: `Learn more about the foundational storage concepts for cloud-based application and how they work with Amplify Framework.`,\n};\n\nAWS Amplify storage module provides a simple mechanism for managing user content for your app in public, protected or private storage buckets. The storage category comes with built-in support for [Amazon S3 (Simple Storage Service)](https://docs.aws.amazon.com/AmazonS3/latest/dev/Welcome.html). \n\n![Image](/images/s3_overview.jpg)\n\n## S3 Core Concepts \n\nAmazon S3 stores data as objects within container buckets. An object consists of a file and optionally any metadata that describes that file. To store an object in Amazon S3, you upload the file you want to store to a bucket. When you upload a file, you can set permissions on the object and any metadata.\n\nBuckets are the containers for objects. You can have one or more buckets. For each bucket, you can control access to it (who can create, delete, and list objects in the bucket), view access logs for it and its objects, and choose the geographical region where Amazon S3 will store the bucket and its contents.\n\n## Accessing AWS services\n\nWith storage, it's important to understand user-level access to storage assets. While Amplify helps with abstraction with provisioning your S3 buckets, it is important to understand the right level of control for your customers.\n\nWhen you run `amplify add storage`, the CLI will configure appropriate IAM policies on the bucket using a Cognito Identity Pool Role. You will have the option of adding CRUD (Create, Update, Read and Delete) based permissions as well, so that Authenticated and Guest users will be granted limited permissions within these levels.\n",
    "meta": {
      "title": "Concepts - JavaScript",
      "description": "Learn more about the foundational storage concepts for cloud-based application and how they work with Amplify Framework. - JavaScript",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/overview/q/platform/js"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "AWS Amplify storage module provides a simple mechanism for managing user content for your app in public, protected or private storage buckets. The storage category comes with built-in support for Amazon S3 (Simple Storage Service)."
      },
      {
        "heading": null,
        "depth": null,
        "text": ""
      },
      {
        "heading": "S3 Core Concepts",
        "depth": 2,
        "text": "Amazon S3 stores data as objects within container buckets. An object consists of a file and optionally any metadata that describes that file. To store an object in Amazon S3, you upload the file you want to store to a bucket. When you upload a file, you can set permissions on the object and any metadata."
      },
      {
        "heading": "S3 Core Concepts",
        "depth": 2,
        "text": "Buckets are the containers for objects. You can have one or more buckets. For each bucket, you can control access to it (who can create, delete, and list objects in the bucket), view access logs for it and its objects, and choose the geographical region where Amazon S3 will store the bucket and its contents."
      },
      {
        "heading": "Accessing AWS services",
        "depth": 2,
        "text": "With storage, it's important to understand user-level access to storage assets. While Amplify helps with abstraction with provisioning your S3 buckets, it is important to understand the right level of control for your customers."
      },
      {
        "heading": "Accessing AWS services",
        "depth": 2,
        "text": "When you run amplify add storage, the CLI will configure appropriate IAM policies on the bucket using a Cognito Identity Pool Role. You will have the option of adding CRUD (Create, Update, Read and Delete) based permissions as well, so that Authenticated and Guest users will be granted limited permissions within these levels."
      }
    ],
    "source": "export const meta = {\n  title: `Concepts`,\n  description: `Learn more about the foundational storage concepts for cloud-based application and how they work with Amplify Framework.`,\n};\n\nAWS Amplify storage module provides a simple mechanism for managing user content for your app in public, protected or private storage buckets. The storage category comes with built-in support for [Amazon S3 (Simple Storage Service)](https://docs.aws.amazon.com/AmazonS3/latest/dev/Welcome.html). \n\n![Image](/images/s3_overview.jpg)\n\n## S3 Core Concepts \n\nAmazon S3 stores data as objects within container buckets. An object consists of a file and optionally any metadata that describes that file. To store an object in Amazon S3, you upload the file you want to store to a bucket. When you upload a file, you can set permissions on the object and any metadata.\n\nBuckets are the containers for objects. You can have one or more buckets. For each bucket, you can control access to it (who can create, delete, and list objects in the bucket), view access logs for it and its objects, and choose the geographical region where Amazon S3 will store the bucket and its contents.\n\n## Accessing AWS services\n\nWith storage, it's important to understand user-level access to storage assets. While Amplify helps with abstraction with provisioning your S3 buckets, it is important to understand the right level of control for your customers.\n\nWhen you run `amplify add storage`, the CLI will configure appropriate IAM policies on the bucket using a Cognito Identity Pool Role. You will have the option of adding CRUD (Create, Update, Read and Delete) based permissions as well, so that Authenticated and Guest users will be granted limited permissions within these levels.\n",
    "meta": {
      "title": "Concepts - Flutter",
      "description": "Learn more about the foundational storage concepts for cloud-based application and how they work with Amplify Framework. - Flutter",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/overview/q/platform/flutter"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "AWS Amplify storage module provides a simple mechanism for managing user content for your app in public, protected or private storage buckets. The storage category comes with built-in support for Amazon S3 (Simple Storage Service)."
      },
      {
        "heading": null,
        "depth": null,
        "text": ""
      },
      {
        "heading": "S3 Core Concepts",
        "depth": 2,
        "text": "Amazon S3 stores data as objects within container buckets. An object consists of a file and optionally any metadata that describes that file. To store an object in Amazon S3, you upload the file you want to store to a bucket. When you upload a file, you can set permissions on the object and any metadata."
      },
      {
        "heading": "S3 Core Concepts",
        "depth": 2,
        "text": "Buckets are the containers for objects. You can have one or more buckets. For each bucket, you can control access to it (who can create, delete, and list objects in the bucket), view access logs for it and its objects, and choose the geographical region where Amazon S3 will store the bucket and its contents."
      },
      {
        "heading": "Accessing AWS services",
        "depth": 2,
        "text": "With storage, it's important to understand user-level access to storage assets. While Amplify helps with abstraction with provisioning your S3 buckets, it is important to understand the right level of control for your customers."
      },
      {
        "heading": "Accessing AWS services",
        "depth": 2,
        "text": "When you run amplify add storage, the CLI will configure appropriate IAM policies on the bucket using a Cognito Identity Pool Role. You will have the option of adding CRUD (Create, Update, Read and Delete) based permissions as well, so that Authenticated and Guest users will be granted limited permissions within these levels."
      }
    ],
    "source": "export const meta = {\n  title: `Concepts`,\n  description: `Learn more about the foundational storage concepts for cloud-based application and how they work with Amplify Framework.`,\n};\n\nAWS Amplify storage module provides a simple mechanism for managing user content for your app in public, protected or private storage buckets. The storage category comes with built-in support for [Amazon S3 (Simple Storage Service)](https://docs.aws.amazon.com/AmazonS3/latest/dev/Welcome.html). \n\n![Image](/images/s3_overview.jpg)\n\n## S3 Core Concepts \n\nAmazon S3 stores data as objects within container buckets. An object consists of a file and optionally any metadata that describes that file. To store an object in Amazon S3, you upload the file you want to store to a bucket. When you upload a file, you can set permissions on the object and any metadata.\n\nBuckets are the containers for objects. You can have one or more buckets. For each bucket, you can control access to it (who can create, delete, and list objects in the bucket), view access logs for it and its objects, and choose the geographical region where Amazon S3 will store the bucket and its contents.\n\n## Accessing AWS services\n\nWith storage, it's important to understand user-level access to storage assets. While Amplify helps with abstraction with provisioning your S3 buckets, it is important to understand the right level of control for your customers.\n\nWhen you run `amplify add storage`, the CLI will configure appropriate IAM policies on the bucket using a Cognito Identity Pool Role. You will have the option of adding CRUD (Create, Update, Read and Delete) based permissions as well, so that Authenticated and Guest users will be granted limited permissions within these levels.\n",
    "meta": {
      "title": "Concepts - iOS",
      "description": "Learn more about the foundational storage concepts for cloud-based application and how they work with Amplify Framework. - iOS",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/overview/q/platform/ios"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "AWS Amplify storage module provides a simple mechanism for managing user content for your app in public, protected or private storage buckets. The storage category comes with built-in support for Amazon S3 (Simple Storage Service)."
      },
      {
        "heading": null,
        "depth": null,
        "text": ""
      },
      {
        "heading": "S3 Core Concepts",
        "depth": 2,
        "text": "Amazon S3 stores data as objects within container buckets. An object consists of a file and optionally any metadata that describes that file. To store an object in Amazon S3, you upload the file you want to store to a bucket. When you upload a file, you can set permissions on the object and any metadata."
      },
      {
        "heading": "S3 Core Concepts",
        "depth": 2,
        "text": "Buckets are the containers for objects. You can have one or more buckets. For each bucket, you can control access to it (who can create, delete, and list objects in the bucket), view access logs for it and its objects, and choose the geographical region where Amazon S3 will store the bucket and its contents."
      },
      {
        "heading": "Accessing AWS services",
        "depth": 2,
        "text": "With storage, it's important to understand user-level access to storage assets. While Amplify helps with abstraction with provisioning your S3 buckets, it is important to understand the right level of control for your customers."
      },
      {
        "heading": "Accessing AWS services",
        "depth": 2,
        "text": "When you run amplify add storage, the CLI will configure appropriate IAM policies on the bucket using a Cognito Identity Pool Role. You will have the option of adding CRUD (Create, Update, Read and Delete) based permissions as well, so that Authenticated and Guest users will be granted limited permissions within these levels."
      }
    ],
    "source": "export const meta = {\n  title: `Concepts`,\n  description: `Learn more about the foundational storage concepts for cloud-based application and how they work with Amplify Framework.`,\n};\n\nAWS Amplify storage module provides a simple mechanism for managing user content for your app in public, protected or private storage buckets. The storage category comes with built-in support for [Amazon S3 (Simple Storage Service)](https://docs.aws.amazon.com/AmazonS3/latest/dev/Welcome.html). \n\n![Image](/images/s3_overview.jpg)\n\n## S3 Core Concepts \n\nAmazon S3 stores data as objects within container buckets. An object consists of a file and optionally any metadata that describes that file. To store an object in Amazon S3, you upload the file you want to store to a bucket. When you upload a file, you can set permissions on the object and any metadata.\n\nBuckets are the containers for objects. You can have one or more buckets. For each bucket, you can control access to it (who can create, delete, and list objects in the bucket), view access logs for it and its objects, and choose the geographical region where Amazon S3 will store the bucket and its contents.\n\n## Accessing AWS services\n\nWith storage, it's important to understand user-level access to storage assets. While Amplify helps with abstraction with provisioning your S3 buckets, it is important to understand the right level of control for your customers.\n\nWhen you run `amplify add storage`, the CLI will configure appropriate IAM policies on the bucket using a Cognito Identity Pool Role. You will have the option of adding CRUD (Create, Update, Read and Delete) based permissions as well, so that Authenticated and Guest users will be granted limited permissions within these levels.\n",
    "meta": {
      "title": "Concepts - Android",
      "description": "Learn more about the foundational storage concepts for cloud-based application and how they work with Amplify Framework. - Android",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/overview/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `The Amplify Storage category provides a simple mechanism for managing user content for your app in public, protected, or private storage buckets. The Amplify AWS S3 Storage plugin leverages Amazon S3.`,\n};\n\nimport js0 from \"/src/fragments/lib/storage/js/getting-started.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/storage/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/storage/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/storage/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Getting started - JavaScript",
      "description": "The Amplify Storage category provides a simple mechanism for managing user content for your app in public, protected, or private storage buckets. The Amplify AWS S3 Storage plugin leverages Amazon S3. - JavaScript",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/getting-started/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `The Amplify Storage category provides a simple mechanism for managing user content for your app in public, protected, or private storage buckets. The Amplify AWS S3 Storage plugin leverages Amazon S3.`,\n};\n\nimport js0 from \"/src/fragments/lib/storage/js/getting-started.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/storage/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/storage/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/storage/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Getting started - Flutter",
      "description": "The Amplify Storage category provides a simple mechanism for managing user content for your app in public, protected, or private storage buckets. The Amplify AWS S3 Storage plugin leverages Amazon S3. - Flutter",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/getting-started/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `The Amplify Storage category provides a simple mechanism for managing user content for your app in public, protected, or private storage buckets. The Amplify AWS S3 Storage plugin leverages Amazon S3.`,\n};\n\nimport js0 from \"/src/fragments/lib/storage/js/getting-started.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/storage/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/storage/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/storage/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Getting started - iOS",
      "description": "The Amplify Storage category provides a simple mechanism for managing user content for your app in public, protected, or private storage buckets. The Amplify AWS S3 Storage plugin leverages Amazon S3. - iOS",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/getting-started/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `The Amplify Storage category provides a simple mechanism for managing user content for your app in public, protected, or private storage buckets. The Amplify AWS S3 Storage plugin leverages Amazon S3.`,\n};\n\nimport js0 from \"/src/fragments/lib/storage/js/getting-started.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/storage/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/storage/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/storage/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Getting started - Android",
      "description": "The Amplify Storage category provides a simple mechanism for managing user content for your app in public, protected, or private storage buckets. The Amplify AWS S3 Storage plugin leverages Amazon S3. - Android",
      "subcategory": "Storage",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/storage/getting-started/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Testing`,\n  description: `Overview of testing your Push Notifications`,\n};\n\nimport js0 from \"/src/fragments/lib/push-notifications/js/testing.mdx\";\nimport rn from \"/src/fragments/lib/push-notifications/js/reactnative.mdx\";\n\n<Fragments fragments={{js: rn}} />\n<Fragments fragments={{js: js0}} />\n",
    "meta": {
      "title": "Testing - JavaScript",
      "description": "Overview of testing your Push Notifications - JavaScript",
      "subcategory": "Push Notifications",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/push-notifications/testing/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Working with API`,\n  description: `Breakdown of using the Push Notifications API in Amplify Framework`,\n};\n\nimport js0 from \"/src/fragments/lib/push-notifications/js/working-with-api.mdx\";\nimport rn from \"/src/fragments/lib/push-notifications/js/reactnative.mdx\";\n\n<Fragments fragments={{js: rn}} />\n<Fragments fragments={{js: js0}} />\n",
    "meta": {
      "title": "Working with API - JavaScript",
      "description": "Breakdown of using the Push Notifications API in Amplify Framework - JavaScript",
      "subcategory": "Push Notifications",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/push-notifications/working-with-api/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `Use of Push Notifications of Amplify Framework`,\n};\n\nimport js0 from \"/src/fragments/lib/push-notifications/js/getting-started.mdx\";\nimport rn from \"/src/fragments/lib/push-notifications/js/reactnative.mdx\";\n\n<Fragments fragments={{js: rn}} />\n<Fragments fragments={{js: js0}} />\n",
    "meta": {
      "title": "Getting started - JavaScript",
      "description": "Use of Push Notifications of Amplify Framework - JavaScript",
      "subcategory": "Push Notifications",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/push-notifications/getting-started/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Overview`,\n  description: `The Push Notifications category allows you to integrate push notifications in your app with Amazon Pinpoint targeting and campaign management support.`,\n};\n\nimport js0 from \"/src/fragments/lib/push-notifications/js/overview.mdx\";\nimport rn from \"/src/fragments/lib/push-notifications/js/reactnative.mdx\";\n\n<Fragments fragments={{js: rn}} />\n<Fragments fragments={{js: js0}} />\n",
    "meta": {
      "title": "Overview - JavaScript",
      "description": "The Push Notifications category allows you to integrate push notifications in your app with Amazon Pinpoint targeting and campaign management support. - JavaScript",
      "subcategory": "Push Notifications",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/push-notifications/overview/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Publish`,\n  description: `Learn more about how to publish a message using the PubSub category in Amplify`,\n};\n\nimport js0 from \"/src/fragments/lib/pubsub/js/publish.mdx\";\n\n<Fragments fragments={{js: js0}} />\n",
    "meta": {
      "title": "Publish - JavaScript",
      "description": "Learn more about how to publish a message using the PubSub category in Amplify - JavaScript",
      "subcategory": "PubSub",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/pubsub/publish/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Subscribe & Unsubscribe`,\n  description: `Learn more about how to subscribe to and unsubscribe from topics using Amplify's PubSub category`,\n};\n\nimport js0 from \"/src/fragments/lib/pubsub/js/subunsub.mdx\";\n\n<Fragments fragments={{js: js0}} />\n",
    "meta": {
      "title": "Subscribe & Unsubscribe - JavaScript",
      "description": "Learn more about how to subscribe to and unsubscribe from topics using Amplify's PubSub category - JavaScript",
      "subcategory": "PubSub",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/pubsub/subunsub/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `The AWS Amplify PubSub category provides connectivity with cloud-based message-oriented middleware. You can use PubSub to pass messages between your app instances and your app’s backend creating real-time interactive experiences.`,\n};\n\nimport js0 from \"/src/fragments/lib/pubsub/js/getting-started.mdx\";\n\n<Fragments fragments={{js: js0}} />\n",
    "meta": {
      "title": "Getting started - JavaScript",
      "description": "The AWS Amplify PubSub category provides connectivity with cloud-based message-oriented middleware. You can use PubSub to pass messages between your app instances and your app’s backend creating real-time interactive experiences. - JavaScript",
      "subcategory": "PubSub",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/pubsub/getting-started/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Example`,\n  description: `Sample code for Amplify Framework's predictions category`,\n};\n\nimport js0 from \"/src/fragments/lib/predictions/js/sample.mdx\";\n\n<Fragments fragments={{js: js0}} />\n",
    "meta": {
      "title": "Example - JavaScript",
      "description": "Sample code for Amplify Framework's predictions category - JavaScript",
      "subcategory": "Predictions",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/predictions/sample/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Escape hatch`,\n  description: `For any of the AWS services behind predictions, you can use the SDK object to get access to any methods we are not calling on your behalf by using an escape hatch.`,\n};\n\nimport ios0 from \"/src/fragments/lib/predictions/ios/escapehatch.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/predictions/android/escapehatch.mdx\";\n\n<Fragments fragments={{android: android1}} />\n",
    "meta": {
      "title": "Escape hatch - iOS",
      "description": "For any of the AWS services behind predictions, you can use the SDK object to get access to any methods we are not calling on your behalf by using an escape hatch. - iOS",
      "subcategory": "Predictions",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/predictions/escapehatch/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Escape hatch`,\n  description: `For any of the AWS services behind predictions, you can use the SDK object to get access to any methods we are not calling on your behalf by using an escape hatch.`,\n};\n\nimport ios0 from \"/src/fragments/lib/predictions/ios/escapehatch.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/predictions/android/escapehatch.mdx\";\n\n<Fragments fragments={{android: android1}} />\n",
    "meta": {
      "title": "Escape hatch - Android",
      "description": "For any of the AWS services behind predictions, you can use the SDK object to get access to any methods we are not calling on your behalf by using an escape hatch. - Android",
      "subcategory": "Predictions",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/predictions/escapehatch/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Interpret sentiment`,\n  description: `Learn more about how to determine key phrases, sentiment, language, syntax, and entities from text using Amplify.`,\n};\n\nimport js0 from \"/src/fragments/lib/predictions/js/interpret.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/predictions/ios/interpret.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/predictions/android/interpret.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Interpret sentiment - JavaScript",
      "description": "Learn more about how to determine key phrases, sentiment, language, syntax, and entities from text using Amplify. - JavaScript",
      "subcategory": "Predictions",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/predictions/interpret/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Interpret sentiment`,\n  description: `Learn more about how to determine key phrases, sentiment, language, syntax, and entities from text using Amplify.`,\n};\n\nimport js0 from \"/src/fragments/lib/predictions/js/interpret.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/predictions/ios/interpret.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/predictions/android/interpret.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Interpret sentiment - iOS",
      "description": "Learn more about how to determine key phrases, sentiment, language, syntax, and entities from text using Amplify. - iOS",
      "subcategory": "Predictions",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/predictions/interpret/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Interpret sentiment`,\n  description: `Learn more about how to determine key phrases, sentiment, language, syntax, and entities from text using Amplify.`,\n};\n\nimport js0 from \"/src/fragments/lib/predictions/js/interpret.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/predictions/ios/interpret.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/predictions/android/interpret.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Interpret sentiment - Android",
      "description": "Learn more about how to determine key phrases, sentiment, language, syntax, and entities from text using Amplify. - Android",
      "subcategory": "Predictions",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/predictions/interpret/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Label objects in image`,\n  description: `Learn more about how to detect labels in an image using Amplify. For example you can detect if an image has objects such as chairs, desks etc.`,\n};\n\nimport js0 from \"/src/fragments/lib/predictions/js/label-image.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/predictions/ios/label-image.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/predictions/android/label-image.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Label objects in image - JavaScript",
      "description": "Learn more about how to detect labels in an image using Amplify. For example you can detect if an image has objects such as chairs, desks etc. - JavaScript",
      "subcategory": "Predictions",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/predictions/label-image/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Label objects in image`,\n  description: `Learn more about how to detect labels in an image using Amplify. For example you can detect if an image has objects such as chairs, desks etc.`,\n};\n\nimport js0 from \"/src/fragments/lib/predictions/js/label-image.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/predictions/ios/label-image.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/predictions/android/label-image.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Label objects in image - iOS",
      "description": "Learn more about how to detect labels in an image using Amplify. For example you can detect if an image has objects such as chairs, desks etc. - iOS",
      "subcategory": "Predictions",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/predictions/label-image/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Label objects in image`,\n  description: `Learn more about how to detect labels in an image using Amplify. For example you can detect if an image has objects such as chairs, desks etc.`,\n};\n\nimport js0 from \"/src/fragments/lib/predictions/js/label-image.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/predictions/ios/label-image.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/predictions/android/label-image.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Label objects in image - Android",
      "description": "Learn more about how to detect labels in an image using Amplify. For example you can detect if an image has objects such as chairs, desks etc. - Android",
      "subcategory": "Predictions",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/predictions/label-image/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Identify entities from images`,\n  description: `Learn more about how to identify entities from an image using Amplify.`,\n};\n\nimport js0 from \"/src/fragments/lib/predictions/js/identify-entity.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/predictions/ios/identify-entity.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/predictions/android/identify-entity.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Identify entities from images - JavaScript",
      "description": "Learn more about how to identify entities from an image using Amplify. - JavaScript",
      "subcategory": "Predictions",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/predictions/identify-entity/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Identify entities from images`,\n  description: `Learn more about how to identify entities from an image using Amplify.`,\n};\n\nimport js0 from \"/src/fragments/lib/predictions/js/identify-entity.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/predictions/ios/identify-entity.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/predictions/android/identify-entity.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Identify entities from images - iOS",
      "description": "Learn more about how to identify entities from an image using Amplify. - iOS",
      "subcategory": "Predictions",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/predictions/identify-entity/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Identify entities from images`,\n  description: `Learn more about how to identify entities from an image using Amplify.`,\n};\n\nimport js0 from \"/src/fragments/lib/predictions/js/identify-entity.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/predictions/ios/identify-entity.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/predictions/android/identify-entity.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Identify entities from images - Android",
      "description": "Learn more about how to identify entities from an image using Amplify. - Android",
      "subcategory": "Predictions",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/predictions/identify-entity/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Identify text`,\n  description: `Learn more about how to identify text from images and documents in your application using AWS Amplify.`,\n};\n\nimport js0 from \"/src/fragments/lib/predictions/js/identify-text.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/predictions/ios/identify-text.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/predictions/android/identify-text.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Identify text - JavaScript",
      "description": "Learn more about how to identify text from images and documents in your application using AWS Amplify. - JavaScript",
      "subcategory": "Predictions",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/predictions/identify-text/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Identify text`,\n  description: `Learn more about how to identify text from images and documents in your application using AWS Amplify.`,\n};\n\nimport js0 from \"/src/fragments/lib/predictions/js/identify-text.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/predictions/ios/identify-text.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/predictions/android/identify-text.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Identify text - iOS",
      "description": "Learn more about how to identify text from images and documents in your application using AWS Amplify. - iOS",
      "subcategory": "Predictions",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/predictions/identify-text/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Identify text`,\n  description: `Learn more about how to identify text from images and documents in your application using AWS Amplify.`,\n};\n\nimport js0 from \"/src/fragments/lib/predictions/js/identify-text.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/predictions/ios/identify-text.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/predictions/android/identify-text.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Identify text - Android",
      "description": "Learn more about how to identify text from images and documents in your application using AWS Amplify. - Android",
      "subcategory": "Predictions",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/predictions/identify-text/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Translate language`,\n  description: `Learn more about how to integrate translation capabilities for your application using Amplify`,\n};\n\nimport js0 from \"/src/fragments/lib/predictions/js/translate.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/predictions/ios/translate.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/predictions/android/translate.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Translate language - JavaScript",
      "description": "Learn more about how to integrate translation capabilities for your application using Amplify - JavaScript",
      "subcategory": "Predictions",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/predictions/translate/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Translate language`,\n  description: `Learn more about how to integrate translation capabilities for your application using Amplify`,\n};\n\nimport js0 from \"/src/fragments/lib/predictions/js/translate.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/predictions/ios/translate.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/predictions/android/translate.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Translate language - iOS",
      "description": "Learn more about how to integrate translation capabilities for your application using Amplify - iOS",
      "subcategory": "Predictions",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/predictions/translate/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Translate language`,\n  description: `Learn more about how to integrate translation capabilities for your application using Amplify`,\n};\n\nimport js0 from \"/src/fragments/lib/predictions/js/translate.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/predictions/ios/translate.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/predictions/android/translate.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Translate language - Android",
      "description": "Learn more about how to integrate translation capabilities for your application using Amplify - Android",
      "subcategory": "Predictions",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/predictions/translate/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Transcribe audio to text`,\n  description: `Learn more about how to transcribe audio to text (also known as speech-to-text) for your application using Amplify`,\n};\n\nimport js0 from \"/src/fragments/lib/predictions/js/transcribe.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/predictions/ios/transcribe.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n",
    "meta": {
      "title": "Transcribe audio to text - JavaScript",
      "description": "Learn more about how to transcribe audio to text (also known as speech-to-text) for your application using Amplify - JavaScript",
      "subcategory": "Predictions",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/predictions/transcribe/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Transcribe audio to text`,\n  description: `Learn more about how to transcribe audio to text (also known as speech-to-text) for your application using Amplify`,\n};\n\nimport js0 from \"/src/fragments/lib/predictions/js/transcribe.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/predictions/ios/transcribe.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n",
    "meta": {
      "title": "Transcribe audio to text - iOS",
      "description": "Learn more about how to transcribe audio to text (also known as speech-to-text) for your application using Amplify - iOS",
      "subcategory": "Predictions",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/predictions/transcribe/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Text to speech`,\n  description: `Learn more about how to integrate text-to-speech capabilities into your application using Amplify.`,\n};\n\nimport js0 from \"/src/fragments/lib/predictions/js/text-speech.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/predictions/ios/text-speech.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/predictions/android/text-speech.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Text to speech - JavaScript",
      "description": "Learn more about how to integrate text-to-speech capabilities into your application using Amplify. - JavaScript",
      "subcategory": "Predictions",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/predictions/text-speech/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Text to speech`,\n  description: `Learn more about how to integrate text-to-speech capabilities into your application using Amplify.`,\n};\n\nimport js0 from \"/src/fragments/lib/predictions/js/text-speech.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/predictions/ios/text-speech.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/predictions/android/text-speech.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Text to speech - iOS",
      "description": "Learn more about how to integrate text-to-speech capabilities into your application using Amplify. - iOS",
      "subcategory": "Predictions",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/predictions/text-speech/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Text to speech`,\n  description: `Learn more about how to integrate text-to-speech capabilities into your application using Amplify.`,\n};\n\nimport js0 from \"/src/fragments/lib/predictions/js/text-speech.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/predictions/ios/text-speech.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/predictions/android/text-speech.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Text to speech - Android",
      "description": "Learn more about how to integrate text-to-speech capabilities into your application using Amplify. - Android",
      "subcategory": "Predictions",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/predictions/text-speech/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `Get started with integrating ML capabilities into your application using Amplify Framework`,\n};\n\nimport js0 from \"/src/fragments/lib/predictions/js/getting-started.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/predictions/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/predictions/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Getting started - JavaScript",
      "description": "Get started with integrating ML capabilities into your application using Amplify Framework - JavaScript",
      "subcategory": "Predictions",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/predictions/getting-started/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `Get started with integrating ML capabilities into your application using Amplify Framework`,\n};\n\nimport js0 from \"/src/fragments/lib/predictions/js/getting-started.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/predictions/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/predictions/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Getting started - iOS",
      "description": "Get started with integrating ML capabilities into your application using Amplify Framework - iOS",
      "subcategory": "Predictions",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/predictions/getting-started/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `Get started with integrating ML capabilities into your application using Amplify Framework`,\n};\n\nimport js0 from \"/src/fragments/lib/predictions/js/getting-started.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/predictions/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/predictions/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Getting started - Android",
      "description": "Get started with integrating ML capabilities into your application using Amplify Framework - Android",
      "subcategory": "Predictions",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/predictions/getting-started/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Overview`,\n  description: `The Predictions category enables you to integrate machine learning in your application without any prior machine learning experience. The Predictions category comes with built-in support for both online and offline use cases.`,\n};\n\nimport js0 from \"/src/fragments/lib/predictions/js/intro.mdx\";\n\n<Fragments fragments={{js: js0}} />\n",
    "meta": {
      "title": "Overview - JavaScript",
      "description": "The Predictions category enables you to integrate machine learning in your application without any prior machine learning experience. The Predictions category comes with built-in support for both online and offline use cases. - JavaScript",
      "subcategory": "Predictions",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/predictions/intro/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Interact with bots`,\n  description: `Learn more about how to integrate chat bot interactions into your application using Amplify Framework.`,\n};\n\nimport js0 from \"/src/fragments/lib/interactions/js/chatbot.mdx\";\n\n<Fragments fragments={{js: js0}} />",
    "meta": {
      "title": "Interact with bots - JavaScript",
      "description": "Learn more about how to integrate chat bot interactions into your application using Amplify Framework. - JavaScript",
      "subcategory": "Interactions",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/interactions/chatbot/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `AWS Amplify Interactions category enables AI-powered chatbots in your web or mobile apps. You can use Interactions to configure your backend chatbot provider and to integrate a chatbot UI into your app with just a single line of code.`,\n};\n\nimport js0 from \"/src/fragments/lib/interactions/js/getting-started.mdx\";\n\n<Fragments fragments={{js: js0}} />",
    "meta": {
      "title": "Getting started - JavaScript",
      "description": "AWS Amplify Interactions category enables AI-powered chatbots in your web or mobile apps. You can use Interactions to configure your backend chatbot provider and to integrate a chatbot UI into your app with just a single line of code. - JavaScript",
      "subcategory": "Interactions",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/interactions/getting-started/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Resolving conflicts`,\n  description: `Learn how to resolve conflicts when an event is sent and meets the criteria set forth by multiple in-app messages.`\n};\n\nimport js0 from '/src/fragments/lib/in-app-messaging/js/resolve-conflicts.mdx';\n\n<Fragments fragments={{ js: js0 }} />\n",
    "meta": {
      "title": "Resolving conflicts - JavaScript",
      "description": "Learn how to resolve conflicts when an event is sent and meets the criteria set forth by multiple in-app messages. - JavaScript",
      "subcategory": "In-App Messaging (Preview)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/in-app-messaging/resolve-conflicts/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Respond to interaction events`,\n  description: `Learn how to respond with additional behavior to your users interacting with in-app messages by adding interaction event listeners.`\n};\n\nimport js0 from '/src/fragments/lib/in-app-messaging/js/respond-interaction-events.mdx';\n\n<Fragments fragments={{ js: js0 }} />\n",
    "meta": {
      "title": "Respond to interaction events - JavaScript",
      "description": "Learn how to respond with additional behavior to your users interacting with in-app messages by adding interaction event listeners. - JavaScript",
      "subcategory": "In-App Messaging (Preview)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/in-app-messaging/respond-interaction-events/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Identify a user`,\n  description: `Learn how to segment and target your In-App Messaging campaigns to specific user subsets.`\n};\n\nimport js0 from '/src/fragments/lib/in-app-messaging/js/identify-user.mdx';\n\n<Fragments fragments={{ js: js0 }} />\n",
    "meta": {
      "title": "Identify a user - JavaScript",
      "description": "Learn how to segment and target your In-App Messaging campaigns to specific user subsets. - JavaScript",
      "subcategory": "In-App Messaging (Preview)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/in-app-messaging/identify-user/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Customize your UI`,\n  description: `Learn how to customize UI for your in-app message and provide your own In-App Messaging UI components to override the default Amplify provided UI components.`\n};\n\nimport js0 from '/src/fragments/lib/in-app-messaging/js/customize.mdx';\n\n<Fragments fragments={{ js: js0 }} />\n",
    "meta": {
      "title": "Customize your UI - JavaScript",
      "description": "Learn how to customize UI for your in-app message and provide your own In-App Messaging UI components to override the default Amplify provided UI components. - JavaScript",
      "subcategory": "In-App Messaging (Preview)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/in-app-messaging/customize/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Clear messages`,\n  description: `Learn more about how to clear synced in-app messages from the user's device.`\n};\n\nimport js0 from '/src/fragments/lib/in-app-messaging/js/clear-messages.mdx';\n\n<Fragments fragments={{ js: js0 }} />\n",
    "meta": {
      "title": "Clear messages - JavaScript",
      "description": "Learn more about how to clear synced in-app messages from the user's device. - JavaScript",
      "subcategory": "In-App Messaging (Preview)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/in-app-messaging/clear-messages/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Display message`,\n  description: `Learn how In-app messages are displayed when an In-App Messaging or analytics event is sent and matches the criteria set forth by your active In-App Messaging campaigns.`\n};\n\nimport js0 from '/src/fragments/lib/in-app-messaging/js/display-message.mdx';\n\n<Fragments fragments={{ js: js0 }} />\n",
    "meta": {
      "title": "Display message - JavaScript",
      "description": "Learn how In-app messages are displayed when an In-App Messaging or analytics event is sent and matches the criteria set forth by your active In-App Messaging campaigns. - JavaScript",
      "subcategory": "In-App Messaging (Preview)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/in-app-messaging/display-message/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Sync messages`,\n  description: `Learn how to sync in-app messages to your user's local device. Synced messages will be displayed when a matching event is triggered.`\n};\n\nimport js0 from '/src/fragments/lib/in-app-messaging/js/sync-messages.mdx';\n\n<Fragments fragments={{ js: js0 }} />\n",
    "meta": {
      "title": "Sync messages - JavaScript",
      "description": "Learn how to sync in-app messages to your user's local device. Synced messages will be displayed when a matching event is triggered. - JavaScript",
      "subcategory": "In-App Messaging (Preview)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/in-app-messaging/sync-messages/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `Learn how to get started with the In-App Messaging and integrate it to your application.`\n};\n\nimport js0 from '/src/fragments/lib/in-app-messaging/js/getting-started.mdx';\n\n<Fragments fragments={{ js: js0 }} />\n",
    "meta": {
      "title": "Getting started - JavaScript",
      "description": "Learn how to get started with the In-App Messaging and integrate it to your application. - JavaScript",
      "subcategory": "In-App Messaging (Preview)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/in-app-messaging/getting-started/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Create an In-App Messaging Campaign`,\n  description: `Learn how to create a new pinpoint campaign and configure it to be used with your amplify project.`\n};\n\nimport js0 from '/src/fragments/lib/in-app-messaging/js/create-campaign.mdx';\n\n<Fragments fragments={{ js: js0 }} />\n",
    "meta": {
      "title": "Create an In-App Messaging campaign - JavaScript",
      "description": "Learn how to create a new pinpoint campaign and configure it to be used with your amplify project. - JavaScript",
      "subcategory": "In-App Messaging (Preview)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/in-app-messaging/create-campaign/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Prerequisites`,\n  description: `Learn how to complete the prerequisites for getting started with In-App Messaging. Initialize and configure amplify permissions to get started.`\n};\n\nimport js0 from '/src/fragments/lib/in-app-messaging/js/prerequisites.mdx';\n\n<Fragments fragments={{ js: js0 }} />\n",
    "meta": {
      "title": "Prerequisites - JavaScript",
      "description": "Learn how to complete the prerequisites for getting started with In-App Messaging. Initialize and configure amplify permissions to get started. - JavaScript",
      "subcategory": "In-App Messaging (Preview)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/in-app-messaging/prerequisites/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Overview`,\n  description: `Amplify In-App Messaging helps you better engage your users with messages they can see while actively using your application. Send targeted messages to your defined user segments or even trigger contextual messages based on user behavior. Once you are up and running with In-App Messaging, you’ll be able to create messages that look native to your application and deliver them to your users all without additional code changes.`\n};\n\nimport js0 from '/src/fragments/lib/in-app-messaging/js/overview.mdx';\n\n<Fragments fragments={{ js: js0 }} />\n",
    "meta": {
      "title": "Overview - JavaScript",
      "description": "Amplify In-App Messaging helps you better engage your users with messages they can see while actively using your application. Send targeted messages to your defined user segments or even trigger contextual messages based on user behavior. Once you are up and running with In-App Messaging, you’ll be able to create messages that look native to your application and deliver them to your users all without additional code changes. - JavaScript",
      "subcategory": "In-App Messaging (Preview)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/in-app-messaging/overview/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Escape hatch`,\n  description: `For specialized use cases where Amplify does not provide the functionality, you can use the escape hatch to access a low-level client instance for Amazon Location Service.`,\n};\n\nimport js0 from \"/src/fragments/lib/geo/js/escapehatch.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport android1 from \"/src/fragments/lib/geo/android/escapehatch.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport ios2 from \"/src/fragments/lib/geo/ios/escapehatch.mdx\";\n\n<Fragments fragments={{ios: ios2}} />",
    "meta": {
      "title": "Escape Hatch - Android",
      "description": "For specialized use cases where Amplify does not provide the functionality, you can use the escape hatch to access a low-level client instance for Amazon Location Service. - Android",
      "subcategory": "Geo",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/geo/escapehatch/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Escape hatch`,\n  description: `For specialized use cases where Amplify does not provide the functionality, you can use the escape hatch to access a low-level client instance for Amazon Location Service.`,\n};\n\nimport js0 from \"/src/fragments/lib/geo/js/escapehatch.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport android1 from \"/src/fragments/lib/geo/android/escapehatch.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport ios2 from \"/src/fragments/lib/geo/ios/escapehatch.mdx\";\n\n<Fragments fragments={{ios: ios2}} />",
    "meta": {
      "title": "Escape Hatch - iOS",
      "description": "For specialized use cases where Amplify does not provide the functionality, you can use the escape hatch to access a low-level client instance for Amazon Location Service. - iOS",
      "subcategory": "Geo",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/geo/escapehatch/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Escape hatch`,\n  description: `For specialized use cases where Amplify does not provide the functionality, you can use the escape hatch to access a low-level client instance for Amazon Location Service.`,\n};\n\nimport js0 from \"/src/fragments/lib/geo/js/escapehatch.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport android1 from \"/src/fragments/lib/geo/android/escapehatch.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport ios2 from \"/src/fragments/lib/geo/ios/escapehatch.mdx\";\n\n<Fragments fragments={{ios: ios2}} />",
    "meta": {
      "title": "Escape Hatch - JavaScript",
      "description": "For specialized use cases where Amplify does not provide the functionality, you can use the escape hatch to access a low-level client instance for Amazon Location Service. - JavaScript",
      "subcategory": "Geo",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/geo/escapehatch/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Migrating from Google Maps`,\n  description: `Migrate applications from Google Maps to Amplify Geo`\n};\n\nimport js0 from '/src/fragments/lib/geo/js/google-migration.mdx';\n\n<Fragments fragments={{ js: js0 }} />\n",
    "meta": {
      "title": "Migrating from Google Maps - JavaScript",
      "description": "Migrate applications from Google Maps to Amplify Geo - JavaScript",
      "subcategory": "Geo",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/geo/google-migration/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Use existing Amazon Location Service resources`,\n  description: `Configure Amplify Geo to use existing Amazon Location Service resources by referencing them in your configuration.`,\n};\n\nimport js0 from \"/src/fragments/lib/geo/existing-resources.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport android1 from \"/src/fragments/lib/geo/existing-resources.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport ios2 from \"/src/fragments/lib/geo/existing-resources.mdx\";\n\n<Fragments fragments={{ios: ios2}} />\n",
    "meta": {
      "title": "Use existing Amazon Location resources - Android",
      "description": "Configure Amplify Geo to use existing Amazon Location Service resources by referencing them in your configuration. - Android",
      "subcategory": "Geo",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/geo/existing-resources/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Use existing Amazon Location Service resources`,\n  description: `Configure Amplify Geo to use existing Amazon Location Service resources by referencing them in your configuration.`,\n};\n\nimport js0 from \"/src/fragments/lib/geo/existing-resources.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport android1 from \"/src/fragments/lib/geo/existing-resources.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport ios2 from \"/src/fragments/lib/geo/existing-resources.mdx\";\n\n<Fragments fragments={{ios: ios2}} />\n",
    "meta": {
      "title": "Use existing Amazon Location resources - iOS",
      "description": "Configure Amplify Geo to use existing Amazon Location Service resources by referencing them in your configuration. - iOS",
      "subcategory": "Geo",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/geo/existing-resources/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Use existing Amazon Location Service resources`,\n  description: `Configure Amplify Geo to use existing Amazon Location Service resources by referencing them in your configuration.`,\n};\n\nimport js0 from \"/src/fragments/lib/geo/existing-resources.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport android1 from \"/src/fragments/lib/geo/existing-resources.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport ios2 from \"/src/fragments/lib/geo/existing-resources.mdx\";\n\n<Fragments fragments={{ios: ios2}} />\n",
    "meta": {
      "title": "Use existing Amazon Location resources - JavaScript",
      "description": "Configure Amplify Geo to use existing Amazon Location Service resources by referencing them in your configuration. - JavaScript",
      "subcategory": "Geo",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/geo/existing-resources/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Geofences`,\n  description: `The Amplify Geo category`\n};\n\nimport js0 from '/src/fragments/lib/geo/js/geofences.mdx';\n\n<Fragments fragments={{ js: js0 }} />\n",
    "meta": {
      "title": "Geofences - JavaScript",
      "description": "The Amplify Geo category - JavaScript",
      "subcategory": "Geo",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/geo/geofences/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Location Search`,\n  description: `The Amplify Geo category`,\n};\n\nimport js0 from \"/src/fragments/lib/geo/js/search.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport android1 from \"/src/fragments/lib/geo/native_common/search/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport ios2 from \"/src/fragments/lib/geo/native_common/search/common.mdx\";\n\n<Fragments fragments={{ios: ios2}} />\n",
    "meta": {
      "title": "Location Search - Android",
      "description": "The Amplify Geo category - Android",
      "subcategory": "Geo",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/geo/search/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Location Search`,\n  description: `The Amplify Geo category`,\n};\n\nimport js0 from \"/src/fragments/lib/geo/js/search.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport android1 from \"/src/fragments/lib/geo/native_common/search/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport ios2 from \"/src/fragments/lib/geo/native_common/search/common.mdx\";\n\n<Fragments fragments={{ios: ios2}} />\n",
    "meta": {
      "title": "Location Search - iOS",
      "description": "The Amplify Geo category - iOS",
      "subcategory": "Geo",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/geo/search/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Location Search`,\n  description: `The Amplify Geo category`,\n};\n\nimport js0 from \"/src/fragments/lib/geo/js/search.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport android1 from \"/src/fragments/lib/geo/native_common/search/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport ios2 from \"/src/fragments/lib/geo/native_common/search/common.mdx\";\n\n<Fragments fragments={{ios: ios2}} />\n",
    "meta": {
      "title": "Location Search - JavaScript",
      "description": "The Amplify Geo category - JavaScript",
      "subcategory": "Geo",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/geo/search/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Maps`,\n  description: `The Amplify Geo category`,\n};\n\nimport js0 from \"/src/fragments/lib/geo/js/maps.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport android1 from \"/src/fragments/lib/geo/native_common/maps/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport ios2 from \"/src/fragments/lib/geo/native_common/maps/common.mdx\";\n\n<Fragments fragments={{ios: ios2}} />\n",
    "meta": {
      "title": "Maps - Android",
      "description": "The Amplify Geo category - Android",
      "subcategory": "Geo",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/geo/maps/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Maps`,\n  description: `The Amplify Geo category`,\n};\n\nimport js0 from \"/src/fragments/lib/geo/js/maps.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport android1 from \"/src/fragments/lib/geo/native_common/maps/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport ios2 from \"/src/fragments/lib/geo/native_common/maps/common.mdx\";\n\n<Fragments fragments={{ios: ios2}} />\n",
    "meta": {
      "title": "Maps - iOS",
      "description": "The Amplify Geo category - iOS",
      "subcategory": "Geo",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/geo/maps/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Maps`,\n  description: `The Amplify Geo category`,\n};\n\nimport js0 from \"/src/fragments/lib/geo/js/maps.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport android1 from \"/src/fragments/lib/geo/native_common/maps/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport ios2 from \"/src/fragments/lib/geo/native_common/maps/common.mdx\";\n\n<Fragments fragments={{ios: ios2}} />\n",
    "meta": {
      "title": "Maps - JavaScript",
      "description": "The Amplify Geo category - JavaScript",
      "subcategory": "Geo",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/geo/maps/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `AWS Amplify Geo module provides a simple way to get map data, search for places, and reverse geocoding.`,\n};\n\nimport js0 from \"/src/fragments/lib/geo/js/getting-started.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport android1 from \"/src/fragments/lib/geo/native_common/getting_started/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport ios2 from \"/src/fragments/lib/geo/native_common/getting_started/common.mdx\";\n\n<Fragments fragments={{ios: ios2}} />\n",
    "meta": {
      "title": "Getting started - Android",
      "description": "AWS Amplify Geo module provides a simple way to get map data, search for places, and reverse geocoding. - Android",
      "subcategory": "Geo",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/geo/getting-started/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `AWS Amplify Geo module provides a simple way to get map data, search for places, and reverse geocoding.`,\n};\n\nimport js0 from \"/src/fragments/lib/geo/js/getting-started.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport android1 from \"/src/fragments/lib/geo/native_common/getting_started/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport ios2 from \"/src/fragments/lib/geo/native_common/getting_started/common.mdx\";\n\n<Fragments fragments={{ios: ios2}} />\n",
    "meta": {
      "title": "Getting started - iOS",
      "description": "AWS Amplify Geo module provides a simple way to get map data, search for places, and reverse geocoding. - iOS",
      "subcategory": "Geo",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/geo/getting-started/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `AWS Amplify Geo module provides a simple way to get map data, search for places, and reverse geocoding.`,\n};\n\nimport js0 from \"/src/fragments/lib/geo/js/getting-started.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport android1 from \"/src/fragments/lib/geo/native_common/getting_started/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport ios2 from \"/src/fragments/lib/geo/native_common/getting_started/common.mdx\";\n\n<Fragments fragments={{ios: ios2}} />\n",
    "meta": {
      "title": "Getting started - JavaScript",
      "description": "AWS Amplify Geo module provides a simple way to get map data, search for places, and reverse geocoding. - JavaScript",
      "subcategory": "Geo",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/geo/getting-started/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Examples`,\n  description: `Full examples and resources using Amplify DataStore.`,\n};\n\nimport js0 from \"/src/fragments/lib/datastore/js/examples.mdx\";\n\n<Fragments fragments={{js: js0}} />",
    "meta": {
      "title": "Examples - JavaScript",
      "description": "Full examples and resources using Amplify DataStore. - JavaScript",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/examples/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `How it works`,\n  description: `Amplify DataStore provides a persistent on-device storage repository for you to write, read, and observe changes to data if you are online or offline, and seamlessly sync to the cloud as well as across devices. Learn more about how it works.`,\n};\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/how-it-works.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/how-it-works.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/how-it-works.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/how-it-works.mdx\";\n\n<Fragments fragments={{js: js3}} />",
    "meta": {
      "title": "How it works - JavaScript",
      "description": "Amplify DataStore provides a persistent on-device storage repository for you to write, read, and observe changes to data if you are online or offline, and seamlessly sync to the cloud as well as across devices. Learn more about how it works. - JavaScript",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/how-it-works/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `How it works`,\n  description: `Amplify DataStore provides a persistent on-device storage repository for you to write, read, and observe changes to data if you are online or offline, and seamlessly sync to the cloud as well as across devices. Learn more about how it works.`,\n};\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/how-it-works.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/how-it-works.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/how-it-works.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/how-it-works.mdx\";\n\n<Fragments fragments={{js: js3}} />",
    "meta": {
      "title": "How it works - iOS",
      "description": "Amplify DataStore provides a persistent on-device storage repository for you to write, read, and observe changes to data if you are online or offline, and seamlessly sync to the cloud as well as across devices. Learn more about how it works. - iOS",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/how-it-works/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `How it works`,\n  description: `Amplify DataStore provides a persistent on-device storage repository for you to write, read, and observe changes to data if you are online or offline, and seamlessly sync to the cloud as well as across devices. Learn more about how it works.`,\n};\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/how-it-works.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/how-it-works.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/how-it-works.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/how-it-works.mdx\";\n\n<Fragments fragments={{js: js3}} />",
    "meta": {
      "title": "How it works - Flutter",
      "description": "Amplify DataStore provides a persistent on-device storage repository for you to write, read, and observe changes to data if you are online or offline, and seamlessly sync to the cloud as well as across devices. Learn more about how it works. - Flutter",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/how-it-works/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `How it works`,\n  description: `Amplify DataStore provides a persistent on-device storage repository for you to write, read, and observe changes to data if you are online or offline, and seamlessly sync to the cloud as well as across devices. Learn more about how it works.`,\n};\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/how-it-works.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/how-it-works.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/how-it-works.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/how-it-works.mdx\";\n\n<Fragments fragments={{js: js3}} />",
    "meta": {
      "title": "How it works - Android",
      "description": "Amplify DataStore provides a persistent on-device storage repository for you to write, read, and observe changes to data if you are online or offline, and seamlessly sync to the cloud as well as across devices. Learn more about how it works. - Android",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/how-it-works/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Schema updates`,\n  description: `Learn more about how to issue schema updates for DataStore`,\n};\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/schema-updates.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/schema-updates.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/schema-updates.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/schema-updates.mdx\";\n\n<Fragments fragments={{js: js3}} />",
    "meta": {
      "title": "Schema updates - JavaScript",
      "description": "Learn more about how to issue schema updates for DataStore - JavaScript",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/schema-updates/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Schema updates`,\n  description: `Learn more about how to issue schema updates for DataStore`,\n};\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/schema-updates.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/schema-updates.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/schema-updates.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/schema-updates.mdx\";\n\n<Fragments fragments={{js: js3}} />",
    "meta": {
      "title": "Schema updates - iOS",
      "description": "Learn more about how to issue schema updates for DataStore - iOS",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/schema-updates/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Schema updates`,\n  description: `Learn more about how to issue schema updates for DataStore`,\n};\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/schema-updates.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/schema-updates.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/schema-updates.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/schema-updates.mdx\";\n\n<Fragments fragments={{js: js3}} />",
    "meta": {
      "title": "Schema updates - Flutter",
      "description": "Learn more about how to issue schema updates for DataStore - Flutter",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/schema-updates/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Schema updates`,\n  description: `Learn more about how to issue schema updates for DataStore`,\n};\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/schema-updates.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/schema-updates.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/schema-updates.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/schema-updates.mdx\";\n\n<Fragments fragments={{js: js3}} />",
    "meta": {
      "title": "Schema updates - Android",
      "description": "Learn more about how to issue schema updates for DataStore - Android",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/schema-updates/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Other methods`,\n  description: `Other Amplify DataStore methods`,\n};\n\nimport js0 from \"/src/fragments/lib/datastore/js/other-methods.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/other-methods.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport ios2 from \"/src/fragments/lib/datastore/native_common/other-methods.mdx\";\n\n<Fragments fragments={{ios: ios2}} />\n\nimport flutter from \"/src/fragments/lib/datastore/native_common/other-methods.mdx\";\n\n<Fragments fragments={{flutter: flutter}} />\n",
    "meta": {
      "title": "Other methods - JavaScript",
      "description": "Other Amplify DataStore methods - JavaScript",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/other-methods/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Other methods`,\n  description: `Other Amplify DataStore methods`,\n};\n\nimport js0 from \"/src/fragments/lib/datastore/js/other-methods.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/other-methods.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport ios2 from \"/src/fragments/lib/datastore/native_common/other-methods.mdx\";\n\n<Fragments fragments={{ios: ios2}} />\n\nimport flutter from \"/src/fragments/lib/datastore/native_common/other-methods.mdx\";\n\n<Fragments fragments={{flutter: flutter}} />\n",
    "meta": {
      "title": "Other methods - iOS",
      "description": "Other Amplify DataStore methods - iOS",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/other-methods/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Other methods`,\n  description: `Other Amplify DataStore methods`,\n};\n\nimport js0 from \"/src/fragments/lib/datastore/js/other-methods.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/other-methods.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport ios2 from \"/src/fragments/lib/datastore/native_common/other-methods.mdx\";\n\n<Fragments fragments={{ios: ios2}} />\n\nimport flutter from \"/src/fragments/lib/datastore/native_common/other-methods.mdx\";\n\n<Fragments fragments={{flutter: flutter}} />\n",
    "meta": {
      "title": "Other methods - Flutter",
      "description": "Other Amplify DataStore methods - Flutter",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/other-methods/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Other methods`,\n  description: `Other Amplify DataStore methods`,\n};\n\nimport js0 from \"/src/fragments/lib/datastore/js/other-methods.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/other-methods.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport ios2 from \"/src/fragments/lib/datastore/native_common/other-methods.mdx\";\n\n<Fragments fragments={{ios: ios2}} />\n\nimport flutter from \"/src/fragments/lib/datastore/native_common/other-methods.mdx\";\n\n<Fragments fragments={{flutter: flutter}} />\n",
    "meta": {
      "title": "Other methods - Android",
      "description": "Other Amplify DataStore methods - Android",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/other-methods/q/platform/android"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "DataStore periodically publishes state notifications onto Amplify's Hub. You can subscribe to the Hub to gain insight into the internal state of the DataStore. Events are published when:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Your device loses or regains network connectivity;"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Data is synchronized with the Cloud;"
      },
      {
        "heading": null,
        "depth": null,
        "text": "There are new, pending changes that have not yet been synchronized."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The following DataStore events are defined:"
      },
      {
        "heading": "networkStatus",
        "depth": 2,
        "text": "Dispatched when DataStore starts and every time network status changes"
      },
      {
        "heading": "networkStatus",
        "depth": 2,
        "text": "HubPayload NetworkStatusEvent contains:"
      },
      {
        "heading": "networkStatus",
        "depth": 2,
        "text": "active (Bool): true if the DataStore is on a network that can connect the Cloud; false, otherwise"
      },
      {
        "heading": "subscriptionsEstablished",
        "depth": 2,
        "text": "Dispatched when DataStore has finished establishing its subscriptions to all models"
      },
      {
        "heading": "subscriptionsEstablished",
        "depth": 2,
        "text": "HubPayload: N/A"
      },
      {
        "heading": "syncQueriesStarted",
        "depth": 2,
        "text": "Dispatched when DataStore is about to perform its initial sync queries"
      },
      {
        "heading": "syncQueriesStarted",
        "depth": 2,
        "text": "HubPayload syncQueriesStartedEvent contains:"
      },
      {
        "heading": "syncQueriesStarted",
        "depth": 2,
        "text": "models ([String]): an array of each model's name"
      },
      {
        "heading": "syncQueriesReady",
        "depth": 2,
        "text": "Dispatched when all models have been synced from the cloud"
      },
      {
        "heading": "syncQueriesReady",
        "depth": 2,
        "text": "HubPayload: N/A"
      },
      {
        "heading": "ready",
        "depth": 2,
        "text": "Dispatched when DataStore as a whole is ready, at this point all data is available"
      },
      {
        "heading": "ready",
        "depth": 2,
        "text": "HubPayload: N/A"
      },
      {
        "heading": "outboxStatus",
        "depth": 2,
        "text": "Dispatched when:"
      },
      {
        "heading": "outboxStatus",
        "depth": 2,
        "text": "the DataStore starts"
      },
      {
        "heading": "outboxStatus",
        "depth": 2,
        "text": "each time a local mutation is enqueued into the outbox"
      },
      {
        "heading": "outboxStatus",
        "depth": 2,
        "text": "each time a local mutation is finished processing"
      },
      {
        "heading": "outboxStatus",
        "depth": 2,
        "text": "HubPayload OutboxStatusEvent contains:"
      },
      {
        "heading": "outboxStatus",
        "depth": 2,
        "text": "isEmpty (Bool): a boolean value indicating that there are no local changes still pending upload to the Cloud"
      },
      {
        "heading": "Usage",
        "depth": 2,
        "text": "To see if the network status is active, you could set up the following listener:"
      }
    ],
    "source": "export const meta = {\n  title: `DataStore Events`,\n  description: `Listening to DataStore events`,\n};\n\nDataStore periodically publishes state notifications onto Amplify's Hub. You can subscribe to the Hub to gain insight into the internal state of the DataStore. Events are published when:\n* Your device loses or regains network connectivity;\n* Data is synchronized with the Cloud;\n* There are new, pending changes that have not yet been synchronized.\n\nThe following DataStore events are defined:\n\n## networkStatus\n\nDispatched when DataStore starts and every time network status changes\n\nHubPayload `NetworkStatusEvent` contains:\n- `active` (Bool): true if the DataStore is on a network that can connect the Cloud; false, otherwise\n\n## subscriptionsEstablished\n\nDispatched when DataStore has finished establishing its subscriptions to all models\n\nHubPayload: N/A\n\n## syncQueriesStarted\n\nDispatched when DataStore is about to perform its initial sync queries\n\nHubPayload `syncQueriesStartedEvent` contains:\n- `models` ([String]): an array of each model's `name`\n\nimport js0 from \"/src/fragments/lib/datastore/js/datastore-events/model-synced.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/datastore-events/model-synced.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/datastore-events/model-synced.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport ios3 from \"/src/fragments/lib/datastore/native_common/datastore-events/model-synced.mdx\";\n\n<Fragments fragments={{ios: ios3}} />\n\n## syncQueriesReady\n\nDispatched when all models have been synced from the cloud\n\nHubPayload: N/A\n\n## ready\n\nDispatched when DataStore as a whole is ready, at this point all data is available\n\nHubPayload: N/A\n\nimport js4 from \"/src/fragments/lib/datastore/js/datastore-events/outbox-mutation-enqueued.mdx\";\n\n<Fragments fragments={{js: js4}} />\n\nimport android5 from \"/src/fragments/lib/datastore/native_common/datastore-events/outbox-mutation-enqueued.mdx\";\n\n<Fragments fragments={{android: android5}} />\n\nimport flutter6 from \"/src/fragments/lib/datastore/native_common/datastore-events/outbox-mutation-enqueued.mdx\";\n\n<Fragments fragments={{flutter: flutter6}} />\n\nimport ios7 from \"/src/fragments/lib/datastore/native_common/datastore-events/outbox-mutation-enqueued.mdx\";\n\n<Fragments fragments={{ios: ios7}} />\n\nimport js8 from \"/src/fragments/lib/datastore/js/datastore-events/outbox-mutation-processed.mdx\";\n\n<Fragments fragments={{js: js8}} />\n\nimport android9 from \"/src/fragments/lib/datastore/native_common/datastore-events/outbox-mutation-processed.mdx\";\n\n<Fragments fragments={{android: android9}} />\n\nimport flutter10 from \"/src/fragments/lib/datastore/native_common/datastore-events/outbox-mutation-processed.mdx\";\n\n<Fragments fragments={{flutter: flutter10}} />\n\nimport ios11 from \"/src/fragments/lib/datastore/native_common/datastore-events/outbox-mutation-processed.mdx\";\n\n<Fragments fragments={{ios: ios11}} />\n\nimport android12 from \"/src/fragments/lib/datastore/android/datastore-events/outbox-mutation-failed.mdx\";\n\n<Fragments fragments={{android: android12}} />\n\n## outboxStatus\n\nDispatched when:\n- the DataStore starts\n- each time a local mutation is enqueued into the outbox\n- each time a local mutation is finished processing\n\nHubPayload `OutboxStatusEvent` contains:\n- `isEmpty` (Bool): a boolean value indicating that there are no local changes still pending upload to the Cloud\n\n## Usage\nTo see if the network status is active, you could set up the following listener:\n\nimport js13 from \"/src/fragments/lib/datastore/js/datastore-events.mdx\";\n\n<Fragments fragments={{js: js13}} />\n\nimport android14 from \"/src/fragments/lib/datastore/android/datastore-events.mdx\";\n\n<Fragments fragments={{android: android14}} />\n\nimport ios15 from \"/src/fragments/lib/datastore/ios/datastore-events.mdx\";\n\n<Fragments fragments={{ios: ios15}} />\n\nimport flutter16 from \"/src/fragments/lib/datastore/flutter/datastore-events.mdx\";\n\n<Fragments fragments={{flutter: flutter16}} />\n",
    "meta": {
      "title": "DataStore Events - JavaScript",
      "description": "Listening to DataStore events - JavaScript",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/datastore-events/q/platform/js"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "DataStore periodically publishes state notifications onto Amplify's Hub. You can subscribe to the Hub to gain insight into the internal state of the DataStore. Events are published when:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Your device loses or regains network connectivity;"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Data is synchronized with the Cloud;"
      },
      {
        "heading": null,
        "depth": null,
        "text": "There are new, pending changes that have not yet been synchronized."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The following DataStore events are defined:"
      },
      {
        "heading": "networkStatus",
        "depth": 2,
        "text": "Dispatched when DataStore starts and every time network status changes"
      },
      {
        "heading": "networkStatus",
        "depth": 2,
        "text": "HubPayload NetworkStatusEvent contains:"
      },
      {
        "heading": "networkStatus",
        "depth": 2,
        "text": "active (Bool): true if the DataStore is on a network that can connect the Cloud; false, otherwise"
      },
      {
        "heading": "subscriptionsEstablished",
        "depth": 2,
        "text": "Dispatched when DataStore has finished establishing its subscriptions to all models"
      },
      {
        "heading": "subscriptionsEstablished",
        "depth": 2,
        "text": "HubPayload: N/A"
      },
      {
        "heading": "syncQueriesStarted",
        "depth": 2,
        "text": "Dispatched when DataStore is about to perform its initial sync queries"
      },
      {
        "heading": "syncQueriesStarted",
        "depth": 2,
        "text": "HubPayload syncQueriesStartedEvent contains:"
      },
      {
        "heading": "syncQueriesStarted",
        "depth": 2,
        "text": "models ([String]): an array of each model's name"
      },
      {
        "heading": "syncQueriesReady",
        "depth": 2,
        "text": "Dispatched when all models have been synced from the cloud"
      },
      {
        "heading": "syncQueriesReady",
        "depth": 2,
        "text": "HubPayload: N/A"
      },
      {
        "heading": "ready",
        "depth": 2,
        "text": "Dispatched when DataStore as a whole is ready, at this point all data is available"
      },
      {
        "heading": "ready",
        "depth": 2,
        "text": "HubPayload: N/A"
      },
      {
        "heading": "outboxStatus",
        "depth": 2,
        "text": "Dispatched when:"
      },
      {
        "heading": "outboxStatus",
        "depth": 2,
        "text": "the DataStore starts"
      },
      {
        "heading": "outboxStatus",
        "depth": 2,
        "text": "each time a local mutation is enqueued into the outbox"
      },
      {
        "heading": "outboxStatus",
        "depth": 2,
        "text": "each time a local mutation is finished processing"
      },
      {
        "heading": "outboxStatus",
        "depth": 2,
        "text": "HubPayload OutboxStatusEvent contains:"
      },
      {
        "heading": "outboxStatus",
        "depth": 2,
        "text": "isEmpty (Bool): a boolean value indicating that there are no local changes still pending upload to the Cloud"
      },
      {
        "heading": "Usage",
        "depth": 2,
        "text": "To see if the network status is active, you could set up the following listener:"
      }
    ],
    "source": "export const meta = {\n  title: `DataStore Events`,\n  description: `Listening to DataStore events`,\n};\n\nDataStore periodically publishes state notifications onto Amplify's Hub. You can subscribe to the Hub to gain insight into the internal state of the DataStore. Events are published when:\n* Your device loses or regains network connectivity;\n* Data is synchronized with the Cloud;\n* There are new, pending changes that have not yet been synchronized.\n\nThe following DataStore events are defined:\n\n## networkStatus\n\nDispatched when DataStore starts and every time network status changes\n\nHubPayload `NetworkStatusEvent` contains:\n- `active` (Bool): true if the DataStore is on a network that can connect the Cloud; false, otherwise\n\n## subscriptionsEstablished\n\nDispatched when DataStore has finished establishing its subscriptions to all models\n\nHubPayload: N/A\n\n## syncQueriesStarted\n\nDispatched when DataStore is about to perform its initial sync queries\n\nHubPayload `syncQueriesStartedEvent` contains:\n- `models` ([String]): an array of each model's `name`\n\nimport js0 from \"/src/fragments/lib/datastore/js/datastore-events/model-synced.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/datastore-events/model-synced.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/datastore-events/model-synced.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport ios3 from \"/src/fragments/lib/datastore/native_common/datastore-events/model-synced.mdx\";\n\n<Fragments fragments={{ios: ios3}} />\n\n## syncQueriesReady\n\nDispatched when all models have been synced from the cloud\n\nHubPayload: N/A\n\n## ready\n\nDispatched when DataStore as a whole is ready, at this point all data is available\n\nHubPayload: N/A\n\nimport js4 from \"/src/fragments/lib/datastore/js/datastore-events/outbox-mutation-enqueued.mdx\";\n\n<Fragments fragments={{js: js4}} />\n\nimport android5 from \"/src/fragments/lib/datastore/native_common/datastore-events/outbox-mutation-enqueued.mdx\";\n\n<Fragments fragments={{android: android5}} />\n\nimport flutter6 from \"/src/fragments/lib/datastore/native_common/datastore-events/outbox-mutation-enqueued.mdx\";\n\n<Fragments fragments={{flutter: flutter6}} />\n\nimport ios7 from \"/src/fragments/lib/datastore/native_common/datastore-events/outbox-mutation-enqueued.mdx\";\n\n<Fragments fragments={{ios: ios7}} />\n\nimport js8 from \"/src/fragments/lib/datastore/js/datastore-events/outbox-mutation-processed.mdx\";\n\n<Fragments fragments={{js: js8}} />\n\nimport android9 from \"/src/fragments/lib/datastore/native_common/datastore-events/outbox-mutation-processed.mdx\";\n\n<Fragments fragments={{android: android9}} />\n\nimport flutter10 from \"/src/fragments/lib/datastore/native_common/datastore-events/outbox-mutation-processed.mdx\";\n\n<Fragments fragments={{flutter: flutter10}} />\n\nimport ios11 from \"/src/fragments/lib/datastore/native_common/datastore-events/outbox-mutation-processed.mdx\";\n\n<Fragments fragments={{ios: ios11}} />\n\nimport android12 from \"/src/fragments/lib/datastore/android/datastore-events/outbox-mutation-failed.mdx\";\n\n<Fragments fragments={{android: android12}} />\n\n## outboxStatus\n\nDispatched when:\n- the DataStore starts\n- each time a local mutation is enqueued into the outbox\n- each time a local mutation is finished processing\n\nHubPayload `OutboxStatusEvent` contains:\n- `isEmpty` (Bool): a boolean value indicating that there are no local changes still pending upload to the Cloud\n\n## Usage\nTo see if the network status is active, you could set up the following listener:\n\nimport js13 from \"/src/fragments/lib/datastore/js/datastore-events.mdx\";\n\n<Fragments fragments={{js: js13}} />\n\nimport android14 from \"/src/fragments/lib/datastore/android/datastore-events.mdx\";\n\n<Fragments fragments={{android: android14}} />\n\nimport ios15 from \"/src/fragments/lib/datastore/ios/datastore-events.mdx\";\n\n<Fragments fragments={{ios: ios15}} />\n\nimport flutter16 from \"/src/fragments/lib/datastore/flutter/datastore-events.mdx\";\n\n<Fragments fragments={{flutter: flutter16}} />\n",
    "meta": {
      "title": "DataStore Events - iOS",
      "description": "Listening to DataStore events - iOS",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/datastore-events/q/platform/ios"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "DataStore periodically publishes state notifications onto Amplify's Hub. You can subscribe to the Hub to gain insight into the internal state of the DataStore. Events are published when:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Your device loses or regains network connectivity;"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Data is synchronized with the Cloud;"
      },
      {
        "heading": null,
        "depth": null,
        "text": "There are new, pending changes that have not yet been synchronized."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The following DataStore events are defined:"
      },
      {
        "heading": "networkStatus",
        "depth": 2,
        "text": "Dispatched when DataStore starts and every time network status changes"
      },
      {
        "heading": "networkStatus",
        "depth": 2,
        "text": "HubPayload NetworkStatusEvent contains:"
      },
      {
        "heading": "networkStatus",
        "depth": 2,
        "text": "active (Bool): true if the DataStore is on a network that can connect the Cloud; false, otherwise"
      },
      {
        "heading": "subscriptionsEstablished",
        "depth": 2,
        "text": "Dispatched when DataStore has finished establishing its subscriptions to all models"
      },
      {
        "heading": "subscriptionsEstablished",
        "depth": 2,
        "text": "HubPayload: N/A"
      },
      {
        "heading": "syncQueriesStarted",
        "depth": 2,
        "text": "Dispatched when DataStore is about to perform its initial sync queries"
      },
      {
        "heading": "syncQueriesStarted",
        "depth": 2,
        "text": "HubPayload syncQueriesStartedEvent contains:"
      },
      {
        "heading": "syncQueriesStarted",
        "depth": 2,
        "text": "models ([String]): an array of each model's name"
      },
      {
        "heading": "syncQueriesReady",
        "depth": 2,
        "text": "Dispatched when all models have been synced from the cloud"
      },
      {
        "heading": "syncQueriesReady",
        "depth": 2,
        "text": "HubPayload: N/A"
      },
      {
        "heading": "ready",
        "depth": 2,
        "text": "Dispatched when DataStore as a whole is ready, at this point all data is available"
      },
      {
        "heading": "ready",
        "depth": 2,
        "text": "HubPayload: N/A"
      },
      {
        "heading": "outboxStatus",
        "depth": 2,
        "text": "Dispatched when:"
      },
      {
        "heading": "outboxStatus",
        "depth": 2,
        "text": "the DataStore starts"
      },
      {
        "heading": "outboxStatus",
        "depth": 2,
        "text": "each time a local mutation is enqueued into the outbox"
      },
      {
        "heading": "outboxStatus",
        "depth": 2,
        "text": "each time a local mutation is finished processing"
      },
      {
        "heading": "outboxStatus",
        "depth": 2,
        "text": "HubPayload OutboxStatusEvent contains:"
      },
      {
        "heading": "outboxStatus",
        "depth": 2,
        "text": "isEmpty (Bool): a boolean value indicating that there are no local changes still pending upload to the Cloud"
      },
      {
        "heading": "Usage",
        "depth": 2,
        "text": "To see if the network status is active, you could set up the following listener:"
      }
    ],
    "source": "export const meta = {\n  title: `DataStore Events`,\n  description: `Listening to DataStore events`,\n};\n\nDataStore periodically publishes state notifications onto Amplify's Hub. You can subscribe to the Hub to gain insight into the internal state of the DataStore. Events are published when:\n* Your device loses or regains network connectivity;\n* Data is synchronized with the Cloud;\n* There are new, pending changes that have not yet been synchronized.\n\nThe following DataStore events are defined:\n\n## networkStatus\n\nDispatched when DataStore starts and every time network status changes\n\nHubPayload `NetworkStatusEvent` contains:\n- `active` (Bool): true if the DataStore is on a network that can connect the Cloud; false, otherwise\n\n## subscriptionsEstablished\n\nDispatched when DataStore has finished establishing its subscriptions to all models\n\nHubPayload: N/A\n\n## syncQueriesStarted\n\nDispatched when DataStore is about to perform its initial sync queries\n\nHubPayload `syncQueriesStartedEvent` contains:\n- `models` ([String]): an array of each model's `name`\n\nimport js0 from \"/src/fragments/lib/datastore/js/datastore-events/model-synced.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/datastore-events/model-synced.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/datastore-events/model-synced.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport ios3 from \"/src/fragments/lib/datastore/native_common/datastore-events/model-synced.mdx\";\n\n<Fragments fragments={{ios: ios3}} />\n\n## syncQueriesReady\n\nDispatched when all models have been synced from the cloud\n\nHubPayload: N/A\n\n## ready\n\nDispatched when DataStore as a whole is ready, at this point all data is available\n\nHubPayload: N/A\n\nimport js4 from \"/src/fragments/lib/datastore/js/datastore-events/outbox-mutation-enqueued.mdx\";\n\n<Fragments fragments={{js: js4}} />\n\nimport android5 from \"/src/fragments/lib/datastore/native_common/datastore-events/outbox-mutation-enqueued.mdx\";\n\n<Fragments fragments={{android: android5}} />\n\nimport flutter6 from \"/src/fragments/lib/datastore/native_common/datastore-events/outbox-mutation-enqueued.mdx\";\n\n<Fragments fragments={{flutter: flutter6}} />\n\nimport ios7 from \"/src/fragments/lib/datastore/native_common/datastore-events/outbox-mutation-enqueued.mdx\";\n\n<Fragments fragments={{ios: ios7}} />\n\nimport js8 from \"/src/fragments/lib/datastore/js/datastore-events/outbox-mutation-processed.mdx\";\n\n<Fragments fragments={{js: js8}} />\n\nimport android9 from \"/src/fragments/lib/datastore/native_common/datastore-events/outbox-mutation-processed.mdx\";\n\n<Fragments fragments={{android: android9}} />\n\nimport flutter10 from \"/src/fragments/lib/datastore/native_common/datastore-events/outbox-mutation-processed.mdx\";\n\n<Fragments fragments={{flutter: flutter10}} />\n\nimport ios11 from \"/src/fragments/lib/datastore/native_common/datastore-events/outbox-mutation-processed.mdx\";\n\n<Fragments fragments={{ios: ios11}} />\n\nimport android12 from \"/src/fragments/lib/datastore/android/datastore-events/outbox-mutation-failed.mdx\";\n\n<Fragments fragments={{android: android12}} />\n\n## outboxStatus\n\nDispatched when:\n- the DataStore starts\n- each time a local mutation is enqueued into the outbox\n- each time a local mutation is finished processing\n\nHubPayload `OutboxStatusEvent` contains:\n- `isEmpty` (Bool): a boolean value indicating that there are no local changes still pending upload to the Cloud\n\n## Usage\nTo see if the network status is active, you could set up the following listener:\n\nimport js13 from \"/src/fragments/lib/datastore/js/datastore-events.mdx\";\n\n<Fragments fragments={{js: js13}} />\n\nimport android14 from \"/src/fragments/lib/datastore/android/datastore-events.mdx\";\n\n<Fragments fragments={{android: android14}} />\n\nimport ios15 from \"/src/fragments/lib/datastore/ios/datastore-events.mdx\";\n\n<Fragments fragments={{ios: ios15}} />\n\nimport flutter16 from \"/src/fragments/lib/datastore/flutter/datastore-events.mdx\";\n\n<Fragments fragments={{flutter: flutter16}} />\n",
    "meta": {
      "title": "DataStore Events - Flutter",
      "description": "Listening to DataStore events - Flutter",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/datastore-events/q/platform/flutter"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "DataStore periodically publishes state notifications onto Amplify's Hub. You can subscribe to the Hub to gain insight into the internal state of the DataStore. Events are published when:"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Your device loses or regains network connectivity;"
      },
      {
        "heading": null,
        "depth": null,
        "text": "Data is synchronized with the Cloud;"
      },
      {
        "heading": null,
        "depth": null,
        "text": "There are new, pending changes that have not yet been synchronized."
      },
      {
        "heading": null,
        "depth": null,
        "text": "The following DataStore events are defined:"
      },
      {
        "heading": "networkStatus",
        "depth": 2,
        "text": "Dispatched when DataStore starts and every time network status changes"
      },
      {
        "heading": "networkStatus",
        "depth": 2,
        "text": "HubPayload NetworkStatusEvent contains:"
      },
      {
        "heading": "networkStatus",
        "depth": 2,
        "text": "active (Bool): true if the DataStore is on a network that can connect the Cloud; false, otherwise"
      },
      {
        "heading": "subscriptionsEstablished",
        "depth": 2,
        "text": "Dispatched when DataStore has finished establishing its subscriptions to all models"
      },
      {
        "heading": "subscriptionsEstablished",
        "depth": 2,
        "text": "HubPayload: N/A"
      },
      {
        "heading": "syncQueriesStarted",
        "depth": 2,
        "text": "Dispatched when DataStore is about to perform its initial sync queries"
      },
      {
        "heading": "syncQueriesStarted",
        "depth": 2,
        "text": "HubPayload syncQueriesStartedEvent contains:"
      },
      {
        "heading": "syncQueriesStarted",
        "depth": 2,
        "text": "models ([String]): an array of each model's name"
      },
      {
        "heading": "syncQueriesReady",
        "depth": 2,
        "text": "Dispatched when all models have been synced from the cloud"
      },
      {
        "heading": "syncQueriesReady",
        "depth": 2,
        "text": "HubPayload: N/A"
      },
      {
        "heading": "ready",
        "depth": 2,
        "text": "Dispatched when DataStore as a whole is ready, at this point all data is available"
      },
      {
        "heading": "ready",
        "depth": 2,
        "text": "HubPayload: N/A"
      },
      {
        "heading": "outboxStatus",
        "depth": 2,
        "text": "Dispatched when:"
      },
      {
        "heading": "outboxStatus",
        "depth": 2,
        "text": "the DataStore starts"
      },
      {
        "heading": "outboxStatus",
        "depth": 2,
        "text": "each time a local mutation is enqueued into the outbox"
      },
      {
        "heading": "outboxStatus",
        "depth": 2,
        "text": "each time a local mutation is finished processing"
      },
      {
        "heading": "outboxStatus",
        "depth": 2,
        "text": "HubPayload OutboxStatusEvent contains:"
      },
      {
        "heading": "outboxStatus",
        "depth": 2,
        "text": "isEmpty (Bool): a boolean value indicating that there are no local changes still pending upload to the Cloud"
      },
      {
        "heading": "Usage",
        "depth": 2,
        "text": "To see if the network status is active, you could set up the following listener:"
      }
    ],
    "source": "export const meta = {\n  title: `DataStore Events`,\n  description: `Listening to DataStore events`,\n};\n\nDataStore periodically publishes state notifications onto Amplify's Hub. You can subscribe to the Hub to gain insight into the internal state of the DataStore. Events are published when:\n* Your device loses or regains network connectivity;\n* Data is synchronized with the Cloud;\n* There are new, pending changes that have not yet been synchronized.\n\nThe following DataStore events are defined:\n\n## networkStatus\n\nDispatched when DataStore starts and every time network status changes\n\nHubPayload `NetworkStatusEvent` contains:\n- `active` (Bool): true if the DataStore is on a network that can connect the Cloud; false, otherwise\n\n## subscriptionsEstablished\n\nDispatched when DataStore has finished establishing its subscriptions to all models\n\nHubPayload: N/A\n\n## syncQueriesStarted\n\nDispatched when DataStore is about to perform its initial sync queries\n\nHubPayload `syncQueriesStartedEvent` contains:\n- `models` ([String]): an array of each model's `name`\n\nimport js0 from \"/src/fragments/lib/datastore/js/datastore-events/model-synced.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/datastore-events/model-synced.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/datastore-events/model-synced.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport ios3 from \"/src/fragments/lib/datastore/native_common/datastore-events/model-synced.mdx\";\n\n<Fragments fragments={{ios: ios3}} />\n\n## syncQueriesReady\n\nDispatched when all models have been synced from the cloud\n\nHubPayload: N/A\n\n## ready\n\nDispatched when DataStore as a whole is ready, at this point all data is available\n\nHubPayload: N/A\n\nimport js4 from \"/src/fragments/lib/datastore/js/datastore-events/outbox-mutation-enqueued.mdx\";\n\n<Fragments fragments={{js: js4}} />\n\nimport android5 from \"/src/fragments/lib/datastore/native_common/datastore-events/outbox-mutation-enqueued.mdx\";\n\n<Fragments fragments={{android: android5}} />\n\nimport flutter6 from \"/src/fragments/lib/datastore/native_common/datastore-events/outbox-mutation-enqueued.mdx\";\n\n<Fragments fragments={{flutter: flutter6}} />\n\nimport ios7 from \"/src/fragments/lib/datastore/native_common/datastore-events/outbox-mutation-enqueued.mdx\";\n\n<Fragments fragments={{ios: ios7}} />\n\nimport js8 from \"/src/fragments/lib/datastore/js/datastore-events/outbox-mutation-processed.mdx\";\n\n<Fragments fragments={{js: js8}} />\n\nimport android9 from \"/src/fragments/lib/datastore/native_common/datastore-events/outbox-mutation-processed.mdx\";\n\n<Fragments fragments={{android: android9}} />\n\nimport flutter10 from \"/src/fragments/lib/datastore/native_common/datastore-events/outbox-mutation-processed.mdx\";\n\n<Fragments fragments={{flutter: flutter10}} />\n\nimport ios11 from \"/src/fragments/lib/datastore/native_common/datastore-events/outbox-mutation-processed.mdx\";\n\n<Fragments fragments={{ios: ios11}} />\n\nimport android12 from \"/src/fragments/lib/datastore/android/datastore-events/outbox-mutation-failed.mdx\";\n\n<Fragments fragments={{android: android12}} />\n\n## outboxStatus\n\nDispatched when:\n- the DataStore starts\n- each time a local mutation is enqueued into the outbox\n- each time a local mutation is finished processing\n\nHubPayload `OutboxStatusEvent` contains:\n- `isEmpty` (Bool): a boolean value indicating that there are no local changes still pending upload to the Cloud\n\n## Usage\nTo see if the network status is active, you could set up the following listener:\n\nimport js13 from \"/src/fragments/lib/datastore/js/datastore-events.mdx\";\n\n<Fragments fragments={{js: js13}} />\n\nimport android14 from \"/src/fragments/lib/datastore/android/datastore-events.mdx\";\n\n<Fragments fragments={{android: android14}} />\n\nimport ios15 from \"/src/fragments/lib/datastore/ios/datastore-events.mdx\";\n\n<Fragments fragments={{ios: ios15}} />\n\nimport flutter16 from \"/src/fragments/lib/datastore/flutter/datastore-events.mdx\";\n\n<Fragments fragments={{flutter: flutter16}} />\n",
    "meta": {
      "title": "DataStore Events - Android",
      "description": "Listening to DataStore events - Android",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/datastore-events/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Real time`,\n  description: `Learn more about how DataStore handles data changes in real-time.`,\n};\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/real-time.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/real-time.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/real-time.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/real-time.mdx\";\n\n<Fragments fragments={{js: js3}} />\n\n",
    "meta": {
      "title": "Real time - JavaScript",
      "description": "Learn more about how DataStore handles data changes in real-time. - JavaScript",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/real-time/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Real time`,\n  description: `Learn more about how DataStore handles data changes in real-time.`,\n};\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/real-time.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/real-time.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/real-time.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/real-time.mdx\";\n\n<Fragments fragments={{js: js3}} />\n\n",
    "meta": {
      "title": "Real time - iOS",
      "description": "Learn more about how DataStore handles data changes in real-time. - iOS",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/real-time/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Real time`,\n  description: `Learn more about how DataStore handles data changes in real-time.`,\n};\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/real-time.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/real-time.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/real-time.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/real-time.mdx\";\n\n<Fragments fragments={{js: js3}} />\n\n",
    "meta": {
      "title": "Real time - Flutter",
      "description": "Learn more about how DataStore handles data changes in real-time. - Flutter",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/real-time/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Real time`,\n  description: `Learn more about how DataStore handles data changes in real-time.`,\n};\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/real-time.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/real-time.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/real-time.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/real-time.mdx\";\n\n<Fragments fragments={{js: js3}} />\n\n",
    "meta": {
      "title": "Real time - Android",
      "description": "Learn more about how DataStore handles data changes in real-time. - Android",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/real-time/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Conflict resolution`,\n  description: `Learn more about how conflict resolution in DataStore is managed and how to configure it.`,\n};\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/conflict.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/conflict.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/conflict.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/conflict.mdx\";\n\n<Fragments fragments={{js: js3}} />",
    "meta": {
      "title": "Conflict resolution - JavaScript",
      "description": "Learn more about how conflict resolution in DataStore is managed and how to configure it. - JavaScript",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/conflict/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Conflict resolution`,\n  description: `Learn more about how conflict resolution in DataStore is managed and how to configure it.`,\n};\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/conflict.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/conflict.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/conflict.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/conflict.mdx\";\n\n<Fragments fragments={{js: js3}} />",
    "meta": {
      "title": "Conflict resolution - iOS",
      "description": "Learn more about how conflict resolution in DataStore is managed and how to configure it. - iOS",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/conflict/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Conflict resolution`,\n  description: `Learn more about how conflict resolution in DataStore is managed and how to configure it.`,\n};\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/conflict.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/conflict.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/conflict.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/conflict.mdx\";\n\n<Fragments fragments={{js: js3}} />",
    "meta": {
      "title": "Conflict resolution - Flutter",
      "description": "Learn more about how conflict resolution in DataStore is managed and how to configure it. - Flutter",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/conflict/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Conflict resolution`,\n  description: `Learn more about how conflict resolution in DataStore is managed and how to configure it.`,\n};\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/conflict.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/conflict.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/conflict.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/conflict.mdx\";\n\n<Fragments fragments={{js: js3}} />",
    "meta": {
      "title": "Conflict resolution - Android",
      "description": "Learn more about how conflict resolution in DataStore is managed and how to configure it. - Android",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/conflict/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Setup authorization rules`,\n  description: `Learn how to apply authorization rules to your models with the @auth directive`,\n};\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/setup-auth-rules.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/setup-auth-rules.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/setup-auth-rules.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/setup-auth-rules.mdx\";\n\n<Fragments fragments={{js: js3}} />\n",
    "meta": {
      "title": "Setup authorization rules - JavaScript",
      "description": "Learn how to apply authorization rules to your models with the @auth directive - JavaScript",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/setup-auth-rules/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Setup authorization rules`,\n  description: `Learn how to apply authorization rules to your models with the @auth directive`,\n};\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/setup-auth-rules.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/setup-auth-rules.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/setup-auth-rules.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/setup-auth-rules.mdx\";\n\n<Fragments fragments={{js: js3}} />\n",
    "meta": {
      "title": "Setup authorization rules - iOS",
      "description": "Learn how to apply authorization rules to your models with the @auth directive - iOS",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/setup-auth-rules/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Setup authorization rules`,\n  description: `Learn how to apply authorization rules to your models with the @auth directive`,\n};\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/setup-auth-rules.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/setup-auth-rules.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/setup-auth-rules.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/setup-auth-rules.mdx\";\n\n<Fragments fragments={{js: js3}} />\n",
    "meta": {
      "title": "Setup authorization rules - Flutter",
      "description": "Learn how to apply authorization rules to your models with the @auth directive - Flutter",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/setup-auth-rules/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Setup authorization rules`,\n  description: `Learn how to apply authorization rules to your models with the @auth directive`,\n};\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/setup-auth-rules.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/setup-auth-rules.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/setup-auth-rules.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/setup-auth-rules.mdx\";\n\n<Fragments fragments={{js: js3}} />\n",
    "meta": {
      "title": "Setup authorization rules - Android",
      "description": "Learn how to apply authorization rules to your models with the @auth directive - Android",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/setup-auth-rules/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Syncing data to cloud`,\n  description: `Learn more about how DataStore connects to an AppSync backend and automatically syncs all locally saved data using GraphQL.`,\n};\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/sync.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/sync.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/sync.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/sync.mdx\";\n\n<Fragments fragments={{js: js3}} />",
    "meta": {
      "title": "Syncing data to cloud - JavaScript",
      "description": "Learn more about how DataStore connects to an AppSync backend and automatically syncs all locally saved data using GraphQL. - JavaScript",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/sync/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Syncing data to cloud`,\n  description: `Learn more about how DataStore connects to an AppSync backend and automatically syncs all locally saved data using GraphQL.`,\n};\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/sync.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/sync.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/sync.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/sync.mdx\";\n\n<Fragments fragments={{js: js3}} />",
    "meta": {
      "title": "Syncing data to cloud - iOS",
      "description": "Learn more about how DataStore connects to an AppSync backend and automatically syncs all locally saved data using GraphQL. - iOS",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/sync/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Syncing data to cloud`,\n  description: `Learn more about how DataStore connects to an AppSync backend and automatically syncs all locally saved data using GraphQL.`,\n};\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/sync.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/sync.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/sync.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/sync.mdx\";\n\n<Fragments fragments={{js: js3}} />",
    "meta": {
      "title": "Syncing data to cloud - Flutter",
      "description": "Learn more about how DataStore connects to an AppSync backend and automatically syncs all locally saved data using GraphQL. - Flutter",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/sync/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Syncing data to cloud`,\n  description: `Learn more about how DataStore connects to an AppSync backend and automatically syncs all locally saved data using GraphQL.`,\n};\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/sync.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/sync.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/sync.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/sync.mdx\";\n\n<Fragments fragments={{js: js3}} />",
    "meta": {
      "title": "Syncing data to cloud - Android",
      "description": "Learn more about how DataStore connects to an AppSync backend and automatically syncs all locally saved data using GraphQL. - Android",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/sync/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Relational models`,\n  description: `Learn more about how DataStore handles relationships between Models, such as \"has one\", \"has many\", \"belongs to\".`,\n};\n\nimport gqlv2callout from \"/src/fragments/cli/gqlv2callout.mdx\";\n\n<Fragments fragments={{all: gqlv2callout}} />\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/relational.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/relational.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/relational.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/relational.mdx\";\n\n<Fragments fragments={{js: js3}} />",
    "meta": {
      "title": "Relational models - JavaScript",
      "description": "Learn more about how DataStore handles relationships between Models, such as \"has one\", \"has many\", \"belongs to\". - JavaScript",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/relational/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Relational models`,\n  description: `Learn more about how DataStore handles relationships between Models, such as \"has one\", \"has many\", \"belongs to\".`,\n};\n\nimport gqlv2callout from \"/src/fragments/cli/gqlv2callout.mdx\";\n\n<Fragments fragments={{all: gqlv2callout}} />\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/relational.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/relational.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/relational.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/relational.mdx\";\n\n<Fragments fragments={{js: js3}} />",
    "meta": {
      "title": "Relational models - iOS",
      "description": "Learn more about how DataStore handles relationships between Models, such as \"has one\", \"has many\", \"belongs to\". - iOS",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/relational/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Relational models`,\n  description: `Learn more about how DataStore handles relationships between Models, such as \"has one\", \"has many\", \"belongs to\".`,\n};\n\nimport gqlv2callout from \"/src/fragments/cli/gqlv2callout.mdx\";\n\n<Fragments fragments={{all: gqlv2callout}} />\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/relational.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/relational.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/relational.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/relational.mdx\";\n\n<Fragments fragments={{js: js3}} />",
    "meta": {
      "title": "Relational models - Flutter",
      "description": "Learn more about how DataStore handles relationships between Models, such as \"has one\", \"has many\", \"belongs to\". - Flutter",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/relational/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Relational models`,\n  description: `Learn more about how DataStore handles relationships between Models, such as \"has one\", \"has many\", \"belongs to\".`,\n};\n\nimport gqlv2callout from \"/src/fragments/cli/gqlv2callout.mdx\";\n\n<Fragments fragments={{all: gqlv2callout}} />\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/relational.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/relational.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/relational.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/relational.mdx\";\n\n<Fragments fragments={{js: js3}} />",
    "meta": {
      "title": "Relational models - Android",
      "description": "Learn more about how DataStore handles relationships between Models, such as \"has one\", \"has many\", \"belongs to\". - Android",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/relational/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Manipulating data`,\n  description: `Learn how to save, query, paginate, update, delete and observe data in DataStore.`,\n};\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/data-access.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/data-access.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/data-access.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/data-access.mdx\";\n\n<Fragments fragments={{js: js3}} />",
    "meta": {
      "title": "Manipulating data - JavaScript",
      "description": "Learn how to save, query, paginate, update, delete and observe data in DataStore. - JavaScript",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/data-access/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Manipulating data`,\n  description: `Learn how to save, query, paginate, update, delete and observe data in DataStore.`,\n};\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/data-access.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/data-access.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/data-access.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/data-access.mdx\";\n\n<Fragments fragments={{js: js3}} />",
    "meta": {
      "title": "Manipulating data - iOS",
      "description": "Learn how to save, query, paginate, update, delete and observe data in DataStore. - iOS",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/data-access/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Manipulating data`,\n  description: `Learn how to save, query, paginate, update, delete and observe data in DataStore.`,\n};\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/data-access.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/data-access.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/data-access.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/data-access.mdx\";\n\n<Fragments fragments={{js: js3}} />",
    "meta": {
      "title": "Manipulating data - Flutter",
      "description": "Learn how to save, query, paginate, update, delete and observe data in DataStore. - Flutter",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/data-access/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Manipulating data`,\n  description: `Learn how to save, query, paginate, update, delete and observe data in DataStore.`,\n};\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/data-access.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/data-access.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/data-access.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/data-access.mdx\";\n\n<Fragments fragments={{js: js3}} />",
    "meta": {
      "title": "Manipulating data - Android",
      "description": "Learn how to save, query, paginate, update, delete and observe data in DataStore. - Android",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/data-access/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `Amplify DataStore provides a programming model for leveraging shared and distributed data without writing additional code for offline and online scenarios, which makes working with distributed, cross-user data just as simple as working with local-only data.`,\n};\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/getting-started.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/getting-started.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/getting-started.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/getting-started.mdx\";\n\n<Fragments fragments={{js: js3}} />",
    "meta": {
      "title": "Getting started - JavaScript",
      "description": "Amplify DataStore provides a programming model for leveraging shared and distributed data without writing additional code for offline and online scenarios, which makes working with distributed, cross-user data just as simple as working with local-only data. - JavaScript",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/getting-started/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `Amplify DataStore provides a programming model for leveraging shared and distributed data without writing additional code for offline and online scenarios, which makes working with distributed, cross-user data just as simple as working with local-only data.`,\n};\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/getting-started.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/getting-started.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/getting-started.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/getting-started.mdx\";\n\n<Fragments fragments={{js: js3}} />",
    "meta": {
      "title": "Getting started - iOS",
      "description": "Amplify DataStore provides a programming model for leveraging shared and distributed data without writing additional code for offline and online scenarios, which makes working with distributed, cross-user data just as simple as working with local-only data. - iOS",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/getting-started/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `Amplify DataStore provides a programming model for leveraging shared and distributed data without writing additional code for offline and online scenarios, which makes working with distributed, cross-user data just as simple as working with local-only data.`,\n};\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/getting-started.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/getting-started.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/getting-started.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/getting-started.mdx\";\n\n<Fragments fragments={{js: js3}} />",
    "meta": {
      "title": "Getting started - Flutter",
      "description": "Amplify DataStore provides a programming model for leveraging shared and distributed data without writing additional code for offline and online scenarios, which makes working with distributed, cross-user data just as simple as working with local-only data. - Flutter",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/getting-started/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `Amplify DataStore provides a programming model for leveraging shared and distributed data without writing additional code for offline and online scenarios, which makes working with distributed, cross-user data just as simple as working with local-only data.`,\n};\n\nimport ios0 from \"/src/fragments/lib/datastore/native_common/getting-started.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/datastore/native_common/getting-started.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/datastore/native_common/getting-started.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport js3 from \"/src/fragments/lib/datastore/native_common/getting-started.mdx\";\n\n<Fragments fragments={{js: js3}} />",
    "meta": {
      "title": "Getting started - Android",
      "description": "Amplify DataStore provides a programming model for leveraging shared and distributed data without writing additional code for offline and online scenarios, which makes working with distributed, cross-user data just as simple as working with local-only data. - Android",
      "subcategory": "DataStore",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/datastore/getting-started/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Use existing Amazon Cognito resources`,\n  description: `Configure the Amplify Libraries to use existing Amazon Cognito resources by referencing them in your configuration.`,\n};\n\nimport android0 from \"/src/fragments/lib/auth/existing-resources.mdx\";\n\n<Fragments fragments={{android: android0}} />\n\nimport ios1 from \"/src/fragments/lib/auth/existing-resources.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport flutter2 from \"/src/fragments/lib/auth/existing-resources.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n",
    "meta": {
      "title": "Use existing Amazon Cognito resources - iOS",
      "description": "Configure the Amplify Libraries to use existing Amazon Cognito resources by referencing them in your configuration. - iOS",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/existing-resources/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Use existing Amazon Cognito resources`,\n  description: `Configure the Amplify Libraries to use existing Amazon Cognito resources by referencing them in your configuration.`,\n};\n\nimport android0 from \"/src/fragments/lib/auth/existing-resources.mdx\";\n\n<Fragments fragments={{android: android0}} />\n\nimport ios1 from \"/src/fragments/lib/auth/existing-resources.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport flutter2 from \"/src/fragments/lib/auth/existing-resources.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n",
    "meta": {
      "title": "Use existing Amazon Cognito resources - Flutter",
      "description": "Configure the Amplify Libraries to use existing Amazon Cognito resources by referencing them in your configuration. - Flutter",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/existing-resources/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Use existing Amazon Cognito resources`,\n  description: `Configure the Amplify Libraries to use existing Amazon Cognito resources by referencing them in your configuration.`,\n};\n\nimport android0 from \"/src/fragments/lib/auth/existing-resources.mdx\";\n\n<Fragments fragments={{android: android0}} />\n\nimport ios1 from \"/src/fragments/lib/auth/existing-resources.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport flutter2 from \"/src/fragments/lib/auth/existing-resources.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n",
    "meta": {
      "title": "Use existing Amazon Cognito resources - Android",
      "description": "Configure the Amplify Libraries to use existing Amazon Cognito resources by referencing them in your configuration. - Android",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/existing-resources/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Under the hood`,\n  description: `Learn more about the foundational auth concepts for cloud-based application and how they work with Amplify Framework.`,\n};\n\nimport js0 from \"/src/fragments/lib/auth/js/overview.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/auth/common/overview.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/auth/common/overview.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Under the hood - JavaScript",
      "description": "Learn more about the foundational auth concepts for cloud-based application and how they work with Amplify Framework. - JavaScript",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/overview/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Under the hood`,\n  description: `Learn more about the foundational auth concepts for cloud-based application and how they work with Amplify Framework.`,\n};\n\nimport js0 from \"/src/fragments/lib/auth/js/overview.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/auth/common/overview.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/auth/common/overview.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Under the hood - iOS",
      "description": "Learn more about the foundational auth concepts for cloud-based application and how they work with Amplify Framework. - iOS",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/overview/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Under the hood`,\n  description: `Learn more about the foundational auth concepts for cloud-based application and how they work with Amplify Framework.`,\n};\n\nimport js0 from \"/src/fragments/lib/auth/js/overview.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/auth/common/overview.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/auth/common/overview.mdx\";\n\n<Fragments fragments={{android: android2}} />\n",
    "meta": {
      "title": "Under the hood - Android",
      "description": "Learn more about the foundational auth concepts for cloud-based application and how they work with Amplify Framework. - Android",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/overview/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Escape hatch`,\n  description: `Underlying service`,\n};\n\nimport ios0 from \"/src/fragments/lib/auth/native_common/escape_hatch/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/auth/native_common/escape_hatch/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n",
    "meta": {
      "title": "Escape hatch - iOS",
      "description": "Underlying service - iOS",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/escapehatch/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Escape hatch`,\n  description: `Underlying service`,\n};\n\nimport ios0 from \"/src/fragments/lib/auth/native_common/escape_hatch/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/auth/native_common/escape_hatch/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n",
    "meta": {
      "title": "Escape hatch - Android",
      "description": "Underlying service - Android",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/escapehatch/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Delete user`,\n  description: `Delete a user`\n};\n\nimport ios0 from '/src/fragments/lib/auth/native_common/delete_user/common.mdx';\n\n<Fragments fragments={{ ios: ios0 }} />\n\nimport flutter1 from '/src/fragments/lib/auth/native_common/delete_user/common.mdx';\n\n<Fragments fragments={{ flutter: flutter1 }} />\n\nimport javascript2 from '/src/fragments/lib/auth/js/delete_user.mdx';\n\n<Fragments fragments = {{ js: javascript2 }}/>\n\nimport android3 from '/src/fragments/lib/auth/native_common/delete_user/common.mdx';\n\n<Fragments fragments={{ android: android3 }} />\n",
    "meta": {
      "title": "Delete user - JavaScript",
      "description": "Delete a user - JavaScript",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/delete_user/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Delete user`,\n  description: `Delete a user`\n};\n\nimport ios0 from '/src/fragments/lib/auth/native_common/delete_user/common.mdx';\n\n<Fragments fragments={{ ios: ios0 }} />\n\nimport flutter1 from '/src/fragments/lib/auth/native_common/delete_user/common.mdx';\n\n<Fragments fragments={{ flutter: flutter1 }} />\n\nimport javascript2 from '/src/fragments/lib/auth/js/delete_user.mdx';\n\n<Fragments fragments = {{ js: javascript2 }}/>\n\nimport android3 from '/src/fragments/lib/auth/native_common/delete_user/common.mdx';\n\n<Fragments fragments={{ android: android3 }} />\n",
    "meta": {
      "title": "Delete user - iOS",
      "description": "Delete a user - iOS",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/delete_user/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Delete user`,\n  description: `Delete a user`\n};\n\nimport ios0 from '/src/fragments/lib/auth/native_common/delete_user/common.mdx';\n\n<Fragments fragments={{ ios: ios0 }} />\n\nimport flutter1 from '/src/fragments/lib/auth/native_common/delete_user/common.mdx';\n\n<Fragments fragments={{ flutter: flutter1 }} />\n\nimport javascript2 from '/src/fragments/lib/auth/js/delete_user.mdx';\n\n<Fragments fragments = {{ js: javascript2 }}/>\n\nimport android3 from '/src/fragments/lib/auth/native_common/delete_user/common.mdx';\n\n<Fragments fragments={{ android: android3 }} />\n",
    "meta": {
      "title": "Delete user - Flutter",
      "description": "Delete a user - Flutter",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/delete_user/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Delete user`,\n  description: `Delete a user`\n};\n\nimport ios0 from '/src/fragments/lib/auth/native_common/delete_user/common.mdx';\n\n<Fragments fragments={{ ios: ios0 }} />\n\nimport flutter1 from '/src/fragments/lib/auth/native_common/delete_user/common.mdx';\n\n<Fragments fragments={{ flutter: flutter1 }} />\n\nimport javascript2 from '/src/fragments/lib/auth/js/delete_user.mdx';\n\n<Fragments fragments = {{ js: javascript2 }}/>\n\nimport android3 from '/src/fragments/lib/auth/native_common/delete_user/common.mdx';\n\n<Fragments fragments={{ android: android3 }} />\n",
    "meta": {
      "title": "Delete user - Android",
      "description": "Delete a user - Android",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/delete_user/q/platform/android"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "The Amplify Auth category persists authentication-related information to make it available to other Amplify categories and to your application."
      }
    ],
    "source": "export const meta = {\n  title: `Managing credentials`,\n  description: `Learn how to customize credential storage.`,\n};\n\nThe Amplify Auth category persists authentication-related information to make it available to other Amplify categories and to your application.\n\nimport flutter0 from \"/src/fragments/lib/auth/flutter/managing_credentials/10_managing_credentials.mdx\";\n\n<Fragments fragments={{flutter: flutter0}} />",
    "meta": {
      "title": "Managing credentials - Flutter",
      "description": "Learn how to customize credential storage. - Flutter",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/managing_credentials/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Accessing credentials`,\n  description: `Use AWS Cognito Auth plugin to access auth credentials`,\n};\n\nimport ios0 from \"/src/fragments/lib/auth/native_common/access_credentials/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/auth/native_common/access_credentials/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/auth/native_common/access_credentials/common.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n",
    "meta": {
      "title": "Accessing credentials - iOS",
      "description": "Use AWS Cognito Auth plugin to access auth credentials - iOS",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/access_credentials/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Accessing credentials`,\n  description: `Use AWS Cognito Auth plugin to access auth credentials`,\n};\n\nimport ios0 from \"/src/fragments/lib/auth/native_common/access_credentials/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/auth/native_common/access_credentials/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/auth/native_common/access_credentials/common.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n",
    "meta": {
      "title": "Accessing credentials - Flutter",
      "description": "Use AWS Cognito Auth plugin to access auth credentials - Flutter",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/access_credentials/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Accessing credentials`,\n  description: `Use AWS Cognito Auth plugin to access auth credentials`,\n};\n\nimport ios0 from \"/src/fragments/lib/auth/native_common/access_credentials/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/auth/native_common/access_credentials/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/auth/native_common/access_credentials/common.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n",
    "meta": {
      "title": "Accessing credentials - Android",
      "description": "Use AWS Cognito Auth plugin to access auth credentials - Android",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/access_credentials/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Sign out`,\n  description: `SignOut a user`,\n};\n\nimport ios0 from \"/src/fragments/lib/auth/native_common/signout/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/auth/native_common/signout/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/auth/native_common/signout/common.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n",
    "meta": {
      "title": "Sign out - iOS",
      "description": "SignOut a user - iOS",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/signOut/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Sign out`,\n  description: `SignOut a user`,\n};\n\nimport ios0 from \"/src/fragments/lib/auth/native_common/signout/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/auth/native_common/signout/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/auth/native_common/signout/common.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n",
    "meta": {
      "title": "Sign out - Flutter",
      "description": "SignOut a user - Flutter",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/signOut/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Sign out`,\n  description: `SignOut a user`,\n};\n\nimport ios0 from \"/src/fragments/lib/auth/native_common/signout/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/auth/native_common/signout/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/auth/native_common/signout/common.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n",
    "meta": {
      "title": "Sign out - Android",
      "description": "SignOut a user - Android",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/signOut/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Password management`,\n  description: `Use AWS Cognito Auth plugin to update or reset user password`,\n};\n\nimport ios0 from \"/src/fragments/lib/auth/native_common/password_management/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/auth/native_common/password_management/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/auth/native_common/password_management/common.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n",
    "meta": {
      "title": "Password management - iOS",
      "description": "Use AWS Cognito Auth plugin to update or reset user password - iOS",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/password_management/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Password management`,\n  description: `Use AWS Cognito Auth plugin to update or reset user password`,\n};\n\nimport ios0 from \"/src/fragments/lib/auth/native_common/password_management/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/auth/native_common/password_management/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/auth/native_common/password_management/common.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n",
    "meta": {
      "title": "Password management - Flutter",
      "description": "Use AWS Cognito Auth plugin to update or reset user password - Flutter",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/password_management/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Password management`,\n  description: `Use AWS Cognito Auth plugin to update or reset user password`,\n};\n\nimport ios0 from \"/src/fragments/lib/auth/native_common/password_management/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/auth/native_common/password_management/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/auth/native_common/password_management/common.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n",
    "meta": {
      "title": "Password management - Android",
      "description": "Use AWS Cognito Auth plugin to update or reset user password - Android",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/password_management/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Remember a device`,\n  description: `You can use the device related features of Amazon Cognito UserPools by enabling the Devices features. Go to your Cognito UserPool, click on Devices in Left Navigation Menu and chose one of User Opt In or Always.`,\n};\n\nimport js0 from \"/src/fragments/lib/auth/common/device_features/common.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/auth/common/device_features/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/auth/common/device_features/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/auth/common/device_features/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Remember a device - Flutter",
      "description": "You can use the device related features of Amazon Cognito UserPools by enabling the Devices features. Go to your Cognito UserPool, click on Devices in Left Navigation Menu and chose one of User Opt In or Always. - Flutter",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/device_features/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Remember a device`,\n  description: `You can use the device related features of Amazon Cognito UserPools by enabling the Devices features. Go to your Cognito UserPool, click on Devices in Left Navigation Menu and chose one of User Opt In or Always.`,\n};\n\nimport js0 from \"/src/fragments/lib/auth/common/device_features/common.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/auth/common/device_features/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/auth/common/device_features/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/auth/common/device_features/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Remember a device - JavaScript",
      "description": "You can use the device related features of Amazon Cognito UserPools by enabling the Devices features. Go to your Cognito UserPool, click on Devices in Left Navigation Menu and chose one of User Opt In or Always. - JavaScript",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/device_features/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Remember a device`,\n  description: `You can use the device related features of Amazon Cognito UserPools by enabling the Devices features. Go to your Cognito UserPool, click on Devices in Left Navigation Menu and chose one of User Opt In or Always.`,\n};\n\nimport js0 from \"/src/fragments/lib/auth/common/device_features/common.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/auth/common/device_features/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/auth/common/device_features/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/auth/common/device_features/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Remember a device - iOS",
      "description": "You can use the device related features of Amazon Cognito UserPools by enabling the Devices features. Go to your Cognito UserPool, click on Devices in Left Navigation Menu and chose one of User Opt In or Always. - iOS",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/device_features/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Remember a device`,\n  description: `You can use the device related features of Amazon Cognito UserPools by enabling the Devices features. Go to your Cognito UserPool, click on Devices in Left Navigation Menu and chose one of User Opt In or Always.`,\n};\n\nimport js0 from \"/src/fragments/lib/auth/common/device_features/common.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/auth/common/device_features/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/auth/common/device_features/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/auth/common/device_features/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Remember a device - Android",
      "description": "You can use the device related features of Amazon Cognito UserPools by enabling the Devices features. Go to your Cognito UserPool, click on Devices in Left Navigation Menu and chose one of User Opt In or Always. - Android",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/device_features/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `User attributes`,\n  description: `Access and update user attributes`,\n};\n\nimport ios0 from \"/src/fragments/lib/auth/native_common/user_attributes/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/auth/native_common/user_attributes/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/auth/native_common/user_attributes/common.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n",
    "meta": {
      "title": "User attributes - iOS",
      "description": "Access and update user attributes - iOS",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/user-attributes/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `User attributes`,\n  description: `Access and update user attributes`,\n};\n\nimport ios0 from \"/src/fragments/lib/auth/native_common/user_attributes/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/auth/native_common/user_attributes/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/auth/native_common/user_attributes/common.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n",
    "meta": {
      "title": "User attributes - Flutter",
      "description": "Access and update user attributes - Flutter",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/user-attributes/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `User attributes`,\n  description: `Access and update user attributes`,\n};\n\nimport ios0 from \"/src/fragments/lib/auth/native_common/user_attributes/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/auth/native_common/user_attributes/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/auth/native_common/user_attributes/common.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n",
    "meta": {
      "title": "User attributes - Android",
      "description": "Access and update user attributes - Android",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/user-attributes/q/platform/android"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "AWS Cognito Auth Plugin sends important events through Amplify Hub."
      }
    ],
    "source": "export const meta = {\n  title: `Auth events`,\n  description: `Listen to various auth events`,\n};\n\nAWS Cognito Auth Plugin sends important events through Amplify Hub.\n\nimport js0 from \"/src/fragments/lib/auth/js/hub_events/10_listen_events.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/auth/ios/hub_events/10_listen_events.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/auth/android/hub_events/10_listen_events.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/auth/flutter/hub_events/10_listen_events.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Auth events - JavaScript",
      "description": "Listen to various auth events - JavaScript",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/auth-events/q/platform/js"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "AWS Cognito Auth Plugin sends important events through Amplify Hub."
      }
    ],
    "source": "export const meta = {\n  title: `Auth events`,\n  description: `Listen to various auth events`,\n};\n\nAWS Cognito Auth Plugin sends important events through Amplify Hub.\n\nimport js0 from \"/src/fragments/lib/auth/js/hub_events/10_listen_events.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/auth/ios/hub_events/10_listen_events.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/auth/android/hub_events/10_listen_events.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/auth/flutter/hub_events/10_listen_events.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Auth events - iOS",
      "description": "Listen to various auth events - iOS",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/auth-events/q/platform/ios"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "AWS Cognito Auth Plugin sends important events through Amplify Hub."
      }
    ],
    "source": "export const meta = {\n  title: `Auth events`,\n  description: `Listen to various auth events`,\n};\n\nAWS Cognito Auth Plugin sends important events through Amplify Hub.\n\nimport js0 from \"/src/fragments/lib/auth/js/hub_events/10_listen_events.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/auth/ios/hub_events/10_listen_events.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/auth/android/hub_events/10_listen_events.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/auth/flutter/hub_events/10_listen_events.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Auth events - Flutter",
      "description": "Listen to various auth events - Flutter",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/auth-events/q/platform/flutter"
  },
  {
    "searchableText": [
      {
        "heading": null,
        "depth": null,
        "text": "AWS Cognito Auth Plugin sends important events through Amplify Hub."
      }
    ],
    "source": "export const meta = {\n  title: `Auth events`,\n  description: `Listen to various auth events`,\n};\n\nAWS Cognito Auth Plugin sends important events through Amplify Hub.\n\nimport js0 from \"/src/fragments/lib/auth/js/hub_events/10_listen_events.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/auth/ios/hub_events/10_listen_events.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/auth/android/hub_events/10_listen_events.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/auth/flutter/hub_events/10_listen_events.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Auth events - Android",
      "description": "Listen to various auth events - Android",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/auth-events/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Guest access`,\n  description: `Access services without needing to sign in.`,\n};\n\nimport ios0 from \"/src/fragments/lib/auth/native_common/guest_access/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/auth/native_common/guest_access/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/auth/native_common/guest_access/common.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n",
    "meta": {
      "title": "Guest access - iOS",
      "description": "Access services without needing to sign in. - iOS",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/guest_access/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Guest access`,\n  description: `Access services without needing to sign in.`,\n};\n\nimport ios0 from \"/src/fragments/lib/auth/native_common/guest_access/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/auth/native_common/guest_access/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/auth/native_common/guest_access/common.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n",
    "meta": {
      "title": "Guest access - Flutter",
      "description": "Access services without needing to sign in. - Flutter",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/guest_access/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Guest access`,\n  description: `Access services without needing to sign in.`,\n};\n\nimport ios0 from \"/src/fragments/lib/auth/native_common/guest_access/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/auth/native_common/guest_access/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/auth/native_common/guest_access/common.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n",
    "meta": {
      "title": "Guest access - Android",
      "description": "Access services without needing to sign in. - Android",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/guest_access/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Sign in next steps`,\n  description: `Use AWS Cognito Auth plugin to complete a multi step authentication flow`,\n};\n\nimport ios0 from \"/src/fragments/lib/auth/native_common/signin_next_steps/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />",
    "meta": {
      "title": "Sign in next steps - iOS",
      "description": "Use AWS Cognito Auth plugin to complete a multi step authentication flow - iOS",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/signin_next_steps/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `SMS flows`,\n  description: `Using phone numbers for sign-in and verification`,\n};\n\nimport flutter0 from \"/src/fragments/lib/auth/common/sms/flows.mdx\";\n\n<Fragments fragments={{flutter: flutter0}} />\n",
    "meta": {
      "title": "SMS flows - Flutter",
      "description": "Using phone numbers for sign-in and verification - Flutter",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/sms_flows/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Social sign-in (OAuth)`,\n  description: `Learn how to setup social sign-in providers like Facebook, Google, Amazon, or Sign in with Apple.`,\n};\n\nimport js0 from \"/src/fragments/lib/auth/js/social.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/auth/native_common/social_signin_web_ui/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/auth/native_common/social_signin_web_ui/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/auth/native_common/social_signin_web_ui/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Social sign-in (OAuth) - iOS",
      "description": "Learn how to setup social sign-in providers like Facebook, Google, Amazon, or Sign in with Apple. - iOS",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/social/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Social sign-in (OAuth)`,\n  description: `Learn how to setup social sign-in providers like Facebook, Google, Amazon, or Sign in with Apple.`,\n};\n\nimport js0 from \"/src/fragments/lib/auth/js/social.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/auth/native_common/social_signin_web_ui/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/auth/native_common/social_signin_web_ui/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/auth/native_common/social_signin_web_ui/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Social sign-in (OAuth) - Flutter",
      "description": "Learn how to setup social sign-in providers like Facebook, Google, Amazon, or Sign in with Apple. - Flutter",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/social/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Social sign-in (OAuth)`,\n  description: `Learn how to setup social sign-in providers like Facebook, Google, Amazon, or Sign in with Apple.`,\n};\n\nimport js0 from \"/src/fragments/lib/auth/js/social.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/auth/native_common/social_signin_web_ui/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/auth/native_common/social_signin_web_ui/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/auth/native_common/social_signin_web_ui/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Social sign-in (OAuth) - Android",
      "description": "Learn how to setup social sign-in providers like Facebook, Google, Amazon, or Sign in with Apple. - Android",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/social/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Sign in with web UI`,\n  description: `Use AWS Cognito Auth plugin to register and authenticate a user with a prebuilt web UI`,\n};\n\nimport ios0 from \"/src/fragments/lib/auth/native_common/signin_web_ui/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/auth/native_common/signin_web_ui/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/auth/native_common/signin_web_ui/common.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />",
    "meta": {
      "title": "Sign in with web UI - iOS",
      "description": "Use AWS Cognito Auth plugin to register and authenticate a user with a prebuilt web UI - iOS",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/signin_web_ui/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Sign in with web UI`,\n  description: `Use AWS Cognito Auth plugin to register and authenticate a user with a prebuilt web UI`,\n};\n\nimport ios0 from \"/src/fragments/lib/auth/native_common/signin_web_ui/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/auth/native_common/signin_web_ui/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/auth/native_common/signin_web_ui/common.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />",
    "meta": {
      "title": "Sign in with web UI - Flutter",
      "description": "Use AWS Cognito Auth plugin to register and authenticate a user with a prebuilt web UI - Flutter",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/signin_web_ui/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Sign in with web UI`,\n  description: `Use AWS Cognito Auth plugin to register and authenticate a user with a prebuilt web UI`,\n};\n\nimport ios0 from \"/src/fragments/lib/auth/native_common/signin_web_ui/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/auth/native_common/signin_web_ui/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/auth/native_common/signin_web_ui/common.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />",
    "meta": {
      "title": "Sign in with web UI - Android",
      "description": "Use AWS Cognito Auth plugin to register and authenticate a user with a prebuilt web UI - Android",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/signin_web_ui/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Sign in with custom flow`,\n  description: `Use AWS Cognito Auth plugin to sign in a user into AWS Cognito User Pool using user defined custom flow`\n};\n\nimport ios0 from '/src/fragments/lib/auth/native_common/signin_with_custom_flow/common.mdx';\n\n<Fragments fragments={{ ios: ios0 }} />\n\nimport flutter1 from '/src/fragments/lib/auth/native_common/signin_with_custom_flow/common.mdx';\n\n<Fragments fragments={{ flutter: flutter1 }} />\n",
    "meta": {
      "title": "Sign in with custom flow - Flutter",
      "description": "Use AWS Cognito Auth plugin to sign in a user into AWS Cognito User Pool using user defined custom flow - Flutter",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/signin_with_custom_flow/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Sign in with custom flow`,\n  description: `Use AWS Cognito Auth plugin to sign in a user into AWS Cognito User Pool using user defined custom flow`\n};\n\nimport ios0 from '/src/fragments/lib/auth/native_common/signin_with_custom_flow/common.mdx';\n\n<Fragments fragments={{ ios: ios0 }} />\n\nimport flutter1 from '/src/fragments/lib/auth/native_common/signin_with_custom_flow/common.mdx';\n\n<Fragments fragments={{ flutter: flutter1 }} />\n",
    "meta": {
      "title": "Sign in with custom flow - iOS",
      "description": "Use AWS Cognito Auth plugin to sign in a user into AWS Cognito User Pool using user defined custom flow - iOS",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/signin_with_custom_flow/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Sign in`,\n  description: `Use AWS Cognito Auth plugin to sign in a user into AWS Cognito User Pool`,\n};\n\nimport ios0 from \"/src/fragments/lib/auth/native_common/signin/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/auth/native_common/signin/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/auth/native_common/signin/common.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n",
    "meta": {
      "title": "Sign in - iOS",
      "description": "Use AWS Cognito Auth plugin to sign in a user into AWS Cognito User Pool - iOS",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/signin/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Sign in`,\n  description: `Use AWS Cognito Auth plugin to sign in a user into AWS Cognito User Pool`,\n};\n\nimport ios0 from \"/src/fragments/lib/auth/native_common/signin/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/auth/native_common/signin/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/auth/native_common/signin/common.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n",
    "meta": {
      "title": "Sign in - Flutter",
      "description": "Use AWS Cognito Auth plugin to sign in a user into AWS Cognito User Pool - Flutter",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/signin/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Sign in`,\n  description: `Use AWS Cognito Auth plugin to sign in a user into AWS Cognito User Pool`,\n};\n\nimport ios0 from \"/src/fragments/lib/auth/native_common/signin/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/auth/native_common/signin/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/auth/native_common/signin/common.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n",
    "meta": {
      "title": "Sign in - Android",
      "description": "Use AWS Cognito Auth plugin to sign in a user into AWS Cognito User Pool - Android",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/signin/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Advanced workflows`,\n  description: `Learn more about advanced workflows in the Amplify auth category. This includes subscribing to events, identity pool federation, auth-related Lambda triggers and working with AWS service objects.`,\n};\n\nimport js0 from \"/src/fragments/lib/auth/js/advanced.mdx\";\n\n<Fragments fragments={{js: js0}} />\n",
    "meta": {
      "title": "Advanced workflows - JavaScript",
      "description": "Learn more about advanced workflows in the Amplify auth category. This includes subscribing to events, identity pool federation, auth-related Lambda triggers and working with AWS service objects. - JavaScript",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/advanced/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Customize UI components`,\n  description: `Learn how to customize the Amplify auth UI components.`,\n};\n\nimport js0 from \"/src/fragments/lib/auth/js/customui.mdx\";\n\n<Fragments fragments={{js: js0}} />",
    "meta": {
      "title": "Customize UI components - JavaScript",
      "description": "Learn how to customize the Amplify auth UI components. - JavaScript",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/customui/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Switching authentication flows`,\n  description: `Learn more about how to switch between different auth flows in Amplify Framework.`,\n};\n\nimport js0 from \"/src/fragments/lib/auth/js/switch-auth.mdx\";\n\n<Fragments fragments={{js: js0}} />",
    "meta": {
      "title": "Switching authentication flows - JavaScript",
      "description": "Learn more about how to switch between different auth flows in Amplify Framework. - JavaScript",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/switch-auth/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Password & user management`,\n  description: `Learn more about how to handle common password and user management scenarios. E.g. password reset, account recovery etc.`,\n};\n\nimport js0 from \"/src/fragments/lib/auth/js/manageusers.mdx\";\n\n<Fragments fragments={{js: js0}} />",
    "meta": {
      "title": "Password & user management - JavaScript",
      "description": "Learn more about how to handle common password and user management scenarios. E.g. password reset, account recovery etc. - JavaScript",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/manageusers/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Multi-factor authentication`,\n  description: `Learn how to enable multi-factor authentication with Amplify Framework.`,\n};\n\nimport js0 from \"/src/fragments/lib/auth/js/mfa.mdx\";\n\n<Fragments fragments={{js: js0}} />",
    "meta": {
      "title": "Multi-factor authentication - JavaScript",
      "description": "Learn how to enable multi-factor authentication with Amplify Framework. - JavaScript",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/mfa/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Social sign-in (OAuth)`,\n  description: `Learn how to setup social sign-in providers like Facebook, Google, Amazon, or Sign in with Apple.`,\n};\n\nimport js0 from \"/src/fragments/lib/auth/js/social.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/auth/native_common/social_signin_web_ui/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/auth/native_common/social_signin_web_ui/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/auth/native_common/social_signin_web_ui/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Social sign-in (OAuth) - JavaScript",
      "description": "Learn how to setup social sign-in providers like Facebook, Google, Amazon, or Sign in with Apple. - JavaScript",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/social/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Sign up, Sign in & Sign out`,\n  description: `Learn how to use Amplify's sign up, sign in and sign out APIs.`,\n};\n\nimport js0 from \"/src/fragments/lib/auth/js/emailpassword.mdx\";\n\n<Fragments fragments={{js: js0}} />",
    "meta": {
      "title": "Sign up, Sign in & Sign out - JavaScript",
      "description": "Learn how to use Amplify's sign up, sign in and sign out APIs. - JavaScript",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/emailpassword/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Create or re-use existing backend`,\n  description: `Learn more about how to create an auth resource or re-use an existing auth backend for Amplify Framework.`,\n};\n\nimport js0 from \"/src/fragments/lib/auth/js/start.mdx\";\n\n<Fragments fragments={{js: js0}} />\n",
    "meta": {
      "title": "Create or re-use existing backend - JavaScript",
      "description": "Learn more about how to create an auth resource or re-use an existing auth backend for Amplify Framework. - JavaScript",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/start/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `The Amplify Framework uses Amazon Cognito as the main authentication provider. Learn how to handle user registration, authentication, account recovery & other operations.`,\n};\n\nimport js0 from \"/src/fragments/lib/auth/js/getting-started.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/auth/native_common/getting_started/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/auth/native_common/getting_started/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/auth/native_common/getting_started/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Getting started - JavaScript",
      "description": "The Amplify Framework uses Amazon Cognito as the main authentication provider. Learn how to handle user registration, authentication, account recovery & other operations. - JavaScript",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/getting-started/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `The Amplify Framework uses Amazon Cognito as the main authentication provider. Learn how to handle user registration, authentication, account recovery & other operations.`,\n};\n\nimport js0 from \"/src/fragments/lib/auth/js/getting-started.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/auth/native_common/getting_started/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/auth/native_common/getting_started/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/auth/native_common/getting_started/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Getting started - iOS",
      "description": "The Amplify Framework uses Amazon Cognito as the main authentication provider. Learn how to handle user registration, authentication, account recovery & other operations. - iOS",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/getting-started/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `The Amplify Framework uses Amazon Cognito as the main authentication provider. Learn how to handle user registration, authentication, account recovery & other operations.`,\n};\n\nimport js0 from \"/src/fragments/lib/auth/js/getting-started.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/auth/native_common/getting_started/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/auth/native_common/getting_started/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/auth/native_common/getting_started/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Getting started - Flutter",
      "description": "The Amplify Framework uses Amazon Cognito as the main authentication provider. Learn how to handle user registration, authentication, account recovery & other operations. - Flutter",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/getting-started/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `The Amplify Framework uses Amazon Cognito as the main authentication provider. Learn how to handle user registration, authentication, account recovery & other operations.`,\n};\n\nimport js0 from \"/src/fragments/lib/auth/js/getting-started.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/auth/native_common/getting_started/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/auth/native_common/getting_started/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/auth/native_common/getting_started/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Getting started - Android",
      "description": "The Amplify Framework uses Amazon Cognito as the main authentication provider. Learn how to handle user registration, authentication, account recovery & other operations. - Android",
      "subcategory": "Authentication",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/auth/getting-started/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Use existing AWS resources`,\n  description: `Configure the Amplify Libraries to use existing Amazon API Gateway resources by referencing them in your configuration.`,\n};\n\nimport android0 from \"/src/fragments/lib/restapi/existing-resources.mdx\";\n\n<Fragments fragments={{android: android0}} />\n\nimport ios1 from \"/src/fragments/lib/restapi/existing-resources.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport flutter2 from \"/src/fragments/lib/restapi/existing-resources.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />",
    "meta": {
      "title": "Use existing AWS resources - Flutter",
      "description": "Configure the Amplify Libraries to use existing Amazon API Gateway resources by referencing them in your configuration. - Flutter",
      "subcategory": "API (REST)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/restapi/existing-resources/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Use existing AWS resources`,\n  description: `Configure the Amplify Libraries to use existing Amazon API Gateway resources by referencing them in your configuration.`,\n};\n\nimport android0 from \"/src/fragments/lib/restapi/existing-resources.mdx\";\n\n<Fragments fragments={{android: android0}} />\n\nimport ios1 from \"/src/fragments/lib/restapi/existing-resources.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport flutter2 from \"/src/fragments/lib/restapi/existing-resources.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />",
    "meta": {
      "title": "Use existing AWS resources - iOS",
      "description": "Configure the Amplify Libraries to use existing Amazon API Gateway resources by referencing them in your configuration. - iOS",
      "subcategory": "API (REST)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/restapi/existing-resources/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Use existing AWS resources`,\n  description: `Configure the Amplify Libraries to use existing Amazon API Gateway resources by referencing them in your configuration.`,\n};\n\nimport android0 from \"/src/fragments/lib/restapi/existing-resources.mdx\";\n\n<Fragments fragments={{android: android0}} />\n\nimport ios1 from \"/src/fragments/lib/restapi/existing-resources.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport flutter2 from \"/src/fragments/lib/restapi/existing-resources.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />",
    "meta": {
      "title": "Use existing AWS resources - Android",
      "description": "Configure the Amplify Libraries to use existing Amazon API Gateway resources by referencing them in your configuration. - Android",
      "subcategory": "API (REST)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/restapi/existing-resources/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Define authorization rules`,\n  description: `Learn more about how to define authorization rules for Amplify's REST API capabilities`,\n};\n\nimport js0 from \"/src/fragments/lib/restapi/js/authz.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/restapi/native_common/authz/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/restapi/native_common/authz/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/restapi/flutter/authz.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Define authorization rules - JavaScript",
      "description": "Learn more about how to define authorization rules for Amplify's REST API capabilities - JavaScript",
      "subcategory": "API (REST)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/restapi/authz/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Define authorization rules`,\n  description: `Learn more about how to define authorization rules for Amplify's REST API capabilities`,\n};\n\nimport js0 from \"/src/fragments/lib/restapi/js/authz.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/restapi/native_common/authz/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/restapi/native_common/authz/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/restapi/flutter/authz.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Define authorization rules - Flutter",
      "description": "Learn more about how to define authorization rules for Amplify's REST API capabilities - Flutter",
      "subcategory": "API (REST)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/restapi/authz/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Define authorization rules`,\n  description: `Learn more about how to define authorization rules for Amplify's REST API capabilities`,\n};\n\nimport js0 from \"/src/fragments/lib/restapi/js/authz.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/restapi/native_common/authz/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/restapi/native_common/authz/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/restapi/flutter/authz.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Define authorization rules - iOS",
      "description": "Learn more about how to define authorization rules for Amplify's REST API capabilities - iOS",
      "subcategory": "API (REST)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/restapi/authz/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Define authorization rules`,\n  description: `Learn more about how to define authorization rules for Amplify's REST API capabilities`,\n};\n\nimport js0 from \"/src/fragments/lib/restapi/js/authz.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/restapi/native_common/authz/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/restapi/native_common/authz/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/restapi/flutter/authz.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Define authorization rules - Android",
      "description": "Learn more about how to define authorization rules for Amplify's REST API capabilities - Android",
      "subcategory": "API (REST)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/restapi/authz/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Cancel API requests`,\n  description: `Using the Cancel API in Amplify Framework`,\n};\n\nimport js0 from \"/src/fragments/lib/restapi/js/cancel.mdx\";\n\n<Fragments fragments={{js: js0}} />\n",
    "meta": {
      "title": "Cancel API requests - JavaScript",
      "description": "Using the Cancel API in Amplify Framework - JavaScript",
      "subcategory": "API (REST)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/restapi/cancel/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Deleting data`,\n  description: `Using the Delete API REST in Amplify Framework`,\n};\n\nimport js0 from \"/src/fragments/lib/restapi/js/delete.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/restapi/ios/delete.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/restapi/android/delete.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/restapi/flutter/delete.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Deleting data - JavaScript",
      "description": "Using the Delete API REST in Amplify Framework - JavaScript",
      "subcategory": "API (REST)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/restapi/delete/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Deleting data`,\n  description: `Using the Delete API REST in Amplify Framework`,\n};\n\nimport js0 from \"/src/fragments/lib/restapi/js/delete.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/restapi/ios/delete.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/restapi/android/delete.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/restapi/flutter/delete.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Deleting data - Flutter",
      "description": "Using the Delete API REST in Amplify Framework - Flutter",
      "subcategory": "API (REST)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/restapi/delete/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Deleting data`,\n  description: `Using the Delete API REST in Amplify Framework`,\n};\n\nimport js0 from \"/src/fragments/lib/restapi/js/delete.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/restapi/ios/delete.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/restapi/android/delete.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/restapi/flutter/delete.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Deleting data - iOS",
      "description": "Using the Delete API REST in Amplify Framework - iOS",
      "subcategory": "API (REST)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/restapi/delete/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Deleting data`,\n  description: `Using the Delete API REST in Amplify Framework`,\n};\n\nimport js0 from \"/src/fragments/lib/restapi/js/delete.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/restapi/ios/delete.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/restapi/android/delete.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/restapi/flutter/delete.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Deleting data - Android",
      "description": "Using the Delete API REST in Amplify Framework - Android",
      "subcategory": "API (REST)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/restapi/delete/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Updating data`,\n  description: `Using Post, Put, etc. in Amplify Framework`,\n};\n\nimport js0 from \"/src/fragments/lib/restapi/js/update.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/restapi/ios/update.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/restapi/android/update.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/restapi/flutter/update.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Updating data - JavaScript",
      "description": "Using Post, Put, etc. in Amplify Framework - JavaScript",
      "subcategory": "API (REST)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/restapi/update/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Updating data`,\n  description: `Using Post, Put, etc. in Amplify Framework`,\n};\n\nimport js0 from \"/src/fragments/lib/restapi/js/update.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/restapi/ios/update.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/restapi/android/update.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/restapi/flutter/update.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Updating data - Flutter",
      "description": "Using Post, Put, etc. in Amplify Framework - Flutter",
      "subcategory": "API (REST)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/restapi/update/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Updating data`,\n  description: `Using Post, Put, etc. in Amplify Framework`,\n};\n\nimport js0 from \"/src/fragments/lib/restapi/js/update.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/restapi/ios/update.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/restapi/android/update.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/restapi/flutter/update.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Updating data - iOS",
      "description": "Using Post, Put, etc. in Amplify Framework - iOS",
      "subcategory": "API (REST)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/restapi/update/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Updating data`,\n  description: `Using Post, Put, etc. in Amplify Framework`,\n};\n\nimport js0 from \"/src/fragments/lib/restapi/js/update.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/restapi/ios/update.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/restapi/android/update.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/restapi/flutter/update.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Updating data - Android",
      "description": "Using Post, Put, etc. in Amplify Framework - Android",
      "subcategory": "API (REST)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/restapi/update/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Fetching data`,\n  description: `Using the GET API REST in Amplify Framework`,\n};\n\nimport js0 from \"/src/fragments/lib/restapi/js/fetch.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/restapi/ios/fetch.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/restapi/android/fetch.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/restapi/flutter/fetch.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Fetching data - JavaScript",
      "description": "Using the GET API REST in Amplify Framework - JavaScript",
      "subcategory": "API (REST)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/restapi/fetch/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Fetching data`,\n  description: `Using the GET API REST in Amplify Framework`,\n};\n\nimport js0 from \"/src/fragments/lib/restapi/js/fetch.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/restapi/ios/fetch.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/restapi/android/fetch.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/restapi/flutter/fetch.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Fetching data - Flutter",
      "description": "Using the GET API REST in Amplify Framework - Flutter",
      "subcategory": "API (REST)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/restapi/fetch/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Fetching data`,\n  description: `Using the GET API REST in Amplify Framework`,\n};\n\nimport js0 from \"/src/fragments/lib/restapi/js/fetch.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/restapi/ios/fetch.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/restapi/android/fetch.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/restapi/flutter/fetch.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Fetching data - iOS",
      "description": "Using the GET API REST in Amplify Framework - iOS",
      "subcategory": "API (REST)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/restapi/fetch/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Fetching data`,\n  description: `Using the GET API REST in Amplify Framework`,\n};\n\nimport js0 from \"/src/fragments/lib/restapi/js/fetch.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/restapi/ios/fetch.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/restapi/android/fetch.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/restapi/flutter/fetch.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Fetching data - Android",
      "description": "Using the GET API REST in Amplify Framework - Android",
      "subcategory": "API (REST)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/restapi/fetch/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `The API category provides a solution for making HTTP requests to REST and GraphQL endpoints. The REST API category can be used for creating signed requests against Amazon API Gateway when the API Gateway Authorization is set to AWS_IAM.`,\n};\n\nimport js0 from \"/src/fragments/lib/restapi/js/getting-started.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/restapi/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/restapi/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/restapi/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Getting started - JavaScript",
      "description": "The API category provides a solution for making HTTP requests to REST and GraphQL endpoints. The REST API category can be used for creating signed requests against Amazon API Gateway when the API Gateway Authorization is set to AWS_IAM. - JavaScript",
      "subcategory": "API (REST)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/restapi/getting-started/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `The API category provides a solution for making HTTP requests to REST and GraphQL endpoints. The REST API category can be used for creating signed requests against Amazon API Gateway when the API Gateway Authorization is set to AWS_IAM.`,\n};\n\nimport js0 from \"/src/fragments/lib/restapi/js/getting-started.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/restapi/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/restapi/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/restapi/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Getting started - Flutter",
      "description": "The API category provides a solution for making HTTP requests to REST and GraphQL endpoints. The REST API category can be used for creating signed requests against Amazon API Gateway when the API Gateway Authorization is set to AWS_IAM. - Flutter",
      "subcategory": "API (REST)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/restapi/getting-started/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `The API category provides a solution for making HTTP requests to REST and GraphQL endpoints. The REST API category can be used for creating signed requests against Amazon API Gateway when the API Gateway Authorization is set to AWS_IAM.`,\n};\n\nimport js0 from \"/src/fragments/lib/restapi/js/getting-started.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/restapi/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/restapi/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/restapi/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Getting started - iOS",
      "description": "The API category provides a solution for making HTTP requests to REST and GraphQL endpoints. The REST API category can be used for creating signed requests against Amazon API Gateway when the API Gateway Authorization is set to AWS_IAM. - iOS",
      "subcategory": "API (REST)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/restapi/getting-started/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `The API category provides a solution for making HTTP requests to REST and GraphQL endpoints. The REST API category can be used for creating signed requests against Amazon API Gateway when the API Gateway Authorization is set to AWS_IAM.`,\n};\n\nimport js0 from \"/src/fragments/lib/restapi/js/getting-started.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/restapi/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/restapi/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/restapi/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Getting started - Android",
      "description": "The API category provides a solution for making HTTP requests to REST and GraphQL endpoints. The REST API category can be used for creating signed requests against Amazon API Gateway when the API Gateway Authorization is set to AWS_IAM. - Android",
      "subcategory": "API (REST)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/restapi/getting-started/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Use existing AWS resources`,\n  description: `Configure the Amplify Libraries to use existing AWS AppSync resources by referencing them in your configuration.`,\n};\n\nimport android0 from \"/src/fragments/lib/graphqlapi/existing-resources.mdx\";\n\n<Fragments fragments={{android: android0}} />\n\nimport ios1 from \"/src/fragments/lib/graphqlapi/existing-resources.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport flutter2 from \"/src/fragments/lib/graphqlapi/existing-resources.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n",
    "meta": {
      "title": "Use existing AWS resources - iOS",
      "description": "Configure the Amplify Libraries to use existing AWS AppSync resources by referencing them in your configuration. - iOS",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/existing-resources/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Use existing AWS resources`,\n  description: `Configure the Amplify Libraries to use existing AWS AppSync resources by referencing them in your configuration.`,\n};\n\nimport android0 from \"/src/fragments/lib/graphqlapi/existing-resources.mdx\";\n\n<Fragments fragments={{android: android0}} />\n\nimport ios1 from \"/src/fragments/lib/graphqlapi/existing-resources.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport flutter2 from \"/src/fragments/lib/graphqlapi/existing-resources.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n",
    "meta": {
      "title": "Use existing AWS resources - Flutter",
      "description": "Configure the Amplify Libraries to use existing AWS AppSync resources by referencing them in your configuration. - Flutter",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/existing-resources/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Use existing AWS resources`,\n  description: `Configure the Amplify Libraries to use existing AWS AppSync resources by referencing them in your configuration.`,\n};\n\nimport android0 from \"/src/fragments/lib/graphqlapi/existing-resources.mdx\";\n\n<Fragments fragments={{android: android0}} />\n\nimport ios1 from \"/src/fragments/lib/graphqlapi/existing-resources.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport flutter2 from \"/src/fragments/lib/graphqlapi/existing-resources.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n",
    "meta": {
      "title": "Use existing AWS resources - Android",
      "description": "Configure the Amplify Libraries to use existing AWS AppSync resources by referencing them in your configuration. - Android",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/existing-resources/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Advanced Workflows`,\n  description: `Learn more about advanced workflows in the Amplify Framework's API category`,\n};\n\nimport js0 from \"/src/fragments/lib/graphqlapi/js/complex-objects.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport js1 from \"/src/fragments/lib/graphqlapi/js/delta-sync.mdx\";\n\n<Fragments fragments={{js: js1}} />\n\nimport ios2 from \"/src/fragments/lib/graphqlapi/native_common/advanced-workflows/common.mdx\";\n\n<Fragments fragments={{ios: ios2}} />\n\nimport android3 from \"/src/fragments/lib/graphqlapi/native_common/advanced-workflows/common.mdx\";\n\n<Fragments fragments={{android: android3}} />\n\nimport flutter3 from \"/src/fragments/lib/graphqlapi/native_common/advanced-workflows/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Advanced Workflows - JavaScript",
      "description": "Learn more about advanced workflows in the Amplify Framework's API category - JavaScript",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/advanced-workflows/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Advanced Workflows`,\n  description: `Learn more about advanced workflows in the Amplify Framework's API category`,\n};\n\nimport js0 from \"/src/fragments/lib/graphqlapi/js/complex-objects.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport js1 from \"/src/fragments/lib/graphqlapi/js/delta-sync.mdx\";\n\n<Fragments fragments={{js: js1}} />\n\nimport ios2 from \"/src/fragments/lib/graphqlapi/native_common/advanced-workflows/common.mdx\";\n\n<Fragments fragments={{ios: ios2}} />\n\nimport android3 from \"/src/fragments/lib/graphqlapi/native_common/advanced-workflows/common.mdx\";\n\n<Fragments fragments={{android: android3}} />\n\nimport flutter3 from \"/src/fragments/lib/graphqlapi/native_common/advanced-workflows/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Advanced Workflows - iOS",
      "description": "Learn more about advanced workflows in the Amplify Framework's API category - iOS",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/advanced-workflows/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Advanced Workflows`,\n  description: `Learn more about advanced workflows in the Amplify Framework's API category`,\n};\n\nimport js0 from \"/src/fragments/lib/graphqlapi/js/complex-objects.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport js1 from \"/src/fragments/lib/graphqlapi/js/delta-sync.mdx\";\n\n<Fragments fragments={{js: js1}} />\n\nimport ios2 from \"/src/fragments/lib/graphqlapi/native_common/advanced-workflows/common.mdx\";\n\n<Fragments fragments={{ios: ios2}} />\n\nimport android3 from \"/src/fragments/lib/graphqlapi/native_common/advanced-workflows/common.mdx\";\n\n<Fragments fragments={{android: android3}} />\n\nimport flutter3 from \"/src/fragments/lib/graphqlapi/native_common/advanced-workflows/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Advanced Workflows - Flutter",
      "description": "Learn more about advanced workflows in the Amplify Framework's API category - Flutter",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/advanced-workflows/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Advanced Workflows`,\n  description: `Learn more about advanced workflows in the Amplify Framework's API category`,\n};\n\nimport js0 from \"/src/fragments/lib/graphqlapi/js/complex-objects.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport js1 from \"/src/fragments/lib/graphqlapi/js/delta-sync.mdx\";\n\n<Fragments fragments={{js: js1}} />\n\nimport ios2 from \"/src/fragments/lib/graphqlapi/native_common/advanced-workflows/common.mdx\";\n\n<Fragments fragments={{ios: ios2}} />\n\nimport android3 from \"/src/fragments/lib/graphqlapi/native_common/advanced-workflows/common.mdx\";\n\n<Fragments fragments={{android: android3}} />\n\nimport flutter3 from \"/src/fragments/lib/graphqlapi/native_common/advanced-workflows/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Advanced Workflows - Android",
      "description": "Learn more about advanced workflows in the Amplify Framework's API category - Android",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/advanced-workflows/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `GraphQL from NodeJS`,\n  description: `Learn more about how to call an AppSync GraphQL API from a NodeJS app or a Lambda function`,\n};\n\nimport js0 from \"/src/fragments/lib/graphqlapi/graphql-from-node.mdx\";\n\n<Fragments fragments={{js: js0}} />\n",
    "meta": {
      "title": "GraphQL from NodeJS - JavaScript",
      "description": "Learn more about how to call an AppSync GraphQL API from a NodeJS app or a Lambda function - JavaScript",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/graphql-from-nodejs/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Offline scenarios`,\n  description: `Learn more about how to support offline scenarios with Amplify's GraphQL API category`,\n};\n\nimport js0 from \"/src/fragments/lib/graphqlapi/js/offline.mdx\";\n\n<Fragments fragments={{js: js0}} />",
    "meta": {
      "title": "Offline scenarios - JavaScript",
      "description": "Learn more about how to support offline scenarios with Amplify's GraphQL API category - JavaScript",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/offline/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Cancel API requests`,\n  description: `Learn more about how to cancel query or mutation requests with Amplify's GraphQL API category`,\n};\n\nimport js0 from \"/src/fragments/lib/graphqlapi/js/cancel-request.mdx\";\n\n<Fragments fragments={{js: js0}} />\n",
    "meta": {
      "title": "Cancel API requests - JavaScript",
      "description": "Learn more about how to cancel query or mutation requests with Amplify's GraphQL API category - JavaScript",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/cancel-request/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Subscribe to data`,\n  description: `Learn more about how to observe to data changes using subscriptions in Amplify.`,\n};\n\nimport ios0 from \"/src/fragments/lib/graphqlapi/ios/subscribe-data.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/graphqlapi/android/subscribe-data.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport js2 from \"/src/fragments/lib/graphqlapi/js/subscribe-data.mdx\";\n\n<Fragments fragments={{js: js2}} />\n\nimport flutter3 from \"/src/fragments/lib/graphqlapi/flutter/subscribe-data.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Subscribe to data - JavaScript",
      "description": "Learn more about how to observe to data changes using subscriptions in Amplify. - JavaScript",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/subscribe-data/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Subscribe to data`,\n  description: `Learn more about how to observe to data changes using subscriptions in Amplify.`,\n};\n\nimport ios0 from \"/src/fragments/lib/graphqlapi/ios/subscribe-data.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/graphqlapi/android/subscribe-data.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport js2 from \"/src/fragments/lib/graphqlapi/js/subscribe-data.mdx\";\n\n<Fragments fragments={{js: js2}} />\n\nimport flutter3 from \"/src/fragments/lib/graphqlapi/flutter/subscribe-data.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Subscribe to data - iOS",
      "description": "Learn more about how to observe to data changes using subscriptions in Amplify. - iOS",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/subscribe-data/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Subscribe to data`,\n  description: `Learn more about how to observe to data changes using subscriptions in Amplify.`,\n};\n\nimport ios0 from \"/src/fragments/lib/graphqlapi/ios/subscribe-data.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/graphqlapi/android/subscribe-data.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport js2 from \"/src/fragments/lib/graphqlapi/js/subscribe-data.mdx\";\n\n<Fragments fragments={{js: js2}} />\n\nimport flutter3 from \"/src/fragments/lib/graphqlapi/flutter/subscribe-data.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Subscribe to data - Flutter",
      "description": "Learn more about how to observe to data changes using subscriptions in Amplify. - Flutter",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/subscribe-data/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Subscribe to data`,\n  description: `Learn more about how to observe to data changes using subscriptions in Amplify.`,\n};\n\nimport ios0 from \"/src/fragments/lib/graphqlapi/ios/subscribe-data.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/graphqlapi/android/subscribe-data.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport js2 from \"/src/fragments/lib/graphqlapi/js/subscribe-data.mdx\";\n\n<Fragments fragments={{js: js2}} />\n\nimport flutter3 from \"/src/fragments/lib/graphqlapi/flutter/subscribe-data.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Subscribe to data - Android",
      "description": "Learn more about how to observe to data changes using subscriptions in Amplify. - Android",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/subscribe-data/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Fetch data`,\n  description: `Learn more about how to fetch data using Amplify's GraphQL API category`,\n};\n\nimport ios0 from \"/src/fragments/lib/graphqlapi/ios/query-data.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/graphqlapi/android/query-data.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport js2 from \"/src/fragments/lib/graphqlapi/js/query-data.mdx\";\n\n<Fragments fragments={{js: js2}} />\n\nimport flutter3 from \"/src/fragments/lib/graphqlapi/flutter/query-data.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Fetch data - JavaScript",
      "description": "Learn more about how to fetch data using Amplify's GraphQL API category - JavaScript",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/query-data/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Fetch data`,\n  description: `Learn more about how to fetch data using Amplify's GraphQL API category`,\n};\n\nimport ios0 from \"/src/fragments/lib/graphqlapi/ios/query-data.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/graphqlapi/android/query-data.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport js2 from \"/src/fragments/lib/graphqlapi/js/query-data.mdx\";\n\n<Fragments fragments={{js: js2}} />\n\nimport flutter3 from \"/src/fragments/lib/graphqlapi/flutter/query-data.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Fetch data - iOS",
      "description": "Learn more about how to fetch data using Amplify's GraphQL API category - iOS",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/query-data/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Fetch data`,\n  description: `Learn more about how to fetch data using Amplify's GraphQL API category`,\n};\n\nimport ios0 from \"/src/fragments/lib/graphqlapi/ios/query-data.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/graphqlapi/android/query-data.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport js2 from \"/src/fragments/lib/graphqlapi/js/query-data.mdx\";\n\n<Fragments fragments={{js: js2}} />\n\nimport flutter3 from \"/src/fragments/lib/graphqlapi/flutter/query-data.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Fetch data - Flutter",
      "description": "Learn more about how to fetch data using Amplify's GraphQL API category - Flutter",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/query-data/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Fetch data`,\n  description: `Learn more about how to fetch data using Amplify's GraphQL API category`,\n};\n\nimport ios0 from \"/src/fragments/lib/graphqlapi/ios/query-data.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/graphqlapi/android/query-data.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport js2 from \"/src/fragments/lib/graphqlapi/js/query-data.mdx\";\n\n<Fragments fragments={{js: js2}} />\n\nimport flutter3 from \"/src/fragments/lib/graphqlapi/flutter/query-data.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Fetch data - Android",
      "description": "Learn more about how to fetch data using Amplify's GraphQL API category - Android",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/query-data/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Create, update, delete data`,\n  description: `Learn more about how to create and update data using GraphQL APIs in Amplify`,\n};\n\nimport ios0 from \"/src/fragments/lib/graphqlapi/ios/mutate-data.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/graphqlapi/android/mutate-data.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport js2 from \"/src/fragments/lib/graphqlapi/js/mutate-data.mdx\";\n\n<Fragments fragments={{js: js2}} />\n\nimport flutter3 from \"/src/fragments/lib/graphqlapi/flutter/mutate-data.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Create, update, delete data - JavaScript",
      "description": "Learn more about how to create and update data using GraphQL APIs in Amplify - JavaScript",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/mutate-data/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Create, update, delete data`,\n  description: `Learn more about how to create and update data using GraphQL APIs in Amplify`,\n};\n\nimport ios0 from \"/src/fragments/lib/graphqlapi/ios/mutate-data.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/graphqlapi/android/mutate-data.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport js2 from \"/src/fragments/lib/graphqlapi/js/mutate-data.mdx\";\n\n<Fragments fragments={{js: js2}} />\n\nimport flutter3 from \"/src/fragments/lib/graphqlapi/flutter/mutate-data.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Create, update, delete data - iOS",
      "description": "Learn more about how to create and update data using GraphQL APIs in Amplify - iOS",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/mutate-data/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Create, update, delete data`,\n  description: `Learn more about how to create and update data using GraphQL APIs in Amplify`,\n};\n\nimport ios0 from \"/src/fragments/lib/graphqlapi/ios/mutate-data.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/graphqlapi/android/mutate-data.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport js2 from \"/src/fragments/lib/graphqlapi/js/mutate-data.mdx\";\n\n<Fragments fragments={{js: js2}} />\n\nimport flutter3 from \"/src/fragments/lib/graphqlapi/flutter/mutate-data.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Create, update, delete data - Flutter",
      "description": "Learn more about how to create and update data using GraphQL APIs in Amplify - Flutter",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/mutate-data/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Create, update, delete data`,\n  description: `Learn more about how to create and update data using GraphQL APIs in Amplify`,\n};\n\nimport ios0 from \"/src/fragments/lib/graphqlapi/ios/mutate-data.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/graphqlapi/android/mutate-data.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport js2 from \"/src/fragments/lib/graphqlapi/js/mutate-data.mdx\";\n\n<Fragments fragments={{js: js2}} />\n\nimport flutter3 from \"/src/fragments/lib/graphqlapi/flutter/mutate-data.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Create, update, delete data - Android",
      "description": "Learn more about how to create and update data using GraphQL APIs in Amplify - Android",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/mutate-data/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Configure authorization modes`,\n  description: `Learn more about how to configure authorization modes in Amplify Framework's API category`,\n};\n\nimport ios0 from \"/src/fragments/lib/graphqlapi/native_common/authz/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/graphqlapi/native_common/authz/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport js2 from \"/src/fragments/lib/graphqlapi/js/authz.mdx\";\n\n<Fragments fragments={{js: js2}} />\n\nimport flutter3 from \"/src/fragments/lib/graphqlapi/native_common/authz/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Configure authorization modes - JavaScript",
      "description": "Learn more about how to configure authorization modes in Amplify Framework's API category - JavaScript",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/authz/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Configure authorization modes`,\n  description: `Learn more about how to configure authorization modes in Amplify Framework's API category`,\n};\n\nimport ios0 from \"/src/fragments/lib/graphqlapi/native_common/authz/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/graphqlapi/native_common/authz/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport js2 from \"/src/fragments/lib/graphqlapi/js/authz.mdx\";\n\n<Fragments fragments={{js: js2}} />\n\nimport flutter3 from \"/src/fragments/lib/graphqlapi/native_common/authz/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Configure authorization modes - iOS",
      "description": "Learn more about how to configure authorization modes in Amplify Framework's API category - iOS",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/authz/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Configure authorization modes`,\n  description: `Learn more about how to configure authorization modes in Amplify Framework's API category`,\n};\n\nimport ios0 from \"/src/fragments/lib/graphqlapi/native_common/authz/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/graphqlapi/native_common/authz/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport js2 from \"/src/fragments/lib/graphqlapi/js/authz.mdx\";\n\n<Fragments fragments={{js: js2}} />\n\nimport flutter3 from \"/src/fragments/lib/graphqlapi/native_common/authz/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Configure authorization modes - Flutter",
      "description": "Learn more about how to configure authorization modes in Amplify Framework's API category - Flutter",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/authz/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Configure authorization modes`,\n  description: `Learn more about how to configure authorization modes in Amplify Framework's API category`,\n};\n\nimport ios0 from \"/src/fragments/lib/graphqlapi/native_common/authz/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/graphqlapi/native_common/authz/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport js2 from \"/src/fragments/lib/graphqlapi/js/authz.mdx\";\n\n<Fragments fragments={{js: js2}} />\n\nimport flutter3 from \"/src/fragments/lib/graphqlapi/native_common/authz/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Configure authorization modes - Android",
      "description": "Learn more about how to configure authorization modes in Amplify Framework's API category - Android",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/authz/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Create or re-use existing backend`,\n  description: `Learn more about how to create or re-use an existing API backend resource in Amplify.`,\n};\n\nimport js0 from \"/src/fragments/lib/graphqlapi/js/create-or-re-use-existing-backend.mdx\";\n\n<Fragments fragments={{js: js0}} />\n",
    "meta": {
      "title": "Create or re-use existing backend - JavaScript",
      "description": "Learn more about how to create or re-use an existing API backend resource in Amplify. - JavaScript",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/create-or-re-use-existing-backend/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Concepts`,\n  description: `Learn more about the foundation concepts of Amplify Framework's API category.`,\n};\n\nimport js0 from \"/src/fragments/lib/graphqlapi/native_common/concepts.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport android1 from \"/src/fragments/lib/graphqlapi/native_common/concepts.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport ios2 from \"/src/fragments/lib/graphqlapi/native_common/concepts.mdx\";\n\n<Fragments fragments={{ios: ios2}} />\n\nimport flutter3 from \"/src/fragments/lib/graphqlapi/native_common/concepts.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Concepts - JavaScript",
      "description": "Learn more about the foundation concepts of Amplify Framework's API category. - JavaScript",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/concepts/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Concepts`,\n  description: `Learn more about the foundation concepts of Amplify Framework's API category.`,\n};\n\nimport js0 from \"/src/fragments/lib/graphqlapi/native_common/concepts.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport android1 from \"/src/fragments/lib/graphqlapi/native_common/concepts.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport ios2 from \"/src/fragments/lib/graphqlapi/native_common/concepts.mdx\";\n\n<Fragments fragments={{ios: ios2}} />\n\nimport flutter3 from \"/src/fragments/lib/graphqlapi/native_common/concepts.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Concepts - iOS",
      "description": "Learn more about the foundation concepts of Amplify Framework's API category. - iOS",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/concepts/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Concepts`,\n  description: `Learn more about the foundation concepts of Amplify Framework's API category.`,\n};\n\nimport js0 from \"/src/fragments/lib/graphqlapi/native_common/concepts.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport android1 from \"/src/fragments/lib/graphqlapi/native_common/concepts.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport ios2 from \"/src/fragments/lib/graphqlapi/native_common/concepts.mdx\";\n\n<Fragments fragments={{ios: ios2}} />\n\nimport flutter3 from \"/src/fragments/lib/graphqlapi/native_common/concepts.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Concepts - Flutter",
      "description": "Learn more about the foundation concepts of Amplify Framework's API category. - Flutter",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/concepts/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Concepts`,\n  description: `Learn more about the foundation concepts of Amplify Framework's API category.`,\n};\n\nimport js0 from \"/src/fragments/lib/graphqlapi/native_common/concepts.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport android1 from \"/src/fragments/lib/graphqlapi/native_common/concepts.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport ios2 from \"/src/fragments/lib/graphqlapi/native_common/concepts.mdx\";\n\n<Fragments fragments={{ios: ios2}} />\n\nimport flutter3 from \"/src/fragments/lib/graphqlapi/native_common/concepts.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Concepts - Android",
      "description": "Learn more about the foundation concepts of Amplify Framework's API category. - Android",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/concepts/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `Learn more about how to get started with Amplify's API category`,\n};\n\nimport ios0 from \"/src/fragments/lib/graphqlapi/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/graphqlapi/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport js2 from \"/src/fragments/lib/graphqlapi/js/getting-started.mdx\";\n\n<Fragments fragments={{js: js2}} />\n\nimport flutter3 from \"/src/fragments/lib/graphqlapi/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Getting started - JavaScript",
      "description": "Learn more about how to get started with Amplify's API category - JavaScript",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/getting-started/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `Learn more about how to get started with Amplify's API category`,\n};\n\nimport ios0 from \"/src/fragments/lib/graphqlapi/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/graphqlapi/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport js2 from \"/src/fragments/lib/graphqlapi/js/getting-started.mdx\";\n\n<Fragments fragments={{js: js2}} />\n\nimport flutter3 from \"/src/fragments/lib/graphqlapi/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Getting started - iOS",
      "description": "Learn more about how to get started with Amplify's API category - iOS",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/getting-started/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `Learn more about how to get started with Amplify's API category`,\n};\n\nimport ios0 from \"/src/fragments/lib/graphqlapi/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/graphqlapi/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport js2 from \"/src/fragments/lib/graphqlapi/js/getting-started.mdx\";\n\n<Fragments fragments={{js: js2}} />\n\nimport flutter3 from \"/src/fragments/lib/graphqlapi/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Getting started - Flutter",
      "description": "Learn more about how to get started with Amplify's API category - Flutter",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/getting-started/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `Learn more about how to get started with Amplify's API category`,\n};\n\nimport ios0 from \"/src/fragments/lib/graphqlapi/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/graphqlapi/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport js2 from \"/src/fragments/lib/graphqlapi/js/getting-started.mdx\";\n\n<Fragments fragments={{js: js2}} />\n\nimport flutter3 from \"/src/fragments/lib/graphqlapi/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Getting started - Android",
      "description": "Learn more about how to get started with Amplify's API category - Android",
      "subcategory": "API (GraphQL)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/graphqlapi/getting-started/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Use existing AWS resources`,\n  description: `Configure the Amplify Libraries to use existing Amazon Pinpoint resources by referencing them in your configuration.`,\n};\n\nimport android0 from \"/src/fragments/lib/analytics/existing-resources.mdx\";\n\n<Fragments fragments={{android: android0}} />\n\nimport ios1 from \"/src/fragments/lib/analytics/existing-resources.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport flutter2 from \"/src/fragments/lib/analytics/existing-resources.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n",
    "meta": {
      "title": "Use existing AWS resources - iOS",
      "description": "Configure the Amplify Libraries to use existing Amazon Pinpoint resources by referencing them in your configuration. - iOS",
      "subcategory": "Analytics",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/analytics/existing-resources/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Use existing AWS resources`,\n  description: `Configure the Amplify Libraries to use existing Amazon Pinpoint resources by referencing them in your configuration.`,\n};\n\nimport android0 from \"/src/fragments/lib/analytics/existing-resources.mdx\";\n\n<Fragments fragments={{android: android0}} />\n\nimport ios1 from \"/src/fragments/lib/analytics/existing-resources.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport flutter2 from \"/src/fragments/lib/analytics/existing-resources.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n",
    "meta": {
      "title": "Use existing AWS resources - Flutter",
      "description": "Configure the Amplify Libraries to use existing Amazon Pinpoint resources by referencing them in your configuration. - Flutter",
      "subcategory": "Analytics",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/analytics/existing-resources/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Use existing AWS resources`,\n  description: `Configure the Amplify Libraries to use existing Amazon Pinpoint resources by referencing them in your configuration.`,\n};\n\nimport android0 from \"/src/fragments/lib/analytics/existing-resources.mdx\";\n\n<Fragments fragments={{android: android0}} />\n\nimport ios1 from \"/src/fragments/lib/analytics/existing-resources.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport flutter2 from \"/src/fragments/lib/analytics/existing-resources.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n",
    "meta": {
      "title": "Use existing AWS resources - Android",
      "description": "Configure the Amplify Libraries to use existing Amazon Pinpoint resources by referencing them in your configuration. - Android",
      "subcategory": "Analytics",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/analytics/existing-resources/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Escape hatch`,\n  description: `For advanced use cases where Amplify does not provide the functionality, you can retrieve the escape hatch to access the AWSPinpoint instance.`,\n};\n\nimport ios0 from \"/src/fragments/lib/analytics/ios/escapehatch.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/analytics/android/escapehatch.mdx\";\n\n<Fragments fragments={{android: android1}} />\n",
    "meta": {
      "title": "Escape hatch - iOS",
      "description": "For advanced use cases where Amplify does not provide the functionality, you can retrieve the escape hatch to access the AWSPinpoint instance. - iOS",
      "subcategory": "Analytics",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/analytics/escapehatch/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Escape hatch`,\n  description: `For advanced use cases where Amplify does not provide the functionality, you can retrieve the escape hatch to access the AWSPinpoint instance.`,\n};\n\nimport ios0 from \"/src/fragments/lib/analytics/ios/escapehatch.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/analytics/android/escapehatch.mdx\";\n\n<Fragments fragments={{android: android1}} />\n",
    "meta": {
      "title": "Escape hatch - Android",
      "description": "For advanced use cases where Amplify does not provide the functionality, you can retrieve the escape hatch to access the AWSPinpoint instance. - Android",
      "subcategory": "Analytics",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/analytics/escapehatch/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Personalized recommendations`,\n  description: `Amazon Personalize can create recommendations by using event data, historical data, or a combination of both. The event data can then be used to create recommendations.`,\n};\n\nimport js0 from \"/src/fragments/lib/analytics/js/personalize.mdx\";\n\n<Fragments fragments={{js: js0}} />",
    "meta": {
      "title": "Personalized recommendations - JavaScript",
      "description": "Amazon Personalize can create recommendations by using event data, historical data, or a combination of both. The event data can then be used to create recommendations. - JavaScript",
      "subcategory": "Analytics",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/analytics/personalize/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Storing analytics data`,\n  description: `The Amazon Kinesis Firehose analytics provider allows you to send analytics data to an Amazon Kinesis Firehose stream for reliably storing data.`,\n};\n\nimport js0 from \"/src/fragments/lib/analytics/js/storing.mdx\";\n\n<Fragments fragments={{js: js0}} />",
    "meta": {
      "title": "Storing analytics data - JavaScript",
      "description": "The Amazon Kinesis Firehose analytics provider allows you to send analytics data to an Amazon Kinesis Firehose stream for reliably storing data. - JavaScript",
      "subcategory": "Analytics",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/analytics/storing/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Streaming analytics data`,\n  description: `The Amazon Kinesis analytics provider allows you to send analytics data to an Amazon Kinesis stream for real-time processing.`,\n};\n\nimport js0 from \"/src/fragments/lib/analytics/js/streaming.mdx\";\n\n<Fragments fragments={{js: js0}} />",
    "meta": {
      "title": "Streaming analytics data - JavaScript",
      "description": "The Amazon Kinesis analytics provider allows you to send analytics data to an Amazon Kinesis stream for real-time processing. - JavaScript",
      "subcategory": "Analytics",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/analytics/streaming/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Identify user`,\n  description: `Use the Amplify analytics plugin to inform Pinpoint about your users.`,\n};\n\nimport ios0 from \"/src/fragments/lib/analytics/ios/identifyuser.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/analytics/android/identifyuser.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/analytics/flutter/identifyuser.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />",
    "meta": {
      "title": "Identify user - iOS",
      "description": "Use the Amplify analytics plugin to inform Pinpoint about your users. - iOS",
      "subcategory": "Analytics",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/analytics/identifyuser/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Identify user`,\n  description: `Use the Amplify analytics plugin to inform Pinpoint about your users.`,\n};\n\nimport ios0 from \"/src/fragments/lib/analytics/ios/identifyuser.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/analytics/android/identifyuser.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/analytics/flutter/identifyuser.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />",
    "meta": {
      "title": "Identify user - Flutter",
      "description": "Use the Amplify analytics plugin to inform Pinpoint about your users. - Flutter",
      "subcategory": "Analytics",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/analytics/identifyuser/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Identify user`,\n  description: `Use the Amplify analytics plugin to inform Pinpoint about your users.`,\n};\n\nimport ios0 from \"/src/fragments/lib/analytics/ios/identifyuser.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/analytics/android/identifyuser.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/analytics/flutter/identifyuser.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />",
    "meta": {
      "title": "Identify user - Android",
      "description": "Use the Amplify analytics plugin to inform Pinpoint about your users. - Android",
      "subcategory": "Analytics",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/analytics/identifyuser/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Automatically track sessions`,\n  description: `The Amplify analytics plugin records when an application opens and closes. This session information can be viewed either from your local computer’s terminal or the AWS Console for Pinpoint.`,\n};\n\nimport js0 from \"/src/fragments/lib/analytics/js/autotrack.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/analytics/autotrack.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/analytics/autotrack.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/analytics/autotrack.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Automatically track sessions - JavaScript",
      "description": "The Amplify analytics plugin records when an application opens and closes. This session information can be viewed either from your local computer’s terminal or the AWS Console for Pinpoint. - JavaScript",
      "subcategory": "Analytics",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/analytics/autotrack/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Automatically track sessions`,\n  description: `The Amplify analytics plugin records when an application opens and closes. This session information can be viewed either from your local computer’s terminal or the AWS Console for Pinpoint.`,\n};\n\nimport js0 from \"/src/fragments/lib/analytics/js/autotrack.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/analytics/autotrack.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/analytics/autotrack.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/analytics/autotrack.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Automatically track sessions - iOS",
      "description": "The Amplify analytics plugin records when an application opens and closes. This session information can be viewed either from your local computer’s terminal or the AWS Console for Pinpoint. - iOS",
      "subcategory": "Analytics",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/analytics/autotrack/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Automatically track sessions`,\n  description: `The Amplify analytics plugin records when an application opens and closes. This session information can be viewed either from your local computer’s terminal or the AWS Console for Pinpoint.`,\n};\n\nimport js0 from \"/src/fragments/lib/analytics/js/autotrack.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/analytics/autotrack.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/analytics/autotrack.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/analytics/autotrack.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Automatically track sessions - Flutter",
      "description": "The Amplify analytics plugin records when an application opens and closes. This session information can be viewed either from your local computer’s terminal or the AWS Console for Pinpoint. - Flutter",
      "subcategory": "Analytics",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/analytics/autotrack/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Automatically track sessions`,\n  description: `The Amplify analytics plugin records when an application opens and closes. This session information can be viewed either from your local computer’s terminal or the AWS Console for Pinpoint.`,\n};\n\nimport js0 from \"/src/fragments/lib/analytics/js/autotrack.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/analytics/autotrack.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/analytics/autotrack.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/analytics/autotrack.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Automatically track sessions - Android",
      "description": "The Amplify analytics plugin records when an application opens and closes. This session information can be viewed either from your local computer’s terminal or the AWS Console for Pinpoint. - Android",
      "subcategory": "Analytics",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/analytics/autotrack/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Record events`,\n  description: `Learn how to record analytics events using Amplify.`,\n};\n\nimport js0 from \"/src/fragments/lib/analytics/js/record.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/analytics/ios/record.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/analytics/android/record.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/analytics/flutter/record.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Record events - JavaScript",
      "description": "Learn how to record analytics events using Amplify. - JavaScript",
      "subcategory": "Analytics",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/analytics/record/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Record events`,\n  description: `Learn how to record analytics events using Amplify.`,\n};\n\nimport js0 from \"/src/fragments/lib/analytics/js/record.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/analytics/ios/record.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/analytics/android/record.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/analytics/flutter/record.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Record events - iOS",
      "description": "Learn how to record analytics events using Amplify. - iOS",
      "subcategory": "Analytics",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/analytics/record/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Record events`,\n  description: `Learn how to record analytics events using Amplify.`,\n};\n\nimport js0 from \"/src/fragments/lib/analytics/js/record.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/analytics/ios/record.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/analytics/android/record.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/analytics/flutter/record.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Record events - Flutter",
      "description": "Learn how to record analytics events using Amplify. - Flutter",
      "subcategory": "Analytics",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/analytics/record/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Record events`,\n  description: `Learn how to record analytics events using Amplify.`,\n};\n\nimport js0 from \"/src/fragments/lib/analytics/js/record.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/analytics/ios/record.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/analytics/android/record.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/analytics/flutter/record.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />",
    "meta": {
      "title": "Record events - Android",
      "description": "Learn how to record analytics events using Amplify. - Android",
      "subcategory": "Analytics",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/analytics/record/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `The Analytics category enables you to collect analytics data for your app. The Analytics category comes with built-in support for Amazon Pinpoint and Amazon Kinesis (Kinesis support is currently only available in the Amplify JavaScript library). The Analytics category uses Amazon Cognito Identity pools to identify users in your App. Cognito allows you to receive data from authenticated, and unauthenticated users in your App.`,\n};\n\nimport js0 from \"/src/fragments/lib/analytics/js/getting-started.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/analytics/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/analytics/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/analytics/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Getting started - JavaScript",
      "description": "The Analytics category enables you to collect analytics data for your app. The Analytics category comes with built-in support for Amazon Pinpoint and Amazon Kinesis (Kinesis support is currently only available in the Amplify JavaScript library). The Analytics category uses Amazon Cognito Identity pools to identify users in your App. Cognito allows you to receive data from authenticated, and unauthenticated users in your App. - JavaScript",
      "subcategory": "Analytics",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/analytics/getting-started/q/platform/js"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `The Analytics category enables you to collect analytics data for your app. The Analytics category comes with built-in support for Amazon Pinpoint and Amazon Kinesis (Kinesis support is currently only available in the Amplify JavaScript library). The Analytics category uses Amazon Cognito Identity pools to identify users in your App. Cognito allows you to receive data from authenticated, and unauthenticated users in your App.`,\n};\n\nimport js0 from \"/src/fragments/lib/analytics/js/getting-started.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/analytics/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/analytics/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/analytics/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Getting started - iOS",
      "description": "The Analytics category enables you to collect analytics data for your app. The Analytics category comes with built-in support for Amazon Pinpoint and Amazon Kinesis (Kinesis support is currently only available in the Amplify JavaScript library). The Analytics category uses Amazon Cognito Identity pools to identify users in your App. Cognito allows you to receive data from authenticated, and unauthenticated users in your App. - iOS",
      "subcategory": "Analytics",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/analytics/getting-started/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `The Analytics category enables you to collect analytics data for your app. The Analytics category comes with built-in support for Amazon Pinpoint and Amazon Kinesis (Kinesis support is currently only available in the Amplify JavaScript library). The Analytics category uses Amazon Cognito Identity pools to identify users in your App. Cognito allows you to receive data from authenticated, and unauthenticated users in your App.`,\n};\n\nimport js0 from \"/src/fragments/lib/analytics/js/getting-started.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/analytics/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/analytics/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/analytics/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Getting started - Flutter",
      "description": "The Analytics category enables you to collect analytics data for your app. The Analytics category comes with built-in support for Amazon Pinpoint and Amazon Kinesis (Kinesis support is currently only available in the Amplify JavaScript library). The Analytics category uses Amazon Cognito Identity pools to identify users in your App. Cognito allows you to receive data from authenticated, and unauthenticated users in your App. - Flutter",
      "subcategory": "Analytics",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/analytics/getting-started/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `The Analytics category enables you to collect analytics data for your app. The Analytics category comes with built-in support for Amazon Pinpoint and Amazon Kinesis (Kinesis support is currently only available in the Amplify JavaScript library). The Analytics category uses Amazon Cognito Identity pools to identify users in your App. Cognito allows you to receive data from authenticated, and unauthenticated users in your App.`,\n};\n\nimport js0 from \"/src/fragments/lib/analytics/js/getting-started.mdx\";\n\n<Fragments fragments={{js: js0}} />\n\nimport ios1 from \"/src/fragments/lib/analytics/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{ios: ios1}} />\n\nimport android2 from \"/src/fragments/lib/analytics/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{android: android2}} />\n\nimport flutter3 from \"/src/fragments/lib/analytics/native_common/getting-started/common.mdx\";\n\n<Fragments fragments={{flutter: flutter3}} />\n",
    "meta": {
      "title": "Getting started - Android",
      "description": "The Analytics category enables you to collect analytics data for your app. The Analytics category comes with built-in support for Amazon Pinpoint and Amazon Kinesis (Kinesis support is currently only available in the Amplify JavaScript library). The Analytics category uses Amazon Cognito Identity pools to identify users in your App. Cognito allows you to receive data from authenticated, and unauthenticated users in your App. - Android",
      "subcategory": "Analytics",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/analytics/getting-started/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Use existing AWS resources`,\n  description: `Add existing AWS resources to an application without the CLI.`,\n};\n\nimport ios0 from \"/src/fragments/lib/project-setup/ios/use-existing-resources/use-existing-resources.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/project-setup/android/use-existing-resources/use-existing-resources.mdx\";\n\n<Fragments fragments={{android: android1}} />\n",
    "meta": {
      "title": "Use existing AWS resources - iOS",
      "description": "Add existing AWS resources to an application without the CLI. - iOS",
      "subcategory": "Project Setup",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/project-setup/use-existing-resources/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Use existing AWS resources`,\n  description: `Add existing AWS resources to an application without the CLI.`,\n};\n\nimport ios0 from \"/src/fragments/lib/project-setup/ios/use-existing-resources/use-existing-resources.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/project-setup/android/use-existing-resources/use-existing-resources.mdx\";\n\n<Fragments fragments={{android: android1}} />\n",
    "meta": {
      "title": "Use existing AWS resources - Android",
      "description": "Add existing AWS resources to an application without the CLI. - Android",
      "subcategory": "Project Setup",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/project-setup/use-existing-resources/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Using RxJava with Amplify`,\n  description: `Amplify Android has first-class support for Reactive Extensions / RxJava.`,\n};\n\nimport android0 from \"/src/fragments/lib/project-setup/android/rxjava/rxjava.mdx\";\n\n<Fragments fragments={{android: android0}} />\n",
    "meta": {
      "title": "Using RxJava with Amplify - Android",
      "description": "Amplify Android has first-class support for Reactive Extensions / RxJava. - Android",
      "subcategory": "Project Setup",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/project-setup/rxjava/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Kotlin Coroutines Support`,\n  description: `Amplify Android includes first-class support for Kotlin Coroutines and Flows.`,\n};\n\nimport android0 from \"/src/fragments/lib/project-setup/android/coroutines/coroutines.mdx\";\n\n<Fragments fragments={{android: android0}} />\n",
    "meta": {
      "title": "Kotlin Coroutines Support - Android",
      "description": "Amplify Android includes first-class support for Kotlin Coroutines and Flows. - Android",
      "subcategory": "Project Setup",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/project-setup/coroutines/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Async Programming Model`,\n  description: `Amplify Android uses an asynchronous programming model`,\n};\n\nimport android0 from \"/src/fragments/lib/project-setup/android/async/async.mdx\";\n\n<Fragments fragments={{android: android0}} />\n",
    "meta": {
      "title": "Async Programming Model - Android",
      "description": "Amplify Android uses an asynchronous programming model - Android",
      "subcategory": "Project Setup",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/project-setup/async/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Using Combine with Amplify`,\n  description: `Amplify's support for Apple's Combine framework`,\n};\n\nimport ios0 from \"/src/fragments/lib/project-setup/ios/combine/combine.mdx\";\n\n<Fragments fragments={{ios: ios0}} />",
    "meta": {
      "title": "Using Combine with Amplify - iOS",
      "description": "Amplify's support for Apple's Combine framework - iOS",
      "subcategory": "Project Setup",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/project-setup/combine/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Escape hatch`,\n  description: `Advanced use cases in Amplify Flutter`,\n};\n\nimport flutter from \"/src/fragments/lib/project-setup/flutter/escape-hatch/escape-hatch.mdx\";\n\n<Fragments fragments={{flutter: flutter}} />\n\n",
    "meta": {
      "title": "Escape hatch - Flutter",
      "description": "Advanced use cases in Amplify Flutter - Flutter",
      "subcategory": "Project Setup",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/project-setup/escape-hatch/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Platform Setup`,\n  description: `Instructions for platform-specific configurations needed for amplify-flutter`,\n};\n\nimport flutter0 from \"/src/fragments/lib/project-setup/flutter/platform-setup/platform-setup.mdx\";\n\n<Fragments fragments={{flutter: flutter0}} />\n",
    "meta": {
      "title": "Platform Setup - Flutter",
      "description": "Instructions for platform-specific configurations needed for amplify-flutter - Flutter",
      "subcategory": "Project Setup",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/project-setup/platform-setup/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Null safety`,\n  description: `Using Dart null safety with amplify-flutter`,\n};\n\nimport flutter0 from \"/src/fragments/lib/project-setup/flutter/null-safety/null-safety.mdx\";\n\n<Fragments fragments={{flutter: flutter0}} />\n\n",
    "meta": {
      "title": "Null safety - Flutter",
      "description": "Using Dart null safety with amplify-flutter - Flutter",
      "subcategory": "Project Setup",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/project-setup/null-safety/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Create your application`,\n  description: `Project setup for Amplify prior to adding category specific example.`,\n};\n\nimport ios0 from \"/src/fragments/lib/project-setup/native_common/create-application/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/project-setup/native_common/create-application/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/project-setup/native_common/create-application/common.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />",
    "meta": {
      "title": "Create your application - Flutter",
      "description": "Project setup for Amplify prior to adding category specific example. - Flutter",
      "subcategory": "Project Setup",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/project-setup/create-application/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Create your application`,\n  description: `Project setup for Amplify prior to adding category specific example.`,\n};\n\nimport ios0 from \"/src/fragments/lib/project-setup/native_common/create-application/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/project-setup/native_common/create-application/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/project-setup/native_common/create-application/common.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />",
    "meta": {
      "title": "Create your application - iOS",
      "description": "Project setup for Amplify prior to adding category specific example. - iOS",
      "subcategory": "Project Setup",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/project-setup/create-application/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Create your application`,\n  description: `Project setup for Amplify prior to adding category specific example.`,\n};\n\nimport ios0 from \"/src/fragments/lib/project-setup/native_common/create-application/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/project-setup/native_common/create-application/common.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/project-setup/native_common/create-application/common.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />",
    "meta": {
      "title": "Create your application - Android",
      "description": "Project setup for Amplify prior to adding category specific example. - Android",
      "subcategory": "Project Setup",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/project-setup/create-application/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Prerequisites`,\n  description: `Project Setup with Amplify Framework - Prerequisites`,\n};\n\nimport ios0 from \"/src/fragments/lib/project-setup/native_common/prereq/common_header.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/project-setup/native_common/prereq/common_header.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/project-setup/native_common/prereq/common_header.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport ios3 from \"/src/fragments/lib/project-setup/ios/prereq/prereq.mdx\";\n\n<Fragments fragments={{ios: ios3}} />\n\nimport android4 from \"/src/fragments/lib/project-setup/android/prereq/prereq.mdx\";\n\n<Fragments fragments={{android: android4}} />\n\nimport flutter5 from \"/src/fragments/lib/project-setup/flutter/prereq/prereq.mdx\";\n\n<Fragments fragments={{flutter: flutter5}} />\n\nimport ios6 from \"/src/fragments/lib/project-setup/native_common/prereq/common_body.mdx\";\n\n<Fragments fragments={{ios: ios6}} />\n\nimport android7 from \"/src/fragments/lib/project-setup/native_common/prereq/common_body.mdx\";\n\n<Fragments fragments={{android: android7}} />\n\nimport flutter8 from \"/src/fragments/lib/project-setup/native_common/prereq/common_body.mdx\";\n\n<Fragments fragments={{flutter: flutter8}} />\n",
    "meta": {
      "title": "Prerequisites - Flutter",
      "description": "Project Setup with Amplify Framework - Prerequisites - Flutter",
      "subcategory": "Project Setup",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/project-setup/prereq/q/platform/flutter"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Prerequisites`,\n  description: `Project Setup with Amplify Framework - Prerequisites`,\n};\n\nimport ios0 from \"/src/fragments/lib/project-setup/native_common/prereq/common_header.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/project-setup/native_common/prereq/common_header.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/project-setup/native_common/prereq/common_header.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport ios3 from \"/src/fragments/lib/project-setup/ios/prereq/prereq.mdx\";\n\n<Fragments fragments={{ios: ios3}} />\n\nimport android4 from \"/src/fragments/lib/project-setup/android/prereq/prereq.mdx\";\n\n<Fragments fragments={{android: android4}} />\n\nimport flutter5 from \"/src/fragments/lib/project-setup/flutter/prereq/prereq.mdx\";\n\n<Fragments fragments={{flutter: flutter5}} />\n\nimport ios6 from \"/src/fragments/lib/project-setup/native_common/prereq/common_body.mdx\";\n\n<Fragments fragments={{ios: ios6}} />\n\nimport android7 from \"/src/fragments/lib/project-setup/native_common/prereq/common_body.mdx\";\n\n<Fragments fragments={{android: android7}} />\n\nimport flutter8 from \"/src/fragments/lib/project-setup/native_common/prereq/common_body.mdx\";\n\n<Fragments fragments={{flutter: flutter8}} />\n",
    "meta": {
      "title": "Prerequisites - iOS",
      "description": "Project Setup with Amplify Framework - Prerequisites - iOS",
      "subcategory": "Project Setup",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/project-setup/prereq/q/platform/ios"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Prerequisites`,\n  description: `Project Setup with Amplify Framework - Prerequisites`,\n};\n\nimport ios0 from \"/src/fragments/lib/project-setup/native_common/prereq/common_header.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android1 from \"/src/fragments/lib/project-setup/native_common/prereq/common_header.mdx\";\n\n<Fragments fragments={{android: android1}} />\n\nimport flutter2 from \"/src/fragments/lib/project-setup/native_common/prereq/common_header.mdx\";\n\n<Fragments fragments={{flutter: flutter2}} />\n\nimport ios3 from \"/src/fragments/lib/project-setup/ios/prereq/prereq.mdx\";\n\n<Fragments fragments={{ios: ios3}} />\n\nimport android4 from \"/src/fragments/lib/project-setup/android/prereq/prereq.mdx\";\n\n<Fragments fragments={{android: android4}} />\n\nimport flutter5 from \"/src/fragments/lib/project-setup/flutter/prereq/prereq.mdx\";\n\n<Fragments fragments={{flutter: flutter5}} />\n\nimport ios6 from \"/src/fragments/lib/project-setup/native_common/prereq/common_body.mdx\";\n\n<Fragments fragments={{ios: ios6}} />\n\nimport android7 from \"/src/fragments/lib/project-setup/native_common/prereq/common_body.mdx\";\n\n<Fragments fragments={{android: android7}} />\n\nimport flutter8 from \"/src/fragments/lib/project-setup/native_common/prereq/common_body.mdx\";\n\n<Fragments fragments={{flutter: flutter8}} />\n",
    "meta": {
      "title": "Prerequisites - Android",
      "description": "Project Setup with Amplify Framework - Prerequisites - Android",
      "subcategory": "Project Setup",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/project-setup/prereq/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `Learn how to setup and configure your application with Amplify (Developer Preview).`,\n};\n\nimport ios0 from \"/src/fragments/lib/devpreview/native_common/getting_started/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android0 from \"/src/fragments/lib/devpreview/native_common/getting_started/common.mdx\";\n\n<Fragments fragments={{android: android0}} />\n",
    "meta": {
      "title": "Getting started - Android",
      "description": "Learn how to setup and configure your application with Amplify (Developer Preview). - Android",
      "subcategory": "New! Amplify Mobile (Developer Preview)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/devpreview/getting-started/q/platform/android"
  },
  {
    "searchableText": [],
    "source": "export const meta = {\n  title: `Getting started`,\n  description: `Learn how to setup and configure your application with Amplify (Developer Preview).`,\n};\n\nimport ios0 from \"/src/fragments/lib/devpreview/native_common/getting_started/common.mdx\";\n\n<Fragments fragments={{ios: ios0}} />\n\nimport android0 from \"/src/fragments/lib/devpreview/native_common/getting_started/common.mdx\";\n\n<Fragments fragments={{android: android0}} />\n",
    "meta": {
      "title": "Getting started - iOS",
      "description": "Learn how to setup and configure your application with Amplify (Developer Preview). - iOS",
      "subcategory": "New! Amplify Mobile (Developer Preview)",
      "category": "Amplify Libraries"
    },
    "filename": "/lib/devpreview/getting-started/q/platform/ios"
  }
]